hello everyone welcome to this video
tutorial on gpd3
gpt3 has been trending since its beta
release in july of 2020
it's believed to be one of the most
significant models in the field of
artificial intelligence
in this video you will learn what is
gpt3
we will discuss gpt3 specifications
then we will look at it language models
and the parameters used to build those
models
we will go over data sets used for gpd3
and gpt3 accuracy and finally the
applications of gpt3
some of our content has been taken from
multiple videos that people have posted
on twitter
and we have given due credit to them
you can check out the links to see the
source of these videos
let's begin by looking at what is gpt3
gpt3 stands for generative pre-trained
transformer
it is a powerful third generation
language model developed by open ai
which is an artificial intelligence
company based out of san francisco
california gpt3 beta testing began in
july of 2020 it can easily understand
your problems and generate human-like
texts in a matter of seconds
gpt3 is the latest example of a long
line of pre-trained models like google's
bert facebook's roberta and microsoft's
touring nlg
pre-trained models are large networks
trained on massive data sets usually
without supervision
soon after its release the internet was
flooded with text examples generated by
gpt-3 openai has been working on
building language models for quite some
time now and every breakthrough makes
the news gpt3 seems to be a turning
point in the field of ai
let's get started by looking at the
different specifications of gpt3
gpt3 has been created using 175 billion
parameters none of the previous language
models have used such large number of
parameters it's been trained with 45
terabytes of text data which includes
sources from wikipedia google books and
coding tutorials
sixty percent of the data for
pre-training the gpt-3 model was taken
from common crawl common crawl is an
organization that crawls the web and
freely provides its archives and data
sets to the public
common crawls web archives consists of
petabytes of data collected since 2011
amazon web service began hosting common
crawls archives through its public data
sets program in 2012. using all this
data gpt-3 taught itself the statistical
dependencies between different words
which were encoded as parameters in its
neural network
gpt3 has 96 decoder layers and is built
on a system of 285 000 cpu cores 10 000
graphical processing units and 400 gbps
network connectivity for each gpu server
gpt-3 was trained on a supercomputer
that was developed by microsoft and
openai collectively this chart reflects
the different language models and number
of parameters in billions that were used
to create the model using pre-trained
models and fine-tuning them to solve
specific tasks has become a popular
trend in the field of natural language
processing looking at the graph you can
see that google's burt model uses 110
million parameters
however the large model uses 340 million
parameters
the previous gpt model that is gpt2 had
1.5 billion parameters then the t5 model
has 11 billion parameters next touring
nlg which is microsoft's language model
had 17 billion parameters
but gpt3 stands out among all the models
with 175 billion parameters
next let's talk about the data sets that
were used to train the gpt3 model
a total of five data sets were used in
gpd3 which is common crawl web text 2
books 1 books 2 and wikipedia
the next column shows the number of
tokens that were used in billions
gpt3 models using 175 billion parameters
are trained with 499 billion tokens in
total out of which common crawl with 410
billion tokens has 60 of the training
data web text with 19 billion tokens
contributes 22 percent of the training
data and then you can see the breakdown
for books 1 books 2 and wikipedia
so we have the respective tokens the
weight in training matrix and epoxy
lapsed when training for 300 billion
tokens
moving ahead the graph that you see on
your screen shows the benefit and
accuracy for various zero one and few
shot tasks as a function of the number
of model parameters
the graph depicts that the accuracy of
the model increases with the number of
parameters there is no need to do
gradient update or fine tuning for using
the gpt3 model
you could just interact with the model
using normal language or provide some
examples of the task that you are trying
to complete and the model will perform
on its own
larger models make increasingly
efficient use of in-text information in
xero shot the model predicts the answer
given only a natural language
description of the task no gradient
updates are performed here in one shot
the model sees a single example of the
task along with the task description in
few shot along with the task description
the model sees a few examples of the
task
before we move on make sure to subscribe
to our channel and hit the bell icon to
never miss an update from simply learn
so this is probably the most important
part of the gpt3 tutorial that is its
applications
since its release users who got access
to gpt3 have displayed a wide range of
utilities of the gpt3 language model
let's explore a few of them
first you can create a fully functional
search engine using gpt3
you can search for anything randomly and
it will return an exact solution along
with the url which is pretty exciting
here you can see the user is randomly
searching for some information
for example who killed mahatma gandhi
and you can see gpt 3 returns the result
along with the url
you could search for how many atoms
there are in benzene
and see the results six carbon atoms in
benzene
or perhaps how many atoms there are in
benzene
the result being six carbon atoms and
six hydrogen atoms
another application of gpt 3 is that it
can build a machine learning model by
generating the code automatically so the
user is given the description of the
data set a desired output it's looking
for in plain english he wants to build a
model to classify images into five
groups the data set has twenty five
thousand images with an input shape of
five hundred by five hundred you can see
the gpt3 understands the user input and
creates a convolutional neural network
model using the keras library and has
all the pooling layers the relu layer
and the activation functions as well
the next application of gpt3 we will
discuss is creating resumes so gpt3
allows you to create resumes by looking
at a few lines of text related to your
work experience your educational
background the projects you have worked
on your hobbies and other details
so you can see here the user inputs
personal information about himself such
as his designation as a software
engineer and the company he used to or
is currently working for he has worked
on react js since september 2018 in los
angeles you can see on the left the
resume will update automatically later
if the user updates his resume and makes
changes to it those changes will
automatically be reflected in his resume
so let's see what happens as the user
updates his resume here we see he
changed to august 2018
and is now in san francisco california
and we see that information added to the
resume
next the gpt3 model can help you write
sql queries given a line of text and a
table in place
we can see here the user wants to find
out how many users have
signed
up
since the start of 2020
and now if you search for this result
gpt 3 will automatically give you an sql
query and we can see it here
select account id from users where
created at january 1 2020.
if you want to find the average number
of influencers each user id
is subscribed to
if you search for that
again gpt3 will automatically create an
sql query for you as you can see here
up next we have an example of where gpt3
can be used as a function in excel or
google spreadsheets
here we have a few state names and the
population so for example if you want to
find the population of michigan
you can select that table and give
michigan as a parameter
gpt3 will automatically search for the
population in michigan and it will
return the result in a few seconds
you can see it's loading
and we see 10.31 million
let's say you want to check for the
total population of alaska you can find
it easily using gpt3
we see it's loading now
and you see the population is 603 000.
so let's say we wanted to find out the
date these states were founded
we could add a few dates here
and it will return the date for alaska
you can see alaska was founded in 1906.
you can also perform some numerical or
mathematical operations using gpt3
so here we are finding out the sum of
two numbers given a table
so we are calculating the sum of 14 plus
40. so it should return a sum of 54
and we can see that here
we could find the twitter username of a
person given a set of examples
you can see here we have the person's
name and the employer
and if you're looking for the employer
of a certain person it will return the
results
now if we change this to twitter
username and search the twitter username
for a new person it should give us the
result
the final application we have is
building interactive web and mobile
applications
using the gpt3 model and the available
plugins you can give the description of
an application and its look and feel
then gpt3 will automatically create an
application for you
you can see here the user is typing a
website like stripe.com that is about a
chat app and if you click on design gpt3
will automatically create an app for you
and we see it here it says text video
and photos then if you want you can go
ahead and customize this app as well
moving ahead let's see if gpg3 is just a
hype according to a report the training
process would have required 350
gigabytes of memory and cost nearly 12.6
million dollars there is no doubt that
gpt-3 is worthy it's been trained with
almost the entire internet there are
downsides and room for improvement
though the authors of the paper have
acknowledged the same as well here's
what sam altman the ceo of open ai has
to say about gpt3 he says the gpt3 hype
is way too much it's impressive thanks
for the nice compliment but it still has
serious weaknesses and sometimes makes
very silly mistakes ai is going to
change the world but gpt3 is just a very
early glimpse we have a lot still to
figure out now if you want to get access
to gpd3 please visit the open ai website
and fill out the form to join the
waiting list with that we have reached
the end of this video we hope you've
enjoyed it and if you have any questions
please add those to the comments section
of the video again don't forget to
subscribe to our channel stay safe and
keep learning
hi there if you like this video
subscribe to the simply learn youtube
channel and click here to watch similar
videos to nerd up and get certified
click here