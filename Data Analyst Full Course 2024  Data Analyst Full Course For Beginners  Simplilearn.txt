welcome to your data analytics full
course by simply La if you're ready to
dive into the world of data and learn
how to turn raw information into
actionable insights you have come to the
right place the demand for data
analytics is skyrocketing these days in
today's data driven World businesses are
constantly looking for professionals who
can help them make sense of vast amount
of data they collect from tech companies
to healthcare to retail and finance
every industry is looking out for
skilled data analyst to guide their
decisions and strategies in 2024 data
analytics have become one of the most
sought after skills companies understand
that those who can analyze and interpret
data effectively hold the key to
improving processes understanding
customers and staying ahead of the
competition as a result job
opportunities are booming and salaries
in this field are reaching a new heights
data analysts are not just in demand
they are also highly valued and well
compensated this course will equip you
with everything you need to app into
this exciting career path prepare you
for a successful future in the world of
data analytics craving a career upgrade
subscribe like and comment
below dive into the link in the
description to FasTrack your Ambitions
whether you're making a switch or aiming
higher simply learn has your
back before we move on just a quick info
guys if you are interested in a
professional certificate course in data
analytics then you can begin your
Learning Journey with simply learn and
it coners data analytics certificate
course you can explore our Learning
Management Systems track your progress
and meet completion requirements join
the professional certificate course in
data analytics recognize as a top PG
data program by eim so guys hurry up now
and join the course the course link is
mentioned in the description box we all
use smartphones but have you ever
wondered how much data it generates in
the form of texts phone calls emails
photos video
searches and music approximately 40
exabytes of data gets generated every
month by a single smartphone user now
imagine this number multiplied by 5
billion smartphone users that's a lot
for our mind to even process isn't it in
fact this amount of data is quite a lot
for traditional Computing systems to
handle and this massive amount of data
is what we term as Big Data let's have a
look at the data generated per minute on
the internet 2.1 million Snaps are
shared on Snapchat 3.8 million search
queries are made on Google 1 million
people log on to Facebook 4.5 million
videos are watched on YouTube 188
million emails are sent that's a lot of
data so how do you classify any data as
Big Data this is possible with the
concept of 5 vs volume velocity variety
veracity and value
let us understand this with an example
from the healthcare industry Hospitals
and Clinics across the world generate
massive volumes of data
2,314 exabytes of data are collected
annually in the form of patient records
and test results all this data is
generated at a very high speed which
attributes to the velocity of Big Data
variety refers to the various data types
such as structured semi-structured and
unstructured data example tools include
Excel records log files and x-ray
images accuracy and trustworthiness of
the generated data is termed as veracity
analyzing all this data will benefit the
medical sector by enabling faster
disease detection better treatment and
reduced cost this is known as the value
of big data but how do we store and
process this big data to do this job we
have various framework such as Cassandra
Hadoop and Spark let us take Hadoop as
an example and see how Hadoop stores and
processes Big Data Hadoop uses a
distributed file system known as Hadoop
distributed file system to store Big
Data if you have a huge file your file
will be broken down into smaller chunks
and stored in various machines not only
that when you break the file you also
make copies of it which goes into
different nodes this way you store your
big data in a distributed way and and
make sure that even if one machine fails
your data is safe on
another map reduce technique is used to
process Big Data a lengthy task a is
broken into smaller tasks b c and d now
instead of one machine three machines
take up each task and complete it in a
parallel fashion and assemble the
results at the end thanks to this the
processing becomes easy and fast this is
known as parallel process
processing now that we have stored and
processed our big data we can analyze
this data for numerous applications in
games like Halo 3 and Call of Duty
designers analyze user data to
understand at which stage most of the
users pause restart or quit playing this
Insight can help them rework on the
storyline of the game and improve the
user experience which in turn reduces
the customer churn rate similarly Big
Data also helped with disaster
management during Hurricane Sandy in
2012 it was used to gain a better
understanding of the storm's effect on
the east coast of the US and necessary
measures were taken it could predict the
Hurricane's landfall 5 days in advance
which wasn't possible earlier these are
some of the clear indications of how
valuable big data can be once it is
accurately processed and
analyzed companies around the world are
generating V volumes of data every hour
this data could be be in the form of log
files web server and transactional data
as well as various customer related data
also data is being generated at a rapid
rate from social media websites and
applications such as Facebook Instagram
Twitter and
WhatsApp companies want to use this data
to derive value out of it and make
business
decisions that's where data analytics
comes into
use data analytics is the process of
exploring and analyzing data sets to
find hidden patterns unseen Trends
discover correlations and valuable
insights to make business
predictions data analytics improves the
speed and efficiency of your
business a few years ago a business
would have gathered information manually
perform statistical and complex
analytics and Unearthed information that
could be used for future
decisions but today that business can
identify insights on the Fly for
immediate decisions
most organizations have big data and
many understand the need to harness that
data and extract value out of it so they
use a lot of modern tools and
Technologies to perform data analytics
some of the tools I will discuss in
detail later in this tutorial now that
we have looked at at what data analytics
really is so now you will be wondering
what does a data analysis do so what
does data analyst do on huge data set
data analyst gather analyze and run stat
iCal studies to glean insights and spot
RS they use various methods and tools to
transform complicated data into useful
insights they therefore provide
insightful data that enables businesses
to make informed decision and this is
the answer of question what data analyst
do so moving forward let's jump into
roles and responsibilities of a data
analysis the roles and responsibilities
of a data analyst often consist of the
following the first one is create and
manage databases and data system fixing
coding mistakes and other data related
problem as necessary the second one is
using both primary and secondary sources
for data mining the third one is
rearranging data in a way that both
individuals and machine can understand
the fourth one is create documentation
that clarifies the data analyst process
for stakeholder so now let's jump into
how to become a data analyst with no
experience steps and strategies so
becoming a data analyst without prer
experience can be challenging but
achieveable goal so here is a detail
guide on how to break into the field of
data analysis from a sketch so the first
one is master the basics data analysis
need a mix of Technical and softare
skills start by learning the basics of
Statics and Mathematics so key topics
are descriptive statistic learn measures
of central tendency mean Medan mode
measures of variability range variance
and standard deviation and data
distribution like normal distribution
and exess and CIS the second is
inferential stat understanding
hypothesis testing confidence intervals
P values and statical significance the
third one is probability Theory basic
probability concept conditional
probability and Bas theorems and manim
the fourth point is linear algebra and
calculus fundamental concept that
underpin many statical algorithm so you
guys can learn these topics from our
simply YouTube channel where each topic
is explained in depth by our experts the
second point is programming languages
and python in Python learn the basic
syntax data types and control structures
like loops and condition the second one
is libraries for data analysis like nump
pandas and metp lip for data
manipulation and visualization the third
one is library for statical analysis
like CPI and St models for performing
statical test and modeling and in our
like basic syntax like data types and
structures data manipulation like DPL yr
t y the third point is statical analysis
basar function and package like ggplot 2
or data visualization so you guys can
learn these topics from our snance
YouTube channel where each topic is
explained in depth by our expert the
third point is data visualization and
Reporting so in this we have first T
creating and customizing various charts
and types like bar charts line graphs
Scatter Plots the second is building
interactive dashboards and stories the
third one is connecting two different
data sources and data blending the
second one we have powerbi data modeling
and creating relationship between data
sets the second point is designing
reports with visuals filters and slicers
the third point is using Dex data
analysis expressions for advanced
calculation in this category third we
have Excel so in this you can learn
advaned formulas like V lookup hookup
index match and AR formulas the second
is p tables summarizing analyzing and
visualizing data the third is data
visualization creating and formatting
charts spark lines and conditional
formatting so you guys can learn these
topics from our simpl YouTube channel
where the each topic explained Anda by
our expert or you can go through their
official document websites in master the
basics the last point is SQL database
and the key concept the key concept are
basic SQL commands select from where
join group by having or order by second
is database design understanding tables
relationships and normalization the
third is Advanced SQL subqueries window
function and Common Table expression CTS
the fourth one is database management
connecting to a database writing
optimized queries and understanding
indexes so you guys can learn these
topics from our simpl YouTube channel
where we have SQL playlist covering each
topic that is explained in depth by our
expert the second point is work on your
personal project applying your new
skills to real world problems is a great
way to gain experience so here are some
projects idea to help you get started
the first one is personal project public
data analysis choose a public data set
that interests you and perform a
comprehensive analysis for example
analyzing covid-19 Trends over time
predicting house prices or studying
climate change impacts the second is
kaggle competition kagle is a fantastic
platform where you can participate in
desence competition these competition
provide real world data and problems to
solve for example predicting customer
churn classifying image or creating
models to improve sales forecasting the
third one is build a dashboard create an
interactive dashboard using tools like
Tableau or power to visualize data
insight for example a dashboard tracking
Global Financial Market or visualizing
crime rates in different cities the
third point is get certified while
certification won't replace Real World
Experience they can be valuable
additional to your resume so there are
numerous data analy certification
available online such as the Google data
analytics certificate the data analy
program by simply this data analy course
by simply learn in collaboration with
IBM will transform you into a data
analytic expert in this course you will
learn the latest analytics tools and
techniques how to work with SQL the
languages of R and python the art of
creating data visualization and how to
apply stat and Predictive Analytics in
the business environment these
certification not only provide you with
the solid foundation but also show
potential employers your commitment to
learning and growing in the field the
fourth point is build a portfolio one of
the best way to Showcase your skills to
potential employer is by building a
portfolio this can include personal
projects data analysis on real world
data set or even kle competition the key
here is to demonstrate your ability to
apply what you have have learned to real
world problem don't worry if you don't
have access to fancy data set or tools
there are plenty of publicly available
data set on sites like kle or even
government website you guys can make
portfolio like this so this is an
example of one portfolio so you can
distribute your projects like this or
you can take help from this okay the
next point is networking and mentorship
connect with professional in the field
through Linkedin local meetups or
professional association look for Mentor
who can provide guidance feedback on
your projects and potentially help you
with the job referals networking can be
invaluable in learning about
unadvertised job openings or internship
the next point is internship apply for
anti- level position or internship look
for job titles like Junior data analyst
data technicians or analytics assistant
look for opportunities in local
community reach out to startups or
nonprofits or even consider offering
your services for free initially even
customer service or administrator roles
that involves data entry or reporting
can serve as stepping stones giving you
practical experience with data the
seventh point is prepare for interviews
be ready to discuss your projects how
you approach problems and what you have
learned you should also be prepared for
technical interview that may test your
knowledge of stat programming and data
analysis technique you can refer to
Simply video on data analyst interview
question and answer on YouTube so to sum
it up master the basics build a
portfolio get certified get experience
through internship and freelancing
network like crazy and never stop
learning and most importantly believe in
yourself and your abilities now let's
discuss the various steps involved in
the data analytics process as you can
see on the screen there are five process
steps now let me make you understand
each of this one by
one so the first step is to understand
the problem
before starting with the analysis you
need to understand the business problem
and Define your goals asking questions
at the outlet is vital because this
would address issues such as how can we
reduce production costs without
sacrificing quality what are some of the
ways to increase sales opportunities
with our current
resources do customers view your brand
in a favorable way answers to these
questions will help you build a clear
road map with lucrative Solutions also
try to find out the key per performance
indicators and consider the matrics to
track along the
way the second step in the process is
data
collection after you have finalized your
goals it's time to start looking for
your data data collection is the process
of gathering information on targeted
variables identified as data
requirements the emphasis is on ensuring
accurate and right data is collected
data collection starts with primary
sources which are also known as internal
sour ources this is typically structured
data gathered from CRM software Erp
systems marketing automation tools and
others these sources contain information
about customers finances gaps in sales
Etc under external sources you have both
structured and unstructured data so if
you're looking to perform a sentiment
analysis towards your brand you would
gather data from various review websites
or social media
apps the next step is to clean the
data the data which is collected from
various sources is highly likely to
contain in complete duplicate and
missing values so you need to clean
these unwanted redundant data to make it
ready for analysis so to generate
accurate results analytics professionals
must identify duplicate and anomalous
data and other inconsistencies that
could skew the analysis according to a
report 60% of data scientists say most
of the time is spent cleaning the data
while 57% of data scientists say it's
their least enjoyable
task now the fourth step in the process
is data exploration and
Analysis once data is cleaned and ready
you can go ahead and explore the data
using data visualization and business
intelligence tools you can also use
various Data Mining and predictive
modeling techniques to analyze the data
and build
models you can use different supervisor
and unsupervised algorithm such as
linear regression logistic regression
decision tree KNN K means clustering and
lots more to build prediction models for
making business
decisions and the final step is to
interpret the
results this part is important because
it's how a business will gain actual
value from the previous four
steps interpreting the results will help
you find unseen Trends and patterns in
the data and Gain insights you can have
a validation check if the results are
answering your questions these results
can be shown to your clients and
stakeholders for better understanding
and business
collaboration now that we have looked at
the various steps involved in data
analytics let's now see the different
tools that can be used to perform the
above steps we are going to talk about
data science and how you can become a
data scientist whether you're just
starting out or looking to improve your
skills this guide will help you get
started your journey in data science
firstly what is data science in simple
terms data science is a field where you
use programming math and knowledge about
a specific area to find useful
information in data data scientists look
at large sets of data to find patterns
Trends and connections that can help
companies make smart decisions for
example think about Netflix have you
noticed how it always seems to know what
show or movie you want to watch next
that's because Netflix uses data science
it looks at what you have watched before
what you have liked and even what time
of day you watched by studying all this
information Netflix can suggest shows
and movies it thinks you will enjoy
making it easy for you to find something
to watch and Amazon does something
similar when you shop online when you
search for items buy something or even
just add something to your card Amazon
keeps track of that it then uses this
data to recommend other products you
might like this helps you discover
things you might need and it also helps
Amazon sell more products now that we
have a clear idea of what data science
is let's talk about how you can actually
become a data scientist this might seem
like a big task but don't worry we'll
break it down step by step so you can
see exactly what you need to learn and
why it's important so the first step is
to learn programming language data
scientists often use two main languages
Python and R python is very popular
because it's easy to learn and has lots
of libraries or tools that help with
data analysis and machine learning R is
also great especially for statistics and
creating graphs learning these languages
will help you write code to work with
data which is a big part of being a data
scientist so once you have choosen your
programming language it's important to
start with the basics understand these
fundamentals will make everything else
you learn much easier so before you dive
into complex stuff you need to
understand the basics of python includes
learning about called variables which
are like containers that store data and
if else Loops which are used to make
decisions in your code these Basics are
like the ABCs of programming and you'll
use them all the time when you start
working on data science projects so now
that you have the basics down it's time
to move on to some tools that will make
working with data much easier let's talk
about dumpy and pandas so once you're
comfortable with python Basics it's time
to learn about two important libraries
numai and pandas so numai helps you work
with num numbers especially if you're
dealing with large amounts of data it's
like a superpowered calculator and
pandas is used for handling and
organizing data in tables making it
easier to clean transform and analyze
data so these tools are essential for
any data scientist now data science
isn't just about coding it also involves
a lot of math here's a quick rundown of
the key areas you need to focus
on statistics for beginners focus on
descriptive statistics which involves
understanding measures of central
tendency like mean median and mode as
well as measures of spread like variance
and standard deviation you'll also need
to bras the basics of data distribution
such as normal and binomial
distributions and as you move on to
intermediate level statistics you will
explore inferential statistics which
involves drawing conclusions from data
samples through Concepts like sampling
confidence intervals and hypothesis
testing you'll also need to understand
probability distribution such as poison
and exponential distributions at the
advanced level delve into regression
analysis learning techniques like linear
regression logistic regression and
multiple regression which are crucial
for making predictions Based on data
additionally understanding basent
statistics will be key especially
Concepts like base theorem priors and
likelihoods which are used in advanced
predictive
modeling next comes linear algebra so in
linear algebra start by understanding
vectors and scalars which are fun m al
in representing data so as you progress
study metrices and metrix operations
which are crucial for handling data in
multiple Dimensions finally at an
advanced level learn about Egan values
and Egan vectors which are important in
many machine learning algorithms such as
principal component analysis now
calculus is another important area
though you don't need to be an expert in
it begin by understanding derivatives
which measure how a function changes as
its inputs change this concept is
essential when you're optimizing using
machine learning models and finally in
probability start with basic concepts
like odds and conditional probability
which will help you understand and
manage uncertainty in data as you
advance explore base theorem and learn
about probability distributions which
are used extensively in statistical
modeling and machine learning algorithms
now once you crunched the numbers the
next step is to make your findings easy
to understand that's where data
visualization comes in now data
visualization is all about presenting
your data in a way that's easy for
others to understand so start with
matplot li a python library that allows
you to create simple plots like line
graphs and Scatter Plots this will help
you identify Trends and patterns in your
data and as you gain confidence move on
to seon which Builds on matplot lib and
allows you to create more complex and
aesthetically pleasing visualizations
like heat maps that can show cor
relations between
variables additionally it's important to
have a basic understanding of excel
especially if you'll be working in a
business environment Excel is widely
used for quick data analysis and knowing
how to create basic charts and pivot
tables will make it easier to share your
results with colleagues who may not be
familiar with python now to take your
data visualizations to the next level
you can learn tools like powerbi and tab
powerbi a tool from Microsoft allows you
to create interactive dashboards that
easy to share and update in real time
this makes it great for businesses that
need to monitor key metrics on an
ongoing basis tab is another powerful
tool for creating interactive and
sharable visualizations so it's
particularly useful for working with
large data sets and Performing complex
analytics so both of these tools are
highly valued in the industry for their
ability to turn data into actionable
insights making your visualizations even
more impactful and useful for decision
making so now that you can analyze and
visualize data it's time to explore one
of the most exciting parts of data
science which is machine learning in
machine learning is a powerful tool that
allows computers to learn from data and
make predictions or decisions without
being explicitly programmed let's break
down the different types of
machine number one supervised
learning so supervised learning is one
of the most common types of machine
learning in supervised learning you
train your model on a data set that
contains both the input features and the
corresponding correct outputs so this
means the data you use to train your
model is labeled and the goal is to
teach the model to make predictions
based on these labels for instance you
might model that predicts house prices
based on features like the number of
bedrooms location and size of the house
so popular algorithms and supervised
learning include linear regression for
predicting continuous values and
classification algorithms like logistic
regression decision trees and support
Vector machines for categorizing data
into classes next up is unsupervised
learning now unlike supervised learning
with data that doesn't have enables so
the goal here is to find the patterns or
structures within the data so for
example you might use unsupervised
learning to group customers into
different segments based on their
purchasing Behavior without knowing
beforehand what those segments should be
so clustering algorithms like K means
and hierarchical clustering are commonly
used in unsupervised learning to
identify these groupings additionally
you'll use techniques like principal
component analysis to reduce the
dimensionality of your data while
preserving its import important features
next comes semi-supervised learning so
semi-supervised learning combines
elements of both supervised and
unsupervised learning so in
semisupervised learning you work with a
data set that is partially labeled this
approach is useful when labeling data is
expensive or time consuming the model
learns from the labeled portion of the
data and makes predictions on the
unlabeled portion so this technique can
be very effective in scenarios where you
have a small amount of labeled data and
a large amount of unlabelled data such
as in text classification or image
recognition tasks now finally let's talk
about reinforcement learning in this
type of learning an agent which can be a
computer program or robot learns by
trying things out and getting feedback
so the agent makes decisions and based
on whether those decisions are good or
bad it gets Rewards or penalties so the
goal is to figure out which actions lead
to the best outcomes over time now with
a good grasp of programming math and
machine learning under your belt there's
one more Essen IAL skill you need to
master working with databases so let's
talk about SQL so SQL which stands for
structured query language is a standard
language for managing and quiding
relational databases it's crucial for
extracting and manipulating data from
large databases start by learning the
basics like how to write simple queries
to select insert update and delete data
understanding how to join tables is also
important as it allows you to combine
data from different sources into a
single query as you advance Explore More
more complex SQL features like
subqueries transactions and indexing
which helps improve the efficiency and
performance of your database queries the
mastering SQL will enable you to handle
data extractions and manipulation tasks
more effectively making you a more
versatile data scientist so now that you
have got a solid foundation it's time to
put your skills into practice so kagle
is a fantastic platform to start
applying what you have learned it's a
popular website where data scientists
and machine learning enthusiasts can jum
competitions and work with real data
it's a fantastic way to get hands-on
experience and build a portfolio so you
can start by exploring the data sets on
kaggle and try solving some easy
problems to get used to working with
data you can also join competitions to
test your skills and see how you
compared to others so doing projects on
kaggle helps you practice what you have
learned and gives you results you can
show to Future employees so there you
have it a step-by-step guide on how to
become a data scientist remember it
takes time and effort but with
dedication you can can definitely make
it who is a data analyst a data analyst
collects analyzes and interprets data a
data analyst will convert raw data into
useful information data analyst are in
high demand because every industry uses
data analysis work of a data analyst as
a data analyst you will work closely
with the raw data and generate valuable
insights to help companies decide their
future goal if you like thinking out of
the box you are the perfect fit for this
domain data analyst help maximize output
when it comes to generating Revenue
working closely with both business and
data nevertheless this field boost
handsome salaries for all levels of
expertise can you become a data analyst
without prior experience yes anyone can
become a data analyst if they enjoy
solving real world problems have a
strong background in statistics and have
a creative mind if you feel you don't
have it you can definitely develop it so
let us know the skills in detail what
are the basic skill sets required for a
data analyst data analyst must know
basic mathematics and statistics
programming skills machine learning and
also data visualizations tools so let us
know what are the basics that you need
to learn as a data
analyst mathematics it is always better
to know basic mathematics like linear
algebra and probability fundamentals
linear algebra is used in data
pre-processing and transformation which
is the critical process of every data
analysis
statistics a branch of mathematics that
deals with collection analysis
presentation and
implementation probability we know that
probability is the study of How likely
something will happen which is essential
for concluding both probability and
statistics are the backbones of data
analysis it is feasible to become a data
analyst with only a basic understanding
of these three areas of mathematics but
in order to remain relevant and grow as
a data analy one's mathematical
knowledge should not be restricted
compulsorily use some of the tools as a
data analystic what are
that first is Microsoft Excel it is the
most well-known spreadsheet software in
the world it also has computation and
graphick features that are excellent for
data analyst no matter your area of
expertise or additional software you
might want Excel is a standard in the
industry it's useful built-in features
include form design tools and pivot
table it also generate a wide range of
additional features that help simplify
data
manipulation as a programming language
every data analyst should know python it
is easy to learn and has a simple syntax
python is quite adaptable and includes a
vast variety of resource libraries that
are appropriate for a wide range of
diverse data analytics activities these
libraries help in numerical and data
computation the panda and numpy
libraries for instance are excellent for
supporting standard data processing and
streamlining highly computational
operations you can also choose between
Python or r r is a well-known
open-source programming language much
like python data visualization tool as
we previously mentioned data
visualization tool is also necessary to
become a data analyst pobi is a
userfriendly interface makes building
interactive visual reports and dashboard
simple it's most vital selling point is
its superb data integration it works
flawlessly with Cloud sources like
Google and Facebook analytics as well as
text files SQL servers and
Excel is one of the best commercial data
analysis tool available it handles huge
amounts of data better than many other
bi tools and S effortless it has a
visual drag and drop interface however
because it has no scripting layer there
is a limit to what tblo can do for
example it could be better for
pre-processing data or building more
complex
calculations you might have heard about
MySQL a lot of time it is a standard
language for interacting with datab
basis and it is very helpful when
working with structur data SQL creates
userfriendly dashboards that may present
in various data base in since it is so
simple to send complex commands to
databases and change data in seconds it
has commands like add edit delete data
in addition SQL is an excellent tool for
creating data warehouses because of its
Simplicity Clarity and
interactivity overall I would suggest
that to become a data analyst you should
work on programming languages like
python or R plus MySQL to work on
databases adding to that Excel plus
visualization tools like tblo or powerbi
you now know what are the skills are and
how it is used what are you up to in an
organization as a data
analyst to create and evaluate the
report using automated tools like tblo
or
powerbi to troubleshoot the reporting
database environment and reports data
analyst you will use statistical method
to analyze data sets and spot any
valuable trends that may develop over
time evaluate company's functional
non-functional requirement data analyst
assess data warehousing in inspecting
and Reporting needs these are all the
responsibility of a data analyst in an
organization coming to companies hiring
a data analyst IBM accentor capam mini
TCS Facebook Amazon flip cart meta these
are the top companies hiring a data
analyst but data suggest that every
small and mediumsized Company needs a
data analyst therefore demand demand of
a data analyst is in every company so
there is no need to worry job and salary
of a data analyst this is the final part
the salary of a data analyst is high all
over the world when it comes to the USA
the average salary for a data analyst as
a beginner is going as high as 70,000
plus dollar per anom for experienced
professional it is going as high as
$120,000 per anom in India for a fresher
it is going as high as 8 lakh perom and
for experienced professionals it is 20
lakh plus perom such is the demand for
data analyst now that we have covered
every important skill it's time for you
to start working on it so Sky limit on
what you use it for let's take a look at
types of data
analytics and this can be broken up in
so many ways uh but we're going to start
with looking at the most basic questions
that you're going to be asking in data
analytics and the first one is you want
descriptive analytics what has happened
hindsight uh how many cells per call
ratio coming out of the call center if
we have 500 tourists in a forest and you
have a certain temperature how many
fires were started how many times did
the police have to show up to certain
houses um all that's descriptive the
next one is predictive Predictive
Analytics is what will happen next we
want to predict uh this is great if you
want have a ice cream store and you want
to predict how many people to work at
the ice cream store in a certain day
based on the temperature coming up in
the time of the year and then one of the
biggest growing and most important parts
of the industry is now prescriptive
analytics and you can think of that as a
combining the first two we have
descriptive and we have predictive then
you get
prescriptive analytics how can we make
it happen foresight what can we change
to make this work better you know all
the industries we looked at before we
can start asking questions uh especially
in City development there's a good one
if we want to have our city generate
more income and we want that income to
be commercial based uh what kind of
commercial buildings do we need to build
in that area that are going to bring
people over do we need huge warehouse
sales Costco sales buildings or do we
need little mom pod joints that are
going to bring in uh people from the
country to come shop there or do you
want an industrial setup what do you
need to bring that IND industry in there
is there a car industry available in
that area uh if it's not a car industry
what other Industries are in that area
all those things are prescriptive we're
guessing we're guessing what can we do
to fix it what can we do to fix crime in
area with education what kind of
education are we going to use to help
people understand what's going on so
that we lower the rate of crime and we
help our communities grow better that's
all prescriptive it's all guessing we
went foresight into how can we make it
happen how can we make this
better and we really can't not go into
enough detail on these three because a
lot of people stumble on this when they
come in and are doing analytics whether
you're the manager shareholder or the
data scientist coming in you really need
to understand the descriptive analytics
where you're studying the total units of
furniture sold and the profit that was
made in the past uh here we go into
Predictive Analytics predicting the
total units that would sell and the
profit we can expect in the future gear
up for how many employees we need how
much money we're going to make and
prescriptive analytics finding ways to
improve the sales and the profit so we
can uh sell maybe a different kind of
furniture uh we're going to guess at
what the area is looking for and how
that marketing is going to change hello
everyone we welcome you all to this
video by simply learn in today's session
we will learn a really interesting topic
that is the top 10 skills to become a
data analyst in
2022 in today's digital World data is
being generated by companies and
individuals every second so the role of
a data analyst holds supreme
importance so if you're looking for a
career in data analytics this video will
help you learn what a data analyst does
and the various skills you need to
process to become a data analyst in
2022 before we get started make sure you
subscribe to the simply learn Channel
and hit the Bell icon to never miss an
update from
us let's look at the agenda for this
video video first we will understand who
a data analyst is then we will
understand the top 10 data analyst
skills for 2022 moving on we will look
at the salary of a data analyst and
finally we will look at the company's
hiring data analysts so now let's
understand who is a data analyst a data
analyst is a professional who collects
business data from various sources
interprets it and uses various
statistical tools and techniques to
extract insights and useful information
from it
they acquire data from primary or
secondary data sources and maintain
databases they also recognize and
understand the organization's goal and
collaborate with different team members
such as programmers business analysts
and data scientists to build an
effective solution to a business
problem now with this basic
understanding of who a data analyst is
let's learn the top 10 data analyst
skills for
2022 at number one one we have
structured query language or SQL SQL is
a top skill that every data analyst
should have data analysts use SQL
commands and functions to store process
analyze and manipulate structured data
using relational and nosql
databases they also build data models
and write complex SQL queries and
scripts to gather and extract
information from several databases and
data
warehouses some of the popular datab
bases a data analyst should be familiar
with our Microsoft SQL Server MySQL
postr SQL and ibmdb to the second
important skill for a data analyst is
Microsoft
Excel Microsoft Excel is one of the most
popular and oldest spreadsheet
applications for creating reports
performing calculations and analyzing
data data analysts need to know how to
handle tabular data in Excel so they
should be aware of features like sorting
filtering conditional formatting pivot
tables water analyses and functions such
as sumifs and
countifs the third crucial data analyst
skill for 2022 is data cleaning and
wrangling usually the data collected by
analyst from various heterogeneous
sources is often messy and contains a
lot of missing
values so it is always crucial to clean
the data and remove noise missing or
erroneous
elements it is also important important
to format data using tools and methods
before using it for analysis they're
responsible for data mining as well the
data mined from various sources are
organized in order to obtain new
information from it some of the tools
you need to know for data cleaning and
wrangling our Excel power query and open
refine the fourth skill on our list is
mathematics and
statistics data analysts often work on
data for higher Dimensions that are
greater than three in in order to
interpret such data they need to be good
at linear algebra and calculus they also
buil predictive models and statistical
models such as linear regression
logistic regression knife base and K
means clustering in order to understand
the working of these algorithms they
must have knowledge about statistics and
probability coming to the fifth
important skill for a data analyst in
2022 we have programming data analysts
need to master at least one programming
language preferably python or R in order
to work with complex business problems
analysts need to write scripts and
userdefined functions to automate
tedious tasks Python and art language
provide a collection of different
libraries and packages such as numai
pandas DLI matplot lip ggplot which data
analist can use to discover Trends and
patterns from complex data
sets after this we have data
visualization as our sixth skill another
dat data analyst job role is to
visualize large volumes of data and
prepare summary reports and dashboards
for the leadership team and clients so
that they can make timely business
decisions to do this data analysts use
various data visualization tools such as
powerbi tblo and click View using these
tools data analyst can integrate various
data sets apply joint conditions sort
and filter data as well create different
visualizations using charts and graphs
the seventh skill for a data analyst is
industry
knowledge data analyst should have good
knowledge and understanding of the
industry or domain they are working in
for example if you're working in a
healthcare domain you need to know how
Healthcare analytics can be applied to
improve patient care you should have
knowledge about the challenges faced in
healthcare and how you can leverage data
and analytics to solve the issues only
if you have strong industry knowledge
can you try to improve the business
the eighth skill that is important for a
data analyst in 2022 is problem
solving a business deals with several
problems on a daily basis data analyst
should be ready to face those challenges
data analysts are expected to use their
problem solving skills work with the
team troubleshoot what went wrong and
provide an effective solution via data
analysis a data analyst with good
problem solving skills can help a
business identify current and potential
issues and determine a viable solution
based on the data it
collects the ninth skill on our list is
analytical thinking data analysts need
analytical thinking ability to break
down a complex problem into simple
components and resolve these components
one by one it is a must-have skill for
data anal lists analytical thinking
includes deciding the parameters that
need to be considered for defining data
sets analyzing them from different
perspectives and determining variable
dependencies coming to the 10th skill
among the top 10 skills for a data
analyst in 2022 we have
communication data analysts don't just
interact with computers and programs
they also interact with team members
stakeholders and data
suppliers so good communication skills
are essential data analysts also present
their findings in front of an audience
who might not be familiar with the analy
iCal methods and processes so they need
to clearly translate their findings and
insights into non-technical terms so
those were the top 10 skills a data
analyst needs to possess in 2022 do you
think we missed out on any skills then
please put your answers in the comment
section
below now let's look at the salary of a
data
analyst according to glaso the average
annual salary for a data analyst in the
United States is $69,500
while in India you can earn nearly 7
lakh rupees per random finally let's
look at the top companies that are
hiring data analyst in
2022 here we have the consultancy and
big four Giant deoe and the
pharmaceutical company cner Corporation
then we have the tech giant IBM retail
company Walmart and the e-commerce
leader
Amazon to achieve the goals of data
analysis we use a number of data
analysis tools
companies rely on these tools to gather
and transform their data into meaningful
insights so which tool should you choose
to analyze your data which tool should
you learn if you want to make a career
in this field we will answer that in
this session after extensive research we
have come up with these top 10 data
analysis tools here we will look at the
features of each of these tools and the
companies using them so let's start off
at number 10 we have Microsoft Excel all
of us would have used Microsoft Excel at
some point right it is easy to use and
one of the best tools for data analysis
developed by Microsoft Excel is
basically a spreadsheet program using
Excel you can create grids of numbers
text and formula it is one of the widely
used tools be it in a small or large
setup the interface of Microsoft Excel
looks like this
let's now move on to the features of
excel firstly Excel works
with the windows version of excel
supports programming through Microsoft's
Visual Basic for applications
VBA programming with VBA allows
spreadsheet manipulation that is
difficult with standard spreadsheet
techniques in addition to this the user
can automate tasks such as formatting or
data organization in
VBA one of the biggest benefits of excel
is its ability to organize large amounts
of data into orderly logical
spreadsheets and charts by doing so it's
a lot easier to analyze data especially
while creating graphs and other visual
data
representations the visualization can be
generated from specified group of
cells those were few of the features of
Microsoft Excel let's now have a look at
the companies using it most of the
organizations today use Excel few of
them that use it for analysis are the UK
based compan Ernest and Young then we
have Urban Pro whpr and
Amazon moving on to our next data
analysis tool at number nine we have
rapid
minor a data science software platform
rapid Miner provides an integrated
environment for data preparation
analysis machine learning and deep
learning it is used in almost every
business and Commercial sector rapid
Miner also supports all the steps of the
machine learning
process seen on your screens is the
interface or rapid
minor moving on to the features of Rapid
minor firstly it offers the ability to
drag and drop it is very convenient to
just drag drop some columns as you are
exploring a data set and working on some
analysis rapid Miner allows the usage of
any data and it also gives an
opportunity to create mod models which
are used as a basis for decision- making
and formulation of
strategies it has data exploration
features such as graphs descriptive
statistics and visualization which
allows users to get valuable
insights it also has more than 1,500
operators for every data transformation
and Analysis
task let's now have a look at the
companies using rapid Miner we have the
Caribbean Airline leward Islands Air
transport next we have the United Health
Group the American online payment
company PayPal and the Australian
Telecom company mobilecon so that was
all about rapid Miner now let's see
which tool we have at number
eight we have talent at
number8 Talent is an open- Source
software platform which offers data
integration and management it
specializes in Big Data integration
Talent is available both in open source
and premium versions it is one of the
best tools for cloud computing and Big
Data
integration the interface of talent is
as seen on your
screens moving on to the features of
talent firstly automation is one of the
great Bon Talent offers it even
maintains the tasks for the users this
helps with quick deployment and
development it also offers open- Source
tools Talent lets you download these
tools for free the development costs
redu significantly as the processes
gradually speed
up Talent provides a unified platform it
allows you to integrate with many
databases SAS and other Technologies
with the help of the data integration
platform you can build flat files
relational databases and Cloud apps 10
times
faster those were the features of talent
the companies using Talent are Air
France L'Oreal Cap Gemini and the
American multinational pizza restaurant
chain do
next on the list at seven we have nine
constant information minor on N is a
free and open- Source data analytics
reporting and integration
platform it can integrate various
components for machine learning and data
mining through its modular data
pipelining concept nime has been used in
pharmaceutical research and other areas
like CRM customer data analysis business
intelligence text Mining and financial
data
analysis here is how the interface of n
application looks
like now coming to the nine
features nine provides an interactive
graphical user interface to create
visual workflows using the drag and drop
feature use of jdbc allows assembly of
nodes blending different data sources
including pre-processing such as ETL
that is extraction transformation
loading for modeling data analysis and
visualization with minimal
programming it supports multi-threaded
in-memory data processing n allows users
to visually create data flows
selectively execute some or all analysis
steps and later inspect the results
models and interactive
views n server automates workflow
execution and supports team-based
collaboration Nim integrates various
other open- source projects such as
machine learning algorithms from Becca
H2 Caris Park and our project n allows
analysis of 300 million custom addresses
20 million cell images and 10 million
molecular
structures some of the companies hiring
for n are United Health Group asml
fractal analytics atos and LEGO Group
let's now move on to the next tool we
have SAS at number
six SAS facilitates analysis reporting
and predictive modeling with the help of
powerful visualizations and dashboards
in SAS data is extracted and categorized
which helps in identifying and analyzing
data patterns as you can see on your
screens this is how the interface looks
like moving on to the features of
SAS using SAS better analysis of data is
achieved by using automatic code
generation and SAS SQL SAS allows you to
access through mic Microsoft Office by
letting you create reports using it and
by Distributing them through
it SAS helps with an easy understanding
of complex data and allows you to create
interactive dashboards and
reports let's now have a look at the
companies using SAS we have companies
like genpact iqa accenta and IBM to name
a
few that was all about SAS so for all
those who joined in late let me just
quickly repeat our list list at number
10 we have Microsoft Excel then at
number nine we have rapid minor at
number eight we have talent at number
seven we have n and at number six we
have SAS so far do you all agree with
this list let us know in the comment
section below let's now move on to the
next five Tools in our
list so at number five we have both R
and python yes we have two of the in the
fifth
position R is a programming language
which is used for analysis as well it
has traditionally been used in academics
and research python is a highlevel
programming language which has a python
data analysis Library it is used for
everything starting from importing data
from Excel spreadsheets to processing
them for
analysis this is the interface of
R next up is the interface of the python
Jupiter
notebook let's now move on to the
features of both our and
python when it comes to the availability
of R and python it is very easy both R
and python are completely free hence it
can be used without any
license R used to compute everything in
memory and hence the computations were
limited but now it has changed bothar
and python have options for parallel
computations and good data handling
capabil
ities as mentioned earlier as both R and
python are open in nature all the latest
features are available without any
delay moving on to the companies using R
we have Uber Google Facebook to name a
few python is used by many companies
again to name a few we have Amazon
Google and the American photo and video
sharing social networking service
Instagram that was all about our
python at number four we have Apache
spark Apache spark is an open- Source
engine developed specifically for
handling large scale data processing and
analytics spark offers the ability to
access data in a variety of sources
including Hado distributed file system
htfs open stack Swift Amazon S3 and
Cassandra it allows you to store and
process data in real time across various
clusters of computers using simple
programming
constructs Apache spark is designed to
accelerate analytics on Hadoop while
providing a complete Suite of
complimentary tools that include a fully
featured machine learning library a
graph processing engine and stream
processing so this is how the interface
of a pares spark looks like
now let's look at the important features
of Apaches
spark spark stores data in the ram hence
it can access the data quickly and
accelerate the speed of analytics spark
helps to run an application in a Hadoop
cluster up to 100 times faster in memory
and 10 times faster when running on
disk it supports multiple languages and
allows the developers to write
applications in Java Scala r or python
Spar comes up with 80 high level OP
ators for interactive querying Spar code
for batch processing join stream against
historical data or run ad hoc queries on
stream
State analytics can be performed better
as spark has a rich set of SQL queries
machine learning algorithms complex
analytics Etc Apache spark provides fall
tolerance through spark rdd spark
resilient distributed data sets are
designed to handle the failure of any
worker node in the cluster thus it
ensures that the the loss of data
reduces to
zero conviva Netflix iqa Loy Martin and
eBay are some of the companies that use
a party spark on a daily
basis at number three we have another
important growing data analysis tool
that is Click
view click viw software is a product of
Click for business intelligence and data
visualization click view is a business
Discovery platform that provides
self-service bi for all business users
and
organizations with click view you can
analyze data and use your data
discoveries to support decision making
click viw is a leading business
intelligence and analytics platform in
Gartner magic
quadrant on the screen you can see how
the interface of Click view looks
like now talking about its features
click view provides Interactive guid
analytics within memory storage
technology during the process of data
Discovery and interpretation of
collected data The Click view software
helps the user by suggesting possible
interpretations click view uses a new
patent in memory architecture for data
storage all the data from the different
sources is loaded in the ram of the
system and it is ready to be retrieved
from there it has the capability of
efficient social and mobile data
Discovery social data Discovery offers
to share individual Data Insights within
groups or out of it a user can add
annotations as an addition to someone
else's insights on a particular data
report click view supports mobile data
Discovery within an HTML F enabled touch
feature which lets the user search the
data and conduct data Discovery
interactively and explore other
server-based
applications click view performs olap
and ETL features to perform analytical
operations extract data from multiple
sources transform it for usage and load
it to a data
warehouse the companies that can help
you start your career in Click view a
Mercedes-Benz Cap Gemini City Bank
cognizant and Accenture to name a
few at number two we have
powerbi powerbi is a business analytic
solution that lets you visualize your
data and share insights across your
organization or embed them in your app
or
website it can connect to hundreds of
data sources and bring your data to life
with live dashboards and
reports powerbi is the collective name
for a combination of cloud-based apps
and services that help organizations
collate manage and analyze data from a
variety of sources through a
userfriendly
interface powerbi is built on the
foundation of Microsoft Excel and has
several components such as Windows desk
toop application called powerbi desktop
and online software is a service called
powerbi service mobile powerbi apps
available on Windows phones and tablets
as well as for IOS and Android
devices here is how the powerbi
interface looks like as you can see
there is a visually interactive sales
report with different charts and
graphs moving on to the feat features of
powerbi it has an easy drag and drop
functionality with features that make
data visually appealing you can create
reports without having the knowledge of
any programming language powerbi helps
users see not only what's happened in
the past and what's happening in the
present but also what might happen in
the
future it offers a wide range of
detailed and attractive visualizations
to create reports and dashboards you can
select several charts and graphs from
the visualization pain powerbi has
machine learning capabilities with which
it can spot patterns in data and use
those patterns to make informed
predictions and run what if
scenarios powerbi supports multiple data
sources such as Excel Tech CSV Oracle
SQL Server PDF and XML files the
platform integrates with other popular
business management tools like
SharePoint Office 365 and dynamic 365 as
well as other non-microsoft products
like like spark Hadoop Google analytics
sap Salesforce and
MailChimp some of the companies using
powerbi are Adobe AXA carlsburg capure
mani and
Nestle moving on to the next tool so any
guesses as to what we have at number one
you can comment in the chat section
below finally on the top of the pyramid
we have Tablo
Gartner's magic quadrant of 2020
classified Tapo as a leader in business
intelligence and data analysis tblo
interactive data visualization software
company was founded in Jan 2003 in
Mountain View
California tblo is a data visualization
software that is used for data science
and business intelligence it can create
a wide range of different visualization
to interactively present the data and
showcase
insights the important prod of tblo are
tblo desktop tblo public tblo server
tblo online and tblo
reader this is how the interface of
Tablo desktop looks
like now coming to the features of
tblo data analysis is very fast with
tblo and the visualizations created are
in the form of dashboards and worksheets
tblo delivers interactive dashboards
that support insights on the
fly in it can translate queries to
visualizations and import all ranges and
sizes of data writing simple SQL queries
can help join multiple data sets and
then build reports out of it you can
create transparent filters parameters
and
highlighters tblo allows you to ask
questions spot Trends and identify
opportunities with the help of tblo
online you can connect with Cloud
databases Amazon dread shift and Google
big
query the company using Tabo are deoe
Adobe Cisco LinkedIn and the American
e-commerce giant Amazon to name a few
and there you go those are the top 10
data analysis Tools R is a statistical
programming language and environment
that integrates statistical Computing
and Graphics R is powerful and stable
software python python can also be
called as a general purpose programming
language for data anal analysis and
scientific Computing python can be
considered as the best player in machine
learning python is an expressive
language with many built-in function
both are open-source software and
platform
independent and they are platform
neutral and also compatible with all
major operating systems including Unix
Windows and Mac next we will be covering
different
parameters we will will be covering
learning preferability mathematical
fundamentals speed of both
languages visualization and
Graphics data handling
capacity
demand community and customer
support employment possibility in both
the
languages let us cover it one by one
first one is learning preferability or
ease of
learning python is is Renown for its
ease of use Python's notebooks offer
excellent tools for sharing and
documentation despite the fact that
there are currently no gois for them
programmers find R as difficult language
as a beginner this implies that the
programmers must devote a significant
amount of time to learn and
comprehending our
coding coming to mathematical
fundamentals required
coming to python understanding
descriptive analysis is very important
in layman's terms descriptive statistics
often refers to the process of
explaining using certain representative
techniques such as charts tables Excel
files
Etc python statistics is a built-in
library for descriptive
statistics if your data sets are not too
big or if you can't rely on importing
other libraries you can use python
on the other hand R requires basic
statistics from basic statist statistics
what I mean is mean mode and median are
the terms used most frequently in basic
statistics it is referred to as measures
of central
tendency probability statistics plays an
important role in handling various types
of probability distribution it includes
binomial and normal distribution
next parameter is
speed python is an interpreted language
with Dynamic typing python always
executes slowly because the code is
executed line by
line compared to matlb and python R is
our language is significantly slower our
packages are substantially slower than
those for other languages
now that we have covered speed coming to
data visualization and data collection
in
Python When selecting data analysis
tools with visualization are crucial and
python has some incredible visualization
tool in Python to large and varied
scater plots using regression lines we
can use gz plot 2 and GZ plot
tools compared to draw values visualized
data is easier to comprehend therefore R
has many packages that offers
sophisticated graphic
features in R we can
use in R we can use tools like M plot
lip saond
Etc data handling capability in both
Python and
R the new releases in Python have
resolved the issue with the python
packages for data analysis R is useful
for analysis because of the abundance of
packages accessibility of the test and
benefit of employing formulas however
simple data analysis can also be done
using it the need to install many
packages crucial part of parameter that
is tools and libraries in Python and r
as a python developer one needs to be
well vered in the best libraries because
python has a lot of libraries that have
many different
uses libraries like tensorflow pyit Lear
numai play an important role in solving
many python related
problems libraries perform a wide
variety of tasking are that are very
beneficial for data science operations
example for that is depler bioconductor
Etc community and customer support
support index offered by Python and
R compared to R python has a larger
Community for assistance we can contact
www.python.org
for any queries regarding Python and
help you can support uh you I repeat you
can visit support. real pon.com
for any help and queries our offers you
with our studio Community R provides
assistance through its official
website for queries and Community
related issues we can contact
www.r project.org
next is job opportunities in Python and
r a recent survey from indie.com
predicts that at least 55,000 python
jobs in the USA with exponential pay
rates are available big tech companies
like Google Amazon Twitter Facebook
requires python developer to handle
massive amount of data position provided
for a python developer is software
engineer data analyst data scientist and
many more
career in R is an excellent job
opportunity for you as a beginner big
tech companies like Google Twitter
Facebook are using
R position provided by companies as a r
developer is data scientist data analyst
data visualization analyst Etc moving on
let us wrap up an important topic which
language to be used between R and python
there is no right or wrong way to study
both python or R both are in demand
skills that will enable you to complete
almost any data analytics work you come
across It ultimately depends on your
background interest and career
objectives that which one is better for
you but compared to R python is easy to
learn let's compare its strength and
weaknesses it is used to handle large
amount of data
python performs non-statistical
functions and it is best suitable for
programming however python is better
when it comes to
coding whereas R is used in data
visualization
Graphics R is a widespread language in
the statistical
Community it is used to accomplish many
mathematical task so before concluding
the topic let me answer the query that I
have asked asked regarding R and python
do you guys remember the
question the query
was our language is superficially
related to which
language so the answer for the question
is C
language so the number of reasons one
it's easy to learn with simple
syntax uh you don't have a very high
type set like you do in Java and other
coding so it allows you to kind of be a
little lazy in your programming uh that
doesn't mean that it can't be set that
way and that you don't have to be
careful it just makes means you can spin
up a code much quicker in Python the
same amount of code to do something in
Python A lot of times is one two or
three or four lines where when I did the
same thing say in Java I found myself
with 10 12 13 20 lines depending on what
it was it's very scalable and flexible
uh so there's our flexibility because
you can do a lot with it and you can
easily scale it up you can go from
something on your machine
to using uh P spark in the spark
environment and spread that across
hundreds if not thousands of servers
across terabytes of data or pedabytes of
data so it's very scalable there's a
huge collection of
libraries this one's always interesting
because Java has a huge collection of
libraries C has a huge collection of
libraries net does and they're always in
competition to get those libraries out
uh Scala for your spark all those have
huge collection of libraries this is
always changing uh but because Python's
open source you almost always have easy
to access libraries that anybody can use
you don't have to go check your
licensing and have special licensing
like you do in some
packages graphics and visualization they
have a really powerful package for that
so it makes it easy to create nice
displays for people to read and
community support because python is open
source it has a huge community that
supports it you can do a quick Google
and probably find a solution for almost
anything you're working on
python libraries let's bring it together
we have data analytics and we have
python so when we're talking data
analytics we're talking python libraries
for data analytics and the big five
players are numpy pandas Matt plot
Library scipi which is going to be in
the background so we're not going to
talk too much about the scientific
formulas in scipi
andsit so numpy supports in dimensional
arrays provides iCal Computing tools
useful for linear algebra and for year
transform um and you can think of this
as just a grid of numbers um and you can
even have uh a grid inside a grid or
data it's not even numbers because you
can also put uh words and characters and
just about anything into that array but
you can think of a grid and then you can
have a grid inside a grid and you end up
with a nice three-dimensional array if
you want to talk threedimensional array
you can think of images you have your
three channels of color for if you have
an alpha and then you have your XY
coordinates for the image we're looking
at so you can go x y and then what are
the three channels to generate that
color and numpy isn't restricted to
three dimensions you could imagine uh
watching a movie well now you have your
movie clips and they each have their X
number of frames and each of those
frames have X number of XY coordinates
for the pictures in each frame and then
you have your three dimensions for the
colors so numpy is just a great way to
work with in dimensional arrays
now closely with numpy is pandas uh
useful for handling missing data perform
mathematical operations provides
functions to manipulate data pandas is
becoming huge because it is basically a
data frame and if you're working with
big data and you're working in spark or
any of the other major packages out
there you realize that the data frame is
very Central to a lot of that and you
can look at it as a Excel spreadsheet
you have your columns you have your rows
or indexes and uh you can do all kinds
of different manipulations of the data
within uh including filling in missling
data which is a big thing when you're
dealing with large pools or lakes of
data where they might be collected
differently from different
locations and Matt plot Library we did
kick over the scipi which is a lot of
mathematical computations which usually
runs in the background of the of numpy
and pandas um although you do use them
they're useful for a lot of other things
in there but the map plot Library that's
the final part that's what you want to
show people and this is your plotting
library in Python several toolkits
extend map plot Library
functionality there's like a hundred
different toolkits to extend matap plot
Library which range from uh how to
properly display star constellations
from astronomy there's a very specific
one built just for that all the way to
some uh very generic ones will actually
add Seaborn when we do the labs in a
minute several toolkits extend met plot
Library functionality and it creates
interactive
visualization uh so there's all kinds of
cool things you can do as far as just
displaying graphs and there's even some
that you can create interactive graphs
we won't do the interactive grasp but
you'll see you'll get a a pretty good
grasp of some of the different things
you can do in matplot
library let's jump over to the demo
which is my favorite roll up our sleeves
get our hands in on what we're doing now
there's a lot of options when we're
dealing with python uh you can use py
charm is a really popular
one uh and you'll see this all over the
place um so it's one of the main ones
that's out there and there's a lot of
other ones I used to use net beans which
has kind of lost favor uh don't even
have it installed on my new
computer but the most popular one right
now for data science now py charm's
really popular for python General
development for data science we usually
go to Jupiter uh notebook or anac anonda
and we're going to jump into Anaconda
because that's my favorite one to go to
CU it has a lot of external tools for us
we're not going to dig into those but we
will pop in there so you can see what it
looks like so with Anaconda we have our
Jupiter lab we have our um notebook
these are identical Jupiter lab is an
upgrade to the notebook with multiple
tabs that's all it is and we'll be using
the notebook and you can see that pie
charm is so popular with um python that
we even have a highlighted here in
Anaconda as part of the setup uh Jupiter
notebook can also be a standalone uh so
we're actually going to be running
Jupiter notebook and then you have your
different environments um I have we're
going to be under main Pi 36 there's a
root one and I usually label it Pi
36 the reason is is currently as of
writing this tensor flow only works in
36 and not in 37 or 38 for doing neural
networks but you can actually have
multiple environments which is nice
they're they separate the kernel so it
helps protect your computer when you're
doing development and this is just a
great way to do a display or a demo
especially if you're looking for that
job pull up your laptop open it up or if
you're doing a meeting get it broadcast
up to the big screen so that the uh CEO
can see what you're looking
at and when we launch the notebook uh it
actually opens up a file browser in
whatever web browser you have this
happens to be Chrome and then you can
just go under new there's a lot of
different options depending on what you
have installed uh Python 3 and this just
creates an Untitled uh version of this
and you can see here I'm actually in a
simply learned folder for other work
I've done for simply
learn uh and that's where I save all my
stuff and I can browse through other
folders making it really easy to jump
from one project to another and under
here we'll go ahead and change the name
of this and we'll go ahead and rename
it data analytics data analytics just so
I can remember what I was doing
which is probably about 50 of the
folders in here right or files in here
right now uh so let's go ahead and jump
in there and take a look at some of
these different uh tools that we were
looking
at and as we go through the demo let's
start with the uh numpy uh the least
visually exciting and I'm going to zoom
in here so you can see what we're
doing and the first thing we want to do
is import
numpy and we'll import it as NP that is
the most common numpy
terminology and let's go and change the
view so we also have the line numbers um
I don't know why we probably won't need
them but likeing for easy reference uh
and then we'll create a onedimensional
array we'll just call this array one and
it equals np. array and you put your
array information in here in this case
we'll spell it out uh you can actually
do like a range and other ways there's
lots of ways to generate these arrays
but we'll just do one two three so three
integers
and if we
print our array
one we can go ahead and run this and you
can see right here prints one two three
you can see why this is a really nice
interface to show other people what
you're doing uh with the Jupiter
notebook uh so this is the basic we've
created an array this is a
onedimensional array and then array is
one two three one of the nice things
about the jupyter notebook is whatever
ran in this first setup is still running
it's still in the kernel so it still has
the nump imported as NP and it still has
our variable um arr1 for array 1 equal
to NP array of 1 two three so when we go
to the next
cell we can check the type of the array
we're just going to print we say hey
what's what what what is this um setup
in here and we want
type um and then we want what is the
type of array one let's go ahead and run
that and it says class numpy in D array
so it's its own class that's all we're
doing is is checking to see what that
class
is and if you're going to look at the uh
array class uh probably the biggest
thing you do I don't know how many times
I find myself uh doing this uh because I
forget what I'm working on and I forget
I'm working with a three-dimensional or
four-dimensional array uh and I have to
reformat somehow so it works with
whatever other things I have and so we
do the array shape uh the array shape is
just three because it has three members
and it's onedimensional array that's all
that
is and with the numpy array we can
easily access um stick with the print
statement if you actually put a variable
in Jupiter notebook and it's the last
one in the cell it will the same as a
print statement so if I do this where
array one of two it's the same as doing
print array of two that's those are
identical statements in our Jupiter
notebook we'll go and stick with the
print on this one
and it's three so there's our print
space two and we have 0 1 2 2 = 3 we can
easily change that so we have array one
of place
two equals
5 and then if we print our array
one uh you can see right down here when
it comes out it's one two and five and
there I lift the print statement off
because it's the last variable in the
list um and it'll always print the
variable if you just put it in like that
that's a Jupiter notebook thing don't do
that in by charm I've forgotten before
doing a
demo and we talked about multiple
Dimensions so we'll do an array um
two-dimensional array and this is again
a numpy
array and in the numpy array we need um
our first Dimension we'll do one two 3
and
our second dimension uh 3 4 5 and you
can see right here that when we hit the
uh we'll do this we'll just do array
two and we can run that and there's our
array two 1 2 3 3 4 5 we can also do
array
two of uh
one and then we can do let's do zero
doesn't really matter which one actually
let's do uh two there we go and if I run
this it'll print out five uh cuz here we
are this is zero
uh 0 1 2 3 is on our zero row 345 is on
our one row always start with zero and
then the two 0 one two goes to the
five and then maybe we forgot what we
were working with so we'll go do array
2.
shape and if we do array two of
shape uh we'll go and run that we'll see
we have two rows and each row has three
elements a two-dimensional array 2 three
if you looked up here when we did it
before it just had three comma nothing
when you have a single entity it always
saves it as a tuple with a blank
space uh but you can see right here we
have 2 comma
3 and if you remember from up here we
just did this array two of oh let's go
what is it one comma
two we run that we get the five you can
also count backwards this is kind of fun
and you'll see I just kind of Switched
something on you because you can also do
one comma two to get to the same spot um
now two is the last one 0 one two it's
the last one in there we can count
backwards and do minus one and if we run
this we get the same answer whether we
count it as uh let's go back up here
whether we count this as
012 or we count backwards as min-1 -2 -3
and you can see that if I change this
minus one to a minus two and run
that I get four which is going backwards
minus one min-2 so there's a lot of
different ways to reference what we're
working on inside the numpy
array it's really a cool tool it's got a
lot of things you can do with
it and we talked about the fact that it
can also hold things that are not values
and we'll call this array ask for
Strings equals uh np.
array put our setup in there
brackets and let's
go
China
um
[Music]
India
USA uh
Mexico doesn't matter we can make
whatever we want on here and if we print
that
out we run this you can see that we get
our numpy of Ray China India USA Mexico
it even gives us our dtype of a U6
and a lot of times when you're uh
messing with data we'll call this array
R for range just to kind of keep it
uniform np. a range so this is a command
inside numpy to create a range of
numbers and if you're testing data Maybe
you want maybe you have equal time
increments um that are spaced a certain
point apart but in this case we're just
going to do
integers and we're going to do a uh a
setup from 0 20 skipping every other one
and we'll print it out and see what that
looks
like and you can see here we have 0 2 4
6 8 10 12 14 16 18 like you expected it
skips every one and just a quick
note there's no 20 on here uh why well
this starts at zero and counts up to 20
so if you're used to another language
where explicitly says uh less than or
less than equal to 20 like for X = 0 um
x++ uh X is less than 20 that's what
this is it just assumes X is less than
20 on
here and if we want to create a very
uniform uh set you know 0 2 4 6 what
happens if I want to create numbers uh
from 0 to 10 but I need 20 increments in
there uh we can do that with line space
so we can create um an R uh we'll call
this l
equals I don't think we'll actually use
any of this again so I don't know why
I'm creating unique um identifiers for
it uh but we'll do
NP Lin
space and we're going to do
zero to 10 or 0 to 9 uh remember it
doesn't it goes up to 10 and then we
want to let's say we have
20 different um increments in there so
we're creating a we have a data set and
we know it's over a certain time period
and we need to divide that time period
by 20 and it happens to just have 10
pieces in it um and here we go you can
see right here we have 20 or it has 20
pieces in it but it's over 10 years we
got to divide it in the middle and you
can see it does it goes 0.52 remember
yeah there's our 10 on the end so it
goes up to
10 uh and then we can also do random
there's np. random if you're doing
neural
networks uh usually you start it by
seating it with random numbers and we'll
just do np. random and we'll just call
this array we'll stop giving it unique
numbers we'll print that one out and run
it and you can see we have random
numbers they are 0o to one so you'll see
that all these numbers are under one and
you can easily alter that by multiplying
them out or something like that if you
want to do like zero to 100 um you can
also round them up if it's integer 0 to
100 there's all kinds of things you can
do but generates a random float between
zero and one and you have a couple
options you could reshape that um or you
can just generate them uh in whatever
shape you want and so we can see here uh
we did three and four and so you can see
three rows by four variables same thing
as doing a reshape of 12 variables to
three and
four and if you're going to do that you
might need an empty data set um I have
had this come up many times or I need a
start off with zero and I don't know you
know because I'm going to be adding
stuff in there or it might be zero and
one or one is uh if you're removing the
background of an image you might want
the background is zero and then you
figure out where the image is and you
set all those boxes to one and you
create a mask so creating mask over
images is really big and doing that with
a a numpy array of
zero and we can also
uh give it a
space and we'll just do this all in one
shot this time and we'll do the same
thing like we did
before zeros and in this case we'll do
uh 2 comma 3 and so when we run
this forgot the asteris around it I knew
I was forgetting something there we go
so when we run this uh you can see here
we have uh our 10 zeros in a row and
maybe this is a mask for an image and so
it has uh two two rows of three digits
in it so it's a very small image little
tiny
pixel and maybe you're looking to do
something the opposite way uh instead of
uh creating a mask of zeros and filling
in with ones uh maybe you want to create
a mask of ones and fill them in with uh
zeros and we'll just do just like we did
before we'll do three comma four and
when we run this you'll see it's all
ones and we could even do this even U
we'll do it this way way let's do
10 10 x 10 icon and then you have your
three colors you so creates quite a
large array there for doing pictures and
stuff like that when you add that third
dimension
in um if we take that off it's a little
bit easier to
see U we'll do 10
again and you can easily see how we have
10 rows of 10
ones and you can also so do something uh
like create an
array and we'll do 0 one
2 and then in this array um we actually
print it right out we want a repeat so
you can actually do a repeat of the
array and maybe you need this array um
let's repeat it three
times so there's our repeat of an array
repeat three
times and if we run this you'll see we
have 00001
111222 and whenever I think of a repeat
I don't really think of repeating being
the first digit three times the second
digit I really always think of it as um
012 012 012 it catches me every time uh
but the actual code for that one is
going to be tile uh and again if we do
arrange
three and we run this you can see how
you can generate one 0 1 2 012
012 and if you're dealing with um an
identity Matrix um we can do that also
if you're big on you're doing your
matrixes and we'll just
identity I guess we'll go and spill it
out today
Matrix and the command we're looking for
is um I eye and we'll do three and then
we'll just go ahead and print this out
there we go there's our identity Matrix
and it comes out by a 3X3 array because
there's our
Matrix uh and then it puts the ones down
the middle and for doing your different
Matrix math and we can manipulate that a
little bit too um we talk
about uh
matrixes we might not want ones across
the middle in which case we now have uh
the diagonal so we can do an np.
diagonal and we do a diagonal let's put
in the
diagonal one two 3 4 five and when we
run
this again this generates a value and by
just putting that value in there is the
same as putting print around it or
putting array equals and then print
array and you can see it generates a
diagonal 1 2 3 4 5 and there's your uh
your beginning of your Matrix array for
working with matrixes
and we can actually go in reverse uh
let's create an array equals remember
our
random random. random and we'll do a 5x5
array uh oops there we go five by
five just so you can see what that looks
like helps if I tpe don't mistype the
numbers which in this case I just need
to take out the brackets and there you
go you have your your 5x5 array set up
in there and we can now because we're
working with matrixes we might want to
do this in reverse and extract the
diagonals which would be the 79 the 678
and so
on and we simply type in np.
diagonal we put our array in there um
and this will of course print it out
because it returns it as a variable and
you can see here here's our diagonal
going across from our
Matrix and we did talk about shape
earlier if you remember you can do um
print the shape out you can also do the
dimensions uh so in Dimensions very
similar to shape it comes out and just
has two Dimensions we can also look at
the size so if we do size on here we can
run that and you can see has a size of
25 two dimensions and of course 5x5 and
that was from the shape from earlier
that we looked at uh there's our 5x5
shape and if you remember earlier we did
random well you can all Al do uh random
I talked a little bit about manipulating
0o to one and how you can get different
answers you can also do straight for the
integer part and we'll do minus uh 10 to
10
4 and so we're going to Generate random
integers between minus 10 to 10 uh we're
going to generate four of those and so
when we run that we have 7 - 3 - 6 - 3
they're all between - 10 and 10 and
there's four of them
and now we jump into some of the
functionality of arrays uh which is
really great because this is where they
come
in here's your array and you can add tin
to it and if I run this um there takes
my original array from up
here with the integers and adds 10 to
all of those values so now we have oh
this is the decimal that's right this is
a random decimal I had stored in
Array um but this takes a random decim
the random numbers I had from 0 to one
and adds 10 to them
and we can just as easily do uh minus
10 we could even
do times
2 and we could do divide by two and it
would it'll take that random number we
generated and cut it in half so now all
these numbers are under
05 uh another way you can change the
numbers to what you need on there
and as you dig deeper into numpy we can
also do exponential so as an exponential
function uh which should generate some
interesting numbers off of the random so
we're taking them to the power I don't
even remember what the original numbers
in the um array were because we did the
random numbers up there here's our
original numbers and if you build an
exponential on there uh this is where
you get e to the X on this and just like
you can do e to the X you can also do
the log so if you're doing logarithmic
functions that reinforced learning you
might be doing some kind of log setup on
there and you can see the logarithmic of
these different array
numbers and if you're working with uh
log base
2 you can do you can just change it in
there NP log 2 you have to look it up
because this is not log 1 2 3 4 5 um it
is Log and log two uh so just a quick
note that's not a variable going in that
is an actual command there's a number of
them in there and you'll have to go look
and see uh what the documentation is but
you can also do log 10 so here's log
value
10 uh some other really cool functions
you can do with this is your sign so we
can take a sign value of all of our
different uh values in there and if you
have sign you of course have
cosine we can run that uh so here's a
cosine of those and if you're doing
activations in your numpy array and
you're doing a tangent activation uh
there's your tangent for
that and the tangent activation is
actually uh from uh neural networks
that's one of the ways you can activate
it because it forms a nice curve between
uh from whether you're generating one to
negative one uh with some discrepancy in
the
middle just jumping a little bit in
there into neural
networks and then we get into let me
just put the array back out there so
that we can see it uh while we're doing
this as we're getting into this you can
also sum the values so we have NP
sum and you can do a summation of all
the values in this array and you'll see
that if you added all these together
they'd equal
12519 so on I don't know what the whole
setup is in
there uh but you can see right here the
the summation of this one of the things
you can also do is by axes so we could
do axes equals zero and if if we run the
summation of the axis equal
zero and you can think of that uh in
numpy as the rows so that would be uh or
you can think of that in numpy as being
the columns we summing these columns
going across and you can also change
this to
one and now we're summing the
rows and so that is the summation of
this row and so forth and so forth going
down
and maybe you don't need to um know the
summation maybe what you're looking for
is the
minimum uh so here's our minimal you're
looking for and this comes up a lot
because you have like your errors we
want to find the minimal error inside of
this array and just like um the other
one we can do X is equals
z and you can see here
0.645 is the smallest number in this
First Column is 06 4 five and so
on and if you have a minimum well you
might also want to know the max maybe
we're looking for the maximum profit and
here we go you can see maximum 79 is a
maximum on this first column and just
like we did before you can change this
to a one on axes you can take the axes
out of here and just find the max value
for the whole array and the max value in
here was 8344 so on so
on and since we're we're talking data
analytics uh we want to go ahead and
look at the mean uh pretty much the same
as the average this is the mean across
the whole thing and just like we did
before we could also do axis equals
zero and then you'll see this is the
mean of this axis and so
on and we have mean we might want to
know the
median and there's our median our most
common numbers uh if we have median we
might want to know the standard
deviation
or if we have the average a lot of times
you do the means and the standard
deviation um we can run that and there's
our standard deviations along the axes
we can also do it across the whole
array uh if we're going to do standard
deviations there's also uh
variance which is your
V and there's our variant across the
different
levels and so if we looked at that we
looked at variance we looked at standard
deviation the median and the means
there's more but those are the most
common ones used with data analytics um
and going through your data and figuring
out uh uh what you're going to present
to the
shareholders and some other things we
can do is we can actually take slices uh
you'll hear that
terminology and a slice might be um like
we have a 5x5 array but maybe we don't
want the whole array maybe we want uh
from one on we don't want the zero in
there so we got up to four and maybe on
the second part we just want two to row
three and see this notation right here
says one to the end and if we run this
you can see how that generates a single
row to the end and then row two and
three now remember it doesn't include
three that's why we only get the one
column so if you wanted two and three
you would need to go ahead and go two to
four so it goes up to four we could also
do this in Reverse just like we learned
earlier we can go minus one
oops and when we go to minus one it's
the same thing because we have 0 1 2 3 4
this is the same thing as two to four
goes two to the last
one also very common with arrays is
you're going to want to sort them so we
still have our array up here that we
randomly generated and we might want to
um sort it and we'll go and throw an
axis back in there uh axis equals 1 if
we run this you can see from the axis
that it sorts it uh the point 2 being
the lowest value to the highest value by
the row we can also change this of
course to axis zero if you're sorting it
by columns so maybe your values are
based on columns and then of course you
can do the whole
array and we can sort that don't usually
do that but you know I guess sometimes
you might that might come
up and so you can see right here we have
a nice sorted array uh something else
let's just go ahead and reprint our
array so we can look at it again
starting to get too many boxes up there
uh something else you can do with an
array is we can take and transpose it
this comes up more than you would think
when you transpose it you'll see that um
the rows and the column are transposed
so where
7957 064 is a column now we've switched
it and we have 7 9.42 as the
index you can see this really more
dramatic if we take a
slice and we'll just do a slice of the
first couple and then we'll just do all
the other um the full rows and if we run
this you can see how it comes up a
little bit different and we'll just do
the same slice up here so you can see
how those two look next to each
other there we go there's our slice
run uh and so you can see the slice
comes up and it has uh 1 2 3 four five
columns now we have 1 2 3 4 five rows
and three columns versus three
rows and the original version when they
first started putting this um together
uh was a function so the original
version was transpose and this still
works you can still see it generates the
same value as just a capital T so many
times we flip this data because we'll
have an XY value or we'll have an image
or something like that and it's being
read one way into the next process and
the next one needs it the opposite uh so
this actually happens a lot you need to
know how to transpose the data really
quick and we can go ahead oh let's just
take um here's our transpose we'll just
stick with the transpose on here and
instead of uh doing it this way we might
need to do something called flattening
why would you flatten your data uh if
this is an array go going into a neural
network you might want to send it in as
one set of values instead of two rows
and you can see here is all the values
as a single array it just flattens it
down into one
array so we covered our scientific uh
means transpose median um some different
variations on here some of the other
things we want to do is what happens if
we want to pin to our array uh so let's
create a new array getting tired of
looking at the same set of random
numbers we generated earlier um so we'll
go and create a new array here something
a little simpler so it's easier to see
what we're
doing and four five six
78 uh that's good enough we just do four
five six
S8 and if we print this
array there it is four five 6
78 and we might want to pend something
to the array so we have our array we
need to extend it you got to be very
very careful about appending things to
your array and there's a number of
reasons for that uh one is runtime
because of the way the numpy array is
set up a lot of times you build your
data and then push it into the numpy
array instead of continually adding on
to the array um and then it also usually
it automatically generates a copy for
protecting your data so there's a lot of
reasons to be careful about appending
this way uh but you can certainly do it
and we can just take our array we're
going to create a new array array one
and if we print array one and we append
eight to it you'll see four five six 7
and then there's our eight appended on
to the
end and if you want to appin something
to an array um you'd probably also want
to
whoops array one let's try that again
there we go now we have the eight
appended on to the end um so you can see
four five six seven eight and then we
pined another eight on there
and if you're going to append something
you might want to um go ahead and insert
instead of appending it might be you
need to keep a certain order and we can
do the same thing we do our
array um and we're going to pin or
insert at the beginning and let's go
ahead and insert uh one two three one
two 3 and we go ah and print our array
to we run it and you can see one two
three a pin is inserted at the beginning
uh inserts a lot more powerful and that
you can put it anywhere in the array we
can move it to the one spot and there we
go one two three uh we can do a minus
one just for fun and you'll see it comes
up uh one two three we're counting
backwards by one I imagine you can do a
minus
0 and run this and it turns out that
minus 0 puts it back at the beginning
because that's why it registers a zero
just takes a minus sign
off and just like we add numbers on we
might want to delete numbers and so uh
let's do an np. delete Well's let's keep
it a little bit make it a little easy
here um to watch we'll go and create an
array three and we'll do NP delete we
were just working with array uh
two and what we want to do is delete
zero space uh so if you look at this
here's our array two array two starts
with one and when we delete the space on
here and print that out uh we deleted
the one right out of
there and we can also do something like
this where we can do it as a slice and
we can do let's do one comma 3 and if we
run one comma 3 you'll see we've deleted
the one space and the three space out
which deleted our two and
four now keep in mind when you're
messing with um adding lines and
deleting
lines uh you have to be really careful
because there's a time element involved
um as far as where the data is coming
from and it's really easy to delete the
wrong data and corrupt what you're
working on or to insert stuff where you
don't want it um so there always a
warning when we talk about manipulating
numpy
arrays and just like anything else we're
doing uh we'll create an array C which
equals we'll just do our um our numpy
array that we just created oury array
three and we can do copy so you can make
a copy of it um maybe you want to
protect your original data or maybe
you're making a mask and so you copy the
array and then the new array make all
these alterations and change it from
values to 0er to one to mask over the
first one and of course we if we do um
array C since it equals a copy of uh
array three it's the same thing 1 3 5 6
7
8 and now we're getting into uh combine
and split arrays I end up doing a lot of
this
and I don't know how many times I endend
up fiddling with this and having a mess
uh so but but you do it a lot you know
you combine your arrays you split them
you might need one set of data for one
thing another set of data for the
other so let's go a and create two
arrays array one array 2 and I want you
to
note and the terminology we're going to
look for is concatenate what that means
is we're going to take um we'll call
this a ray cat I like a ray cat here we
go um our array cat or concatenated
array we're taking array one and two and
it's very important to really pay
attention to your axes and your counts I
can't merge two arrays that have like if
their axes are messed up and I'm merging
on axis zero it's going to give me an
error and I'll have to reshape them so
you got to make sure that whatever
you're concatenating together works and
what that means
as you can see here we have 1 2 3 4 1 2
3 4 and then 5 6 78 5 6 78 along the
zero axis these each are four values um
so it's a 2x4 value and if we go ahead
and switch this to one you can see how
that's that flips it a little bit so now
we have 1 2 3 4 5 6 7even
8 it's interesting that we chose that
one if I did something like
this where this is
now there we go and we concatenate it um
run this and it gives me an answer okay
because I have two by two and I'm using
axis one but if I switch this to axis
zero where now it's got three and
five it gives me an error so you got to
be really careful on that to make sure
that your whatever axes you are putting
together that they match um so like I
said this one oops axis one axis one has
two entities and since we're going on
axis one or by row you can see that lets
it merge it right onto the end there and
you could imagine this if this was a XY
plot of value or the x value going in
and the predicted yvalue coming out and
then you have another prediction and you
want to combine them this works really
easy for that we'll go back and let's
just put this back to where we had
it oops I forgot how many changes I made
there we go 'll just put it Oops I
messed up in my concatenation order here
uh
there we
go okay so you can see that we went
through the different concatenation axes
is really important when you're doing
your concatenation values on here we'll
switch this back to one just because I
like the looks of that better there we
go two
rows now there are other commands in
here um so we can do uh cap V
equals
npv v stack this is nothing more than
your
concatenation uh but instead we don't
have to put the axes in there uh because
it's v stands for vertical and so if we
print out
cat V and we run this you can see we get
the 1 two 3 4 1 2 3 4 and that would be
the same as making this axis zero for
vertical stack and if you're going to
have a vertical stack uh you can also
have an H
stack so if we change this to from v
stack to oops here we go H stack and
we'll just change this from cat to cat
and I run
this it's a same as doing axis zero the
process is identical in the background
um this is like a legacy setup uh your
vstack in your H stack most people just
use concatenate and then put the axes in
there cuz it's much uh has a lot more
clarity and um is more more commonly
used
nowadays the last section in numpy we're
going to cover uh
is is kind of uh data exploration um and
that'll make a little bit more sense
than just a moment they sometimes they
call them set operations but let's say
we have an array 1 2 3 4 5 6 3 whatever
it is uh you we generate a nice little
array here and what I want to go ahead
and do is find the unique values in that
array uh so maybe I'm generating what
they call a one hot encoder and so these
values then all become I need to know
how long my bit array is going to be so
each word how many how many each word is
represented by a number and then I want
to know just how many of those words are
in there if we're doing word count very
popular thing to
do um and you can see here when we do
unique uh we have 1 2 3 4 five six those
are our unique values
uh some of the things we can do with the
unique values is we can also instead of
doing just unique we can do
uniques our unique values and counts of
each unique value and this is very
similar to what we just did up here
where we uh were're doing NP unique uh
but we're going to add a little bit more
into
there and it's just part of the
arguments in this and we want to do
return counts equals true so in instead
of just returning the unique values uh
we want to know how many of those unique
values are in each one and we'll go
ahead and
print our
uniques and
print our
counts let we run that uh you can see
here we have our unique value 1 2 3 4 5
six just like we had before and then
there's two of the first of two ones two
twos two 3es two fours one five two
sixes and so on and you can go through
and actually look at that if you want to
count them um but a quick way to find
out your um distribution of different
values so you might want to know how
often the word the' is used versus the
word and if each word is represented as
a unique
number and along the set variables we
might want to know um let me just put a
note up here we're going to start
looking
at uh
intersection and we might want to also
know different
differentiation and
neither so when we're oops
neighbor neither um so what we're
looking at now is we want to know hey
where do these two arrays intersect and
we have 1 2 3 4 5 3 4 5 6 7 we might
want to know what is common between the
two
arrays um and so when we do that we have
um NP
intersect and it's a ond array
onedimensional
array and then we need to go ahead and
put array uh one array
two and if we run
this we can see they intersect at 3 4
five that's what they have
common uh and because we're going to go
ahead and go through these and look at a
couple different options let's change
this from intersect
1D and we'll do the same thing we go and
print this so we might want to know the
intersection uh where they have
commonalities another uh unique word is
Union of 1D uh so instead of uh
intersect we want to know all the values
that are in both of them so here's our
Union of 1D when we run that you can see
we have 1 2 3 4 5 6 7 so it's all the
different values in
there and the last one of the last words
we have two more to go uh is we want to
know what the set set difference
is uh and so that's where the you'll see
if you remember set we talked about that
being the what they call these things um
so the set
difference of a 1D array when we run
that you can see that one is only in one
array and two is only in one
array and if we want to know uh what's
in Array one but not in Array two we
might want to know what is in Array one
but not two and what's in two but not
one
uh and this would be the set X or 1D on
here uh so we have the four different
options here where we can do an
intersection what do they both have in
common uh we can do a union what are all
the unique values in both arrays we can
see the difference what's in Array one
but not array two so set diff 1D and
then set X or what is not in one but is
in two and what is in not in two but in
one
so we dug a lot in numpy because we're
talking um there's a lot of different
little mathematical things going on in
numpy a lot of this can also be done in
pandas although usually the heavy
lifting is left for numpy because that's
what it's designed for let's go ahead
and open up another Python
3 setup in here and so we want to
explore uh what happens when you want to
display this this is where it starts
getting in my opinion a little fun
because you're actually playing with it
and you have something to show people
and we'll go ahead and rename this we're
going to call this uh
pandas uh and pip plot so pandas pip
plot just so we can remember for next
time and we want to go ahead and import
the necessary libraries we're going to
import pandas as PD now remember this is
a data frame so we're talking rows and
columns and you'll see how uh pandas
work so nicely uh when you're actually
showing data to people and then we're
going to have numpy in the background
numpy works with pandas uh so a lot of
times you just import them by
default caborn sits on top of the map
plot Library uh so sometimes we use the
Seaborn because it kind of extends it's
one of the 100 packages that extends a
matplot library probably the most common
used because it has a lot of built-in
functionality um almost by default I
usually just put caborn in there in case
I need it and of course we have uh map
plot Library as pylot as PLT and note we
have as PD as NP as SN SS PLT those are
pretty standard so when you're doing
your Imports I would probably keep those
just so other people can read your code
and it makes sense to them that's pretty
much a standard
nowadays and then we have the strange
line here uh says uh amber sign matplot
Library
inline that is for Jupiter notebook only
so if you're running this in a different
package you'll have a popup when it goes
to display the matplot library um you
can with the most current version of
Jupiter usually leave that out and it
will still display it right on the page
as we go and we'll see what that looks
like and then we're going to go ahead
and just uh do the um caborn the SNS
doet and we're going to set the color
codes equals true let them uh just keep
the default on so we don't have to think
about it too
much and we of course have to run this
um the reason we run this is because
these values are all set if we don't run
this and I access one of these um
afterward it'll it'll crash the cool
thing about Jupiter uh notebooks is if
you forgot to import one of these you
forgot to install it because you do have
to install this under your anaconda
setup or whatever setup you're in you
can flip over to Anaconda and run your
install for these um and then just come
back and run it you don't have to close
anything
out and we'll go ahead and paste this
one in here real quick where we have car
equals pd. read CSV and then we have uh
the actual path this path of course will
vary depending on what you are working
with uh so it's wherever you saved the
file at and you can see here I have um
like my one drive documents simply Learn
Python data analytic using python slash
car CSV it's quite a long
file when we' open that up what we get
is we get a CSV file and we have the
make the model the year the engine fuel
type uh engine horsepower cylinders and
so on um and and this is just a comma
separated file so each row is like a row
of data think of it as a um
spreadsheet and then each one is a
column of data on here and as you can
see right here it has the uh make model
so it has columns for a header on
here now your pandas just does an
excellent job of automatically pulling a
lot of this in so when you start seeing
the pandas on here you realize that you
are already like halfway done with
getting your data in I just love pandas
for that reason numpy also has it you
can load a CSV directly into numpy um
but we're working with pandas and this
is where it really gets cool is I can
come down here and I can print uh you
remember our print statement we can
actually get rid of it and we're just
going to do car head because it's going
to print that out the head is going to
print the top values of that data file
we just ran in and so you can see right
here it does a nice print out it's all
nice and line because we're in Jupiter
notebook I can scroll back and forth and
look at the different data uh and just
like we expected we have our column and
brought the header right in one thing to
note is the index it automatically
created an index 0 1 2 3 4 and so on and
we're just looking at the head so we got
0 1 2 3
4 um you can change this you might want
to just look at the top two we can run
that there's our top two
BMWs um another thing we can do is
instead of head we can do
tail and look at the last three values
that are in that data file and uh you
can see right here it numbered them all
the way up to
11,910 oh my goodness they put a lot of
data in this file I didn't even look to
see how big the file was uh so you can
really easily get through and view the
different data in here when you're
talking about Big
Data you almost never just print out car
um fact let's see what happens when we
do if we run this and we just run the
car it's huge uh in fact it's so big
that the pandas automatically truncates
it and just does head plus tail so you
can see the two um so we really don't
want to look at the whole thing I'm go
and go back to we'll stick with the head
displaying our data there we go so
there's the head of our data it gives us
a quick look to see what's actually in
there um I can zoom out if we want so
you actually get a better View
although we'll keep it zoomed in so you
can see the code I'm working
on and then from the data standpoint we
course want to look at um data types uh
what's going on with our data what does
it look like uh now this you know you
show your when you're talking to your
shareholders they like to see these nice
easy to read charts they look like a
spreadsheet uh so it's a nice way of
displaying pieces of the
chart when we talk about the data type
types now we're getting into the data
science side of it what are we working
with well we have uh make model we have
an integer 64 for the year uh engine
fuel type is an object if we go up here
you can see that there most of them are
um like you know it's a set manual rear
wheel drive uh so they might be very
limited number of types in
there uh and so forth and you it's
either going to be a float 64 an integer
or an object is the way it's going to
read it on here
and the next thing you going to know is
like your
columns and since it loaded the columns
automatically uh we have here the make
the model the year the engine the size
all the way up to the
MSRP and um just out of something you'll
see come up a lot is whenever you're in
pandas you type in values it converts it
from a pandas uh list to a numpy
array and that's true of any of these uh
so then you end up in a numpy array so
you'll see a little switch in there in
the way that the data is actually stored
and that's true of any of these uh in
this case so we want car.
columns you have a total list of your
car columns and like any good data um
scientist we want to start looking at
analytical summary of the data set
what's going on with our data so we can
start trying to um piec Mill it together
so we can do car
uh
describe and then we'll do is we'll do
include equals all uh so a nice Panda
command is to describe your data if
you're working with r this should start
looking familiar uh and we come down
here and you can see um count there's uh
make the model the year um how many of
each one how many unique values of each
one uh the top value of each one what's
most common the frequency the mean um
clearly on some of these it's an object
so it really can't tell you what the um
average is you know it' just be the top
ones the average I guess um the year
what's the average year on there um all
this stuff comes down here your standard
deviation your minimum value your
maximum value uh what's in the lower
quarter 50% Mark where's that line at
and what's in the upper 75% the top 25%
going into the max
now this next part is just cool uh this
is what we always wanted computers to be
back like in the 90s instead of 5,000
lines of code to do this maybe not 5,000
all right I built my own plot uh Library
back in 95 and the amount of code for
doing a simple plot was um I don't know
probably about 100 lines of code this is
being done in one line of code we have
our car which is our pandas we generated
that it's our data frame and we have Dot
hist for histogram that is the power of
Seaborn now it's still going to generate
a numpy graph but caborn sits on top and
then we can do the figure size this is
just um so it fits nicely on the paper
on here and we do something simple like
this and you can see here where it comes
up and it does say m plot library and
does subplots and
everything but we're looking at a
histogram of all the different pieces in
our database and we have our engine
Cinders um that's always a good one
because you can see like they have some
that are they had a null on there so
they came out at zero um maybe a couple
maybe one of them had a two-cylinder
engine away back when four is a common
uh six a little less common and then you
see the 8 cylinder uh 12 cylinder
engines Bo that's got to be a Speedster
or something uh but you can see right
here it just breaks it down so now you
have uh how many cars with how many
whatever it is cylinders horsepower uh
and so on and it does a nice job
displaying it you can see if you're
working with your uh um you're going
into your uh demo it's really nice just
to be able to type that in and boom
there it is I can see it all the way
across and we might want to zero in uh
and use like a box plot and this time
we'll go ahead and call the um caborn
SNS box plot and we're going to go ahead
and do um vehicle size versus um engine
horsepower X y+ plot and the data comes
from the car so if we run this we end up
with a nice box plot you see our midsize
Compact and large you can see the
variation there's our outlier showing up
there on the compact that must be a
high-end sports car uh large car might
have a couple engines and again we have
all these outliers and then your
deviation on
them very powerful and quick way to zero
in on one small piece of data and
display it for people who need to have
it reduced to something they can see and
look at and understand and that's our
caborn boxplot or SNS dobox
plot and then if we're going to back out
and we want a quick look at um what they
call pair plotting uh we can run that
and you can see with the caborn it just
does all the work for you uh it takes it
just a moment for it to pull the data in
and compile
it and once it does it creates a nice
grid um and this grid if you look at uh
this one space here which is you might
not be able to see the small number says
engine horsepower this is engine
horsepower uh to the year was built and
it's just flipped so everything to the
right of the middle diagonal is just the
rotation of what's on the left and as
you expect um the engine horsepower um
gets bigger and bigger and bigger as
time goes on so the the year it was
built further up in the year the more
likely you are to have a heavy
horsepower engine
and you can quickly look at
Trends with our uh pair plot coming up
uh and look how fast that was that was
it took it a c you know a moment to
process uh but right away I get a nice
view of all these different um
information which I can look at visually
and and kind of see how things group and
look now if I was doing a meeting I
probably wouldn't show all the data
um one of the things I've learned over
the years is um people myself included
love to show all our work you know we
were taught in school show all your work
prove what you know the CEO doesn't want
to see a huge uh grid of of graphs I
guarantee it uh so we want to do is we
want to go ahead and
drop um the stuff that might not be
interested in and we're going to I'm not
really a car person guing the back is
obviously so you have your engine fuel
type we're going to drop that we're
going to drop Market category vehicle
style popularity number of doors vehicle
size
um and we have the axes in here if you
remember from numpy we have to include
that axes to make it clear what we're
working on that's also true with pandas
and then we'll look at just what it
looks like um from the head and you can
see that we dropped out those categories
and now we have the make model year uh
and so forth um and we took out the
engine fuel type Market category
Etc uh and this should look familiar to
you now when you start working with
pandas I just love pandas for this
reason look how easy it is it just
displays it as a nice um uh spreadsheet
for you you can just look at it and view
it very easily uh it's also the same
kind of view you're going to get if
you're working in spark or P spark which
is python for spark across Big Data this
is the kind of thing that they they come
up with this is why pandas is so
powerful and we may look at this and
decide we don't like these columns and
so you can go in here and we can
actually rename the
columns simple command car equals car
rename uh columns equals engine
horsepower equals
horsepower this is just your standard
python
dictionary um so it just Maps them out
and you know instead of having like a
lengthy here we had U engine horsepower
we just want horsepower we don't need to
know it's the engine horsepower engine
cylinders we don't need to know that
it's for the engine because there's only
one thing we're describing if we're
talking about cars and that
cylinders uh we go ahead and just run
this and again here's our car head and
you can see how that changed we have
model year and horsepower versus model
year engine horsepower engine cylinders
just
cylinders again we want to keep reducing
this so it's more and more readable the
more readable you get it the better um
and of course we can also adjust the
size a little bit so that when it prints
out instead of splitting it on two lines
we get like a single line we can do that
also that's just your control mouse up
or plus sign you use in Chrome that's a
chrome
command and if you remember from numpy
we had shape well pandas works the same
way uh we can look at the shape of the
data so we now have um
11,914 rows and 10 columns uh so you see
some similarities because pandas is
built on
numpy and questions that come up just
like you did in numpy we might want to
know duplicate rows and so we can do car
and look at this switch here um we're
doing a selection this is a panda
selection with the brackets but we want
to select it based on car. duplicated so
how many duplicates on
there so it's starting to look a little
bit different as far as how we access
some of the data on here this can be a
logical statement and we get the number
of duplicate rows we have 989 rows by 10
columns
again and this is one of those
troubleshooting things that we end up
doing uh a lot more than we really feel
like we should uh we might go ahead and
do like a car count uh just to see how
many rows we're dealing with and then
right after that we might want to go
ahead and say hey um let's drop
duplicates so remember we did all the
duplicates on there so car equals car.
drop duplicates and then we can print
the head again we'll just do car head
here and you can see the data on there
um looks the same as
before uh and just note that we did car
equals car drw duplicates
there are commands in here where you can
do where it changes the actual value and
it works on some of them and not on
others depending on what you're doing
but by default it always returns a copy
so when we do this we're reassigning it
to car and you can see it's the same
header but we want to go ahead and do
count and see how the count changes
let's go ahead and run this and you can
see here instead of 11914 we have
10,925 uh so we've removed about 100 car
they were duplicated just slightly under
100
there and then as we're prepping our
data we might want to know um car is
null uh so it's going to count the
values of null and then we want to sum
that up and when we do that uh we do the
car is n function. suum uh we end up
with uh HP the horsepower is 69 have
null values and 30 have cylinders have
null values now if you don't put the sum
at the end it's just going to return a
mask with the true false of is it null
or is it not by zero and one so you're
summing up the ones underneath each
column and this of course uh then you
have to decide what you're going to do
with the uh null values there's a lot of
different options it might be that you
need to put in the average or means uh
maybe you want to put in the median
value um there's a lot of different ways
to fill it usually when you first start
out with the data a lot of them you just
drop your null values and you can see
here car. drop na which is equal to all
and then we're going to go ahead and
count it and you can see that we've
dropped almost another hundred values so
from 10 9 25 2 10
827 and maybe 75 or so values uh so we
clean this is really a big part of
cleaning data you need to know how to
get rid of your null values or at least
count them and what to do with them and
of course if we go back to um uh
counting our null values we should now
have uh null null values there we go and
you'll see there's zero null values I
don't know how many times I've been
running a model that doesn't take null
values and it crashes and I just sit
there and look at it trying to why did
that crash it should have worked uh it's
because I forgot to remove the null
values so we've been jumping around a
lot we're going to go back to uh finding
outliers and let's go ahead and bring
that back into our Seaborn and if you
remember we did a box plot earlier uh
this time we're going to do a box plot
just on the price and you can see here
um our price value and we have the
deviation with the two thinner bars on
each side of the main value and then as
we get up here we have all these
outliers um in fact we have one way out
here that's um probably a really
expensive high-end car is what we're
looking
at if you were doing um fraud analysis
you would be jumping on all over these
outliers why are these deviation from
the standard what are these people doing
again this is probably like I said a
really high-end expensive car out here
that's what we're looking at and we can
also look at the um box plot for the
horsepower we'll put that in down
here and run that and you can see again
here's our horsepower and it just jumps
and there's these really odd huge muscle
cars out here that are
outliers and we're going to jump into
making this a little bit more um as you
start displaying your data or your
information to your shareholders uh
we're going to look at plotting a
histogram for the number of cars per
brand and the first thing we want to go
ahead and do is we have with our car go
back over here here we go uh we have our
make value counts largest plot um and we
want to do a kind equals bar uh figure
size
105 and right off the bat we jump up
here we see Chevrolet it's going against
what was it it's um figure the value
counts and we want the largest value so
here's our value counts and compared to
what the different cars are Chevrolet
puts out a lot of different kinds of
cars I didn't realize that they made
that many cars or different types and
then for readability uh let's go ahead
and add a title number of cars by make
number of cars and make if you had
looked at this the first time you would
have been like well what the heck am I
looking at well we're looking at the
number of cars by make and then you can
see here now we're talking about the
type of cars and the different uh ones
were put out Lotus I guess only had a
few different kinds of cars over there
very high-end
cars and then as a doing data analytics
and as a data scientist one of the
things I am most interested in is the
relationship between the
variables uh so this is always a place
to start we want to know what's going on
with our variables and how they connect
with each other uh so the first thing
we're going to do is we're going to go
ahead and set a figure size because we
want to make sure it fits our graph um
we'll just go ahead and set this one
plot Figure Set to figure size 20110 if
you never used the matap plot Library
which is sitting behind Seaborn uh
whatever is in the PLT this is what's
loaded it's like a canvas you're
painting on so the second you load that
uh pip plot as PLT anything you do to
that is affecting everything on
it uh and then we want to go ahead uh
since we're using
caborn we'll go ahead and create a
variable C for relationships or
correspondence and car. Co RR that's a
correlation in Seaborn on top of pandas
again one line and you get the whole
correlation on there and because we're
working with Seaborn let's put it into a
nice heat map if you're not familiar
with heat maps that means we're just
using color as part of our um uh setup
so we have a nice
visual and we can see here that the
caborn connected to the pandas prints
out a nice chart we'll talk a little bit
about the color here in a second it
prints out a nice chart this is a chart
I look at as a data scientist these are
the numbers I want to look at uh and
we'll just highlight one of them um
here's cylinders versus horsepower the
closer to one the higher the correlation
so 788 pretty high correlation between
the number of cylinders how heavy the
horsepower
is I'm betting if you looked at the year
versus uh horsepower we just look at
that one here's year and horsepower 314
not as so much but if you combine them
uh you don't actually add them but if
you combine them you'll start to see an
increase in Horsepower per year in
cylinders you could probably get a
correlation there and just like 78 is a
positive correlation uh you might notice
if we look at
cylinders and or let's look at
horsepower and mileage uh so if we go
here to horsepower to mileage you get a
nice um negative we'll do cylinders
that's a bigger number with cylinders to
the miles per gallon it's a minus. 6 so
it's a negative correlation the closer
to minus1 the more the negative
correlation
is and then the chart you would actually
show people is a nice heat map this is
all our colors and it's just those
numbers put into a heat map the darker
the color the higher the correlation you
can can see straight down the middle um
obviously the year correlates directly
with the year horsepower with horsepower
and so on that's why it's a one the
closer to the one the higher the
correlation between the two pieces of
data now this is a good introduction uh
pandas goes Way Beyond this most the
functionality in numpy since Panda sits
on it is also in pandas and then it even
has additional features in it and we use
Seaborn pretty extensively sitting on
top over our P plot uh so keep in mind
that our High plot has a ton of other
features in it that we didn't even touch
on in here uh we couldn't even if you
had a sole course in it uh there's just
so many things hidden in there depending
on what your domain you're working on uh
but you can see here here's our Seaborn
and here's our Matt plot Library that's
all our Graphics that we did and then
the Seaborn worked really nicely with
the pandas U we really like that so that
wraps up our demo part for today let's
learn about data manipulation in R and
here we will learn about deer package
and when we talk about this deer package
it is much faster and much easier to
read than base R so depler package is
used to transform and summarize tabular
data with rows and columns you might be
working on a data frame or you might be
getting in a inbuilt r data set which
can then be converted into a data frame
so we can get this package deer here by
just calling in library function and
this can be used for grouping by data
summarizing the data adding new
variables selecting different set of
columns filtering our data sets sorting
it selecting it arranging it or even
mutating that is basically creating new
columns using functions on existing
variables so let's see how we work with
deer now here I can basically get the
package here so I can just say install.
packages deer now we already see the the
package here which is showing up so I
will just select this one I can do a
control enter and that will basically
set up the package package deer
successfully unpacked so that is done
now you can start using this package by
just doing a library deer and this was
built it shows me my version of R so
let's also use a inbuilt data set that
is New York flights 133 so we can do
install. packages and that will search
and get that relevant data set I can
again Call It by using Library function
now once that is done we can look at
some sample data here by just doing view
flights and that shows me the data in a
neat and a tabular format which shows me
year month day departure time schedule
departure time and so on now now we can
also do a head to look at some initial
data which can help us in understanding
the data better so what is this data
about how many columns we have what are
the data types or object types here it
shows me how many variables we have so
this is fine now we can start using deer
and in that we can use Save filter
function if we would want to look in for
specific value now here we have the
column as month so I will do a filter
now I'm creating a variable F1 I'm using
the filter function on flights which we
already
have and then what we can do is we can
basically look at the month where the
month value is
07 so let's look at that and this one
you can do a view on F1 which shows me
the data wherein you have filtered out
all the data based on month being seven
so this is a simple usage of filter we
can take some other example we may want
to include multiple columns so we can
say F2 filter flights and here we will
say month is equal to 7 day is three and
then look at the value of F2 if you are
interested in seeing
this and that tells you the month is
seven and day is three you could also
look look into a more readable format by
using view on F2 and that gives me my
selected result so we are just
extracting in some specific value we can
keep extending this so here we can say
flights is what we would want to work on
I'm using the filter function so I can
straight away instead of creating a
variable then then doing a view I can
also do a view in this way I can just
pass in my filter within the view and
within this I'm saying filter I would
want to look at the flights month being
09 day being two and origin being
lgaa and then that shows me the value
here and obviously you can scroll and
look at all the columns and if you see
the origin column it shows the selected
value so now we have filtered our our
data based on values in three different
columns now what we can also do is we
can use and or we can use or operators
so I could have done this in a a little
different way so I could have said head
which shows me initial result I will do
a flights so within my head function I'm
passing in this and what does that
contain so you are saying flights and in
this flights data set you would want to
pick up the month being the column so we
use the dollar symbol here we given a
value and I'll say and and I'll again
say flights wherein I will select the
day being two and and and remember when
you talk about and it is going to check
if all the values are met true so then
you say flight's origin LG a and you
look at the value so in this way I can
filter out specifically multiple values
by specifying columns now we could have
done it in this way we could have
created a view or we could have assigned
this to a variable and then done a view
on that where we could have selected
month being day and origin or you can be
more specific in specifying all the
columns it makes the code more readable
so let's look at the values and here you
are looking at head which shows me based
on month day and then you can look for
further columns for other variables that
is origin being LGA now what we can also
do is we can do some slicing here to
select rows by particular position so I
can say slice and I would want to look
at rows 1 to 5 and I can do this so you
can always assign or look at the view of
this I can just do here so when I did a
slide 1 is to 5 it shows me my entries
for 1 to 5 now similar L we can do a
slice 5 to 10 and now you're looking at
5 to 10
values so you can always look at the
complete data and then you can slice out
particular data now mutate is usually a
function which is used when you would
want to apply some variable on a
particular data set and then you would
want to add it to your existing data
frame or you would want to add a new
column so this is where you use mutate
which is mainly used to add new
variables so let's see how you you work
on mutate so it's pretty simple so you
create a variable over delay now I would
want to do a mutate so that it adds a
new column so I'm selecting my data
which is flights I will call the new
column as overall delay and then
basically I can look at overall delay
being arrival delay minus departure
DeLay So let's create this and let's
look at view of this which shows me or
which should show me my new column which
is overall delay which was not in my
original data set so you can anytime do
a head on this one to compare the value
so this one shows me arrival delay and
then there are many other variables what
you can also do is you can do a view and
you could have have just look at flights
if you would want to compare so you can
look at the flights and this one would
not have any overall delay column so it
basically shows me 19 columns only what
we see here and if
you do a view on overall delay then that
basically shows me 20 column so we know
that the new column has been added to
this overall delays so if you would want
to work with 20 columns you will use
overall delay if you would want to work
with your original data set you will use
flights now you can also use a transmute
function which is used to show only the
new column so we can do a overall delay
and at this time we will say transmute
we will say flights overall delay the
computation remains same but at this
time if I look at view on overall delay
it only shows me the new column so
sometimes we may want to compute result
based on two variables or two columns
and just look at the new value and then
we can decide if we would want to add it
to our existing structure now you can
also use summarize and summarize
basically helps us in getting a
summary based on certain criteria so we
can always do a
summarize and what we can do is we can
look at our data and we can say on what
basis we would want to summarize this
particular data so we can do a summarize
function now summarize on flights I will
say average a time and I would want to
calculate an average so for that I'm
using in build function called mean I
will do that on airtime
column so let's look at flights once
again and here we can see there is
arrival time not air time sorry arrival
time and we would want to do some
average on this particular data we would
want to summarize this so what I'll do
is I will use the summarized function I
will say average air time and this one I
will look at mean of air time so let's
see if there is a air time column I
might be let's look at this one arrival
delay and yes we have an air time so we
were actually looking at summarizing
based on air time not the arrival time
so air time is how much time it takes in
air for this particular fight and we
will want to use the trans summarize
function not the transmute so summarize
flights average air time and this one we
will calculate the mean of average a
time and I will also do a na removal
which is I'm saying true so let's do
this and that basically shows me the
average air time is
151 I can also do a total air time where
I'm doing a summation of values or I can
get the standard deviation or I can
basically get multiple values such as
mean I can say total air time where I'm
doing a summation and then I can look at
other values which is if you would want
to put in standard deviation here you
could do that so let's look at the
result of this summarize and this
basically allows me to get some useful
information which is summarized based on
a particular function such as mean sum
standard deviation
or all three of them now let's look at
grouping by so sometimes we may be
interested in summarizing the data by
groups and that's where we use the group
by function so we can always use the
group by Clause now here we are taking a
different data set so we will say for
example let's look at head of empty cars
and that is basically my data set on
empty cars now that shows me the model
of the car it shows me Mage
cylinder and your horsepower and various
other characteristics or variables in
this particular data set so here we can
say let's do a grouping by gear so there
is a column called gear so I will call
it by gear I will look at my data set
and then what I'm using here which you
see with these percentage and greater
symbol is called piping so that
basically feeds your previous data frame
into next one so this is sometimes
useful and you can get this by just
saying control shift and M and you can
then use this so we are going to have
piping so I'm saying empty cars now this
is my original data set where I did a
head or I could have done a view on this
one if you would want to see it in a
more readable format and that basically
shows me the data so we are using a
different data set so I want to group it
by the gear column so I'm going to call
it by gear and this one takes my data
that is empty cars I'm using the piping
and then I'm saying group the data based
on gear column that's done now let's
look at the value of by gear or you can
always do a view so remember whenever
you're doing a group by it is giving you
a internal object where your data is
grouped based on a particular column so
we can look at the values here you can
do a view that shows you your data
grouped based on a particular column now
I can again use the summarized function
where I would want to Now work on the
new one one where it was grouped based
on gear so I'm doing a summarize and
here I'm going to say gear one which
will be having the value of summation on
the gear column and then I'm saying gear
two which is mean well you could give
some meaningful names to this and let's
look at the value of this one where we
are basically now looking at the values
which is sum and mean values based on
the gear
similarly we can use look at different
example so we can say by gear and I'm
again using
piping but earlier we had taken gear we
had grouped the data and we called it by
gear so we took our original data set
empty cars but now within this
particular data which was grouped by
gear I will take this data set I will
use the piping and I will summarize it
where I saying within this part
particular data set I would want to get
the sum or I would want to get the mean
and then you can look at the values so
what you're doing is you are either
looking at your original data set or
you're looking at the data which was
already grouped and then you can look at
the values now here what we can do is we
can Group by cylinder say might be you
are interested in looking at data which
is summarized based on the cylinder
column you can do that and then for this
by cylinder I'm doing a piping where I'm
using the summarize function and
summarizing will then be done based on
the mean values of the gear column or
the horsepower so let's do this and then
you can basically look at the value at
any point you may want to look at the
data set again so just do ahead and you
can look at what does the value contain
and by cylinder or by gear and do a head
and it gives you the value so you can
always do some summarizing or grouping
in these ways now here we are going to
use sample uncore n function and Sample
underscore fraction for creating samples
so for this let's take the flights data
set again and we would want to get 15
random values now that is done and it
shows me 15 row with some random values
from the data what you can also do is
you can do a portion of data by using
sample under score fraction and here
I'll say flights I'll say 04 which will
return 40% of the total data so this can
be useful when you are building your
machine learning where you would want to
split your data into training and test
might be you are interested in some
portion of the data so you can do this
which is very useful function function
and then you can look at the value of
that
now what we can also do is we can use
arrange function so like we were doing a
grouping by or we were trying to pull
out a particular column so in the same
way we can use arrange which is a
convenient way of sorting than your base
are sorting so for arrange function lets
do a view based on arrange so we will
work on the flights data set which we
have and here what we would want to do
is we would want to arrange the flights
data set which is based on year and
departure time and we are doing a view
out of it so that basically gives me the
data which is arranged based on your
year and departure time now I can do a
head to give me some highlighting of
that data now the piping of operator
what we are using can be used in these
ways also so here I will say DF I will
just assign the data set Mt cards to it
let's look at the DF which has basically
your different models you can obviously
look at the head or view of it to look
at useful information we can also go for
nesting options which can be useful so
we are creating a variable called result
here now that has the arrange function
so what does this arrange function do so
when we would want to use arrange to
sort the data so I would want to sort
the data but what data would I sort so I
will use sample n which will give me
some portion of the data or some sample
data now what is that sample data so
here we are using nesting that is
earlier when we did a sample we just
said data and how many random samples we
want but instead of giving that what we
are going to do is we are going to use
filter here now this filter will work on
DF so filtering will happen based on the
mileage which is greater than 20 I will
say size is five and I would want to
basically arrange this in a descending
order so I'm using the desk on this
particular mileage column by default it
is always ascending so let's get the
result out of this
which will basically show me the mileage
details in a descending order so this is
my data frame and now we can look at the
result what we have created so just do a
view or do a head and look at the view
so here you see mileage where the
highest value is on the
top and we were only interested in five
values in a random sample so that's why
when you did a view it shows your five
values and it shows in a descending
order based on mileage so we have not
only used an inbuild function we have
not only arranged the data that is we
have sorted the data but we have sorted
the data based on a descending order on
a particular column we have said the
value should be greater than 20 and we
have also said we just need five random
samples now let's look at some other
examp examples so you can always do a
multi- assignment so I can say filter
wherein I'm going to use DF which was
assigned empty cars I'm going to say
mileage should be greater than 20 then I
say B which is going to get a sample out
of a and I just want five random values
so let's look at that so we have B which
is going to get a set of five values
from a now I will create a result
variable which will arrange B which is
sample data in a descending order now
let's look at the result of this and
that basically shows me what we were
seeing earlier so you can do a multi-
assignment where you can create a
variable get a sample out of it and then
basically whatever is that result you
can arrange that or sort that in a
descending or by default descending
order so same thing we can do it using
pipe operator so piping so here I will
say result I'm passing in my DF that's
the data set I'm using piping and which
basically tells what you need to do on
this particular data set so I'm going to
filter out the data based on mileage 50
sorry mileage 20 then I'm going to push
that or forward it to get the random
sample and whatever is this random
sample is going to be pushed so you you
are arranging this in a descending order
so this is one more way of doing it and
then basically you can look at the
result so these are some simple examples
where you can use your deer with
multiple assignments or using your
nesting to filter out the data you can
also do a range which is to sort the
data you can get some random samples out
of it you can summarize the data you can
also summarize the data based on one or
two or M multiple columns and you can
use some inbuilt functions to summarize
the data based on some functions which
are applied on the variables are on the
columns you can transmute it where you
would be interested in only looking at
one column you can mutate it where you
want to add a new column you can slice
it and you can give the conditions where
you can say and and or to filter out the
data so what we can also do is on this
particular data set which we have say
for example DF where I have my data
let's look at this one and if I just do
a DF at this point it shows me my data
set and if you would be interested only
in particular column then your deer also
allows you to either we can do a filter
or we can simply do a select now for
selecting we can
choose uh our data so for examp example
I'll say DF underscore I'm interested in
mileage I'm interested in Horsepower
might be I'm interested in your
cylinders in this and for this one what
I can do is when I would want to do a
select I can basically say selected DF
let's call it some name I can say
control shift M which is for piping and
then basically what you can do is you
can do a select and you can choose your
columns so I was interested in mileage I
was interested in
Horsepower I was interested in cylinder
and here what I'm doing is I'm using a
select where I can look at the new data
frame so let's do this and uh I'm sorry
here we will have to give it DF this is
where your you're are passing in your
data yeah now this one is done and we
can look at the value of this one by
just doing a DF or head on
DF underscore mileage horsepower
cylinder and look at the selected result
so you can be looking at selective
columns I could have done this filter
but filter will always look for a
condition say your mileage is greater
than 20 or might be your cylinders are
more than four or something else but
when you do a select you are selecting
specific columns so view always gives
you all the columns head gives you
highlight but then select can be useful
when we are interested in looking at
only specific data so this is how you
can use deer for manipulation for your
data transformation for basically
filtering out the data by selecting
particular data and then working on it
with today's topic which is about how to
create powerbi dashboard in a few
minutes Yes you heard me right you can
create a complete powerbi dashboard or
also known as a report in just a few
clicks and a few minutes now in this
particular video we are minimizing the
time in creating dashboard because
sometimes data cleaning process you
already know if you're an expert or if
you are a beginner in data analytics you
already know there are steps steps in
data report or dashboard right first you
load the data from a source it can be
Cloud PDF Excel workbook CSV or anything
and after that you do some data cleaning
right you split the columns or you
eliminate some blank rows blank colums
and some irrelevant data which does not
fit or some um for more reference on
data cleaning you can also refer to the
video which is Link in the description
box below and so right that's the
process so basically you import the data
from The Source clean it transform it
and then load it and then create a
dashboard right so in this particular
video we have the completely cleaned
data set which is really available for
creating report which will be also
linked in the description box below if
you want to follow us along so um with
that uh let's get started right so
that's how it goes now let's have a look
at our data so our data has um some row
ID order ID a date ship date so
basically you can totally understand
this particular data set is about sales
report right let's say I'm working with
XYZ company which is based on data
analytics and I get an email from my
client that he or she wants to know how
exactly the sales are performing in what
exact States or countries and uh what
exact regions and what category of
products or subcategory of products and
what's the sales quantity or profit
right so let's say you have a one uh
category or subcategory or a product
which is giving you high number of sales
and profit right you want to improve
more you can increase the price or let's
say you have some product which is not
performing so well right so you can uh
offer some uh discounts let's say like
50% off so that you can move out the
product from your store right so some uh
basically if you analyze the data and
you come up to a decision where which
product is performing in which region or
state or country and which product is
performing and not performing in which
region state or country right you can
come up with a strategy for sales and
improve your Revenue so that's the
entire process right so with that said
so this is the data we have and let's
quickly jump onto powerbi and get going
with creating a report or dashboard
within a few minutes right so here we
are on the powerbi desktop so here
absolutely you can see you can import
data from Excel you can import data from
SQL Server you can import data from a
blank table or use some sample data AP
from that you can also get data from a
different sources as well right see uh
we will be trying to do some automation
right so regarding the automation we can
also uh go through another video from
simp learn which will help you
understand how to automate the process
of data transformation cleaning and
uploading so uh you can just give the
file location here the folder so I'm
going going with the folder here so it
will give me a new window uh you can go
to browse and I think I have my folder
in
downloads and uh Excel data sets um
Excel I think I'll be having that named
as
sales report yes just click okay and you
have the sales report
here you can have a quick preview of the
data so here you have the options
combine load transform data right you
can just directly load because I've said
you that this particular data set is
completely clean and is ready for
reports right so you can just select the
data you want and just load right I'm
doing it this way because let's say uh
for let's not not let's say uh we have
uh the data here in a form and in such a
form that the data is from last 3 to
four years right so let me select it
this
way so in this case as well it will take
the Excel file and uh even if you add
some more data to it it will U apply the
changes to it right so let's say uh we
have the data for the last four years
2020
209 2021 2 and 3 and since 2024 is not
completed yet we are not taking that
data let's say we enter into 2025 then
the new data for 2024 gets updated and
loaded onto the same data table and you
don't have to uh you know process the
data once again clean it transform it
load it no that's not going to happen
you can just load the data you can just
drop the data on the Excel spreadsheet
and your dashboard or report will
reflect the new changes automatically
just by refreshing the dashboard right
that's the automation you can do so what
exactly automation is the process where
human effort is not involved and the
computer or your any uh tool that's the
job for you is called as automation
which reduces a lot of time of yours and
you can use that valuable time to plan
on the strategies to improve your
Revenue right that's the overall Moto of
the data analytics now that's the uh
preview of the data I'm just going to
directly load it I'm not going to
transform it because uh it's completely
clean and transform data and ready for
reports so here you go and uh you can
close if there are my new errors you can
just close it and uh if you want to
check your data you can go to your data
here and you can have the sample data
right here right if you check the r date
not ship date sorry uh ship date can
enter into into uh 2023 as well right so
here you have 2020 and uh the other
dates right so you will have okay let's
go to the data filter so you basically
have four years not 2024 right so uh
that's the way if you just add the 2024
data it will automatically reflect in
the visualization now uh all that we
need is create a dashboard or report
which will help us analyze some data
right so uh let's get started just
double click on the report section and
here you'll have icon or visit which
will ask you what exactly you're looking
for preparing Q&A so I
want region wise sales and I want it in
a
paragraph there you go you have the
region by sales and barograph press on
okay
and you have it and you can place it
somewhere in the corner then if you want
another one double click and you want
category
wise category
sales and let's take that in pie
chart category sales p and here you have
it press on agree and accept and you
have it over here and ear on ear sales
in aine
graph sales
by date or sales
by sales by date line
graph here you have it accept that so
that you can identify which is the peak
uh performance ER or Peak Performance
date for us which gave us the highest
number of sales in a certain region
right so here we have it you can place
it can customize it right and now let's
go for subcategory double click and uh
subcategory I think we have a high from
a space
there sales uh the type of chart you
want you can go with the donut
one select that and
itre so you have subcategory wi sale and
now let's go with uh region wise I mean
the country wise right so let's go to
the data again here so here we have
segment city state country okay let's go
with country now
right
country country
sales map chart so whenever you
have a region or state or a country
involved go with map charts it's the
best way to represent right so we have
considered European nations over here so
for that reason we have the European
States here and uh now we can go with
let's go with the data once again and
have a look what else we can do and
shiping mode right so you have the
shipment mode as well so uh you can
identify what type of shipment mode
customers are majorly
preferring shipment mode Barra
agree so basically I think we have uh
three types of shipment
mode let's check the column name of
shipment mode properly ship mode it's
not shipment mode it's ship mode right
so let's type again ship
mode
bar
graph okay shipment mode
sales but
there you go so agree accepted so you
have standard shipment is the most
preferred one now we have this so let's
add some kpis here so uh kpi of
sales you will adjust that agree there
you go and let's add a kpi
for profit
and you have it
agree kpi for Revenue double
click let's check if we have a column
called Revenue quantity discount profit
right so let's go with
quantity and
discount so revenue is not added so it's
okay
so you can identify which uh uh product
or subcategory is highly selling in in
number of quantities so you have you'll
have some of profit some of sales sum of
quantity and what else we left the last
one discount and rate singles discount
profit so let's identify if we have
offered
any okay so let's add kpi or rate as
well if we are completely focusing on a
single product a single category we must
be having uh kpi for rate as well double
click somewhere kpi on
rate there you go accept it and you have
the
completely
formatted dashboard or sales report
ready for a meeting let's close all
these so that we have a better
visualization and you can just go to the
uh SlideShare mode or fit to the page
mode where you can have it that's good
so uh this is how you create a
completely functional fully functional
sales report or sales dashboard just
within a few clicks and just within a
few minutes let's say uh I want the
sales report only for central region
click that and it's completely
Interactive
and let's say we don't want that click
outside and you will have everything
back to the normal right and let's say I
wanted to focus on a particular category
technology category alone they have
these sales happening and the
subcategory of sales and what are the
products over here right you'll have
that and which is the country uh
happening to ship the most of them and
what's the shipment more preferred by
them and highest performing date or year
so here you can see 2022 June was the
highest performance for sales and uh the
lowest one is somewhere here in March
2020 or something right so that's how
you can create a fully interactive
dashboard or report based on sales data
in a few minutes and in a few clicks and
that brings us to the end of this
tutorial on the topic how to create a
completely functional sales report or
sales dashboard in a few clicks and in a
few minutes now this comes with the
mainly four functions so you have gather
which makes your data wide or it makes
white data longer so that is basically
used to stack up multiple columns you
have spread function which makes long
data wider that is stacking the data
together or stack if you would want to
unstack the data to data and you are
talking about data which has same
attributes and then your spread can
spread the data across multiple columns
you have separate which is function
which splits single column into multiple
columns and to complement that you have
one more function which is unite and
that combines multiple columns into
single columns so these are four main
functions which are used in your tidd
packet so let's look how we work with
this so let me bring up my R Studio here
now for this first is let me just clean
up my screen here here doing a contr l
so I will install the package it is
already installed but we can just do a
control enter and then I can say do you
want to restart or prior to reinstall to
install I'll say
okay and it is basically going to get
the
package now it says package T tiyr that
is TDR has been successfully unpacked
let's use that package with using using
our library
function and that was built under R
version
3.6 now I can basically start using
these functions so for example here we
are creating a data frame so let's say n
is
10 and then we basically would say we
will call it white now that's the
variable name I'm using the data. frame
function I'm saying ID which will be 1
to n so that will take the values from 1
to 10
and then these are the values which
have 10 entries so this is a vector
phase one phase 2 phase three let's
create a data frame out of it now that's
done we can have a look at our data
frame by just doing a view wide and that
shows me the ID column and it has ph. 1
pH do2 and pH do3 now we can use our
function so for example we can work with
gather that is reshaping the data from
wide format to long format and basically
you can say stacking up multiple columns
so let's see how we do that here I'll
call it long I'm working on wi I'm using
the piping functionality and then I'm
using gather so this one I will say what
will be the data which I will use so we
are using wide as a data frame then I'm
saying response time so that will be
basically one more column and then you
have your columns which you would want
to
basically stack so I'm saying from phase
one to phase three so let's do this and
once this is done let's have a look at
our variable long so this one shows me
that I have an ID column I have the
response time column and I have the face
column which we mentioned and that
basically has all the values stacked in
so you have ph. one phas do2 and phas
do3 so have all the columns are being
stacked here so all my data so now I
have totally 30 entries in this one so
this is basically using your gather
function now sometimes we may want to
use a separate function now separate
function is basically splitting a single
column into multiple columns so which we
would want to use when multiple
variables are captured in a single
variable column okay so let's look at an
example of this one so let's say long
separate that's what we will call we
will work on this long which has all the
data stacked in as the columns we
selected then I'm saying separate I want
the face column and then I would say
when I separate the columns what are my
column names now I could also give a
separator by giving a comma and then
mentioning the separator if that is
required so let's do this now once this
is done let's have a look at our long
separate so what we see here is the
column which we used so we were doing a
face column and that was to be split and
we wanted to split it into Target and
number so that's what we see here so you
have face being split into Target and
number and then you have the response
time so this is how you use the separate
function now there is also something
called as unite function which is
basically a complimenting of separate
function so it takes multiple columns
and combines the elements to a single
column so for example here we will call
it long unite and we will take long
separate which was separating the data
we want to unite so we will take phase
Target number and we want to have a
separator between them so let's
basically do this and now let's look at
the result of this unite so you see you
have the face and Target merge together
so you have ph. one the separator is dot
as we have mentioned and we have United
multiple columns so this is one more
function of your tid R which helps you
basically uh tidy up your data or put it
in a particular way now then you have
your spread function and this is
basically for unstacking so that is if
you have if you would want to convert a
stack to data or if you would want to
unstack the data which is of same
attributes spread can be used so that
you can spread the data across multiple
columns so it will take two columns say
key and value and spread it into
multiple columns so it makes long data
wider so we can look at this one we will
say long unite I'm using the piping I
will use the spread function I'll work
on the face column and response time and
let's do this and then let's do a view
on this so it tells me our dat back in
the shape as it was in the beginning so
these are four functions which are very
helpful when we work with tid package so
let's learn about
visualization and here we will learn
about R which can be used for your
visualization now one thing which we
need to understand is because of our
ability to see patterns which is highly
developed we can understand the data
better if we can visualize it so the
efficient way or effective way to
understand what is in our data or what
we have understood in our data we should
or we can use graphical displays that is
your data visualization so there are
actually two types of data
visualizations so you have exploratory
data visualization which helps us to
understand the data and then you have
explanatory visualization which helps us
to share our understanding with others
so when you talk about r r provides
various tools and packages to create
data
visualizations and which can be used for
both kind of data analysis or both kind
of visualizations so when you talk about
exploratory data visualization the key
is to keep all the potentially relevant
details together now now the objective
when we talk about explor data analysis
is to help you see what is in your data
and the main question is how much
details can we interpret now when you
talk about different functions which we
see here such as plot which is more for
a generic uh plotting you have bar plot
which is used to plot data using
rectangular bars or you can say creating
bar charts you have histogram or hist
function to create histograms where you
look at the
frequency of uh the data or basically
used to look at the central tendency of
the data you have box plot which is used
to represent data in the form of
quartiles you have ggplot which is a
package which enables the user to create
sophisticated visualizations with the
little code using the grammar of
graphics and then you have plotly or
plot l l y it creates interactive web
based graphs via the open-source
JavaScript graphing library now before
we see some examples here let's also
talk about when you talk about plotting
let's also try to understand what kind
of plots you can have and what kind of
techniques you have so let me open up my
R Studio here now for example I can pull
out a particular data set and let's look
at this one so here I can look at all
the pains and that shows me the
information now what I can do is I can
install and get the inbuilt data sets
and then I can simply do a plot wherein
I am doing a plot on chiwa data set so
let's see what does that show it
summarizes the relationship between four
variables in chick weight data frame
which is in ours buil-in data set
package now from these plots we can see
for example weight varies systematically
over time you can also see that chicks
were assigned to four different diets
now when we talk about explanatory data
analysis or visualization that shows
others what we found in the data this
means we need to make some editorial
decisions what features we would want to
highlight for
emphasis what features are distracting
or confusing and you want them to be
eliminated right so there are different
ways of doing it now when you talk about
your graphics or visualizations you have
I would say three different types or you
can say four so you have the base
Graphics which is easiest to learn now
here we are having an example of Base
Graphics where I can use the base
Graphics I can get a
um data set using library then I can
simply create using plot function to a
generate a simple scatter plot of
calories with sugar from us serial data
frame in the mass package and then I can
give it a title so this is basically a
simple example of Base Graphics now you
also have what we call as grid Graphics
which is powerful set of modules for
building other tools now you you also
have latest Graphics which is general
purpose system based on grid graphics
and then you have your GG plot 2 which
implements grammar of graphics and is
based on grid Graphics so you have
different ways now here since I already
have used library and I have the data
set I can just do a x so I can assign
the sugar related values to X and
calories related value to Y then I can
use one more which is Library function
and calling in Grid now I can basically
use functions such as push view Port if
I would want to create a plot using your
grid Graphics to create the similar kind
of plot which we created using base
Graphics but this will give you much
more power than base Graphics it will
have uh a steep learning curve but it is
usually useful so I can do this where
I'm saying push view Port then I can and
basically say I would want to have a
data view Port I would say different
functions of your grid package so I'm
saying rectangle you have x axis y AIS
given some points here and then
basically you can add details to the
graph by giving the names to the columns
and you can basically create a simple
grid Graphics based plot here now there
are different other options which we can
use to create plots now before we go
into understanding how you create plots
let me just give you a brief on what are
the different kind of plots and how they
can be used so here we will look at
these different plots now for example we
have a bar chart which is a graph which
shows comparisons across discrete
categories so you have x axis which will
show the categories being compared and Y
AIS which represents a measure measured
value and height of the bars are
proportional to measured values Now to
create different kind of charts you can
use ggplot which is a package for
creating graphs in R it is basically
method of thinking about and decomposing
complex graphs into logical subunits and
that is a part of Tidy worse ecosystem
so it takes each component of graph
axises you can give scales you can give
colors you you can give the objects and
you can build graphs on particular data
you can modify each of those components
in a way that's more flexible and user
friendly you can if you are not
providing details for the components
then ggplot will use sensible defaults
and this basically makes it a powerful
and a flexible tool now here are
different options when you use your GG
plot such as you can use geom or what we
call as geometry objects to form the
basis of different type of graphs for
bar charts you have for line graphs you
have Scatter Plots that is uncore point
you have underscore box plot for box
plots you have quartile for continuous X
wiin for richer display of distribution
and Jitter for small data so here is
some simple example where I would not go
into too many details here but you can
just have a look at this one where we
are using Library function to get the
ggplot 2 package then basically we would
want to look into the mileage data we
would want to look at the structure of
it and then we can basically get the
Tidy worse package finally we can create
a bar chart using gomore bar and we can
basically also mention what would be in
x-axis now you can also give different
colors to basically add more meaning to
your data you could also go for stacked
bar chart s so here we are actually
telling GG plot to map the data in the
drive column to fill the aesthetic so
here I am
giving aesthetic access class and I'm
saying what is the data we need to have
and then we are using gomore bar so you
can also have dodged bar in your GG plot
that is not bar charts which are stacked
but next to each other and you can
create that by using your position as
position _ Dodge okay now you can
obviously use your different packages
which are inbuilt and you can create
your bar charts and you have other kind
of graphs such as line graph which is
basically a type of graph that displays
information as a series of data points
connected by straight line segment such
as this one and for this one we are
using if you see gomore line
now you can also create a scatter plot
which is a
two-dimensional data visualization that
uses points to graph the values of two
different variables one in on x axis one
on Y axis like what we saw in base
Graphics example and they are mainly
used if you would want to assess the
relationship or lack of relationship
between two variables and you also have
histogram which I mentioned is mainly to
look at the distribution of a data to
look at the central tendency of the data
basically looking at your um large
amount of data or for a single variable
you would be interested in saying where
is more data found in terms of frequency
where is lesser data found in the graph
how close the data is towards its uh
midp point or what we call as mean
median mode so you can use histogram
where you can categorize the data in
what we call as bins so these are some
Basics on different kind of graphs now
we can look at some examples and see how
that works so what we were seeing is
some quick examples of Base Graphics or
grid Graphics now here let's do an
example of pie chart for different
products and units sold so you want to
create a graph for this first let's
create a vector and pass in the value
here now I can also create labels which
I would would want to assign to these
values and then basically I can plot the
chart by saying Pi so that's the kind of
chart which I would want to create and I
would say the data would be X and labels
so let's do this and that shows me a
simple pie chart now I can also give
main details here so instead of just
doing a pi x comma labels I can say what
is the main and then what kind of
coloring it should follow so this is the
way you can create a
simple uh plot now I can also find out
what is the
percentage and then basically I would be
interested in plotting the pie chart
which takes X which takes the labels
which will be the percentage which we
are calculating here by doing a round
function and then you can basically give
details to your graph you can say what
color it follows you can basically look
at the legend where it needs to be in
your
chart what are the values and then
basically fill up the colors so let's
run this one and that shows me the
percentage which was calculated and it
gives me the details and we can always
have a look at our plot now if you would
want to go for a 3D pie chart then you
can get the package which is plot Trix
let's use that by calling in the library
function let's let's pass in some data
to X and let's give some values or
labels which will make more meaning to
the data and then let's plot the 3D
graph so I'm saying Pi 3D here where I'm
using X and labels then I'm basically
doing an explode which will basically
control how your graph looks like and
basically give the values so it also
takes the title when you say Main and by
chart of countries now let's create
create data for graph so again we are
having a variable here we are create
using the C function creating a vector
and then let's create a histogram for
this one where I would say xlab what
would be your data around x-axis what is
the color what is the border and here
I'm creating a simple histogram which as
I discussed earlier will always show
your values on the x axis and y AIS is
more of frequency and then you can look
at the set of values and what is their
frequency and we can basically use this
histogram for exploratory data analysis
look at the data try to understand what
is the central tendency of your data
values now we can also give some limits
by using the X limb and Y Lim and then I
can also specify what is the limit so we
have given some values here wherein we
have said your X limit is 0 to 40 and Y
limit is 0 to 5 now if you compare this
with the previous one which we had
created this one based on the frequency
had taken the limits but we can assign
limits explicitly by giving this and
then create a histogram which makes more
meaning now let's take another data set
that is air quality let's view this to
see what does that data contain so you
have oh Zone solar wind temperature
month and the day so this is the kind of
information we have in the air quality
now let's use the plot function to draw
a scatter plot where as I mentioned you
would be interested in analyzing
variables and see what is the
relationship between them so to plot a
graph between ozone and wind values so
we will say plot we will say the data
which is air quality from that I would
be interested in the ozone column or
Zone field and the wind field I can
create a plot based on this now I can
also be saying what should be the color
what is the type of the data which you
would want to create and you can look at
the in information so you can create a
histogram you can create a a scatter
plot to basically understand the data
better and then infer some information
from that data so let's take the air
quality data set itself self without
specifying any particular column and you
can create a plot which shows me all the
different values which you have in the
data and it basically shows you the
difference this is more of an example
like what we did for chick weight where
we dat a base Graphics now you can
assign labels to the plot so that is
when you are creating a plot you can say
air quality you will say ozone and then
that's your ozone concentration you have
your ylab which is the number of
instances you have what is the title
ozone levels in New York City what is
the color so these are the details what
we have given with our plot function and
let's look at the data so it just tells
me that this is the ozone
concentration uh the number of instances
what you have and you looking at the
data now we could also create a
histogram by picking up a particular
column that is such as solar from your
air quality and that basically shows me
the frequency of solar values and we can
then try to find out what is the mid
what is the mean what is the standard
deviation and so on you can also look at
your histogram and try to understand if
it is left skewed and right skewed so we
can do that now here let's get the
temperature out from this particular
data set let's create a histogram on
temperature and that basically shows
show me the frequency of the temperature
values and what values have the most
frequency or most occurrence now you can
create a
histogram with
labels so let's do that with the limit
and then let's also use text to
basically given the values which also
takes the values and for each set of
frequency or each set of values it gives
me the labels now you can have a
histogram with non-uniform width so you
could do that by doing a hist function
and then passing in your temperature you
can say what will be the main what is
the title what will be your
xlab it will tell you a limit around
x-axis what is the color what is the
Border what are the brakes you would
want to have for your bars and you can
simply create a histogram using this so
This basically takes the breakes which
we have given such as 55 to 60 60 to 70
70 to 75 and so on so this is basically
creating a histogram with non-uniform
width and it purely depends on the kind
of values what you have now you can also
create a box plot which sometimes helps
us in understanding the the data
quartiles also understanding our
outliers so you can create multiple box
plots based B on the data from air
quality so we'll select all the data and
then we'll do some slicing on the data
so let's create a box plot which tells
me the values and if you look at these
points here like single dots these are
basically your outliers we can learn
about that more in later sections so you
can use your GG plot 2 library to
analyze a particular data set so for
that we will first use the install do
packages and get gplot
2 so it says do you want to restart R
and I can say yes so let it get the
package I think the package was already
there and now let's look at using ggplot
2 so for that I have the library
function and let's do a attach where I'm
getting the data set which is empty cars
now then I will create a variable P1 I
will use GG plot I will pass in my data
I'll give the Aesthetics what is the
columns which you would be interested in
and then you using gomore boox plot to
basically create a plot which gives me
the box plot for the values here and
this is based on the cylinders which is
there in your data so we can always look
at what does our data contain and what
kind of values or features are available
in the data now let's create a box plot
we will also use the coordinate function
and that basically gives me based on the
data so I've changed the coordinates now
if you look at the previous one where we
created a plot we had mileage on the Y
AIS and cylinders on the
x-axis now I did a coordinate flip and
that's like your transpose function so
you have created the box plot but you
have just flip the coordinates you can
create a box plot and then say fill
which is the factor of cylinder so that
can be used to fill up the values in
your box plot now what we can also do is
we can create factors so we have learned
about factors earlier which is usually
used to work on categorical variables so
here let's create a factor which is
empty cars gear you have a you have
cylinder and if you look at the factors
which we have created we have passed our
data what is the field or the column we
are interested in what is the level of
values there and what are the labels for
those values right so we have learned
about factors you can always look into
the previous section and learn more
about factors now let's create a scatter
plot by using the GG plot function again
we will use the data as empd cars I will
go for mapping option and then I will
give my Aesthetics that is what would be
x what would be your Y and you also
would want to use what kind of function
you're using so let's go for geom Pawn
point and that basically helps me in
creating a scatter plot now you can
create a scatter plot by factors so here
we will say GG plot so notice in all of
these cases depending on the kind of
data you have depending on the kind of
plot you are interested in you will use
the GG plot and then basically a
function with that or the inbuilt
package so here I'm saying data is empty
cars I'm going for mapping which
basically will take the values for your
X and Y what is the color and the
coloring will be done based on the
factor values now if you remember
factors will obviously have some levels
and uh those levels will basically help
you in differentiating between your
categorical variables so I'm saying as.
Factor on cylinder and then I'm using
Gom point to basically create this
scatter plot so let's do this and I can
look at the values of this one so it
says must be there is an error which
says must at least one color from the
Hue pallet so let's look at that one so
the error which we were facing when we
gave color as the fact Factor values was
because when you look at these factors
which were created with some labels if
we look at the values of these it tells
me there are any values in that
particular column similarly your gar or
similarly you can completely look at the
complete data set it tells me cylinder
you have am you have gear now these have
some we have created some labels but
these have na values so what we can do
is we can create a SC plot as we did
earlier by giving the Aesthetics and
that's a simple scatter plot wherein I'm
also using geom point so that I can have
these points by defaults or with
defaults you can also give a color
specific basically if you would want to
have different kind of data in the same
plot or I can create Scatter Plots by
different sizes by giving a size or I
can give a color and size and that's
again one way in which you can create
your Scatter Plots now let's also see
how you can visualize one more data set
which is
MPG so I can also do it in this way
where I set GG plot two and then pass in
look at the data set what we have here
you can just do a view on this to see
what my data contains if the fields have
any any values if that's going to affect
your plotting so now what we can do is
we can create create a bar plot or a bar
chart so I'm saying GG plot the data
would be as we have given in previous
lines that is ggplot 2 MPG then I will
say what should be in my Aesthetics and
what kind of chart are you going to
create so I'm saying gomore bar so
that's my bar chart and that has
basically your class and account now you
can create a stacked bar chart where
your information is stacked in the same
bar
and we are still using the same data we
are going for Aesthetics which is class
and then when you say gome bar which
creates your stack bar we will use fill
which is drive and we can always go back
and look at our data for example you can
always look into this so you have the
drive column here and you are also
working on this complete data set so
let's go ahead and create a stacked bar
chart and that basically gives me the
information where you have the drive
information which is stacked here now
you can do a Dodge by giving the
position as Dodge so we are still going
to go for a stack chart but this time
the bars will be next to each other and
that can also be done which is very
useful you can use this by using geom
point where you mapping and you're
specifying what are your Aesthetics so
we were creating a scatter plot now you
can also use or give more details where
you can say color can be based on the
class and we have different classes and
based on that my points have been
colored now you can also use a plot ly
or plotly Library so let's install this
one I will say yes for example let it
basically restart so that all my
packages are
updated then I can access that package
us using Library function and then
create a variable to which you are
assigning your plot unor ly plot so data
is empty cars what will be your xais
what will be your y AIS and details on
your marker which we have given wherein
I will give a list which is size color
which is a combination and then you have
your
line what kind of color it will have and
what will be the width so this is where
I'm going to use use plot ly and let's
look at this
plot so it basically gives me some
information now we see some warnings
which are getting generated but there is
you don't need to worry about that so
you can look at the packages what you
have and what options you're using so
similarly we can create one more plot
using plot ly and look at the values of
those so that's a plot with a trend
which explains me about my data so this
is a simple small tutorial on
understanding or uh how you can have
your graphics or
visualization used to understand your
data obviously there are much more
examples much more ways in which you can
pass into your plot functions or your GG
plot and the inbuilt packages which are
available in R for your visualization
now that could be for explor it data
analysis or explanat data analysis so
try these graphs and see if you can
change these options and try or create
new
visualizations good morning and good
evening everyone so welcome to this
session where we will learn on time
series analysis using our programming
language so this is basically a mini
project where we will look at time
series data and how we can analyze it
visualize it to basically find some
important information or gather insights
from the data now when you talk about
time series analysis time series is
basically any data set where your values
are measured at different points in time
so when you talk about time series data
data is usually uniformly spaced at a
specific frequency for example hourly
weather measurements you have daily
counts of website visits monthly sales
total and so on so when you talk about
time series that can also be irregularly
spaced and sporadic for example time
stamp data in computer systems event log
or history of 911 emergency calls now
when we work with time series data for
example here I'm taking a energy data
set we can see how techniques such as
time based indexing resampling rolling
windows can help us explore variations
in electricity demand and renewable
energy Supply over time now here we will
look at some aspects of this data set
which I'm considering so there is this
is open Power Systems data set and here
is the data set I have we can look at
the data set now this is in a simple
format it has time it basically has
values for consumption and then you have
data for wind and solar and wind Plus
Sol so in certain cases you have only
the date and the consumption but then if
we scroll down we will also find data
for wind solar wind plus solar and so on
so this is a Time series data set which
we would want to work on sometimes you
may also have the data collected which
just does not have the time but it may
also have timestamp that is it would
have say hour minutes and seconds and
that can also be worked upon so let's
consider this data set and let's work on
this project where we will Analyze This
Time series data set now here we can
work on this time series data we can
basically create some data structures
out of it such as data frames we can do
some time based indexing we can visualiz
the data we can look at the seasonality
in the data look at some frequencies and
also do some Trend detection now when
you talk about this data set it has
electricity production and consumption
which is reported as daily totals in
gigawatt hours and here are The Columns
of the data which I was just showing you
so you have data you have consumption
you have wind you have solar and wind
plus solar so this is the data we have
and we will basically explore say
electricity consumption and production
in Germany which has varied over time so
some of the questions which we can
answer here is when is electricity
consumption typically highest and lowest
how do wind and solar power production
vary with seasons of the year what are
the long-term trends in electricity
consumption solar power and wind power
how do wind and solar power production
compare with electricity consumption and
how has this ratio changed over time we
can also do wrangling or cleaning of
this data or pre-processing of data and
create a data frame and then we can
visualize this now let's see how do we
do that so I will open up my R studio
and let's look at the data set so here
is the data set now I'm picking it up
from my machine you can also pick it up
from GitHub so all the data sets or
similar data sets can be find in my
GitHub repository and here I can look in
the data sets you will find lot of
different data sets here there are some
time series data sets such as power I
can search for power or you have
basically
coal or you have
this
opsd Germany daily data set and there
are many other data sets which you can
work on now to get the documentation on
this project you can also look in my
GitHub repository and you can search for
Repository
and then basically you can look in data
science and R and here there is a
project folder where I've have given the
documentation sample data set and also
your time series analysis related
document this is also the code which you
can directly Import in your R studio and
you can practice or work on this project
so let's see how does that work so first
thing is we will create a data frame
from this data set now here if you see
I'm using header as true so that it
understands the heading of each column
I'm also giving row. names and I'm
specifying date so there is this date
column in the data set as I showed you
earlier let's look at it again so you
have date consumption wind solar wind
plus solar so you can suggest that date
should become the index column which can
be useful so you can do this now let's
just create this
let's look at what does this data frame
contain and here if you see it shows me
some data which has
been now as a part of this data frame
structure it starts with consumption
wind solar wind plus solar and if you
see this one is becoming my index column
so I can always do a head and look at
part of the data frame using head or
tail so look at the first records so
let's see this now that shows me the
head data I can also do a tail and look
at the ending values so if you closely
see here we have wind solar wind do
solar and that basically has na values
so there are missing values but let's
look at the tail and that tells me that
there is some data available for wind
and solar and wind solar now we can
always look in a tabular format using
View
and we can look at the data so this
shows me that there are values in these
columns we see na values but if I really
scroll down I can see some values which
would be available for wind and solar
and wind solar so I can just use view
now I can look at the dimensions of this
particular object and that tells me
there are
400
4,384 rows and four columns you can
always look at the structure that is
check the data type of each column which
can be very useful so if I see here I
don't see the date column because date
column was considered as an index which
can be useful but I also look at my
other columns they are of the num types
so that's the data type for each
attribute or each column here now we
would be interested in looking at this
date column so let's look at the data
type of this date column now if if I try
to do this this will show me that this
is null because date as a column does
not exist because we created it as an
index so if I look at row names and then
I search for my data show me the index
column or row. names it tells me these
are the values that's the date column
which we are seeing here now we can
access a specific row by just doing a my
data and give the index value or row
name value so let's look at that and
that shows me based on this index you're
looking at the value you can obviously
search for a different date something
like this you can also pass in a vector
and you can give range of values so that
is
01 2006 to 4 of January and we can look
at this one so it shows me these are the
values so here actually I'm not giving a
range but I'm just selecting multiple
values from row. names now we already
know that in R you have a summary
function so you can always do a summary
and that gives you for each column it
gives you minimum first quartile median
mean third quartile and maximum values
so we are looking at consumption we are
looking at wind solar and wind. solar
now this is good but then if I would
want to really visualize the data access
the data do some analysis then it would
be good to take all the columns and then
we can later decide to change the data
type of say date column if we want to
use it so earlier I was using date as
row. names or the name of the rows or
index what you call in any other
programming language so here I will just
use my data set and I'll say header is
true I'm calling it my data 2 let's look
at the data and this one shows me five
columns where in My First Column is the
date consumption wind solar and so on
now looking at the structure so let's
look at the data type so it tells me
that if now I'm interested in looking at
the date column from my data 2 Data
frame it tells me it is a factor with 4
384 levels and these are the values
so it is not in a datetime format it's a
factor now what we can do is we can
convert this into a date format how do
we do that so let's have a variable X
and I'm going to use as. date function
and I'm going to pass in my date column
so that's assigned to X now let's look
at the head of X and it shows me the
values we will also see what kind of
class it is and we will look at the
structure of X so class already says it
is there type and look at the structure
so it shows me the format now we have
converted this column or column related
value into X now how do I basically
extract values out of it or make it a
part of data frame so first I will use
so all once it has been converted in
date format I will go for as. numeric
and here I will create a variable called
ear and I will just do a format on X
which is basically of date type and then
I'm saying percentage y so that will get
me the ear component out of this let's
look at the values that shows me year
component now similarly we can get the
month out of this and then basically
look at the month values we can get the
day out of it and we can get the day
component now if I look at my data 2
which we had created earlier this
basically had date consumption wind
solar wind solar so what I can do is I
can add these extracted columns such as
ear month Day to my data frame using a
cbind that is column bind and I will
assign it to my data 2 again so let's do
this and now if you look at head it
shows me date so that should be date
format consumption now this one might
not be date format but we'll see you
have consumption wind solar and we have
extracted the year month and day which
can help us for group buy we can do some
aggregations we can do a plotting and we
can do various things by these
additional columns now let's look at
first three rows here so I'll say 1 is
to three for my data 2 and that shows me
some data here you can always do ahead
and look at the sample of data so that
basically shows me month day your
columns and then you have your date
now what we can do is we would want to
visualize this data we would want to
basically understand the consumption now
as I said if we want to visualize the
data say for example I want this which
is consumption of data over years and
this one is in terms of gigawatts per
hour as we were mentioning here gigawatt
hours so if I would want to create this
visual to basically understand the
pattern of the data how do we do it so
we can you create a line plot of
full-time series of Germany's
electricity consumption using the plot
method now how do we do that so here one
of the option is I can straight away use
the plot method I can then say what
would be in my x-axis what would be on
my y AIS what would be the type of graph
I would want to plot what is my name on
x x axis y AIS and this is the simplest
way so I'm saying my data 2 I'm
extracting the year column and here I'm
taking the consumption so let's create a
plot and here if you see we are looking
at a plot we do see some tick times and
we see that the data has been divided
with every two years so from 2006
onwards to
2016 but then really this data does not
give me uh you know a very useful way of
looking at the data or understanding it
might be what I can do is I can use the
same way but I can give apart from
x-axis and y axis I can say the limits
that is X limit is 2006 to 2018 and Y
limit is from 800 to 1700 so we can do
this and let's look at this again this
is a plot but it really does not help me
in visualizing and understanding the
data so what are the better options I
can go for multiple plots in a window as
of now we are just sticking to one plot
in window so if you would want to have
multiple plots you can always change the
value here and make it two or three that
will say how many rows and how many
columns so as of now we will just keep
it as it is par MF row now if I would
want to plot I can straight away give
the column name so I am interested in
getting the consumption now I can just
do a plot I'll say my data 2 and I will
choose the second column which is
consumption which we saw here from our
data so consumption was the second
column so I can just do a plot in a
straightway way without mentioning your
x axis y AIS limits and so on and if you
look at this this one is giving me a
pattern now here I am looking at uh um
x-axis y AIS which is not really named
we do not have a name to this graph and
we are looking at the data it does show
me some kind of pattern but mightbe we
can make it more meaningful so I can do
it this way where I say my data second
column let's give axis as ear xaxis Y
axis as consumption now that has changed
the x axis and y axis now I can also
give some more details I can say type
should be line I have the line width I'm
saying color is blue and let's do this
so this looks more meaningful might be
shows a wavering pattern of consumption
over years I can also give a limit of x
that is 0 to 2018 and that basically
shows me the range now we can change
that and we can be more specific and
saying X limit should be 2006 to 2018
and and let's look at this now this one
once you have given a proper limit it
shows the line graph and it shows what
was the consumption in 2006 and over a
period till
2018 I can then use any of these options
are fine but it depends on what and whom
you are presenting the data or what kind
of analysis you're doing so I can do a
plot I can choose column second xlab
which is x- Axis y AIS type is line
width giving a x limit y limit and then
I'm giving a title to this which is
consumption graph and then basically
you're looking at the line graph now
those are the options which you can do
either you could be very specific or you
could just give your column which you
want to plot or obviously make it more
meaningful by giving all the details now
what we can do is if we would want to
look at this data and understand it
better rather than just looking at a
simple line I can take the log values so
here I'm saying log of my data 2 second
column so I'm taking log values of
consumption and I'm taking the
difference of logs so I can say
difference and then you can basically
increase or decrease this by multiplying
it by some number so rest Remains the
Same I'm changing the color and let's
look at this plot and you see this
basically is giving me a better pattern
which makes meaning here we see the log
values so this is you are using a simple
plot
function in R you can also use ggplot
now for that we can install the ggplot
package it's already there in my machine
so I'll say no I will access this by
using the library ggplot
2 and now I can use ggplot to plot so
the way you specify here you can say my
data 2 that's the data frame I'm saying
type as o and when I'm saying line I am
basically going to use xais which is ear
why is consumption and let's look at
this plot so again we are back to the
one which we were doing earlier really
does not make any sense gives us some
data but then really does not give me
enough information I can in my
Aesthetics I can say x as ear Y is
consumption I can do grouping and then I
can give line and plot so again we have
some information but really does not
help me right now let's look at other
example so I'm just doing the same thing
here and I'm looking at line type being
tased I'm using the GG plots other
methods such as gome line and gome point
to give me more information and if I
look at the plot it does give me data it
tells me what are the different values
it gives me some kind of pattern but I
would still prefer the way we were doing
with plot now we can change the color
and obviously add details to it so what
we see is when you use the plot method
which I did earlier it was choosing
pretty good tick locations that is every
two years and labels the years for the
x-axis which was helpful right but with
these data points which we were seeing
here or say for example this
one or say this one or say this one we
are looking at some data but then that
really is quite crowded and it is hard
to read you can look at the values but
then it really does not give you enough
information so we can go for plot method
but then we will see how we can consider
different data now if I would want to
plot the solar and windin time series so
let's see how do we do that so wind
column is what I'm interested in so
first thing is it was always good to
find out the minimum and the maximum
values in every column so I'm saying
minimum I'm saying let's put in here my
data
2 and then let's look at the values so
we are looking at the columns we know
consumption is the second column wind is
the third column and you have so is the
fourth and this one is the fifth so
let's say let's find out the minimum of
each of these columns which we would
want to plot so let's say minimum of
data third column and here I'm also
saying remove the na values because we
do not want to consider the na values so
let's look at the minimum that shows me
5.7 757 what is the maximum value it is
826 so that also helps me in giving a
limit if I want to plot wind on y AIS I
can give a y limit from 5 to
850 consumption wise let's find out the
minimum from second column and maximum
and similarly for solar find the minimum
and maximum and wind plus solar minimum
and maximum so this will be helpful when
you would want to plot multiple graphs
or give some limits so that's fine now
for multiple plots as I said instead of
having one plot let's plot consumption
and wind and solar and try to see a
pattern so I can say par function and I
will say three rows and one column so
now when I start plotting you will see
you will have multiple plots in one
single window so let's see how we do it
so here let's look at plot one so this
one is consumption as we did earlier and
let's look at the data so that gives me
some data you can always do a zoom and
you can look at the data you can
basically expand this graph or you can
reduce this graph to see what kind of
pattern we have in consumption similarly
we can basically choose date being
x-axis my consumption being Y axis right
so this is being more specific because
here we have a range but it really does
not give me enough information so I will
basically give x-axis Y axis I will give
the name that is daily totals and then I
will basically give consumption color
and Y limit based on my minimum and
maximum limits so let's do this and now
we can look at the data here so let's
see this data makes a little more
meaning because we are looking at the
dates and let me do a zoom so it shows
shows me all the dates it shows me the
data points it shows me how the data
pattern is changing for consumption now
this is for consumption so what we can
do is we can also extract specific data
so if you see here I have done some
testing where I am saying okay I would
want to get a date specifically I would
want to extract some Valu so we are
looking at the date column but if you
remember we did not change the data type
we just changed the data type of date
column we extracted year mon month out
of it it would be good if we can convert
a column into date time format and put
that in our data frame now let's look at
the plot two this is mainly for your uh
column which should be consumption and
wind and solar so here I see it is solar
data and I can plot this one to see how
it looks like and that tells me from
2006 onwards we have some pattern I can
be more specific where I say I would be
giving date and then the column for
solar xaxis y AIS what is the type what
is the Y limit and what is the color it
is always good to specify your X and Y
axis given name the rather than let it
automatically pick up now this makes
more meaning because it shows me some
dates similarly we can do for wind so
either you do it just by giving the
column or you give your X and Y AIS so
let's look at this one and this shows me
the data so we can choose plot three
this one we can choose plot two we can
choose plot one and we can put all that
data in one graph so that's when you you
are putting in multi plots in one
particular graph you can always do a
zoom you can always look at the data
right and this is usually useful to look
at the pattern what kind of pattern we
see what data we have and so on now
moving forward so we have seen how you
are creating these plots all in one
window let me reset this back to one
plot per window and let's basically plot
time series in a single year so what we
have seen is is that when you look at
the plot method it was quite crowded
then we looked at solar and wind and if
you compare that you will see your
consumption pattern your solar pattern
your wind pattern and basically we can
see from this particular data some kind
of pattern so electricity consumption is
highest in the
winter where we will see what is the
consumption is it highest in Winter or
is it in summer we can see that by
breaking a year further into months we
can see that but we see a pattern which
goes for every year or every two years
being highest at a particular point of
time and then it drops down so
electricity consumption is highest in
Winter and that might be due to
electrical Heating and increased
lighting usage and lowest in summer now
when you look at electricity consumption
appears to split into two clusters we
can always look at the consumption one
with oscillation centered roundly around
1,400 gaws so you can always look at,
1400 GS and you see all the values here
which are in that particular consumption
another with fewer and more scattered
data points Cent roughed around 1150 so
if you really expand this you can see
you will have lot of data points at this
point now we might guess that these
clusters correspond with weekday and
weekends which which we can see if you
break that data into yearly monthly
weekly and so on now if you look at
solar production that is highest in
summer when sunlight is most abundant
and lowest in winter so obviously when
you're making or gathering some insights
when you're looking at the data you are
also using your domain knowledge your
business knowledge your you know
knowledge of business to understand how
this goes if you look at wind power
production that's again highest in
Winters and drops down in summer so due
to stronger winds and more frequent
storms and lowest in summer so there is
some kind of increasing Trend in wind
power production over years which we can
see here over the years and all the time
series data what we are looking at is
referring or showing us some kind of
seasonality that is we are looking at
seasonality in which a pattern is
repeating again and again at regular
time
at regular intervals so if you look at
consumption solar and wind time series
that oscillates between high and low
values on a yearly time scale which we
can break down and see I'll show you
that it corresponds with the seasonal
changes in weather over the year so
seasonality does not have to correspond
with meteorological reasons for example
if you look at retail stale sales data
uh that will show you yearly seasonality
with increased sales in particular
months so seasonality when we say can
occur on other time scales so the plots
what we are seeing here they are fine
but if you look at those plots they
might show some kind of weekly
seasonality also so in your consumption
corresponding to weekday and weekend so
let's plot for one single year now how
do I do that so first is I will look at
my data two
that shows me the structure it shows me
date which is Factor other columns which
are all numerics now like we did earlier
I'll repeat this step where I'm going to
convert the date column into date type
look at head of it look at class of it
look at the structure of it right and
then what I want to do is I want to add
this as to my data frame so I will
create a variable called data and this
one will have as data and I'm formatting
the value of x which is date time into
month day and year so let's do that and
now you look at the mod data which I
created like modified data so this is
the format I have it is in date type if
you carefully see here and then I can
look at the head of it so it says me mod
data now we are what we did here is when
I said my data
3 so my data 3 we did a cbind and I did
a mod data which is going to add this
column to my other Columns of my data
too so my new data frame is my data 3
let's look at the structure of it and
you see there is this date column I can
delete it I can remove it I can let it
be right so that depends on our choice
mightbe we want to once our analysis
done we want to remove the mod data
right so we can keep both of them now
let's basically extract data for a
particular year now how do you do that
so this is some wrangling so I will say
my data 4 let's call it my data 4 and I
will use subset function so subset will
work on my data 3 that's the data and
what I'll do is I will do a subset how
do how is the subset found so I'll say
take the mod data column
the value should be greater than or
equal to 2017 and should be less than
2017 December 31st so I'm getting data
for one year and I'm storing it as my
data
4 let's get the head of it and you see
we are specifically looking at 2017
related data now let's do a plotting of
this where I will only create a plot for
one year so I'm saying my data 4 four
that's my
new data what we got so here I am going
to take the First
Column which is mod data I'm going to
take the third column which is
consumption so I'm looking at the date
format for one year consumption values
for it and then rest of the things as we
have done earlier let's look at the plot
and this makes more meaning right so
when you look at this plot it tells me
Jan to Jan it shows me some kind of
pattern where I have divided the year
into months right and it is broken down
into say two months so Jan and March and
May and July and so on but we still see
a pattern and that gives me good
understanding of pattern where I've
broken it down into months so this is
where you have taken time series in a
single year to investigate further and
this is is what we see right now we can
clearly see there are some weekly o
oscillations what one more interesting
feature is that at this level of
granularity that is when you're looking
at yearly data there is a drastic
decrease in electricity consumption in
early January and late December during
the holidays or probably we can assume
that this is holidays now I can zoom in
further and look at just Jan and F web
data let's see how we do that and let's
see how we work by zooming in the data
further so to zoom in the data further
let's see how we do it now here we have
this my data 4 which is basically having
a subset right so let's work on this one
so I will say my data 4 which earlier I
was taking data 3 I was doing a subset
and I was giving the date but this time
I will make it more narrower so I'll say
my data 4 I will say subset from my data
3 and I will choose mod data column
which we have modified with the date
format I will choose the starting date
as
1701 that is Jan and then let's go till
Feb and let's create
this now let's look at the head of this
so it shows me we have the data which is
Jan
and then you you can basically look at
more on this now again as I said earlier
let's find out the minimum of this from
the First Column so that is basically
your mod data so let's look into this
one and that
basically will give me minimum and
maximum let's look at the values so this
one tells me Jan 17 January 1 and
maximum is
your fa web 28th 2nd month 2017 so we
are actually looking at two months data
here let's look at the Y minimum so this
is I will look at column three now what
is column three consumption so let's
look at the minimum value for
consumption maximum value of consumption
let's look at the values which can be
given as our limits now this is the
minimum and maximum now let's do a
plotting for this data which has been
narrowed down for consumption based on
my data so I'm saying My First Column
which is mod data and then third column
which is consumption I'm giving some
naming convention for sorry namings for
your x axis y AIS what is my
consumption or what is my title here
what is the color and then you see I'm
using X limit to give the minimum and
maximum limit and Y limit so let's look
at this data and if you look at this
data it is specifically for two months
and again I can look at the pattern here
what I can also do is I can add some
grid here so I can basically look at
this data and make more meaning out of
it so it is biweekly data you can see
now I can add a line here using AB line
and then I can basically choose what
lines I would want to add
horizontally so that basically allows me
to dce the data and look at data in a
more meaningful way I can also add
vertical lines so vertical lines is I'm
saying sequence will be minimum maximum
and I'm saying an interval of seven so
let's do this and this basically has
added some lines every week and you can
see at the end of week it is dropping
and then it is starting again it Peaks
somewhere in the mid of the week and
again it drops down so this is your
looking at your consumption data right
now what we can also do is we can create
some box plots so when we looked at
zooming in data for Jan and Feb you can
add some data points like this so
consumption is highest on the week days
as I showed you here and lowest on the
weekends so this is what we are seeing
when we are breaking the data or zooming
it further for a couple of months so we
have vertical grid lines and we have
nicely formatted tick labels that is Jan
1st Jan 15 Feb 1st and so on so we can
easily tell which days are weekday and
weekends with use of these grid lines
and basically breaking it down so there
are many other ways to actually
visualize your time series data
depending on what patterns you're trying
to explore you can use Scatter Plots you
can use heat maps you can use histograms
and so on now moving further we would
want to explore the seasonality right so
when when you further explore the
seasonality of our data we can use box
plots basically to group the data by
different time periods and display the
distribution for each group now how do
we do
that let's come here and let's see how
box plot works so I can just do a simple
box plot and I can choose my consumption
column and that gives me just the
consumption data but this really does
not give me any meaning I can look at
solar data I can look at the wind data
and we can also see some outliers here
so we can create box plots but if we
would want to do a box plot what is box
plot it is basically a visual display of
your five number summary that is you
want to look at your mean median you
want to look at your 25th percentile 50
percentile or 75th percentile so we can
use a quantile function use the
consumption column and then you
basically give a vector which shows you
five number summary so that's your
quantile and then let's do a box plot so
if you are looking at quantile it tells
me what is the minimum what is 25th
percentile 50 75th and 100 that's from
my consumption column so let's create a
box plot for consumption let's give it a
name as consumption let's give Y axis as
consumption and a limit for y AIS now
that's my consumption graph so I can
look at yearly data now that will make
more meaning rather than just looking at
the complete consumption data so how do
we do it yearly so we will say
consumption and then I will say the ear
column so it is consumption but grouped
based on ear so here I can give x-axis y
AIS and I can give y limit so let's
create this and this makes more meaning
we can give some coloring scheme here
but but now I'm looking at 2006 2007 8 9
and so on and we can look at the data
what is the range right it gives me 5
percentile or sorry five number summary
of the data per year and it basically
allows me to look at the seasonality of
this similarly we can create box plot by
just giving consumption yearly grouped
and here I'm giving the title as
consumption y axis x axis and y limit
wherein I can also use lass so this is
one more feature which you can do and
that basically will give me the tick
points if you compare this one to the
previous graph so when I created this
previous graph I had 2006 2008 and I had
from 600 to 18800 and if I go for the
next one I am basically seeing more
useful information now let's look look
at monthly data so I would want to group
it based on months and let's create that
so this gives me the monthly data where
I'm looking at
months and I could select a particular
year or I can just do a grouping based
on months so I can have multiple plots
to see a difference here so let's do
this now let's create a box plot for
consumption which is monthly data and
let's give it a color let's look at the
wind data which is again grouped monthly
and let's look at the solar data which
is grouped monthly now if I zoom in it
basically gives me the seasonality of
the data for your wind for your
consumption for your solar so what we
are doing is we are creating these box
plots which are giving us values now
what I can also do is I could look at
the day wise also but before we look
into this how do I infer some
information from these box plots which
are being created so this is what we
have done where we are looking at the
data for month and these box plots give
me year seasonality which we were seeing
in earlier plots but give some
additional insights so if I look at the
data here it tells me the electricity
consumption is generally higher in win
winter now this is based on months so we
can see consumption is higher in Winters
and lower in summer so we can obviously
look at our plot we can see where it is
lower where it is higher and then we can
look at the median and lower two
quartiles are lower in December and
January compared to November and
February so that is you look at the
quartiles and you will see that the
median and lower two quartiles are lower
in December and
January here Chan and December so you
can look at from my plot now this is
giving you some idea on
seasonality now that might be due to
business being closed over holidays now
this one we were also seeing when we
looked at time series for 2017 only and
box plot basically confirms that there
is this consistent pattern throughout
the years now when you look at your
solar and wind power production both
will give you a year seasonality what we
are seeing here and if basically I look
at the data so it depends on what
parameters you are choosing but if you
look at solar it will reflect the effect
of occasional extreme wind speeds
associated with storms and other
transient and since we are grouping it
based on mon we can see this pattern is
quite evident every year now what we can
do is we can group the data day wise so
here let me again reset this to one plot
per graph now I'll say box plot I'll say
consumption which is group based on day
now we know that there is a day column
and let's give a y limit and let's look
at the data so this is where I'm
grouping the data day wise so you look
at 31 days and you look at the box plot
so this is where you are plotting it on
a daily basis so you can look at the
data you can break it down to a
particular week so here I have given day
and I have chosen all the 31 days but I
can break it down to a week and I can
look at the data so if we look at the
data per week or per day we can
basically infer that electricity
consumption where I'm doing consumption
group by day is higher on weekday than
on
weekends so time series with strong
seasonality can often be represented
with models that can decompose signal
into seasonality and long Trend now this
is an easy way now how do we look at the
frequency of the data that could be
interesting to see so let me uh look at
say the yearly
data which we were seeing
here now let's go further and here we
have looked at data so what we will do
is we look at the frequency now when you
look at the frequency when you talk
about frequency in your data so we have
the modified date column which gives me
a frequency and if we really look into
the data that will tell me that the data
is is on a daily basis so for that let's
look at my data 3 again which gives me
data and you can just see all the datas
data or dates are in sequence so your 22
23 24 25 26 and so on I can look at I
can access a deer
package that is basically allowing me to
work in a better way now I can look at
the summary of this and for all my
columns I'm seeing what is the minimum
five number summary date and consumption
so date does not show me anything
because this is not in a date format it
is just a factor but other things have
the fin number summary so we are looking
at wind plus solar we are looking at
year and month and day and all these
columns now what we will do is we will
want to find out the sum of
each column how many entries does it
have and we will say the value should na
value should not be considered so let's
look at this one so it tells me for my
particular columns so let me run this
again and that shows me for each column
how many values you have and these
counts do not include the na values now
similarly I can find out specifically
for consumption I can find out is there
any na value so I'm saying is Na and
let's find out if there is any na value
or missing value in consumption it says
zero okay that's good if you look in
wind it tells me there are, 1463 entries
which are na similarly solar similarly
wind do solar or wind plus solar so it
gives me a count of Na values that is
missing values and also values which are
not missing so to understand frequency
what we can do is we can find out the
minimum on the date that is the First
Column and I'm saying
RM na. RM is true that is get rid of Na
values and find out the minimum and
let's look at the minimum value this is
the minimum from my modified date now if
I would want to get the frequency I can
basically use sequence function so I can
say from X minimum that is the minimum
value I want to look at the frequency
that is day wise and let's just look at
five entries and see if there is a
day-by-day
frequency so let's look at the value of
this and obviously it tells me there is
day wise frequency so that allows me to
look at the frequency look at the type
of it it is an integer class is a date
so similarly we can say from X minimum
we can basically look at the frequency
month-wise
and I can again look at five records so
that shows me monthly data right so I
can extract the data for frequency
similarly yearly data and that's also
very useful now we can select data which
has na values for wind so how do I do it
I would want to find out the wind column
and I want to find out where the Val
values R na a so I will create a
variable and here I will say my data 3
and then I give a conditional where I
say is na in the column so let's do this
now once I've done this once I've done
this I have said that my selected wind
data from my data 3 where we said na
values and I will give the names to this
so names should be in my data 3 I'm
interested in mod data consumption wind
and solar so these are the four columns
I'm interested in let's look at first 10
records here or first 10 rows so that
tells me these are the values where wind
has na or missing
values I can always do a view and that
gives me the complete data so it
basically shows me
1,463
entries and here it shows me all na
values so you can look at all the way to
the end and it shows me wind has na
solar does have some value here in the
last row but then also if you see the
numbers
have a difference so you have 1 4 61 and
then you have 2174 so there is a
difference so there is some data in
between where wind has some values so we
have found out na values now what we
will do is we will select data which
does not have any values so I will call
it cell selected wi two I'll again use
my data 3 I will say which but now I'm
saying not na from this column and I
will select the data for the columns so
I'm interested in looking at 10 records
and this shows me not any values so no
more missing values so if I really look
at this data as I saw earlier which has
Na and if I look at these values which
are not na for the wind column so
looking at these two result we will know
that in year 2011 wind
column has some missing values so let's
focus on year 2011 so how do I do that
let's call it a different variable I'll
say my data three I will say here when I
say which where we were saying na here I
will say the year should have a value of
2011 and I want all these
columns let's look at the data here and
this is showing me 2011 but we are not
seeing all the values so there are some
values but then there are some missing
values also for 2011 based on whatever
analysis we have done so let's look at
the class of this it is basically a data
frame do a view and this one will help
me in finding out where are the na
values so if you just scroll down
looking at all the data let's search if
wind column has a na or a missing value
and I will see if there is any missing
value in which column or which row it is
for the wind column so we have all the
values which are
existing I could select and search for
one specific value and I'll show you how
we can do that so here let's scroll all
the way down so it's like you're
exploring your data and seeing is
wind column having na or missing value
for a particular row and let's scroll
here and here you see there is a missing
value for one particular row so
13th December 2011 has wind value 15
December has wind value but your 14th
December does not have right similarly
we can search so there was only one
entry which was missing now that could
be for some reason and might be it was
not calculated mightbe it was not
tabulated so we have a missing value and
that can affect my plotting that can
affect my analysis so let's look at the
number of rows in this which will tell
me how many rows we have for 2011 so it
tells me 365 so that is basically the
number of days in a year now we will
find out if there were na values so we
earlier checked total number of Na
values per column
that is in your row number 265 to
269 we can see here 265 to
269 so this is where we were seeing are
there any na values right so let's go
back
here and we want to find out the number
of Na values for a particular year how
do I do it so I can just do a sum I will
say is na now I'm interested in my data
3 wind column and I'm saying my year has
to be 2011 but I'm finding out the na
values so let's do this and it tells me
one and that's right that's what we saw
when we did a view let's see how many
non na values you have and that is 364
so that
basically satisfies my logic so it's 364
+ 1 missing so there are 365 let's look
at the structure of this it tells me you
have modified date and date format you
have consumption wind and solar now
let's create a variable selected wind
four I will say wind three that is which
was having all my Na and non na values
for 2011 I will say let's find out the
na value because I'm interested in
finding out that particular row so I'm
saying find out where the value na and I
want all the columns let's look at this
one and this is my specific row which
has a na value now we know that data
follows a day wise frequency which we
have clearly seen now let's select data
which has Na and non na values so let's
say let's call it test one I will use
wind 3 which has Na and non na values
but now I will say I want the modified
date which should be greater than
12122 2001 now remember we had when we
were doing a view we saw that one
particular day or what we see here 14th
of December there is no date so I will
select a subset of data which includes
This na and non na that is might be I
can take 13th of December and 15th of
December so let's start from 12 12 so
the date should be greater than 12 12
that means 13th and it should be less
than 16 so that is 15th and the columns
right so now we have some data let's
look at this so I have a I've selected a
subset of data I could have done this
using subset also so I have Na and non
na values now why are we doing this so
sometimes you might have some data for a
particular column and you may want to
find out if there are any missing values
might be you want to fill them up or
replace them with something so that is
usually useful when you are doing a
trend detection so say for example you
have data for every month and might be
in one one of the months you have missed
or might be you have data for every year
collected monthly and then in one of the
years for couple of months you don't
have the data like I can say 2016 I have
data for all 12 months 2017 all 12
months 2018 might be I don't have data
from March and June 2019 I don't have
data for same months so I can forward
fill or backward fill them using the
previous year's same month data so we
can do that so here I have test data
where I've extracted a subset of data I
can look at the class of this it is a
data frame structure of this it has the
columns now let's use the library and
function and use the Tidy our package
and what we will do is we will fill it
up so I will use test one I will fill
the wind column which has a missing
value now once you do this if you notice
it has done a forward fill so it has
taken the previous value and it has just
filled up that so you can fill up the
data using different directions such as
up and down left and right and so on so
we can take care of missing values in
our frequency data which allows us to
basically analyze the data in a better
way now here we will want to also look
at some more data so this is to deal
with frequency of fill column wherein
you can take care of missing values
forward filled so filling values can be
done in different directions as I said
and you may want to First convert your
time series to specified frequency if
your data does not have a frequency but
we had now if you do not have a
frequency might be you can convert it
into a frequency such as weekly daily
monthly as I showed you and then
basically you can do a forward fill for
the values so for example if I have my
data I can break it down into weekly and
then look at the values and if there are
any values missing for weekly data I can
use a forward fill so that can take care
of my frequency data there
let's look at the trends of the data
which is the last part of this project
so basically let's look at the trend So
when you say Trend what does that mean
so in Time series data you always have
some kind of trend so that will exhibit
some slow gradual variability in
addition to higher frequency variability
such as seasonality and noise now to
visualize these Trends what we do is we
use what we call as rolling means so we
know how our data is spread over year or
month or day but how about looking at a
rolling average and see what is the
difference so a rolling mean will tend
to smooth a Time series by averaging out
the variations and
frequencies so this can be higher than
the window size so there is something
called as windowing where you can choose
a set of time frame you can also average
out any season ality on a time scale
equal to window size so this will allow
you to look at lower frequency variation
in the data so when we are looking at
electricity consumption time series we
already saw there is a weekly pattern
there is a yearly seasonality which we
saw using box plots so we can also look
at the rolling means of the time scales
how do we do that so for this you can
use some package like zoo and then you
can basically use a rolling mean using
this Zoo package and you can say what is
the frequency with which you want to
calculate the rolling mean now how do we
do this let's look at this data so here
I'm going to my look at my data 3 which
we have been using so far now let's call
it a 3-day test you can give it any name
I'm going to use my data 3 I'm using the
PIP in function
now I will use deer and I will arrange
the data descending in ear now you can
always break it down step by step and
you can see the result of this so I'm
going to arrange this data in descending
order of year so obviously my last one
2017 or 2018 will be on the top you want
to group the data by year so it depends
on how many years we have we'll see so
you can group the data by year now this
data is there then used to basically
mutate so mutate function is going to
allow me to use this rolling mean so
I'll call it as says 03 day so I'm going
to calculate a rolling mean every 3 days
for my consumption column and basically
let's ungroup this so let's see how this
works sorry yeah let's look at this and
here when I'm doing a 3-day test let's
look at the result of this
and then I'll explain this so if you see
here we have the test 3day column now
this has the rolling average now what
does that mean so first value here what
we see is
1367 is the average consumption
in7 from the first date with a data
point on either side of it that is you
can look at this date so 113 0 then you
look
at you looking looking at the value 1367
here so you look at 1 13 0 1441 1 153 0
if I take a mean of these so for example
if I would just do this
part and that is giving me mean okay
because I have a comment so let's
basically add anything as comment and
then let's do this so it saves me 1367
that's what we are seeing here right so
you're got getting a rolling average
every 3 days similarly if you want every
five days it takes the five values and
it gets the mid value right so you can
always find out the mean rolling mean
for a particular frequency now let's do
that for 7 days that is weekly data and
yearly data that is 365 days so how do I
do it same logic my data test now I'm
using my data three I'm arranging it in
a descending order I'm grouping by year
so when you do a group by year so
earlier when we did a grouping by and
when we looked at the data it was
telling me how many rows we had right so
let's do a grouping by year and let's
say test 07 so that's a rolling average
every 7 days and I'm also saying take
care of the na values similarly I'm
getting rolling average every 365 days
might be you can do quarterly mightbe
you can do half yearly and let's do this
so let's create this my data test and
let's look at the result of this so I
will use my data test I will say arrange
based on modified date now we know there
is a column called modified date I want
to just look at 2017 data so I'm doing a
filter right and then I will choose what
are the columns I'm interested in so I
will look at the 7 and 365 day and let's
look at say first seven records so let's
do this and that basically gives me the
consumption value modified date year and
my rolling 7day average or 7day mean
which is for first 7 days and then 365
you will not see the data here but if I
do a view on this I can basically see
the values so you can always select a
particular column to see the
values these are the values for every 7
Day rolling average this is for 365 days
every 365 days so you see all the values
are missing but every 365 entry you will
have basically some data now let's do a
plotting of this and basically visualize
this data which we are seeing rolling
average so let me first do a plotting
one plot per graph and let's do a
plotting I will take consumption
data xaxis y AIS color and give a title
to this so let's create this and that's
my consumption data which is spread over
a period of time and that's fair enough
but now let's add some more plot to this
so I will add the 7day rolling average
to this so for second plot to be added
in the same one in R you can use points
so I will say points I will choose seven
data column type is line width x limit y
limit and color so let's do this this
and that's my pattern 7day rolling
average which basically gives me some
kind of trend similarly I can add one
more here and this time I will choose
the 365 day and look at the pattern
lines so now you see some Dots here well
you could do it in a different way so I
can just add Legend to this and I can
say Legend will be aware in x-axis and y
axis so I'm saying it will be
2,500 and Y is 1,800 so my Legend will
come in somewhere here I'm saying my
Legend will have consumption test and
this one I can give some names I can
give what is the color I can say what
kind of Legend it explains what is for
each color and then basically a vector
so let's add a legend to this and I've
added a legend now you can do a zoom and
look at the
data and here I see that uh my x-axis is
fine but y- axis is going a little out
of my plotting area so I can actually
change that so here I have 1,800 how
about making it
1,600 and let's look at this one so we
can
basically uh go for this one and start
again here plot and points and line and
then add a legend right and you can
basically place your Legend anywhere in
the plot so this basically is giving me
me the trend what I'm looking at my
rolling average so similarly you can
look at the trend for wind and solar
data so what we are seeing here is when
you look at Trend this is one more way
of looking at it you can always create
plots in different ways so 7-Day rolling
mean has smoothed out all weekly
seasonality which we were seeing Here in
My Graph where you look at every 7 Day
preserving the yearly seasonality so
7day will tell that electricity
consumption is typically higher in
Winter and lower in summer so better is
you break it down uh yearly so here if
you look at every year you can see when
is winter when is summer what is the
seasonality what your Trend what you're
seeing here and if there is a decrease
or increase uh for few weeks every
winter so similarly if you look at 365
now as you said as I said rolling
average basically uh reduces the
variation so if I look at 365 rolling
mean we can see long-term Trend in
electricity consumption is pretty flat
now that's what we are seeing it's kind
of pretty flat there is not much
variation over years if you really join
these dots
so we can basically see some highs and
lows and that gives me a trend now this
is how you can do a trend detection and
similarly we can do plotting for wind
and solar so this is a small project
which I demonstrated using R now all
this code which you have here in the
form of a project. r file you can find
here in my GitHub page this is the
document which explains some things
field free to download this and you can
add details to it this is the sample
data set which you can also find in my
repository in the data sets folder so
continue learning and continue
practicing are want to be a certified
data expert then here we have
postgraduate program in data analytics
by simply learn take a glance at the
notable features and skills offered in
this course you will benefit from
exclusive IBM hackathons and ask me
anything sessions 8 times more
interaction in live online classes with
industry experts Capstone projects
across three domains and over 14 data
analytics projects using real data sets
from Google Play Store Lyft World Bank
and more master classes from puu faulty
and IBM experts along with simply learns
job assist for better job prospects
acquire skills in data analytics
statistical analysis using Excel data
analysis using Python and R and data
visualization using tableu and powerbi
enroll Now using the course Link in the
description box Excel is a really
powerful tool for data analytics and
Reporting and pivot tables are one of
the features that Excel offers for
creating table reports to summarize our
data let's begin by understanding what
is a pivot table a pivot table is a tool
that summarizes and reorganizes selected
columns and rows of data in a
spreadsheet to obtain a desired report
it does not actually change the
spreadsheet data it simply pivots or
turns the data to view it in different
perspectives pivot tables are specially
useful with large amounts of data that
would be time consuming to calculate
manually now let's understand the
different components of a pivot table so
there are four main components first we
have rows when a field is chosen for the
row area it populates as the first
column in the pivot table similar to The
Columns all row label
are unique values and duplicates are
removed columns is the second component
when a field is chosen for the column
area only the unique values of the field
are listed across the top then we have
values each value is kept in a pivot
table cell and display the summarized
information the most common values are
sum average minimum and maximum finally
we have filters filters apply a
calculation or restriction to the entire
table so let's jump over to Microsoft
Excel and let me show you the data set
that we will use in this demo so with
India being ready for its 16th census in
2021 that is next year it is a good time
for us to analyze India's last census
data from 2011 and see where different
states and cities across India stood in
terms of population literacy and other
socio economic factors we will analyze
this data by creating different pivot
tables in Excel and explore some of its
features so let's begin first I'll show
you one of the features that Excel
offers us so suppose I click on any cell
and hit control + Q you can see our
entire table is selected and at the
right bottom there's an option of quick
analysis now you can see by default
Excel has prompted certain features such
as formatting we have charts totals and
there's one more called tables now Excel
by default has created some P tables for
us now the first one you say sum of
District Cod Cod by state names next we
have sum of sex ratio by state name then
we have sum of child sex ratio some of
male graduates and some of female
graduates by state name and there are
others before creating our pivote table
so let's have a final look at our data
set so First Column you see is the city
column so there are different cities
from different parts of India then we
have the state code we have the state
name district code we have we have the
total population followed by male and
female population next you can see we
have the total literates from each City
then we have the male and female
literates next we have the sex ratio
then we have the child sex ratio next we
have total number of graduates and
finally you can see we have male and
female graduates so using this table
we'll create several peot
tables now first of all let's create a
peot table to find the total population
for each state and sort it in descending
order so you can see here we have the
problem statement so our first P table
will have the total population for each
of the states in descending order so to
create a poot table you can click any
cell in your data go to the insert Tab
and here left you can see we have the
option to create a pivote table so let
me select pivote table now now my range
is already selected the entire table and
here I'll choose existing worksheet
because I want to place my pivote table
in the same worksheet and I'll give my
location I'll point to cell Q5 now let
me click
okay you can see the peot table Fields
appears here on the right now since we
want to find the total population for
each state so what I'll do is I'll drag
my state name name on two rows so here
in our P table you can see we have the
different state names listed now we want
the total population for each of these
states so in the field list I'll search
for total population which is this one
and drag it under
values you can see we have our sum of
total population for each of these
states by default Excel will sum any
numeric column you can always change it
to average minimum maximum anything you
want now we want to sort this colum in
descending order so I right click go to
sort option and choose Zed to a that is
largest to
smallest you can see here in 2011
Maharashtra had the highest number of
population or the total population in
Maharashtra was the highest then it was
utar Pradesh we had Andra Pradesh and if
I come down we have Nagal land and
andman and nicobar Islands towards the
end so this is a simple peot table that
we created now the next problem we have
is we want to find the total sum of lats
in each City belonging to a certain
state so let's see how to do it I'll
click on any cell go to insert and here
I can click on pivot table my range is
selected I'll choose existing worksheet
and give my location which is Q5 I click
on
okay now here we want to find the total
sum of literates so what I'll do is
first let me drag total literates column
to values you have the total sum of
literates from all the
states next I want to see the sum of
total literates based on states and
cities so let me first drag state name
onto rows and then
will ra City on two rows you can see
here we have our P table
ready to the left of the pivote table
you can see we have the state names and
the cities per state and on the right
you can see the total number of
literates from each City if I scroll
down we have Assam then you can see we
have
Bihar and if I keep scrolling we have
all the states harana Iman prades this
Jammu and Kashmir which has now become a
union territory we have jarand Karnataka
and other states as well moving
on okay so the next thing we want to see
is what is the average sex ratio and the
child sex ratio for each state with that
we also want to find the states that had
the highest and lowest sex ratio in
2011 so let's create a p table for this
I'll click on any cell go to insert
choose peot table click click on
existing worksheet I'll select cell Q5
and click on
okay now since we want the average sex
ratio and the child sex ratio so first
I'll drag those columns either you can
manually scroll and drag it or here you
have the option to search for it so if I
look for child you can see we
have the same column listed can just
drag it from there let me delete this
and I also want the sex ratio so I'll
place it on top of child sex ratio next
we want to see it based on different
states so what I'll do is I'll take
state name and put it under rows so here
you can see we have our P table ready on
the left you can see we have the
different state names listed and on the
right we have the values now we want to
find the average Now by default Excel
will sum the numeric columns you can see
it tells you sum of sex ratio and child
sex ratio so what you can do can click
on this drop down and go to Value field
settings and here summarize values by
you can choose average you can see the
custom name it says average of sex ratio
click on okay
our entire column is now giving us the
average sex ratio similarly for this
column let me convert it into average
I'll again click on the drop down go to
Value field settings click on average
and click
okay and you can see here we have the
average of child sex ratio for each of
the states now the next question says
which states had the highest and lowest
sex ratio so we'll consider this column
so we'll sort it in any order you want
you can do it either ascending or
descending let me sort it in descending
order you can see we have our column
sorted now so in
2011 Kerala had the highest sex ratio
and if I scroll down to the bottom you
can see Himachal prades had the lowest
which is around 818
up next let's explore one more feature
of peot table so suppose you want to see
the top or bottom few rows of a peot
table you can do that as well so here we
have a question at hand we want to find
the top three cities with the highest
number of female graduates so let's see
from the entire pivote table how we can
filter the top three cities so I'll go
to insert click on the P table option go
to existing worksheet click on on Q5 and
hit
okay now since we want to find the top
three cities I'll drag City column onto
rows and then we want the female
graduates so in the search bar I'll look
for
female and I'll choose this column that
is female graduates and drag it here
onto values so I have the sum of female
graduates for each of the Cities now
since we want to find the highest number
of female graduates in the top three
cities so let me first sort this
column I'll sort it in descending order
now we have it sorted now from this you
can say that Delhi greater Mumbai and
bangaluru are the top three cities but
it's displaying all the cities for us so
let's filter only the top three so what
you can do is right click and go to
filter under filter you have the option
of top 10 I'll select this here I only
want the top three so either you
can go down like this or you can
directly type three your column is
already selected let me just click on
okay there you go we have the required
pivote table ready and it only displays
us the top three cities with the highest
number of female graduates
now the next thing we want to see is how
to use a Slicer in a peot table so we
have a question here What's the total
population for all the cities in
Rajasthan and Karnataka so let's create
a pivot table for this and see how you
can use a slicer to filter the
table click on existing I'll click on a
location this time
q6 click
okay now since I want the total
population so I'll drag total population
onto Val use and then I'll select the
city on to row and then the state name
also I'll place it on top of City so you
have in the peot table all the states
and their cities and on the right you
can see the total population for each of
these cities but our question is we want
to find only for Rajasthan and Karnataka
now for that what you can do is go to
insert and create a slicer either you
can create from this option or you can
go to pivote table analyze option and
here you have the option to create or
insert a slicer I click on this and
since we want to slice the table based
on state that is Rajasthan and Karnataka
I'll choose state name as my slicer
field you can see this is my slicer here
now you only want the data for Rajasthan
and Karnataka so I'll search for these
two so here we have Karnataka so let me
select Karnataka
first and I also want for
Rajasthan so let me select Rajasthan
also you can see in our pivot table we
only have data for for Rajasthan and
Karnataka so this pivote table shows you
different cities from Karnataka and the
total sum of population from each of the
cities and similarly we also have for
Rajasthan moving ahead now we will see
another very interesting feature of
pivot that is how you
can create percentage contribution of a
table for example we have a question
here what's the percentage contribution
of of male and female literates from
each
state now we want to see in terms of
percentage and not as sum or average
let's do that I'll create my pivote
table click on
existing and I'll select an empty
cell okay now here since we want to find
the percentage contribution of male and
female literates so first I'll
drag male literates onto values followed
by female literates onto values by
default it has summed up the male
literat and female lit value and also I
want to drag State
column to
rows so here you can see the sum of male
literates and female literates per state
I want to convert this as percentage
contribution so what we can do is I'll
select any cell and I'll right click and
I'll go to so value as and here I have
the option to select percentage of grand
total so I'll select
this you can see we have the percentage
contribution of male litat through the
total now if I sort this you will get to
know which state contributed or has the
highest percentage
contribution so we have m rra for male
literates then we had utar prades in
2011 if I come
down we had migala nagaland and Andaman
and nicobar
Islands as two states which had little
or minimal contribution to male
literates similarly let's do it for
female literates I'll go to so value as
and select percentage of grand
total so you can see here also
Maharashtra utar Pradesh
then Gujarat and all had the highest
percentage contribution to female
literates so this is another good
feature to convert your data and SE and
terms of
percentage now moving ahead let's say we
want to find the bottom three cities
from each state that had the lowest
female graduates we can do that as well
I'll go to insert click on
pivot go to existing worksheet select an
m worksheet and click on
okay now since I want to see based on
States as well as cities so let me drag
the state name first onto rows and let's
drag the city column onto
rows next we want female graduates so
let me look for female graduates in the
field list I'll drag it onto
values now we have the list of states
and the respective cities and to the
right of the P table you can see the sum
of female graduates from each
City now first I'll sort this column
I'll right click go to sort and click on
sest to largest now we have sorted our
female graduates
from shortest or smallest to largest now
since I want to find the bottom three
cities from each state I'll come to the
cell right click go to filter and select
top 10 now
I'll replace top 10 with bottom and I
want the bottom three cities from each
state I have my column selected that is
some of female graduates if I click on
okay you can see here some of the states
don't have three cities so you can see
andan and nicobar islands has only one
city that is Port player while the
remaining you can find the bottom three
cities with the lowest number of female
graduates so Andra Pradesh had these
three in Assam we had Naga then there
was tiar and Sila similarly if I come
down in harana we have palwal kathal and
zind if I come further here you can see
for Karnataka this gangavati this Rani
benur and this Kolar similarly you can
see for Kerala as
well now moving
ahead now in the next example I'll tell
you how you can create a calculated
field or a calculated column in Excel
with the help of a pivote table so in a
pivot table you can create or use custom
formulas to create calculated fields or
items calculated fields are formulas
that can refer to other fields in the
pivote table calculated Fields appear
with other value fields in the pivote
table like other value Fields a
calculated Fields name May proceed with
sum of followed by the field name so
here we have a sales table that has
columns like the items which has
different fruits and
vegetables and those have been
categorized as fruits and vegetables we
have the price per kg and this is in
terms of
rupees and we have the quantity that was
sold now let's see if you want to find
the sales for each item in the table you
you can create a calculated field so
your sales column is going to be the
product of price per kg and quantity so
let me show you how you can do that with
the help of a pivote table I'll create a
pivote table
first click on an empty cell hit okay
now if you see on the top under P table
analyze and under calculations we have
the option Fields items and sets if I
click on this drop down I get the option
to create a calculated field or insert a
calculated field I click on this I'll
give my field name as
sales and I'll select my
formula I'll first click on price per kg
and hit insert field I'll give a space
hit shift 8 to give the product symbol
and then I'll double click on quantity
now this is my formula fora for sales
that is price per kg multiplied by
quantity I click on ADD and I click on
okay if you see here there's a
calculated field that is present in the
pivote table fields which is seals but
it did not add it to our original table
or original table is the same but here
we have added a calculated field which
is present only in the pivote table list
now we can use this it has already taken
it under values now let's say I want to
find the sum of seals for each item
under each category you can see it here
we have our category fruit and we have
our category vegetable and under that we
have different items like apple apricot
banana similarly in vegetables we have
broccoli the carrots corn eggplant and
others so this is how you can create a
calculated field in a pivote table
now this's one more good feature that
Excel offers us in pivote table is to
create a pivote chart so you can use
your pivote table and create different
charts so I'll show you how to do that
if I go to
insert here I have the option of
recommended charts I click on this Excel
gives me some default charts which you
can use let's say I'll select this
let me drag it a bit to the right here
you can see I'll close this peot field
list this is a nice bar chart that Excel
has created this is called a pivote
chart now here you can see the category
fruits and vegetables and the different
fruits and vegetables or the
items in the y axis you can see the
total Sals if you see from the graph
guava meet the highest amount of Sals
now if I sort this let's sort this
first you can see it here fruit guava
meet the highest amount of sales now
since I sorted and changed my P table
the P chart also automatically gets
updated similarly there are other charts
also that you can create let's go to the
insert Tab and let's click on
recommended charts again let's look for
a pie chart so this is a pie chart that
you can create let me click on okay okay
so here is our PI chart and each Pi
represents a certain item and the pi
that has the highest area represents it
had the highest amount of seals in this
case you can see it is quava and
similarly we have other items as well
this is fruit
banana that's
corn and we have spinach and
others let's explore a few other charts
so first I'll click on my P table go to
insert and under recommended charts
let's now select a line chart if I hit
okay move it to the right so this is a
line chart you can see it starts from
guava which had the highest amount of
sales then it
drops and in the x-axis you can see the
different items similarly when it starts
with the vegetables broli made the
highest amount of sales with 2 800
rupees and our lowest was eggplant at
900 rupees for fruits papaya sold the
least at 700 rupees let's take another
chart I'll go to insert under
recommended charts let's
see this time we'll see a bar chart now
this is
a horizontal bar chart and not a
vertical one we just saw a vertical
column chart like this this is an
horizontal al bar chart now you can
always increase and decrease the size of
these
charts let's explore a last chart let's
take the area chart for now so this is
an area chart again it looks similar to
the line chart it starts with guava
which had the highest amount of sales
similarly papaya under fruits had the
lowest amount of Sals under vegetables
it was broccoli and and finally eggplant
made the lowest amount of sales under
vegetable now let's go to our first
sheet and summarize what we have done in
this demo for p tables in Excel so we
had our
data this is a 2011 Census Data from
India we had the different cities the
state names and we had the total
population total literates female
literates male literates we had the sex
ratio total graduates and other
information
so we began by understanding how to
create a simple pivote table where we
calculated the total population for each
state and sorted it in descending order
we found that Maharashtra utar Pradesh
had the total population in
2011 then we saw another prevote table
where we calculated the total sum of
literates in each City belonging to a
certain state so you can see we had the
different state names and the cities
under each
state then we saw another feature where
you could calculate the average of a
certain numerical column so here we
calculated the average sex ratio and the
child sex ratio for each state and found
out which one had the highest and lowest
sex
ratio after that we saw how you could
find or filter
tables we saw how to find the top three
cities with the highest number of female
graduates we found out the Delhi greater
Mumbai and bangaluru with the top cities
with highest number of female graduates
next we saw how to use Slicer in a PO
table so we sliced our table based on
Rajasthan and Karnataka State and saw
the total population for all the cities
in Rajasthan and
Karnataka in the next
sheet we explored another feature that
was to find the percentage contribution
of male and female literates from each
state then
here we saw how to find out the bottom
three cities for each state having
lowest female graduates one thing marked
that some of the states did not have
three cities for example Andaman had
only one city that was Port player but
the others we found out the bottom three
cities that had the lowest female
graduates finally we looked at how to
create a calculated field in a pivote
table so we saw how to create create a
calculated field called Sals and then we
explored how to create different charts
and graphs so this was an area chart
that we saw there a column chart we also
saw or looked at a bar chart that was a
horizontal bar chart similarly we saw
how to create a pie chart as well in
this video we'll be creating two
dashboards using a sample sales data set
so if you want to get the data and the
dashboard file that we'll be creating in
in this demo then please put your email
IDs in the comment section of the video
our team will share the files via
email now let's begin by understanding
what is a dashboard in
Excel a dashboard is a visual interface
that provides an overview of key
measures relevant to a particular
objective with the help of charts and
graphs dashboard reports allow managers
to get a high level overview of the
business and help them make quick
decisions there are different types of
dashboards such as strategic dashboard
boards analytical dashboards and
operational dashboards an advantage of
dashboards is the quick detection of
outliers and
correlations with Comprehensive data
visualization it is time saving as
compared to running multiple
reports with this understanding let's
jump into our demo for creating our
dashboards we'll be using a sample sales
data set let me show you the data set
first so here is the sales data set that
we'll be using for our demo so this data
set was actually generated using a
simulator and is completely random it
was not validated though we have applied
certain transformations to the data
using power query features so this data
as you can see has thousand rows so
using the simulator we had generated
thousand rows of
data similarly if I go on top you can
see this data set has 17 columns now let
me give you a brief about each of the
columns
so first we have the region column so we
have Middle East and North Africa this
North America Asia subsaharan Africa and
others similarly we have the country
names from which the item was ordered
the third column is the item type so we
have different items Cosmetics
vegetables there's baby food cereal
fruits Etc then we have the
representatives name or you can see this
as the customer name who ordered the
product
then we have a sales Channel column so
there are basically two channels whether
the item was sold offline or online next
we have the order priority column now
here C stands for critical then we have
H which is for high priority orders then
we have M for medium priority orders and
finally we have L which is for low
priority orders you can see the order
date column then we have the order ID
the ship date
next we have units sold which is
basically the total number of units sold
for each item then we have the unit
price column this is the price at which
each product was sold then we have the
unit cost column which is basically the
production cost for each of the items
next we have the total revenue the total
revenue is actually the product of unit
sold and unit price then we have the
total cost column now the total cost
column is actually the product of unit
sold and the unit cost similarly we have
the total profit column so total profit
is the difference between total revenue
and the total cost and finally we have
created two more columns that is order
year and then we have order month now
these two columns were actually
generated using the power query features
so we used the order date column which
is this column and extracted order year
and order
month so first we are going to create a
revenue dashboard where we'll focus on
generating reports for Revenue by order
year Revenue by year and region Revenue
by order priority and much more we'll
create separate po tables and po charts
and format them to make them look more
interesting and presentable We'll add
slices and timeline to our dashboards in
order to filter it based on specific
Fields now let's create our first report
to see the total revenue generated each
year
so we need to create a p table for this
I'll click on a cell in my data set and
then I'll go to the insert tab here we
have the option to select the pivote
table I click on this you can
see my table range is
selected next I want to place my pivote
table in a new worksheet and let's just
click on okay there you go so we have a
new sheet where I can place my P tap
table so first I need to find the total
revenue generated by each year so what
I'll do is I'll drag my order ear column
under rows and then I'll select the
total revenue column under
values you can see I have my pwo chart
ready now if you want you can sort this
so from the data you can see we have
order Year from 2010 to
2017 now based on this data let's create
our pivote chart so I'll click on any
cell go to insert and here you have the
option to select recommended charts I
click on this now actually I want a line
chart so I'll click on line here and
select
okay there you go so we have
successfully created our first pivote
chart now let me show you how you can
format this chart to make it more
readable so first let me delete these so
I'll right click and select hide all
field buttons on the chart so this will
delete the buttons present on the chart
now let me go ahead and edit the chart
title so the title I want is total
revenue I'll type it
down by year
all right next let's do a few more
Transformations so if I click on this
plus sign which is actually for chart
elements we have some options like to
add access access titles chart title
data labels there grid lines Legend and
others okay so let's remove the legend
now you can see the total Legend is gone
now let me add axis titles so we'll
label our x-axis and y axis so here
under
xaxis I can write it
as
ear similarly on the Y AIS I'll put
renue okay now you can move a bit all
right
now let me select this chart Style
option and go to Colors first
first here I'll select yellow color okay
and then let me go back to style let's
select a new style from this
list I
want this style okay now you can also
add data labels so I'll just click on
data labels you can see we have the
revenue for each of the years now this
is not readable at all so we'll format
this a
bit if I click on this Arrow here I have
more
options if I scroll down you can see we
have something called as number here
I'll expand this and under category I'll
select
custom now here we'll give a format
code which is a bit different
so this is actually a kind of a formula
so I'll write if my Revenue value is
greater than let's say 9 lakh
99,000 let me make sure there are six
nines here so 1 2 3 4 5 and six okay we
are good to go I'll close the
bracket I'll give a hash
give two
commas so if the revenue is greater than
999,000 I'll put it in the format of
millions So within double quotes I'll
write
M I'll give a
semicolon followed by another
hash and if the value is less than the
desired
number it should be 0 million ion let me
click on
add all right you can see how nicely we
have formatted our data and you see here
we
have added the new format which is in
millions all right now if you want you
can go ahead and adjust
the boxes let me move this a bit up I'll
delete this now if you notice this line
chart you can make a few conclusions for
example if you you see here in 2010 the
total revenue generated was nearly 175
million now this came down to 15 million
in
2011 then the revenue constantly grew
from 2011 till
2014 it reached 195 million and after
2014 it again came down to 180 million
and the revenue dropped significantly
between 2016 and 2017
in 2017 the revenue was just 96
million now before moving ahead to my
next chart let me just rename this sheet
so I'll write it as
Revenue by Year all
right
now let's analyze the revenue generated
each year in different regions so for
this we'll create another peot table let
me close close this I'll click on any
cell go to insert and select pivote
table I'll just click okay so that my P
table is placed on a new sheet all right
now this time we want the revenue by
each year and region so first of all
let's drag region to
columns
then let's drag the order ear column
under rows and then I'll select total
revenue onto values so here you can see
we have the pivote table ready so for
2010 you can see in Asia this was the
revenue generated similarly if you see
for
2013 this was the total revenue
generated in Europe and we have for
other years as well now let's create a
line chart based on this pivote table so
I'll select any sell in the pivote table
I'll go to insert and I'll click on
recommended charts from this list I'll
select my line chart and click on okay
there you go so we have our next pivote
chart
ready so on the right you see the
different regions that are present in
different colors let me just expand it
so that you can see all the regions we
have so in total we
have seven regions
and each of the regions have been
represented in different
colors so if you notice this
graph for the subsaharan African region
in
2012 subsaharan Africa meet the highest
amount of
sales now from the sample data you can
also tell that the revenue for North
America has been significantly low
compared to other regions similarly if
you see
for
Europe This was the revenue Trend
between 2010 and
2017 so if you see here in 2011 the
sales were at this level then it
significantly dropped in
2012 then in
2013 there was a huge Spike and then in
again came down in 2015 and so on so you
can make your own conclusion by looking
at these line charts now let's format
this chart so first of all let's delete
the field buttons present on the chart
and we'll
also delete the Legend all right now let
me just reduce the size of the
chart next we'll add a chart title
so
we'll give the title as
Revenue
by year and
region
okay you can also format the y axis in
terms of
millions so I'll right click on this
axis and I'll select format
axis I'll scroll down and here we have
the number drop down let me scroll again
under category I'll select custom and we
will use this format that we created for
our previous chart there you go you can
see our access labels have been changed
in terms of millions now so let's close
this and let me save it now you can
reduce the font size or increase the
font size let me just show you suppose
you want to increase the font size of
the chart title so you just select it
and from here you can can either reduce
or you can increase you can see now it's
12 if you want you can make it 16
similarly you can also edit the access
labels also by selecting the chart title
you can also move it to left or right or
you can place it in the center as well
for the time being let me just keep it
to the left all right now we'll see the
revenue and total cost by each region
and we'll create a combo chart for this
so let me show you how to do it I'll go
to my data sheet I have my cell
selected go to insert and click on
pivote table let me just click on okay
all right so for this I'll select my
region onto
rows and
then I'll have two columns under values
the first one is going to be total
revenue and the next column will be the
total cost column all right so here we
have the pivote table ready now based on
this pivote table let's create our
pivote chart so I'll go to recommended
charts and if you see below at the
bottom we have combo chart so this is
the preview of the combo
chart all right now let me just click on
okay there you go so we have a nice
combo chart ready here now now the way
to look at it is the bars represent the
total revenue which is this
column now the line
represents the total cost so let me go
ahead and edit this chart a bit so first
of all let's delete the field buttons
all right and let's also remove the
legend from
here next we'll add data labels so I'll
click on data label labels here okay so
these are the data labels
for the bars or the revenue column now
let's format the data labels in terms of
millions so I'll click on this Arrow go
to more options if I scroll down I have
number from here I'll select custom
and I'll choose my type that is in
millions all right so you can see we
have formatted our data next thing we'll
add a chart title so here I'll write as
Revenue
by
region it's actually revenue and total
cost by
region before moving ahead let me rename
the sheets as well I'll write revenue
and total
cost
similarly sheet three also I'm going to
rename it as
Revenue
by year and
region so this makes your sheet more
readable all right now moving
ahead next we are interested to get the
revenue generated by order priority and
for this we are going to create a pie
chart so let's go to the data sheet and
create our P table first I click on okay
now I'll select order priority under
rows and under values I'll select total
revenue so this is a very simple pivot
so you have your order priority so C is
for critical H is for high L is for low
and M is for medium now based on this
let's create a pie chart so I'll go to
recommended charts and here you have pie
chart I want to select this 3D type of
pie chart and I'll click on okay all
right so we have our pie chart ready let
me just resize it and from here I'll
remove the field buttons
and I also don't need the legend so I'll
delete this as well all right now let's
give a chart title so this is going to
be Revenue
by order
priority now let's add our data labels
I'll check this
option okay now let's again format this
in terms of
millions so here
I'll click on the last option I'll go to
numbers under category I'll select
custom and my type is going to be in
terms of millions there you go let me
close
this I will just move this to the
center all
right now if you want you can change the
color of the text as well so so let's
have it in white color and see how it
looks okay so this looks pretty decent
cool
now moving to our next report so this
time we are going to find the total
revenue by countries so we have multiple
countries present in our data set we
want to visualize the revenue generated
in each country so for this we are going
to create a horizontal bar chart so let
me show you how to do it but before
moving ahead let me just rename this
sheet so I'll write
Revenue
by I'll just put op which stands for
order priority all right now let's
create our horizontal bar chart I'll go
to insert click on pivote table and
select
okay so I want my Revenue based on
different countries so I'll select
country and put it under rows
and then I'll choose total revenue and
place it under values so here you have
the different country names we have
Afghanistan there's Albania let me
scroll down you have
Bangladesh there
are a number of countries you have Czech
Republic there's Estonia France Gabon
similarly if you scroll down we have
India there's Jamaica Italy and all the
way to the bottom if you go we have New
Zealand the Netherlands Philippines
Portugal we also
have
Singapore lots and lots of
countries we have the UAE United States
of America Zimbabwe and
others all right let me go up so based
on this pivote table let's create our
pivote chart so I'll go to insert and
select recommended charts from here I'm
going to select the column chart you can
see see the preview here and let me
click on okay all right so here you can
see the different country names at the
bottom and the revenue for each of the
countries let's go ahead and edit this
chart so first of all I'll
delete the field buttons okay and let me
also remove the
legend here I'll write Revenue
by
countries this going to be my chart
title
okay let's format this chart a little
more so I'll click on this option and
we'll select a new style let's
say I'll
select style six okay and let me now go
under colors and we'll select the color
of the bars so let's choose this color
okay so you have a horizontal column
chart
ready and at the bottom you can see the
different country names and we have
the
revenue
cool now let me go ahead and rename this
sheet so I'll write
Revenue
by
countries and hit enter
okay and finally we'll create another
report which is going to be part of our
Revenue dashboard and this is revenue by
items so we'll visualize our revenue for
different items present in the table so
if you see this we have cosmetic
vegetables cereal fruits the cloths
snacks households and other products as
well so let's check the revenue for each
of these
items so we'll continue the same drill
I'll create my poot table on a new
worksheet and this time I'm going to
drag item type under row and we'll have
the total revenue under values so here
on the left of the table you can see we
have the different item names and then
we have the total revenue so let me just
short this total
revenue from largest to smallest so you
can see here office supplies meet the
highest amount of Revenue followed by
household then cosmetics and fruits meet
the lowest amount of
Revenue I'll click on this go to insert
and select recommended charts this time
I'm going to create a bar chart so this
is how my bar chart is going to look
like I'll select okay all right now
let's format this chart a
bit I'll delete the field buttons and
I'll delete the legend as
well
and let's edit the chart title so this
is going to
be
Revenue by items
cool we also want to change
the color of the bars so I've selected
all the bars I'll go to my home Tab and
here let's say I want to select green
color all
right I've edited my chart a bit
now
let's make
it 40
and I'll remove the
Bold okay here if you want you can
change the font Also let's keep it in
blue color all
right finally let's rename this sheet so
I'll write Revenue by
items
cool finally now it's time for us to
merge all the charts that we have
created to
dashboard so let me show you how you can
create the dashboard I'll create a new
sheet and first thing I'm going to do is
I'll click on The View Tab and uncheck
grid lines so this will remove the grid
lines present in the
worksheet next I'm going to insert an
image so we'll have a background image
on our dashboard so the way to do is
I'll go to the insert tab Tab and under
illustrations I have the option to
select pictures or insert pictures so
I'm going to insert
picture present on the device that is my
computer I'll go to desktop and here I
have a folder called Excel dashboard
files and I'll select this dashboard
background and hit insert so this is
going to insert an image now let me just
drag this image so it covers a Fen of
portion so I'll hit shift and I'll drag
it all
right so you can see I have successfully
added a background image if you want you
can
still expand this background image a bit
to the right
cool now the next
thing is going to be the title of the
dashboard so I'll click on insert and
here I have the option to select a text
box so I'll click on a text box
and I'm going to place a text box in the
middle and I'm going to name this text
box as Excel
Revenue
dashboard on
sales
I'll centrer line
it let's do some more formatting so I'll
select this text box on the top you can
see shape
format here I'm going to expand this
shape fill and I'll select no fill so my
text box is transparent now and I'll
also remove the outline all right now
let me just double click on the title of
my dashboard and I'm going to
select a font you can select whichever
font you
want let me stick to britanica
bold and I'll increase the size to let's
say
all right I'll just drag the text
box I'll make the text as white instead
of black all right so we have
our title of the dashboard ready now if
you want you can also insert some icons
to this dashboard so I'll go to insert
and I'll click on illustrations again
and select pictures
I'm going to
add this two pictures which is of a
store and a
cart to make it
look visually appealing so I'll place
the
icons here and similarly let me just
copy
it and I'll place
the cart and the
store to the right as
well all
right
next the idea is
to bring in all the charts that we have
created and place it on the
dashboard so let me
copy each of the charts and place it on
the dashboard so I'll hit control V to
paste it
and we'll resize this as
well all
right similarly let me bring in all the
other charts as
well all right so now you can see I have
added all my charts and graphs to this
dashboard so you can see here we have
our line charts our column charts the
combo charts the Spy chart and others
now let me go ahead and format these
charts a little more so you can see this
looks a bit cluttered so let's adjust
the labels let me bring this down
similarly I'll bring 190 million a
little
below all right this looks fine
now one more thing we are going to do
is we'll remove the white back ground
from each of the charts and make it
transparent so let me show you how to do
it so I'll select this chart then I'll
right click and go to format chart
area here on the right you see we have
an option called No fill so if I select
no fill you can see the white background
is gone now similarly let me also remove
the grid lines so I'll select the grid
lines and hit delete so you have also
removed the grid lines from here
now let's also remove the white outline
that we have so I'll select this chart
go to format and here I'll go to shape
outline and I'll select no outline you
see this so we have our total revenue by
year which is a line chart and this is
completely transparent now now what I'm
going to do is I'll place this chart
over a box so I'll go to insert and in
insert we have the option to create a sh
shape so I'll click on illustrations and
here I'll choose a shape and let me
select a rectangle so I'll just create a
rectangle
here all right and now what I'll do is
I'll select this and bring this to front
I'll right click and choose bring to
front and I'll place this shape
below it all right now the next thing is
to edit the shape so first I'll change
the color of this box so let me select
this blue color and and let me increase
the transparency so I'll right click and
go to format shape here I'll increase
the transparency let's keep it to
25% or let's say 20% all right
next thing we'll just convert all the
font to white
color including the axis labels the
chart
title will
also convert all
the access labels to white color so it
looks better now we'll just adjust
our chart over here next next thing
let's just remove the outline so I'll go
to shape outline and I'll select no
outline you see we have now formatted
our chart let's just pull this a little
up all right now we'll add this blue
background to all the other charts so
we'll first add the background make it
transparent and then we'll convert the
font text to white color to make it more
readable and visible so for the time
being I'll just pause the video and come
back
again all right so now you can see on
your screens we have nicely formatted
our dashboard so I have added a few
logos for each of the charts you can see
the logos here so for Revenue by
countries we have a globe then if you
see here this is kind of a map or a
location similarly we have all formatted
the
color of the bars then we have also
formatted the labels in terms of
millions if you look on the Y AIS even
the revenue for year and region are all
formatted in terms of
millions if you want this you can also
format the total year by Revenue in
terms of millions so the way to do is
you can select this graph right click
and go to format access
here if I scroll down you have
numbers and under category I'll select
custom then I'll select my type as this
format which is in
millions and you see here we have
successfully formatted our y AIS
labels all right so the next thing is to
add slicers and timelines to our
dashboard now slice ERS are used to
format your data based on a particular
column suppose if you want to see
Revenue by certain items you can add
item as a slicer and you can view the
entire dashboard similarly for timelines
you can add date columns so if you want
to see what was the amount of sales or
revenue generated on a particular year
or a particular month you can do that
using a timeline so I'll select one of
the charts and then either you can go to
the insert Tab and here you can see
under filters we have slices and
timeline or if you go to the pivote
Chart analyze tab here also you have
insert slicer and timeline option so I
select insert slicer here first now it's
giving me the list of fields present in
the data set so I'll select country
region and let's say we want
to know by item type and sales channel
so these are going to be my four slicers
I'll click on
okay you can see it here we have our
four slicers here and these are the list
of values under region we have Asia this
Europe North America and others
similarly we have the different country
names for Country slicers and then for
item type also we have all the items
that were present in our data set
now moving ahead we need to connect all
the slices to a dashboard so what I'll
do is I'll right
click on this option and I'll go to
report
connections okay so under report
connections you have all the pivote
tables that we
created you currently see only one of
the peot table is selected so we need to
select all the P tables so let me check
all the P tables present in this
workbook and click on okay all right now
that we have connected one of our slices
we'll now connect the other remaining
slicers so I'll right click on this go
to report connections and I'll check all
the pivote tables present in this
worksheet click on okay similarly let's
do it for the country slice sir I'll go
to report connections and let me
select all the pivote
tables and finally we have the item type
so I'll right click go to report
connections and then I'll select all my
P
tables and let's hit okay all right now
let me just organize this a bit so I'll
place my Pivot
tables to the right
I'll just reduce the
size let me scroll
down I'll
add my region slicer
here
similarly I'll add my final slicer that
is sales Channel now in our next
dashboard which is going to be the
profit dashboard I'll show you how to
add a
timeline all right now I have arranged
all my
slicers so let's say you want to find
the revenue that was generated for an
item type let's say beverages so you can
just select beverages here and all your
charts show the respective revenues so
you have the total revenue by year for
beverages
only similarly here you can see the
revenue by year and region only for
beverages item type if I scroll
down now this chart represents the
revenue that was generated in each of
the countries only for item type
beverages let me just uncheck
it all
right let's say you want to see
the revenue generated for a country like
India so I have selected India here and
now you can
see my graph has changed only for
country
India you can see here it is showing
only for India
now now similarly you can also filter
your revenues based on the different
regions let's say you want to know the
revenue generated based on sales channel
so we have two sales channel that is
offline and online suppose you want to
know the revenue generated offline so
I'll just select offline you can see the
values have changed so these were the
revenues generated for each of the items
only for
offline if you see here now these were
all the offline sales for the different
regions so
this is our entire Excel Revenue
dashboard on sales we created multiple
charts and graphs then we applied
different formatting we added different
icons then we formatted the labels also
next we added slicers and finally we saw
how we could filter our data based on
these
slicers likewise now we are going to
create a profit dashboard
based on the same data so before moving
ahead let me rename this sheet as
Revenue dashboard I'll write
R dashboard
okay now we'll move to our data sheet
and start creating our P tables and poo
charts for the profit
dashboard all right so let me go ahead
and create my first pivot table
so I'll create a new
worksheet this time I'm going to create
a line chart to visualize the profit for
each year so I'll drag my total profit
column to values and my order year to
rows so here you can see we have
our pivote table ready now you can sort
this data to get an idea as to
which year had the highest profit and
which year had the lowest profit so from
this pivote table you can see since I've
sorted this data in descending order so
2014 had the maximum amount of profit
and 2017 had the least amount of profit
I'll just do control Z to undo it all
right now based on this pivot table let
me go ahead and create my P chart so
I'll go to recommended charts and click
on a line chart so this is the preview
of the chart
I'll click on okay let me close this
similarly we are going
to edit this chart now so first I'll
hide all the field buttons present on
the chart and I'll rename the chart
title as
total
profit by
year next I'm going to remove the legend
so I'll delete
this let's do some more formatting
so I'll go to
style
and this
time I'm going to
select my style type okay and if you
want you can choose the colors as well
for the time being let's have this
yellow color next let me add the data
labels so again if you see here this is
not formatted properly so let's go ahead
and format
the data labels so I'll click on
number and I'll select custom
here and the type I'm going to select is
in millions and I'll click on close so
here you can see we have
our line chart ready which shows total
profit by year let's rename this sheet
as
profit by
Year all right now let's move back to
our data sheet again next we are going
to show the total profit by countries
for this I'm going to create a map so
let me first create my pivote table so
I'll go to insert and I'll click on
pivote
table let me click on
okay since I want the country name so
I'll select country under rul and then I
have
have my total profit under
values the next thing I'm going to do is
I'll just rename the row labels as
countries and then I'm going to delete
the grand total which you can see at the
bottom so here we have the grand total
let me just delete the grand total so
I'm going to select this PO table go to
the design tab here we have sub totals
and Grand totals I'll
switch off the grand total let me just
verify it again I'll scroll down you see
the grand total has gone now all right
now we want to create a map out of this
the way to do is I'm going to select my
data copy it I'll go on top and I'll
paste it here using this data I can
create my field map now so I'll go to
insert here we have the option to create
a field map there you go you can see we
have our map ready I can expand this now
as you can see our map has a color scale
which comes from light gray color to
dark blue color so the countries that
are in Gray or you can say light blue
have the lowest amount of profit while
the regions or the countries that have
been shaded
in dark color or dark blue color have
highest amount of profit I will go ahead
and delete this
scale okay next we need to connect this
map to the original data source so what
I'll do is I'll right click on this map
and I'll go to select data here instead
of the previous range I'll give my new
Range now so my new
Range will be my original P table that I
had
created go on top and and click on okay
so we have our map ready now now if you
want you can change the color of the
shade so I'll just go to colors and
let's say we'll keep green
color so the countries that are shaded
in dark green have the highest amount of
profit while those which are highlighted
in light green color are are the
countries that made least amount of
profit okay now moving
on next we want to create a pivote table
that will show us the profit by year and
sales channel so for this we are going
to create another line chart so I'll go
to insert and click on pivote table so
I'll select new worksheet here since I
want to know the profit by year first of
all I'll drag my order year column to
rows and then
I'll choose my total profit column under
values next I'm going to select my sales
Channel under columns there you go so we
have our pivot table here based on this
pivote table let me create my P chart so
I'll go to recommended charts and I'm
going to create a line
chart I close
this you see here based on this chart
you can tell the profit generated with
online sales were actually lower than
that of offline so here the Blue Line
represents offline profit and the Orange
Line represents Online Profit if you
Mark Clearly in year 2012 the Online
Profit was actually higher than the
offline profit so let me go ahead and
edit this chart a bit so we'll delete
the field buttons I'll also delete the
legend for now let me go ahead and add
add a chart title so I'll
write
profit
by year
and sales
Channel
okay so this is my second report before
moving ahead let me just rename this
sheet so I'll write profit
by
countries similarly let me rename this
sheet as
profit by year and let's say SC for
sales
Channel
okay moving
ahead now I want to create a pie chart
based on a pivot table that will show
The Profit by sales Channel only so this
is going to be a simple pie chart so
I'll first go to insert click on pivote
table and click on okay so I'll drag my
sales Channel under row and then we'll
have the total profit column under
values so this is my simple pivote table
now let's create our pivote chart which
is going to be a pie chart let me
explore the other types of pie charts we
have okay so I'm going to select a donut
chart here I click on okay
let's edit this chart I'll remove the
field buttons let me now remove the
legend as well I'll just resize it and
this is going to
be
profit
by sales
Channel
okay let's also
add data
labels and here here again I'm going
to format this
label I'll select the category as custom
and my type will be in millions okay let
me just move
this to the
left and this to the right
okay let's also delete the lines
cool now let me just rename this sheet
so I'll write profit
by let's say C which stands for sales
Channel cool finally I'm going to create
a report that will show the revenue and
profit by items so I'll go ahead and
create my pivote table first this time
I'll choose my total profit under
values and we'll also have the revenue
column
so I'll put my Revenue at the top then
I'm going to
select item type under row so here is my
pivote table based on this pivote table
let me
now create a combo chart so you can see
the preview of the chart the blue bars
represent the total revenue and the
Orange Line represents the total profit
I'll click on okay let me close this
first let's remove the field
buttons let's also
remove the legend
here then we'll add a chart title I'll
name it
as
revenue
and
profit by
items okay if you want you can also go
go ahead and change the color of the
bars so let me just
select one of these colors
okay all right so we have our five
reports ready that we are going to use
for our profit
dashboard next let's create a new sheet
and we'll get started with building our
dashboard so I'll click on a new sheet
let me just rename this as profit
dashboard
all right we'll continue with the
previous drill so first of all let's go
to the view Tab and remove the grid
lines now we'll insert a background
image like we did for our Revenue
dashboard so I'll go to insert under
illustrations I'll click on pictures and
select this device I'm going to have the
same background I'll click on insert
all right so you can see we have
a picture of a company or you can say an
organization let's just drag
this a bit to the
right we'll adjust the size
also all
right now let's copy the title of my
profit dashboard so here you can see I
have brought my Revenue dashboard
and I'll copy the title and the logos
that we used for the revenue
dashboard I'll paste it on my new
dashboard let's just align
it in the
center all right the next step let me
now go ahead and edit the title so this
is actually going to
be
Excel profit dashboard instead of
Revenue now
we'll copy each of the charts that we
just created for example the revenue and
profit by items then we
had profit by sales
Channel all this we are going to copy
one by one and put it on the profit
dashboard so let me just copy a few
now I'll paste it
here and later on we can make the
adjustment copy this as well
similarly I'll bring the other three
charts onto my sales
dashboard okay so here on my profit
dashboard I have added all the
charts and I have aligned and reshaped
it so that it looks good I've also made
some formatting for example I have
reduced the size of the chart
title now let me go go ahead and show
you a few more formatting that we also
did for the revenue dashboard first
let's remove the white background from
all the charts so I'll select the first
chart I'll right click and I'll click on
format chart area here under fill I'll
select no fill next I'm going to remove
the grid lines so I'll just delete it
let me close this now we also have have
a outline so I'll go to
design actually format and I'll remove
the
outline next I'm going to
add a blue box at the back like how we
did for the revenue dashboard so let me
select a blue box from here and I'm
going to paste it here okay and let me
just select the chart and I'll bring
this to front
and I'll move
this to the
back next I'm going to change the font
color all to White so that it's clearly
visible and it's more
readable I'll do it for the x-axis as
well okay so here I have my first chart
ready the same I'm going to do for the
rest of the
charts okay so now you can see here I
have formatted all my charts I have also
added a blue
background you see here I have also
formatted the Y labels in terms of
millions which is actually the profit
similarly here I have added the data
labels this is for
Revenue some of the charts also have the
data Legends so here you can see the
blue color represents
offline and the red represents online
similarly here you have the legends I've
also formatted the map as well okay now
the next thing is to make this dashboard
more interactive so we'll add our
slicers as well as timeline first let me
show you how to add a timeline so I'll
select one of the charts and I'll go to
insert under insert I have the option to
create a timeline so I'll
just click on timelines
so timeline is actually based on date
columns so since in our data set we only
have two date columns one is order date
and one is ship date so Excel has only
shown us two columns so I'm going to
create my timeline based on order date
so I'll select my order date column and
I'll click on okay you can see here this
is called a timeline I can expand this
now this timeline is paced on months now
and if I scroll this timeline you can
see here I have
my order year 2010 and I have all the 12
months similarly we have for 2011 then
we have for
2012 all the way till
2017 now you can filter this in terms of
years quarters months or days let me
just select year now so I have years
from 2010 till
2017 let me just squiz this and I'll
place it somewhere here on the right
now let me go ahead and create a few
slicers for my profit dashboard so I
have selected one of the charts under
insert I'll click on
slicer you can see it gives me the list
of columns from which I want to create
slicers so I'll create region let me
also select
country let's say I
want the representatives name or the
customer's name and I'll click on okay
so here I have created three
slicers let
me first resize it and I'll place
it on the
right similarly I'll place the country
column
also then we have the region
slicer I'll resize this and I'll bring
it here okay the next thing we need to
do is I have to connect all the slicers
and the timeline to the P tables for the
profit dashboard so I'm going to click
on the multiple select option and go to
report connections here I'm going to
select all the pivot tables that are
related to
profit so here I have selected four and
I need one more which is p table number
10 I click on okay similarly let's
create or connect my region filter to
all the P tables so I right click go to
report connections here I'll choose all
my pivote tables which are based on
profit I'll click on okay let's do it
for the country slicer as
well click on okay and similarly I'll
connect my timeline as well I'll go to
report
connections and I'll
select all the pivote tables related to
profit then I'll click on okay let me
now go ahead and create another slicer
based on sales channel so I'm selecting
one of the P charts I'll go to insert
click on slicer and I'll select sales
Channel and hit
okay so I have my sales Channel
slicer now let me connect it to all the
respective pivote
tables that are based on
profit click on
okay now let me just bring it here all
right the next thing I want to show is
how are we going to use the timeline
first so you see we have all
the years here from 2010 till 200 17 now
suppose you want to know the profit that
was generated in the year 2012 so I'll
just click on this range and now you can
see our charts only show information for
2012 so this dot represents that was 51
million profit in the year 2012
similarly you can see
here the profit by sales channel for
2012 from the map you can see the
different countries and the profit each
of these countries made in
2012 if I scroll down you can see the
revenue and profit by items now if I
select another year let's say
2013 I can just drag this to the right
and now you can
see our profit by year and sales channel
for offline and online you can see the
the map or the line chart for total
profit by year so in 2012 it was 51
million and then it went up to 54
million in
2013
similarly our map has also changed now
this is a sort of an information that we
have you can click on this
and check the information that Excel has
prompted all right so this is how you
can use a timeline now as I said we
checked by years you can also see it for
months and quarters as
well let me just uncheck
it I'll send it back to the place where
it was and I'll reduce the
size okay now suppose you want to check
the profit made by different
Representatives you can select them one
by one let's say Adam Churchill this is
the profit generated by Adam
Churchill similarly you can select
multiple persons as well now suppose you
want to see the profit by different
countries so you can use the country
slicer let me just bring this to the
middle and let's expand our chart a
bit okay so here you have
the profit by different countries chart
I'll just bring this to the front so
that you can see it clearly okay now
here suppose you want to see the profit
generated in let's say United Kingdom
you can select United Kingdom so this is
the map of United Kingdom and it tells
you the total profit that was generated
in United Kingdom and Below you can see
the revenue and profit for all the items
that was sold in United Kingdom so you
had beverages clothes household office
supplies you can see clearly office
supplies item meet the highest amount of
profit in United Kingdom now you can
also select multiple countries let's say
I want to know for France as well so
my map will change accordingly so now I
have United Kingdom and France selected
and the other charts present in my
dashboard change accordingly now I have
my country selected as India you can see
the map of India
here and these were the respective
profit values now one thing to note here
is this is actually not millions that
should be in K that is Thousands so
please mark this as thousand and not in
millions even for this this is actually
K and not million
all right so we have
successfully created our second
dashboard that is on profit let me just
resize this a bit and we'll place it
where it was
earlier
cool so we saw how to create different P
tables and P charts and then we
formatted our po charts based on our
requirement we saw how to edit the
colors now let me show you one more
thing you can also change the look and
feel of the dashboard by going to the
page layout tab under page layout you
have themes so here you can select
different themes currently we are with
the office theme now let me just select
another theme let's say faet you see the
colors have changed and it looks really
beautiful similarly let me try out
another
another theme let's say organic you see
our chart has changed let me just delete
this okay so you now once you change the
theme the text also change a bit you can
see the slicers are in a different font
let me explore One More theme let's say
this time I'm going to choose
depth and this is more of a green type
of color
you can play around and select whatever
theme suits the best all
right now let me just move back to my
Revenue dashboard and see how it looks
there you go so since we changed our
theme even our Revenue dashboard is also
impacted
so this is how it looks
now you can always go ahead and and play
with different themes colors fonts and
effects all right so in this demo we saw
how to create a revenue dashboard so we
created line charts this combo chart pie
chart horizontal and vertical bar charts
and then we learned how to add slicers
and connected to different P tables and
we filtered our data to see Revenue as
well as profit by items by countries by
different regions sales Channel we
learned how to create a map and lots
more welcome to Simply learn in this
video we are focusing on chat jpt and
its groundbreaking role in data
analytics in a world where data is the
new goal understanding and analyzing
this wealth of information is crucial
but as the volume of data grows
exponentially traditional analysis
methods are being pushed to their limits
and enter chat jpd a revolutionary AI
developed by open AI That's transforming
how we approach data analytics but what
makes chat JP stand out in the crowded
field of data analytics tools how can it
not only streamline complex processes
but also uncover insights that were
previously hidden in plain site stay
tuned as we unrel the capabilities of
chat GPT share real world applications
and show you how it's being used by
analysis and businesses alike to make
smarter dat driven decisions and whether
you are a data scientist a business
professional or just a tech Enthusiast
curious about the future of AI in data
analytics this video is for you so let's
dive in and discover how chat GPT is not
just revolutionizing data analytics but
also how we understand and interact with
the vast Universe of data and don't
forget to hit that like button subscribe
and ring the bell to stay updated on all
our future Explorations into the
fascinating world of technology now
let's get started and the potential of
chat GPD for data analytics together so
guys an Excel data analyst always looks
for ways to improve their efficiency and
gain deeper insights from the data
that's where chat jbt comes in handy so
chat jbt is an AI powered language model
that can assist you in various task
including Excel based data analysis and
for that data analysis let's dive into
some demos to see how it works so guys
as you can see this is the chat juty 4
and you could see this has the support
of D browsing and Analysis and usage
limits May apply like we have the
version that has some usage limits and
for the data I have downloaded the data
from the K I will provide you the link
in the description if you want to
download the same data you can and I
have that in my downloads so this is the
data that we'll be using so the first
thing will will be doing is data
cleaning and preparation so firstly
let's explore data cleaning and
preparation before d into analysis it's
essential to ensure our data is clean
and ready for processing so for that we
will write a prompt in chj and ask him
to clean the data J jpt has the feature
to insert the files provide the Excel
file to the chat jpt and we'll ask him
that can you help me identify and remove
duplicates in this Excel spreadsheet so
let's ask
him can you help me identify and remove
duplicates
duplicates from this Excel spreadsheet
from the
provided
Excel spreadsheet you could see that sh
J has started generating the response
and he is telling us that he can
definitely help us with that and he is
analyzing that
so you could see that chj has provided
us the response so let's first go to our
spreadsheet so this is the spreadsheet
order number quantity
ordered price of each quantity and Order
lines so you could see that first chart
GPT has encountered an error and that is
with the character and coding mpch and
then he has loaded the spread
successfully with the second attempt and
you could see that he has provided a
like the smaller or the briefer version
of the spreadsheet that is the data set
consist of sales data with column such
as order number quantity order price
each order line sales order date status
so he asking us could you specify how
you would like to identify duplicates
for example should we consider a row a
duplicate if all its values match
another row exactly or are this
specifically column we should focus on
to determine duplicates so we should or
here we'll be focusing on the column
section so here we want to
identify column
section so is asking which columns they
should identify duplicates so we want
the duplicates in order number
so the J GD has started analyzing the
spreadsheet so you could see that CH G
has Pur justed the response that they
have identified a total of
287 rows in the spreadsheet that have
duplicates based on the order number
column so this indicates that multiple
rows share the same order number
suggesting there might be different
items or transactions within the same
order would you like to proceed by
removing these duplicates while keeping
either the first or last occurence of
each order number or do you have another
approach in mind for handling these
duplicates so before identifying the
duplicates what we'll do is we'll first
get rid of the extra spaces so we'll ask
CH jbt that first
find the extra
spaces in the
spreadsheet
and help us remove
them so you could see that it has
started analyzing
it so he is asking us that would you
like to proceed with any further
cleaning or data manipulation yes we
want to proceed further with data
cleaning only and now we will treat all
the blank cells if there are
any now treat all the blank
cells if there are
any so the spreadsheet contains plank
cells in the following columns with the
respective counts of blank entries that
is address line two has 25 21 blank
cells than the state so depending on
preference or the requirements of data
analysis we can treat these blank cells
in several ways such as filling them
with a placeholder value that is not
provided using a specific value that
makes sense for data that is example a
default state or Tory but potentially
leaving them as if blanks carry
meaningful information in the context of
your data so what we'll do we will
provide a
placeholder provide a placeholder
instead
that
is not provided or not applicable
okay so you would see in that has
responded that it has replaced the plank
cells in the columns that is address
line to State postal code and territory
with the placeholder note provided so
you could see there's a verification
sample showing the updates so this is
how you could clean the data and now
with chat jpt you you can quickly
identify and eliminate duplicates in
your Excel spreadsheet using build-in
functions and formulas saving your time
and effort so that would be done by the
chat GPD and you can download the Excel
file from the chat GPD only after that
you can just ask him that provide me the
output or the resulted spreadsheet so if
we talk about now data analysis and
visualization let's delve into that so
Excel offers powerful tools for
analyzing and visualizing data and chat
GPT can help to make the most of them so
for this also we'll write a prompt to
the chat JY and we'll write for example
we'll write please create a PIV table
and a corresponding chart to analyze
sales performance by region so let's see
like this prompt what output does chat
Jey show to us so let's ask him please
create a PV
table and a
corresponding chart to
analyze sales performance by
region so you would see that chat has
started analyzing the data and the
spreadsheet and you could see that the
pivot table below shows the sales
performance per region or the territory
so this table indicates that the EMA
region has the highest sales performance
followed by regions where the territory
was not provided then ape and finally
Japan so now let's create a chart to
visually represent this sales
performance by region we could see that
it has provided a chart that is a bar
chart illustrating the sales performance
by
Tory so you could see the guys that it
has provided us the analysis and CH jpd
can guide you through the process of
creating pivot tables charts and other
visualizations in Excel enabling you to
gain valuable insights from your data
with ease so let's move to Advanced
analysis and automation so lastly we
will explore Advanced analysis and
automation so Excel capabilities extend
beyond basic functions and chat jpd can
help you leverage its full potential and
for this also we'll write a prompt to
the chat GPD that can you assist me in
building a forecasting model to predict
future sales based on historical data
present in the spreadsheet so let's see
what Chad j respond to us so let's ask
him can
you assist
me in
building a forecasting
model to predict future
sales based on historical
data so let's see what chj a respond to
us so you could see that building a
forecasting model to BU future sales
based on historical data involves
several steps so for this you have to
prepare the data select a model train
the model evaluate the model and make
predictions so let's start by preparing
the data we'll aggregate sales by order
date to create a Time series of total
daily sales then we'll choose a model
based on data's characteristics so we
will grant the permission to J gyt to
proceed with the steps so we started
analyzing the
data so you could see that that the data
has been prepared into a Time series of
total daily sales and before choosing a
forecasting model it's helpful to
visualize the sales time series to
understand its characteristics such as
Trend and seasonality so Chad GPT has
loed a daily sales data and then he has
given the visual Trends and the possible
seasonal patterns and the next steps
would include testing for stationarity
model selection and parameter touring
model training and then forecasting so
you could follow all these steps with
the help of chat GPT and could create a
forecasting model if you want you can
move to the next step so you could like
provide a PR to the chat gipd that move
to
or proceed with Next
Step so step by step J Gip will provide
you a forecasting model or it will help
you create a forecasting model as you
can see it has started analyzing it to
the augmented Dy Fuller that is ADF test
gives up a P value of approximately
0.33 since this P value is less than the
common significance level of 0.05 we can
reject the null hypothesis that the time
Series has a unit root meaning the time
series is stationary so you could see
that he's asking us shall we proceed
with the Sima model parameter selection
yes here is the model parameter
selection so you could select any based
on the trends and the bar graphs ploted
by the chat
GD so you could see guys that the chat
GT has analyzed the spreadsheet and Ed
the response that the grid search for
the optimal Sima parameters based on the
lower information Criterion suggest the
best fit model uses the parameter 011
and for ARA and
01112 that is for the seasonal component
so you could see that it has provided
the model and the parameters now it's
asking us shall we move on to
forecasting future sales with this model
yes proceed with that so you could see
that with ch G's assistance you can
build complex forecasting models in
Excel allowing you to make informed
decisions and plan for the future
effectively so chat jpt is a valuable
tool for Excel users and data analysis
offering assistance in data cleaning
analysis visualization and Automation
and by integrating Chad j in your Excel
workflows you can enhance your
productivity and uncover new insights
from your data so you can try J gbd for
Excel data analytics today and take your
Excel skills to the new level and you
could see that uh there's an error in
the analyzing and he has encountered an
error while trying to plot the forecast
with its confidence intervals so this
type of error can occur due to data type
issues particularly when handling data
indicis in forecast and despite the hiup
the forecasting process using the ca
model was completed and we were able to
generate forecast for the next 12 months
unfortunately due to the plotting issue
he couldn't visually display it so we'll
ask him can you try one once
again so you could see that this time CH
gbt has provided us the forecast for the
next 12 months that is the forecast have
been successfully ploted along with the
historical daily data so here we have
our forecast model and with the chat G's
assistance we can move with other
analysis also so welcome to the demo
part of the SQL project so in this we
will do
digital music store analysis okay so
this SQL project is for the beginners so
what you will learn from this uh project
main thing is like so what's the
objective of this project this
particular project so this project is
for bers and we teach you how to analyze
the music playlist database and you can
examine the data set with SQL and help
the store understand its business growth
by answering simple questions so as you
can see I will show you so I have three
set of questions first one is easy okay
and the second one is
moderate and the third one is advanced
level so we have three set of questions
easy set moderate and the Advan okay so
every set is of three three questions I
guess yes every said there is three
three questions so okay in easy one
there are five so we have 5 + 3 8 8 + 3
11 we have 11 questions to solve okay
from this you will understand how you
can you know analyze data with SQL how
you can extract something from database
how you can store something like
this
okay so and one more thing I will show
you the schema of the particular uh data
set which we will you know soon we will
restore so we have the tables in this
artist album track media type genre
invoice line invoice customer employee
ID playlist playlist track and all okay
so this is the music playlist database
schema so without any further Ado let
me create one database so here just
right click create
database
okay here I will
write
music okay and
save so now our database is created okay
so if you will go to
schema and if you go to tables there is
no and tables in it means there is no
there is database but nothing is there
the database is empty so now what I will
do just go to your database just right
click here you can see the restore
option okay
restore so format as it is then here
file name go to this music store
database I will put this database Link
in the description box below don't worry
open then this store process started
process complete some people will face
this uh that the process is failed or
something okay so for that what you have
to do just go to file then
preferences here you have to set the
path just binary path okay see I am
using the 15th version okay so I have
set the path here also and this also but
you have to set this path is important
okay if you will not set this edv
Advanced server path it's fine but this
path is most important
okay but for the future reference I have
added on the both so what you have to do
you have to just see where you will find
this path just go to this PC then OS
then program
files here you will find this post G SQL
then I'm using C15 15 then bin so you
have to
copy this
path right you have to just copy
it and paste it here and then select
this one after that just save you
won't find any failed thing okay the
process will complete right so now let's
move forward and see the tables okay
it's still empty why just refresh it see
now you can see all the you know columns
in my tables okay
so what I will do for the checking I
will run one query here okay let me
close it okay I will write here
select
star from
album okay let me run
it so now as you can see here my table
is working fine everything seems
good
okay so now what we will do we will
solve question one by
one okay so the first question let's see
the first question easy one who is the
senior most employee based on job title
okay who is the senior
most okay so I will
write
here like the first question is
who is the
senior
most
imploy based
on job
title okay so this is our
question so we know we have the table
named name called employer so we will
select that table first so I will write
here
Select Staff
from
employee
so you should know uh which table should
to select okay so here as you can see in
this question there is you know t uh
word employe who is the senior most
employee based on the job title most
employee means employees and employee
table
right
so I will run
it
okay so what I will do I will just
select this and run it okay so now you
can see there in employer there is
employee ID last name first name title
report levels but date higher date and
all the details of the
particular
okay so we will do so there is one more
thing you can see the levels okay level
one level two so we have to write who is
the senior most employee based on the
job title so what I will do I will write
here
order by
levels and decreasing order
okay so first I will do so now you can
see the levels are in the descending
order from
senior to this okay L7 to L L1 so what
we want we want only one uh employee
name so what I will write here limit is
one okay I will copy this and done it
okay so now you can see the last name is
Madan moan sorry moan Madan this is last
name this is first name so moan Madan is
the senior most employee based on the
job de so question
first is done so the second question is
which countries have the most
invoices okay first I will write down
the question
which country has
the have the most
in have the most
invoices
okay so for
this what we have to do see just first
check first we have to check from which
table you know we will get the solution
so here you can see the word
invoices okay so we have one table
invoice and invoice line we have to
select it from this
okay so I will write
here Select Staff
from
invoice
okay so we have customer ID invoice date
billing address billing city
billing State and
everything so here you can see we have
the billing country as well okay because
we need the country name so we will take
this column right so I will write
here so I will write
select we change it
select count
start from
the select start
billing
country from
invoice Group by
billing
country so why I'm doing this group by
because as you can see uh we have USA
multiple times USA USA USA then Canada
also and the other countries as well so
from this I will get only the one okay I
will group them and I will get the one
fine so from this we will uh get the
count so after this I will write
order by so here I will
write
see see descending okay let me run
it so now you can see the billing this
is the billing order Okay so or you can
say the on voices USA got the
131 and Canada 76 Brazil 61 if I will
write here again the limit one what I
will
get see
USA we got the USA so USA is the country
which have the most
invoices okay if you will remove this
limit
so you will
get the other country as well second in
Canada third is Brazil and like this
okay and the third question is what are
the top three values of total
invoices okay again we need the same
table okay first I will write the
question third question is what
are uh
the top three values of total
invoices top three
value of
total invoices okay I know I can this
solve this question by the second one
but I want to do it from the
starting
okay so first I will take select stuff
from invoice
let me run
it so first we will sort the data here I
will write order
by
total because the last you know this is
a table name okay
total and the descending
order so first I will select
so we need just the top three so first I
will do everyone know limit
three
okay
okay so here I have done I have wrote
this star that is why it's giving me the
all the values if I want this only this
value so I can write select
total from invoice order by
this okay I will say and on it so I have
this total like 23.75 999 and 19.8 and
19.8 so these are the top three values
of total
invoices okay so here the fourth
question is which city has the best
customer we would like to throw a
promotional music festival in the city
we made the most money write a query
that returns one city that has the
highest some some of invoice Total
return both the city name and sum of the
all invoice total so let me write the
question first okay I'm writing question
for you know your better understanding
okay question
fourth which city has the
best
customers we would
like to throw a
party or
promotional promotional music
festival in the
city we made the most
money we made
the most
money right
a
query that it does one
city that has
the
highest sum of
invoices as sum of
invoices
total return
both the
city
name and
sum of
all
invoices
okay so we have this question okay so V
city has the best customer we would like
to throw a promotional music festival in
the city we made the most money write a
query that returns one city that has the
highest sum of invoice Total return both
the city name and the sum of all
invoices okay so first what we will do
we will
select select stuff
from
invoice okay
sorry we'll select this okay so first we
will select the billing city we have to
focus on this and the total in this two
table we have to just focus on okay so
here I will write
sum
of
total
as
invoice
total comma billing
City from
invoice so this time we will do group
by
billing city because we need the city
names uh then I will add
order
by
invoice
total in the descending order
seems good select some total as invoice
Total Building City from invoice
building okay so let me select
this so as you can see the highest
billing city
is
parag Prague and the best customer is
from the parox
city Okay so which city has the best
customer obviously parag pragu or sorry
for the you know
mispronunciation okay so this is how we
have solved our fourth question as well
okay because WR both the city name and
the sum of all the inv you know these is
the city names and the invoice total
okay moving forward to a fifth
question which is again the long one who
is the best customer the customer who
has spent the most money will be the
declared the best customer write a query
that Returns the person who has spent
the most
money okay so I will write here
who is the
best
customer the
customer who has
spent the most
money will be
declar the best
customer so write a
query C that returns that
Returns
the
person who has spent
the most money
okay yeah so who is the best customer
the customer who has spent the most
money will be declared as the best Comm
write a query that Returns the person
who has spent the most money okay so for
this we have to take this customer Data
customer table data okay so I will write
as
select stuff
from customer
okay I will select this and I will run
it okay so this is
our know data table data of customer
okay so we have the country facts emails
state city address last name first name
okay so as you can see there is nothing
uh like no detail of invoice or the
money okay which have spent by the
customers so what we will do we will
look at our schema so now what we can do
if we can't solve a particular question
from with one table we have to you know
join the table to the other table so
here we have to join customer table to
invoice table so in this you can see
there is customer ID and here also
customer ID so on the Bas of customer ID
we can join the join both the table and
with the help of this total we will sort
out the uh that guy okay that
customer
right so for this I will
write here
select customer
Dot
customer ID comma
customer
DOT first
name comma
customer dot last name because we need
need the full name of that guy
comma
sum invoice do
total as
total okay
okay let me can be okay I don't need the
search
pad
right then I will write
from
customer okay my
bad then
join
invoice
on customer Dot
customer
idals
to
invoice
do customer
ID
then I need Group
by
okay Group
by
customer
Dot customer ID after this
is uh uh let me order it by the
descending order so the most you know
spend customer will come
up so I will write here
order order
by
total the descending
order then
limit = to 1
fine let me run it let's see what output
should
okay okay some error is
coming okay
sorry okay so as you can see the
customer ID is five the first name is
our the last name is mother our mother
is spent the highest value
14454 00 and two so who is the best
customer ma our mother sorry my bad our
mother right our mother has spent the
most
money okay so this is how we are done
with our easy set of questions now let's
jump into the moderate one okay so let
me write the question first for the
moderate so I will write
here modate
questions so these analytics skill help
you in the data analytics to become a
data analyst or to become a data
scientist
okay so the question first
is
write
query to
return okay
write query to
return the
email query to
return the
email comma first
name first
name comma last
name
and
genre of
all talk music listen
okay then
return
your
list
ordered
alphabetically by
email
starting with a okay let
yeah so for
this
okay let me open this
first
yeah okay fine so first what I will
do so now in this question as you can
see we need the we have to return the
email first name and the last name and
the genre of all rock music listener so
if you will see select stuff from
customer okay be done
this and if I will see there is no
column name genre okay if I will show
you the schema of this see the genre is
here and the customers is here okay we
need need the first name last name and
the email ID and the genre okay and the
genre is Will should be Rock okay so
what I can do I can connect this genre
with
track then because here is also track ID
and here is also track ID then track ID
to invoice line then invoice line to
invoice then invoice to customer with
the customer ID okay this pattern I have
to
follow right so for this I will write
select just copy
this okay just follow the
steps
select
distinct email comma first
name comma last
name
from customer
join
invoice
on
customer
Dot customer
ID equals
to invoice
Dot customer uncore
ID then
join invo
voice _
line
on
invoice do invoice
ID okay then
invoice _
ID then
where
check I
should be
in here I will
do
select track
ID okay
from
track then
join then join
genre yeah
on track dot genre
dot ID equals
to genre
dot JRA
ID
where this is important genre
name
like rock because we need as you can see
righty to return this is this and genre
of all rock music
listeners okay
rock right
then oh order
by
email okay before that let me show you
this track okay select star from track
okay let me show you this
table you can see the name the track ID
album ID Media type genre ID
okay then the composer this this this
Byes and the unit
price
right okay so you know this we have then
this customer okay invoice ID we took
right fine so now what I will do I will
just select this
and okay invoice ID okay invoice ID is
ambiguous
here I have to
write
invoice
line do invoice
ID okay let me now
run let me run it okay one more join
genre on track. genre ID there is entry
for table genre but it cannot be
referenced from this part of the query
okay
okay as you can see the here the table
name is genre _ ID that was the
mistake okay one more genre.
name spelling
mistake sorry my my bad guys no shoes it
happens okay now you can see we have all
the people who love Frog music and we
have the email then first name then the
last name see Adan Mitchell Alexandra
Roa a
grber like this cam Dan Edward like this
okay so there are total 59 people who
loves rock music from this particular
database okay now question
two question two is let's Okay first let
me show you let's invite the artist who
have written the most rock music data
set write a query that Returns the
artist name and the total track count on
the top 10 rock bands okay so
let's invite
the
artist who
have
written the
most rock
music in our data
set so
write write a query
that
Returns the artist
name
and and the total count
of track count
of top
10
rock band
so now what we need here okay let me do
this so what we need here so let's
invite the artists who have the written
the most rock music first we need the
artist okay and the second is rock music
then we need track okay and the total
count total track count means we will
get from the track so
here we have track column track uh table
and we have the artist so now let's see
the schema part so we have we need
genre
okay for the you know uh rock music then
we have
to combine this with the track ID
because genre ID is there from track ID
to album because we need the artist name
see artist ID and artist ID so this is
how we have to connect the table
now so for this I will write here just
follow the steps
select
artist
dot artist
ID
comma artist dot name comma
count
artist. artist
ID
as number of songs because we needed
total number okay who have written the
most rock
music number of
songs find
from track
now we have to
join
album
on on
album do album
ID equals to
track
dot album
ID okay then we have to join the artist
with artist
ID so
join
artist column on the basis of
Artist Artist ID equals to then
album to album.
artist ID okay so here I have joined the
artist to the album column
table okay then I have to join johra to
the track table with the track table
okay so here I will write join
genre
on genre
do genre
ID equals
to genre
ID okay sorry track
ID track doj
ID okay so here I will write
where where
genre
dot
name
like
rock
okay rock fine then I will Group
by my bad Group
by
artist do artist ID I need the ID as
well then order
by order
by
number
of
songs in the descending then limit I
need only 10 rock bands liit will be
10 let me run it okay
let me run
it okay
album
okay now let me run it okay now you can
see this guy let Zeppelin rid is 22 and
wrote the most songs 144 then U2 122 the
purple 92 then then this is this than
this okay so this is
how we solved our second
question right so now the third
question okay return return all the
track names names that have a song
Length longer than the average
song Length return return the name and
the millisecond of the each
track ordered by the song
Length
okay so first I will write this
question
Q3 so return return all the
track names
that have a
song Length
longer
than the
average strong length Okay as we return
all the track names that have the song
Length longer than the average song
Length okay
then return
return the name and
milliseconds for each track
fine after that order by them order by
the
songs with
the
longest song
listed
first okay fine so we have to return
return all the track names that have
song L and
the okay
first we will find the total length of
this songs then we will do the where
then we will put the V Clause to find
out the
particular uh longest s okay so this is
this will do in the two you know step
first you will find the average stke
length Okay so I will write here select
select name comma
milliseconds
okay
from
track
where
milliseconds here I will write
select average
from the
millisecond
okay then I will write here
as
average
track
length Okay then here I will write from
track
after this I will write
here order
by
milliseconds I need in the descending
order
okay so let me run
it so now you can see see first I will
uh read it again so return return all
the track names that have a song Length
longer than the average song Length
written the name and the millisecond for
each track order by the song with the
longest song listed first okay so this
is the longest song okay so we have all
the songs which are the longer than the
average song Length
right so now moving forward we have jump
into the advanced set of questions okay
so now we will do the advanc questions
Okay so let's see first find how much
amount spent by each customer or not is
Right a query to return customer name
arst name and tot SP okay so first we
will write down the
questions okay then question
one question one okay
find how
much
amount
spent by each
customer on
artist write a
quiry to
return customer
name comma artist
name comma total
Spin and total
spent okay so how to solve this so first
find which artist has earned the most
according to the invoice lines okay
first uh let me show you the schema okay
we need the artist name we need the
customer name and we need the total
spend okay with the invoice line because
the quantity should be there okay so
first we'll see how to join these three
table artist table customer invoice and
invoice line like this okay this is how
we
will you know join the table fine so now
I will tell you the you know steps so
first find which artist has earned the
most according to the invoice line okay
the second now use the artist to find
which customer spent the most on the
artist so for this query you will uh we
need to use the invoice invoice line
track customer album and in the artist
table so just remember this one is
tricky because the total spent in the
invoice table right let me show you so
total spent on the invoice
table might not be a single product so
that is why I was saying we need the
quantity so we need the invoice line
table to find out how many each product
was purchased then we have to multiply
this by the price of each artist okay
fine so now so this is the lengthy one I
will just you know write it for you and
get back to
you yeah so this is how you can see okay
Group by five I have wrote this you can
just you know write
it okay like this okay we took artist
name then sum of invoice line unit price
into invoice line the quantity that I
showed you
okay we have multiply this total with
the quantity okay then we joined the
table track with invoice album with
track artist with album okay so now
let's run
it
yeah so now you can see this H or really
Queen amount spend 27 the customer ID is
this okay then Nicholas
scroller then 18 okay we have
the everything okay customer name artist
name and the total spend this is the
customer Name the artist name and the
total amount this spend fine so now
let's move forward to the next
one which
is
okay okay yeah so
the second one is this we want to find
out the most popular music genre for
each country we determine the most
popular genra as the genre with the
highest amount of purchase so write a
query that returns each country along
with the top genre for countries with
the maximum number of purchases shared
return all the genres okay so what I
will do first I will write the
question okay so we
okay we should do
so
find out the
most
popular
music
music genre for
each country
okay we
determine
determine the
most
popular genre as the
genre with the
highest amount
of
purchase okay
then write a
query that
returns
each
country along with
the top
genre
for
countries where the
maximum number of
purchase
okay
so so there are two parts in this
question first the most popular music
genre and the second is the need of data
at the country level okay so we can do
it from the two methods okay using CT
and the using the recursive method so I
will use the using City I will do this
city so for that you have to write with
popular
genre
as
select
count
invoice
line
dot
quantity
okay as
purchases
comma customer
dot
country comma genre do
name comma genre dot
genre
ID
okay
then here I will write row uncore SC
number
number then I will write
over
Partition
by customer.
country order
by count
voice line
dot
quantity okay into descending
order as row
number
okay so
from invoice line
okay
yeah so here I will join the tables
join
invoice
on invoice
do invoice
ID equals
to
invoice
line do invoice
ID okay then again
join
customer
on customer. customer
ID do
idore ID equal to invoice
Dot customer
ID
fine then again we have to join
track
track
on track. track
ID equals to
invoice uncore
line do trackcore
ID
then
join
genre on
JRE
dot genra
ID okay
then track dot John
Ry okay then I will do group
by Group by 2 comma 3 comma
4 then I will do order
by two then ascending
order and then one 2 descending
order okay
okay then now I will write
select start
from
popular
genre
where row
number SL
than greater than
one okay now let me run
it so now you can see we
have okay I will let me read it so we
have to find the most popular music
genre for each country okay so now we
have the country Argentina the most
popular is alternative and punk John R
is this number is this
okay purchases this then the Australia
this rock rock rock rock rock okay
certain Rock USA Rock and everything is
it right so this is how you can
find the most popular music genre for
each country okay the last question is
still
here now the last question
is write a query that determines the
customer that has spent the
most on the music for each country right
a query that Returns the country along
with the top customer and how much they
spend okay for the countries where the
top amount of spent is
shared
right and they provide all the customer
who spend this amount okay so for this
uh this is like a similar to this
question okay so there are two parts in
this question find the most spent on
music for each country and the second is
to filter the data for the respective
customer it's very easy okay
so okay I will write the solution okay
you can check the question from there I
will write
customer
F
country as
as uh I will here
select customer Dot customer
ID
comma first
name comma last
name comma building
billing
country
comma
sum should be
total
as total spending
right then I will
write zow
number same over we have also written
here
now right the same we have to write here
over
then
Partition
by billing
country order by
as
sum
total descending
order as row
number okay so after this I will
write if
from invoice you have to
fetch then again the same thing we have
to join the
table
join
customer
on customer
Dot customer
ID equals to
invoice do customer ID
okay then here I will write Group
by I 1 comma 2 comma 3 comma 4 comma
okay that's
it okay then I will write here order
by
for ASC ascending
order comma
5 to descending
order
fine so now I will write here
select start
from
customer
with country
where r
w number
is one
fine so let me run
it see we have first name last name
billing country total spting row number
and the customer ID let me show you the
question here write a query that
determines okay let me make it
okay
yeah so write a query that determines
the customer that has spent the most on
the music so customer we have the
customer name for each country write a
query that return the country along with
this so we have the country name with
the top customer how much they spend we
have the total spending for the
countries where the top amount is shared
provide all the customer who
has customer who spent this amount okay
so we have everything
here right we have this Le from Brazil
this this this this this okay with the
customer ID so this is how you can solve
these questions so till now I can say
you have a good data analytics skills so
for this I can say this will help you in
the interview of data analyst in data
science or any SQL thank you guys for
joining the data analytics full course
by simply learn by completing this
course we have taken a significant step
towards rewarding career in data
analytics with the high demand of data
experts in 2024 you are well prepared to
land top job in the field and enjoy a
lucrative
salary staying ahead in your career
requires continuous learning and
upskilling whether you're a student
aiming to learn today's top skills or a
working professional looking to advance
your career we've got you covered
explore our impressive catalog of
certification programs in cuttingedge
domains including data science cloud
computing cyber security AI machine
learning or digital marketing designed
in collaboration with leading
universities and top corporations and
delivered by industry experts choose any
of our programs and set yourself on the
path to Career Success click the link in
the description to know
more hi there if you like this video
subscribe to the simply learn YouTube
channel and click here to watch similar
videos to ner up and get certified click
here