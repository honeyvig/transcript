hey everyone did you know that the
market for cloud computing is expected
to reach $
832.28
according to a report by markets and
markets this situation highlights the
rising demand for cloud engineers in
fact according to the Bureau of Labor
Statistics IT projects a growth rate of
13% from 2020 to
2030 but how to take advantage of this
golden opportunity how to become a
successful Cloud
engineer well to help you with this
situation and give you a Clarity on how
you can plan your way to become a
successful Cloud engineer simply learn
has brought you a new video on cloud
engineer road map to help you build your
career as a cloud engineer also if you
want to upskill yourself in cloud
computing from Basics to advanc then you
can definitely check out our course on
cloud architect it will help you build
your base in cloud computing moving on
let's have a look at what you are going
to expect or explore in this video first
you will learn about what is cloud
computing following that you will
understand who is a cloud engineer then
you will explore what all skills are
required for you to become a cloud
engineer and what roles and
responsibilities you will hold then you
will go through the cloud engineer road
map and what salary you can expect as a
cloud engineer then you will have a look
at all the companies hiring Cloud
engineers and at the end of this video
you will come across cloud computing
interview questions and answers to help
you with bagging a great interview and
an amazing job so let's get started with
the video but before that do subscribe
to our YouTube channel for more such
interesting videos and hit the Bell icon
to never miss an update from Simply loar
the first thing we will come across is
what is cloud computing
cloud computing is the distribution of
Computing Services via the Internet or
the cloud including servers storage
databases networking software analytics
and intelligence to provide faster
Innovation more flexible resources and
economies of scale you usually only pay
for the cloud services you use which
helps you cut cost run your
infrastructure more efficiently and
scale as your business grows
that brings us to who is a cloud
engineer Cloud Engineers are the it
experts in charge of accessing an
organizations technology infrastructure
and transferring operations and
procedures to a cloud based
architecture they assist with the
migration of critical corporate
applications and processes to private
public and hybrid Cloud environments a
cloud engineer's job is to access a
company's it INF structure and migrate
certain processes and operations to the
Cloud public private and hybrid cloud
computing systems are among these
functions and
operations now that we know who a cloud
engineer is let's have a look at the
skills required to become
one Cloud Engineers must have a diverse
set of technical talents that they will
use in a variety of positions several
key skill sets that cloud Engineers need
to be successful include the ability to
program and code cloud-based
applications and
processes the ability to troubleshoot
technical challenges through problem
solving the ability to plan and design
software and Cloud applications using
critical and creative
thinking should also include data
analysis
skills and should be able to
strategically plan and to fulfill
projects using technical resour
sources now let's have a look at the
roles and responsibilities of cloud
engineer there are three types of cloud
engineers in particular in a small
business one individual may be in charge
of all three roles Cloud architect Cloud
software engineer and Cloud security
engineer Cloud architect and
organization's cloud computing strategy
include application design management
and monitoring is overseen by a cloud
architect Cloud Architects connect
various aspects of cloud computing
including data and networks with tools
and
services Cloud software engineer a cloud
software engineer creates software for
cloud computing systems and isn't in
charge of managing their development and
maintenance Cloud security engineer
control based Technologies and
procedures that enable Regulatory
Compliance regulations are included in
security when dealing with the cloud the
major purpose is to protect information
data data applications and the
infrastructure now let's focus on the
road map to become a cloud
engineer Cloud Engineers generally begin
their careers with the fouryear degree
in computer technology and the steps
below Define fundamental part to
becoming a cloud in
engineer obtain a bachelor's degree in
software and systems infrastructure
Computing or other technical
areas your bachelor's degree program
should emphasize software and system
infrastructure Computing and other
technical courses a bachelor's degree in
a computer or technology related field
will also qualify you for advanced
degrees if you choose to pursue
them learn programming languages
python C++ Java and Ruby for example are
great options to start with aside from
programming languages you'll want to
brush up on your Knowledge and Skills
with some of the most popular cloud
services including AWS Hadoop and
asure it's important that you gain
experience in cloud computing VI
internships and open-source projects
this will help you build a portfolio of
work that you can use to demonstrate
your competence in future job interviews
and it will also teach you vital skills
that you'll need to need on the
job consider a master's degree to
enhance your cloud computing abilities
while also advancing your career because
of their higher level of Education Cloud
Engineers with a master's degree in a
tech subject may have additional career
prospects a master's degree in software
engineering or system engineering for
example will help you develop more of
these technical abilities and expertise
advancing your
career get cloud computing
certification to demonstrate your
understanding and skill level in Cloud
engineering you can also check out our
official website for cloud computing
certification it will help you enhance
your knowledge in this particular
field now that we know everything about
cloud computing and how to become a
cloud engineer let's have a quick look
at the average salary of a cloud
engineer in India and in the
USA in India the average salary of a
cloud engineer is rupees 12 lak 41,000
per en and in the USA the average salary
of a cloud engineer is $128,800
location and how many years you have
been in the field for example a cloud
engineer with a master's degree and
several years of experience may make
more than a new graduate with a
four-year degree who is just starting
out in their
career now let's dive down and explore
the companies hiring Cloud
Engineers cloud computing is gradually
establishing itself as the industry
standard for data storage and
administration by 2022 according to IDC
over a million cloud computing jobs
would be generated in India Amazon IBM
vipo infosis Oracle Cisco these are the
few top companies were are some of the
top Recruiters in this field hi there
I'm Samuel and I'm here to walk you
through some of the AWS interview
questions which we find are important
and our hope is that you would use this
material in your interview preparation
and be able to crack that cloud
interview and step into to your dream
Cloud job by the way I'm an Cloud
technical architect trainer and an
interview panelist for cloud Network and
devops so as you progress in watching
you're going to see that these questions
are practical scenario based questions
that tests the depth of the knowledge of
a person in a particular AWS product or
in a particular AWS architecture so why
wait let's move on all right so in an
interview you would find yourself with a
question that might ask you define and
explain the three basic types of cloud
services and the AWS products that are
built based on them see here it's a very
straightforward question just explain
three basic types of cloud service and
when we talk about basic type of cloud
service it's compute obviously that's a
very basic service storage obviously uh
because you need to store your data
somewhere and networking that actually
connects a couple of other services to
your application these basic will not
include monitoring these basic will not
include analytics because they are
considered as optional they are
considered as Advanced Services you
could choose a non-cloud service or a
product for monitoring of and for
analytics so they're not considered as
Basics so when we talk about Basics they
are compute storage and networking and
the second part of the question says
explain some of the aw's products that
are built based on them of course
compute ec2 is a major one that's that's
the major share of the compute resource
and then we have platform as a service
which is elastic bean stock and then
function as a service which is Lambda
Autos scaling and light sale are also
part of compute services so the compute
domain it really helps us to run any
application and the compute service
helps us in managing the scaling
deployment of an application again
Lambda is a compute service so the
compute service also helps in running
event initiated stateless applications
the next one was storage a lot of
emphasis is on storage these days
because if there's one thing that grows
in a network on a daily basis that's
storage every new day we have new data
to store process manage so a storage is
again a basic and an important cloud
service and the products that are built
based on the storage services are S3
object storage Glacier for archiving EBS
elastic block storage as a drive
attachment for the ec2 instances and EFS
file share for the E2 instances so the
storage domain helps in the following
aspects it holds all the information
that the application uses so it's the
application data and we can also archive
old data using storage which would be
Glacier and any object files and any
requirement for Block storage can be met
through elastic blog store and S3 which
is again an object storage talking about
uh networks it it's just not important
to answer the question with the name of
the services and the name of the product
it'll also be good if you could go in
depth and explain how they can be used
all right so that actually proves you to
be a person knowledgeable enough in that
particular service or product so talking
about networking domain VPC networking
can't imagine networking without VPC in
in the cloud environment especially in
AWS Cloud environment and then we have
Route 53 for domain resolution or uh for
DNS and then we have cloudfront which is
an edge caching service that helps
customers get or customers to read their
application with the low Laten
so networking domain helps with some of
the following use cases it controls and
manages the connectivity of the aw
services within our account and we can
also pick an IP address range if you're
a network engineer or if you are
somebody who works in networks or are
planning to work in network you will
soon realize the importance of choosing
your own IP address for easy remembering
so having an option to have your own IP
address in the cloud own range of IP
address in the cloud it really helps
really really helps in Cloud networking
the other question that get asked would
be the difference between the
availability Zone and the region
actually the question generally gets
asked so to test how well you can
actually differentiate and also
correlate the availability Zone and the
region relationship right so a region is
a separate geographic area like the US
One I mean which represents North
California or the AP South which
represents Mumbai so regions are a
separate geographic area on the contrary
availability Zone resides inside the
region you shouldn't stop there you
should go further and explain about
availability zones and availability
zones are isolated from each other and
some of the services will replicate
themselves within the availability zone
so availability Zone does replication
within the them but regions they don't
generally do replication between them
the other question you could be asked is
uh what is auto scaling what do we
achieve by autoscaling so in short
autoscaling it helps us to automatically
provision and launch new instances
Whenever there is an demand it not only
helps us meeting the increasing demand
it also helps in reducing the resource
usage when there is low demand so aut
scaling also allows us to decrease the
resources or resource capacity as per
the need of that particular AR now this
helps business in not worrying about
putting more effort in managing or
continuously monitoring the server to
see if they have the needed resource or
not because autoscaling is going to
handle it for us so business does not
need to worry about it and Autos scaling
is one big reason why people would want
to go and pick a cloud service
especially an aw service the ability to
increase and Shrink based on the need of
that R that's how powerful is aut
scaling the other question you could get
asked is what's do targeting in Cloud
front now we know that cloudfront is
caching and it caches content globally
in the Amazon caching service globalwide
the whole point is to provide users
worldwide access to the data from a very
nearest server possible that's the whole
point in using or going for cloud front
then what do you mean by geot targeting
geot targeting is showing customer and
specific content based on language we
can customize the content based on
what's popular in that place we can
actually customize the content the URL
is the same but we could actually change
the content a little bit not the whole
content otherwise it would be dynamic
but we can change the content a little
bit a specific spefic a file or a
picture or a particular Link in a
website and show customized content to
users who will be in different parts of
the globe so how does it happen
cloudfront will detect the country where
the viewers are located and it will
forward the country code to the origin
server and once the origin server gets
the specialized or specific country code
it will change the content and it will
send to the caching server and it get
cached there for
and the user gets to view a Content
which is personalized for them for the
country they are in the other question
you could get asked is the steps
involved in using cloud formation or
creating a cloud formation or backing up
an environment with an cloud formation
template we all know that if there is a
template we can simply run it and it
Provisions the environment but there is
a lot more going into it so the first
step in moving towards infrastr
structure as a code is to create the
cloud formation template which as of now
supports Json and yaml file format so
first create the cloud formation
template and then save the code in an S3
bucket S3 bucket serves as the
repository for our code and then from
the cloud formation call the file in the
S3 bucket and create a stack and now
cloud formation uses the file reads the
file understands services that are being
called understands the order understands
how they are connected with each other
cloud formation is actually an
intelligent service it understands the
relation based on the code it would
understand the relationship between the
different services and it would set an
order for itself and then would
provision the services one after the
other let's say a service has a
dependency and the dependent service the
other service which this service let's
say Service A and B service B is
dependent on service a let's say cloud
formation is an intelligent service it
would provision the resource a first and
then would provision resource B what
happens if we inverse the order if we
inverse the order resource B first gets
provision and because it does not have
dependency chances that the cloud
formation's default behavior is that if
something is not provisioned properly
something is not healthy it would roll
back chances that the environment
provisioning will roll back so to avoid
that cloud formation first provision all
the services that has or that's
dependent on that's depended by another
service so it Provisions those service
first and then Provisions the services
that has dependencies and if you're are
being hired for a devops or you know if
the interviewer wanted to test your
skill on systems side this definitely
would be a question in his list how do
you upgrade or downgrade a system with
near zero downtime now everybody's
moving towards zero downtime or near
zero downtime all of them want their
application to be highly available so
the question would be how do you
actually upgrade or downgrade a system
with near zero downtime now we all know
that I can upgrade an ec2 instance to a
better ec2 instance by changing the uh
instance type stopping and starting but
stopping and starting is going to cause
a downtime right so that's you shouldn't
be answering or you should be thinking
in those terms because that's a wrong
answer specifically the interviewer
wants to know how do you upgrade a
system with zero down time so upgrading
system with zero downtime it includes
launching another system parallel with
the bigger uh ec2 instance type with a
bigger capacity and install all that's
needed if you are going to use an Ami of
the old machine well and good you don't
have to go through installing all the
updates and installing all the
application from the Ami once youve
launched in a bigger instance locally
test the application to see if it is
working don't put it on production yet
test the application to see if it is
working and if the application works we
can actually swap if your server is
behind and behind uh Route 53 let's say
all that you could do is go to Route 53
update the uh information with the new
IP address new IP address of the new
server and that's going to send traffic
to the new server now so the cut over is
handled or if you're using static IP you
can actually remove the static IP from
the old machine and assign it to the new
machine that's one way of doing it or if
you are using elastic Nick card you can
actually remove the Nick card from the
old machine and attach the N card to the
new machine so that way we would get
near zero downtime if you're hired for
an architect level you should be
worrying about cost as well along with
the technology and this question would
test how well you manage cost so what
are the tools and techniques we can use
in AWS to identify and correct identify
and know that we are paying the correct
amount for the resources that we are
using or how do you get a visibility of
your AWS resources running one way is to
check the billing there's a place where
you can check the top services that were
utilized it could be free and it could
be paid Service as well top services
that can be utilized it's actually in
the dashboard of the cost Management
console so that table here shows the top
five most used services so looking at it
you can get it all right so I'm using
lot of storage I'm using a lot of ec2
why is storage high you can go ahead and
try to justify that and you will find if
you are storing things that should be
storing and then clean it up why is
compute capacity so high why is data
transfer so high so if you start
thinking in those levels you'll be able
to dig in and clean up unnecessary and
be able to save your bill and there are
cost Explorer services available which
will help you to view your usage pattern
or view your spending for the past 13
months or so and it'll also forecast for
the next 3 months now how much will you
be using if your pattern is like this so
that will actually help and will give
you a visibility on how much you have
spent how much you will be spending if
the trend continues budgets are another
excellent way to control cost you can
actually set a budget all right this is
how much I am willing to spend for this
application for this team or for this
month for this particular resource so
you can actually put a budget Mark and
anytime it exceeds anytime it's nearing
you would get an alarm saying that well
we're about to reach the allocated
budget amount stuff like that that way
you can go back and know and you know
that how much the bill is going to be
for that month or you can take steps to
control bill amount for that particular
month so aw's budget is another very
good tool that you could use cost
allocation tags helps in identifying
which team or which resource has spent
more in that particular month instead of
looking at the bill as one list with no
specifications into it and looking at it
as an expenditure list you can actually
break it down and tag the expenditure to
the teams with cost allocation tags the
dev team has spent so much the uh
production team has spent so much the
training team has spent more than the
dev and the production team why is that
now you'll be able to you know think in
those levels only if you have cost
allocation taxs now cost allocation taxs
are nothing but the tags that you would
put when you create a resource so for
Production Services you would put as a
production T you would create a
production tag and you would associate
that resources to it and at a later
point when you actually pull up your
bill that's going to show a detailed a
list of this is the owner this is the
group and this is how much they have
used in the last month and you can move
forward with your investigation and
encourage or stop users using more
services with the cost allocation tax
the other famous question is are there
any other tools or is there any other
way of accessing AWS resource other than
the console console is GUI right so in
other words other than GUI how would you
use the AWS resource and how familiar
are you with those tools and
Technologies the other tools that are
available that we can leverage and
access the AWS resource are of course
puty you can configure puty to access
the AWS resources like log to an ec2
instance and ec2 instance does not
always have to be logged in through the
console you could use puty to log into
an ec2 instance and like the jump box
like the proxy machine and like the
Gateway machine and from there you can
actually access the rest of the
resources so this is an alternative to
the console and of course we have the aw
CLI in any of the Linux machines or
Windows machines we can install so
that's 2 3 and 4 we can install AWS CLI
for Linux Windows also for Mac so we can
install them and from there from your
local machine we can access run AWS
commands and access provision monitor
the AWS resources the other ones are we
can access the uh AWS resource
programmatically using AWS SDK and
Eclipse so these are bunch of options we
have to use the AWS resource other than
the console if you're interviewed in a
company or bu a company that focuses
more on security and want to use AWS
native services for their security then
you would come across this question what
services can be used to create a
centralized logging solution the basic
Services we could use are cloudwatch
logs store them in S3 and then use
elastic search to visualize them and use
Kinesis to move the data from S3 to
elastic search right so log management
it actually helps organizations to track
the relationship between operational and
security changes and the events that got
triggered based on those logs instead of
logging into an instance or instead of
logging into the environment and
checking the resources physically I can
come to a fair conclusion by just
looking at the logs every time there's a
change the system will scream and it
gets tracked in the cloud watch and then
Cloud watch pushes it to S3 Kinesis
pushes the data from S3 to elastic
search and uh I can do a Time based
filter and I would get an a fair
understanding of what was going on in
the environment for the past one hour or
whatever the time window that I wanted
to look at so it helps in getting a good
understanding of the infrastructure as a
whole all the logs are getting saved in
one place so all the infrastructure logs
are getting saved in one place so it's
easy for me to look at it in an
infrastructure perspective so we know
the services that can be used and here
are some of the services and how they
actually connect to each other it could
be logs that belongs to One account it
could be logs that belongs to multiple
accounts it doesn't matter you know
those three services are going to work
fairly good and they're going to inject
or they're going to like suck logs from
the other accounts put it in one place
and help us to monitor so as you see you
have Cloud watch here that actually
tracks the metrics you can also use
cloud trail if you want to log API calls
as well push them in an S3 bucket so
there are different types of log flow
logs are getting captured in an instance
application logs are getting captured
from the same VPC from a different VPC
from the same account from a different
account and all of them are analyzed
using elastic search using the kibana
client so step one is to deploy the ECS
cluster step two is to restrict access
to the ECS cluster because it's valid
data you don't want anybody to put their
hands and access their data so restic
access to the ECS dashboard and we could
use Lambda also to push the uh data from
cloud watch to the uh elastic search
domain and then kibana is actually the
graphical tool that helps us to
visualize the logs instead of looking at
log as just statements or in a bunch of
characters a bunch of files kibana helps
us to analyze the logs in a graphical or
a chart or a bar diagram format again in
an interview the interview is more con
concerned about testing your knowledge
on AW security products especially on
the logging monitoring event management
or Incident Management then you could
have a question like this what are the
native aw security logging capabilities
now most of the services have their own
logging in them like have their own
loging like S3 S3 has its own login and
cloudfront has its own loging DS has its
own loging VPC has its own logging in
additional there are account level
logins like cloud trail and AWS config
services so there are variety of logging
options available in the AWS like cloud
trail config Cloud front red shift
logging RDS logging VPC flow logs S3
object logging S3 access logging stuff
like that so we're going to look at two
servers in specific cloud trail now this
cloud trail the very first product in
that picture we just saw the cloud trail
provides an very high high level history
of the API calls for all the account and
with that we can actually perform a very
good security analysis a security
analysis of our account and these logs
are actually delivered to you can
configure it they can be delivered to S3
for longtime archival and based on a
particular event it can also send an
email notification to us saying hey just
got this error thought I'll let you know
stuff like that the other one is confix
service now config service helps us to
understand the configuration changes
that happened in our environment and we
can also set up notifications based on
the configuration changes so it records
the cumulative changes that are made in
a short period of time so if you want to
go through the lifetime of a particular
resource what are the things that happen
what are the things it went through they
can be looked at using AWS config all
right the other question you could get
asked is if uh you know your role
includes taking care of cloud security
as well then the other question you
could get asked is the native services
that Amazon provides to mitigate dos
which is denial of service now not all
companies would go with Amazon native
services but there are some companies
which want to stick with Amazon native
Services just to save them from the
headache of managing the other softwares
or bringing in in another tool a third
party tool into managing DS they simply
want to stick with Amazon proprietary
Amazon native services and lot of
companies are using Amazon service to
prevent dos denial of service now denial
of service is if you already know what
denial of service is well and good if
you do not know then let's know it now
denial of service is a user trying to or
maliciously making attempt to access a
website or an application the user would
actually create multiple sessions and he
would occupy all the sessions and he
would not let legimate users access the
service so he's in turn denying the
service for the user a quick uh picture
review of what denial of service is now
look at it these users instead of making
one connection they are making multiple
connections and there are cheap software
programs available that would actually
trigger connections from different
computers in the internet with different
Mac addresses so everything kind of
looks legimate for the uh server and it
would accept those connections and it
would keep the sessions open the actual
users won't be able to use them so
that's denying the service for the
actual users denial of service all right
and distributed denial of service is uh
generating a tax from multiple places
you know from a distributed environment
so that's distributed denial of service
so the tools the native tools that helps
us to prevent to deny of service attacks
in AWS is cloud shield and web access
firewall AWS W now they are the major
ones they are designed to mitigate a
denial of service if your website is
often bothered by denial of service then
we should be using AWS Shield or AWS WF
and there are a couple of other tools
that also does when I say that also does
denal of service is not their primary
job but you could use them for denial of
service Route 53 purpose is to provide
DNS Cloud front is to provide caching
elastic load balancer lb's work is to
provide load balancing VPC is to create
an secure virtual private environment
but they also support mitigating denial
of service but not to the extent you
would get in AWS shield and AWS WF so
AWS shield and WF are the primary ones
but the rest can also be used to
mitigate distributed denial of service
the other tricky question is uh this
actually will test your familiarity with
the region and the services available in
the region so when you're trying to
provision a service in a particular
region you're not seeing the service in
that region how do we go about fixing it
or how do we go about using the service
in the cloud it's a tricky question and
if you have not gone through such
situation you can totally blow it away
you really need to have a good
understanding on regions the services
available in those regions and and what
if a particular service is not available
how to go about doing it the answer is
not all services are available in all
regions anytime Amazon announces a new
service they don't immediately publish
them on all regions they start small and
as in when the traffic increases as in
when it becomes more likable to the
customers they actually move the service
to different regions so as you see in
this picture within America North
Virginia has more service
compared to Ohio or Compared to North
California So within North America
itself North Virginia is the preferred
one so similarly there are preferred
regions within Europe Middle East and
Africa and preferred regions within Asia
Pacific so anytime we don't see a
service in a particular region chances
that the service is not available in
that region yet we got to check the
documentation and find the nearest
region that offers that service and
start using the service from that region
now you might think well if I'm looking
for a service in Asia let's say in
Mumbai and if it is not available why
not simply switch to North Virginia and
start using it you could but you know
that's going to add more latency to your
application so that's why we need to
check for application which is check for
region which is very near to the place
where you want to serve your customers
and find nearest region instead of
always going back to North Virginia and
deploying an application in North
Virginia again there's rep place there's
a link in aws.com that you can go and
look for services available in different
region and that's exactly what you're
seeing here and if your service is not
available in a particular region switch
to the other region that provides your
service the nearest other region that
provides that service and start using
service from there with the uh coming up
of cloud a lot of companies have turned
down their monitoring team instead they
want to go with the monitoring stat
Cloud provides you know nobody wants to
or at least many people don't want to go
through the hazle of at least new
startups and new companies that are
thinking of having a monitoring
environment and they don't want to go
with traditional knock monitoring
instead they would like to leverage AWS
monitorings available because it
monitors a lot of stuff not just the
availability but it monitors a lot of
stuff like failures errors it also
triggers emails stuff like that so how
do you actually set up a monitor to
website I mean how do you set up a
Monitor to Monitor the uh website
metrics in real time in AWS the simple
way anytime you have a question about U
monitoring cloudwatch should strike your
mind because cloudwatch is meant for
monitoring is meant for collecting
metrics is meant for providing graphical
representation of uh what's going on in
a particular Network at a particular
point of time so Cloud watch cloudwatch
helps us to monitor applications and
using cloudwatch we can monitor the
state changes not only the state changes
the autoscaling life cycle events
anytime there there are more services
added there is a reduction in the number
of servers because of less usage a very
informative messages can be received
through cloudwatch any cloudwatch can
now support scheduled events if you want
to schedule anything cloudwatch has an
event that would schedule an action
right schedule a Trigger Time based not
incident based you know anything
happening and then you get an action
happening that's incident based on the
other hand you can simply schedule few
things on time based so that's possible
with Cloud watch So This Cloud watch
integrates very well with a lot of other
services like notifications for
notifying uh the user or for notifying
the administrator about it and it can
integrate well with Lambda so the
trigger an action anytime you're
designing an auto healing environment
this cloudwatch can actually monitor and
send an email if we are integrating it
with SNS simple notification service or
this Cloud watch can monitor and uh
based on what's Happening it can trigger
an event in Lambda and that would in
turn run a function till the uh
environment comes back to normal so
cloudwatch integrates well with a lot of
other aw Services all right so
cloudwatch has uh three statuses green
when everything is going good L when the
service is degraded and red when the
service is not available green is good
so we don't have to do anything about it
but anytime there's an loo the picture
that we're looking at it's actually
calling an Lambda function to debug the
application and to fix it and anytime
there's a red alert it immediately
notifies the um owner of the application
about well the service is down and here
is the report that I have here is the
metrics that I've collected about the
service stuff like that that if the job
role requires you to manage the servers
as well there are certain job roles
which are on the system side there are
certain job roles which is development
plus system side now you're responsible
for the application and the server as
well so if that's the case you might be
tested with some basic questions like
the different types of virtualization in
AWS and what are the difference between
them all right the three major types of
virtualization are hvm which is Hardware
which virtual machine the other one is
PV par virtualization and the third one
is PV on hbm par virtualization on
Hardware virtual module all right the
difference between them or actually
describing them is actually the
difference between them hbm it's
actually a fully virtualized Hardware
you know the whole Hardware is
virtualized and all virtual machines act
uh separate from each other and these
VMS are booted by executing Master boot
record in the block and when we talk
about par virtualization parag grub is
actually the special boot loader which
boots the PV Amis and when we talk about
PV on hvm it's it's actually the the
marriage between hvm and PV and this par
virtualization on hvm in other words PV
on hvm it actually helps operating
system take advantage in storage and the
network input output available through
the host another good question is name
some of the services that are not region
specific now you've been thought that
all services are within a region and
some services are within an availability
zone for example ec2 is within an
availability Zone EBS is within an
availability Zone S3 is region specific
Dynamo DB is region specific stuff like
that VPC is both availability and a
region specific meaning you know subnets
are availability Zone specific and vpc's
region specific stuff like that so you
might have thought you might have
learned in that combination but there
could be some tricky questions that
tests you how well you have understood
the region non region and availability
non-availability Services I should say
there are services that are not region
specific that would be IM am so we can't
have IM am for every availability Zone
and for every region which means you
know users will have to use one username
and password for one region and anytime
they switch to another region they will
have to use another username and
password that that's more work and
that's not a good design as well
authentication has to be Global so IM is
a global Service and which means it's
not region specific on the other hand
Route 53 is again a regional specific so
we can't have Route 53 for every region
Route 53 is not a region specific
service it's a global Service and it's
one application you users access from
everywhere or from every part of the
world so we can't have one URL or one
DNS name for each region if your
application is a global application and
then web application firewall works well
with cloudfront and cloudfront is a
region based service so the web
application firewall it's not region
specific service it's a global Service
and cloudfront is again a global Service
though you can U you know cash content
on a continent and country basis it's
still considered a global Service all
right it's not bound to any region so
when you activate cloudfront you're
activating it away from region or
availability zone so when you're
activating a web application firewall
because it's not a region specific
service you're activating it away from
availability Zone and regions so a quick
recap I am users groups roles and
accounts they are Global Services they
can be used globally R 53 services are
offered at Edge locations and they are
Global as well web application firewall
a service that protects our web
application from common web exploits
they are global Service as well
cloudfront cloudfront is global content
delivery Network CDN and they are
offered at Edge locations which are a
global Service in other words non region
specific service or Beyond region
service all right this is another good
question is as well in the project that
you are being interviewed if they really
want to secure their environment using
natat or if they are already securing
their environment using natat by any of
these two methods like natat Gateway
orat instances you can expect this
question what are the difference between
a Nat Gateway and Nat instances now they
both serve the same thing all right so
they're not two different Services
trying to achieve two different things
they both serve the same thing but still
they do have differences in them all
right on a high level they both achieve
providing nting for the service behind
it but the difference comes when we talk
about the availability of it n Gateway
is a managed service by Amazon whereas
Nat instance is managed by us now I'm
talking about the third Point
maintenance here Nat Gateway is managed
by Amazon Nat instance is managed by us
and availability of nat Gateway is very
high and a avilability of natat instance
is less compared to the natat Gateway
because it's managed by us you know it's
on an easy2 instance which could
actually fail and if it fails we'll have
to relaunch it but if it is not Gateway
something happens to that service Amazon
would take care of reprovision it and
talking about bandwidth it can burst up
to 75 gbits now traffic through the N
Gateway can burst up to 75 gbits but for
n instance it actually depends on the
server that we launch and if we are
launching a T2 micro it barely gets any
bandwidth so there's a difference there
and the performance because it's highly
available because of the bigger pipe 75
GBS the performance of the NAT Gateway
is very high but the performance of the
natat instance is going to be average
again it depends on the size of the
natat instance that we pick and billing
a billing for Nat Gateway is the number
of gateways that we provision and the
duration for which we use the NAT
Gateway but billing for Nat instance is
number of instance and the type of
instance that we use of course number of
instance duration and the type of
instance that we use security n Gateway
cannot be uh assigned meaning it already
comes with full packed security but in
that instance security is a bit
customizable I can go and change the
security because it's a server managed
by me or managed by us I can always
change the security well allow this
allow don't allow this stuff like that
size and load of the N Gateway is
uniform but the size and the load of the
NAT instance changes as per a n Gateway
is a fixed product but Nat instance can
be small instance can be a big instance
so the size and the load through it
varies right the other question you
could get asked is what are the
difference between stopping and
terminating an ec2 instance now you'll
be able to answer only if you have
worked on environments where you have
your instance stopped and where you have
your instance terminated if you have
only used lab and are attending the
interview chances are that you might
your always lost when answering this
question it might look like both are the
same well stopping and terminating both
are the same but there is a difference
in it so when you stop an instance it
actually performs a normal shutdown on
the instance and it simply moves the
instance to the stopped state but when
you actually turn terminate the instance
the instance is moved to this stop State
the EVS volumes that are attached to it
are deleted and removed and we'll never
be able to recover them again so that's
a big difference between stopping and
terminating an instance if you're
thinking of using the instance again
along with the data in it you should
only be thinking of stopping the
instance but you should be terminating
the instance only if you want to get rid
of that instance forever if you are
being interviewed for an architect level
position or a junior architect level
position or even an Cloud consultant
level position or even an an engineering
position this is a very common question
that get asked what are the different
types of E2 instances based on their
cost or based on how we pay them right
they're all computer capacity for
example the different types are on
demand instances spot instances and
reserved instances it kind of looks the
same they all provide the computer
capacity they all provide the same type
of Hardwares for us but if you're
looking at Cost saving or optimizing
cost in our environment we got to be
very careful about which one are we
picking and we might think that well
I'll go with on demand instance because
I pay on a per hour basis which is cheap
you know I can use them anytime I want
and anytime I don't want I can simply
get rid of it by terminating it you're
right but if the requirement is to use
the service for one year the requirement
is to use the service for 3 years then
you'll be wasting a lot of money buying
on demand instances you'll be wasting a
lot of money paying on an hourly basis
instead we should be going for reserved
instance where we can reserve the
capacity for the complete one year or
complete 3 years and save huge amount in
buying reserved instances all right so
underman is cheap to start with if you
only planning to use it for a short
while but if you're planning to run it
for a long while then we should be going
for reserved instance that is what is
cost efficient so spot instance is
cheaper than on demand instance and
there are different use cases for spot
instance as well so let's look at one
after the other the on demand instance
the on demand instance is purchased at a
fixed rate per hour this is very
shortterm and irregular workloads and
for testing for development on demand
instance is a very good use case we
should be using on demand for production
spot instance spot instance allows users
to purchase ec2 at a reduced price and
anytime we have more instances we can
always go and sell it in spot instances
I'm referring to anytime we have more
reserved instances we can always sell
them in spot instance uh catalog and the
way we buy Spot instance is we actually
put a budget this is how much I'm
willing to pay all right would you be
able to give service within this cost so
anytime the price comes down and meets
the cost that we have put in will be
assigned an instance and anytime the
price shoots up the instance will be
taken away from us but in case of on
demand instances we have bought that
instance for that particular R and it
stays with us but with spot instances it
varies based on the price if you meet
the price you get the instance if you
don't meet the price goes away to
somebody else and a spot instance
availability is actually based on supply
and demand in the market there's no
guarantee that you will get spot
instance at all time all right so that's
a caveat there you should be familiar
with that's a caveat there you should be
aware when you are proposing somebody
that we can go for spot instance and
save money it's not always going to be
available if you want your spot instance
to be available to you then we need to
carefully watch the history of the price
of the spot instance now how much was it
last month then how much was it how much
is it this month so how can I code or
how much can I code stuff like that so
you got to look at those history before
you propose somebody that well we're
going to save money using spot instance
on the other hand reserved instance
provide cost savings for the company or
we can opt for reserved instances for
you know one year or 3 years there are
actually three types of reserved
instances light medium and heavy
reserved instances they are based on the
amount that we would be paying and cost
benefit also depends with reserved
instance the cost benefit also depends
based on are we doing all upfront or or
no upfront or partial payment then split
the rest as monthly payments so there
are many purchase options available but
overall if you're looking at using an
application for the next 1 year and 3
years you should not be going for on
demand instance you should be going for
reserved instance and that's what gives
you the cost benefit and in an AWS
interview sometimes you might be asked
you know how you interact with the AWS
environment are you using CLI are you
using console and depending on your
answer whether console or a CLI the
panelist put a score okay this person is
CLI specific this person is console
specific or this person has used AWS
environment through the SDK stuff like
that so this question test whether you
are a CLI person or an console person
and the question goes like this how do
you set up SSH agent forwarding so that
you do not have to copy the key every
time you log in if you have used puy
anytime if you want to log into an ec2
instance you will have to put the IP and
the port number along with that you will
have to map or we will have to map the
key in the Puri and this has to be done
every time that's what we would have
done in our lab environments right but
in production environment using the same
key or mapping the same key again and
again every time it's actually an hazle
it's considered as a blocker so you
might want to cach it you might want to
permanently add it in your pry session
so you can immediately log in and start
uh using it so here in the place where
you would actually map the private key
there's a quick button that actually
fixes or that actually binds your SSH to
your puty instance so we can enable SSH
agent forwarding uh that will actually
bind our key to the SSH and next time
when we try to log in we don't have to
always go through mapping the key and
trying to log in all right this question
what are Solaris and ax operating
systems are they available with AWS that
question generally gets asked to test
how familiar are you with the uh Amis
available how familiar are you with ec2
how familiar are you with the ec2
Hardwares available that basically test
that now the first question or the first
thought that comes to your mind is well
everything is available with AWS I've
seen Windows I've seen Ubuntu I've seen
Red Hat I've seen Amazon uh Amis and if
I don't see my operating system there I
can always go to Marketplace and try
them if I don't find in Marketplace I
can always go to community and try them
so there lot of Amis available there lot
of operating systems available I will be
able to find Solaris and ax but that's
not the case Solaris and ax are not
available with AWS that's because
Solaris uses a different I me Solaris
does not support the architecture does
not support public Cloud currently the
same goes for ax as well and they run on
power CPU and not on Intel and as of now
Amazon does not provide Power machines
this should not be confused with the HPC
which is high performance Computing
should not be confused with that now
these are different Hardwares different
CPU itself that the cloud providers did
do not provide yet another question you
could get asked in organizations that
would want to automate their
infrastructure using Amazon native
Services would be how do you actually
recover an ec2 instance or Auto recover
an ec2 instance when it fails well we
know that ec2 instances are considered
as immutable meaning irrepairable we
don't spend time fixing bugs in an OS
stuff like that you know once an ec2
instance crashes like it goes on a o
Panic or there are various reasons why
it would fail so we don't have to really
worry about fixing it we can always
relaunch that instance and that would
fix it but what if it happens at 2:00 in
the night what if it happens that during
a weekend when nobody's in office
looking or monitoring those insten so
you would want to automate that not only
on a weekend or during midnights but
it's general practice good to automate
it so you could face this question how
do you actually automate an ec2 instance
once it fails and the answer to that
question is using cloudwatch we can
recover the instance so as you see there
is an alarm threshold a set in Cloud
watch and and once the threshold is met
meaning if there is an error if there is
a failure if the uh ec2 instance is not
responding for a certain while we can
set an alarm and once the alarm is met
let's say the CPU utilization stayed
high for 5 minutes all right it's not
taking any new connections or the
instance is not pinging for 5 minutes or
in this case it's 2 minutes it's not
pinging so it's not going to respond
connection so in those cases you would
want to automatically recover that e to
instance by rebooting the instance all
right now look at this they take this
action section under the action so there
we have a bunch of options like recover
this instance meaning reboot the
instance so that's how we would recover
the other two options are beyond the
scope of the question but still you can
go ahead and apply just like I'm going
to do it so the other option is stop the
instance that's very useful when you
want to stop instances that are having
low utilizations nobody's using the
system as of now you don't want them to
be running and wasting the uh Cloud
expenditure so you can actually set an
alarm that stops the ec2 instance that's
having low utilization so somebody was
working in an instance and they left it
without or they forgot to shut down that
instance and it gets I mean they will
only use it again the next day morning
so in between there could be like 12
hours that the system is running idle
nobody's using it and you're paying for
it so you can identify such instances
and actually stop them when the CPU
utilization is low meaning nobody is
using it the other one is to terminate
let's say you want to give system to
somebody temporarily and you don't want
them to hand the system back to you all
right this is actually an idea in other
words this is actually the scenario so
you hand over a system to somebody and
when they're done they're done we can
actually terminate the system so you
could instruct the other person to
terminate the system when they're done
and they could forget and the instance
could be running forever or you can
monitor the system after the uh
specified time is over and you can
terminate the system or best part you
can automate the system termination so
you assign a system to somebody and then
turn on this Cloud watch action to
terminate the instance when the CPU is
low for like 2 hours meaning they've
already left or CPU is low for 30
minutes meaning they've already left
stuff like that so that's possible and
if you're getting hired for an system
side architect or even on the ssop side
you could face this question what are
the common and different types of Ami
designs there are a lot of Ami designs
the question is the common ones and the
difference between them so the common
ones are the full back Amis and the
other one is just enough OS Ami j e OS
Ami and the other one is hybrid type
Amis so let's look at the difference
between them the fullback Ami just like
the name says it's it's fully baked it's
uh ready to use Ami and this is the
simplest Ami to deploy can be a bit
expensive it can be a bit cumbersome
because you'll have to do a lot of work
beforehand you could use the Ami so a
lot of planning a lot of thought process
will go into it and the Ami is ready to
use right you hand over the Ami to
somebody and it's ready to use or if you
want to reuse the Ami it's already ready
for you to use so that's full baked Ami
the other one is just enough operating
system Ami just like the name says uh it
has uh I mean as you can also see in the
diagram or in the picture it covers a
part of the OS all bootstraps are
already packed properly and the security
monitoring logging and the other stuff
are configured at the time of deployment
or at the time you would be using it so
not much thought process will go in here
the only focus is on choosing the
operating system and what goes the
operating system specific agents or
bootstraps that goes into the operating
system that's all we worry about the
advantage of this is it's flexible
meaning you can choose to install
additional softwares at the time of
deploying but that's going to require an
additional expertise on the person who
will be using the Ami so that's another
overhead there but the advantage is that
it's kind of flexible I can change the
configurations during the time of
deployment the other one is hybrid Ami
now the hybrid Ami actually falls in
between the fully baked Ami and just
enough operating system options so these
Amis have some features of the big type
and some features of the just enough OS
type so as you see the security
monitoring logging are packed in that
Ami and the runtime environments are
installed during the time of deployment
so this is where the strict company
policies would go into the Ami company
policies like you got to log this you
got to monitor this these are the ports
that generally gets open in all our
systems stuff like that so they strictly
go into the Ami and sits in an Ami
format and during deployment you have
the flexibility of choosing the
different runtime and the application
that sits in an ec2 instance another
very famous question you would face in
an interview is how can you recover
login to an ec2 instance to which you
lost the key well we know that if the
key is lost we can't recover it there
are some organizations that in integrate
their E2 instances with an ad that's
different all right so you can go and
reset the password in the ad and you
will be able to log in with the new
password but here the specific tricky
question is you are using a key to log
in and how do you recover if you have
lost the key generally companies would
have made a backup of the key so we can
pick from the backup but here the
specific question is we have lost the
key literally no backups on the key at
all so how can we log in and we know
that we can't log log into the instance
without the key present with us so the
steps to recover is that make the
instance use another key and use that
key to log in once the key is lost it's
lost forever we won't be able to recover
it you can't raise a ticket with Amazon
not possible they're not going to help
it's beyond the scope so make the
instance use another key it's only the
key that's the problem you still have
valid data in it you got to recover the
data it's just the key that's having the
problem so we can actually focus on the
key part alone and change the key and
that will allow us to log in so how do
we do it stepbystep procedure so first
verify the EC to config service is
running in that instance uh if you want
you can actually beforehand install the
EC to config in that service or you can
actually make the ec2 config run through
the console just a couple of button
clicks and that will make the ec2 config
run in that E2 instance and then detach
the root volume for that instance of
course it's going to require stop and
start to detach the root volume from the
instance attach the root volume to
another instance as a temporary volume
or it could be a temporary instance that
you've launched only to fix this issue
and then log in to that instance and to
that particular volume and modify the
configuration file configuration file
modify it to use the new key and then
move the root volume back to its
original position and restart the
instance and now the instance is going
to have the new key key and you also
have the new key with which you can log
in so that's how we go ahead and fix it
now let's move on to some product
specific or S3 product specific
questions a general perception is S3 and
EBS can be used interchangeably and the
interviewer would want to test your
knowledge on S3 and EBS well EBS uses S3
that's true but they can't be
interchangeably used so you might face
this question what are some key
differences between AWS S3 and EBS well
the differences are S3 is an object
store meaning you can't install anything
in it you can store drive files but you
can't actually install in it it's not a
file system but EBS is a file system you
can install Services I mean install
applications in it and that's going to
run stuff like that and talking about
performance S3 is much faster and EBS is
uh super faster when accessing from the
instance because from the instance if
you need to access S3 you'll actually
have to go out through the internet and
access the S3 or S3 is an external
service very external service you'll
have to go through or you'll have to go
outside of your VPC to access S3 S3 does
not come under a VPC but EBS comes under
a VPC it's on the same VPC so you would
be able to use it kind of locally
compared to S3 EBS is very local so that
way it's going to be faster and
redundancy talking about redundancy of
S3 and EBS S3 is replicated the data in
S3 is replicated across the data centers
but EBS is replicated within the data
center meaning S3 is replicated across
availability zones EBS is within an
availability zone so that way redundancy
is a bit less in EBS in other words
rency is higher in S3 than EBS and
talking about security of S3 S3 can be
made private as well as public meaning
anybody can access S3 from anywhere in
the internet that's possible with S3 but
EBS can only only be accessed when
attached to an E2 instance right just
one instance can access it whereas S3 is
publicly directly accessible the other
question related to S3 security is how
do you allow access to a user to a
certain a user to a certain bucket which
means this user is not having access to
S3 at all but this user needs to be
given access to a certain bucket how do
we do it the same case applies to
Service as well in few cases there could
be an instance where a person is new to
the team and you actually don't want
them to access the production servers
now he is in the production group and by
default he or she's granted access to
that server but you specifically want to
deny access to that production server
till the time he or she is matured
enough to access or understand the
process understand the dos and don'ts
before they can put their hands on the
production server so how do we go about
doing it so first we would C categorize
our instances well these are critical
instances these are normal instances and
we would actually put a tag on them
that's how we categorize right so you
put a tag on them put a tag saying well
they are highly critical they are medium
critical and they are not critical at
all still there in production stuff like
that and then you would pick the users
who wants to or who should be or should
not be given access to a certain server
and you would actually allow the user to
access or not access servers based on a
specific tag in other words you can use
actually tags in in the previous step we
put tags on the critical server right so
you would Define that this user is not
going to use this tag all right this
user is not allowed to use the resources
with this tag so that's how you would
make your step forward so you would
allow or deny based on the tags that you
have put so in this case he or she will
not be allowed to servers which are TAG
critical servers so that's how you allow
deny access to them and the same goes
for bucket as well if an organization is
excessively using S3 for their data
storage because of the benefit that it
provides the cost and the durability you
might get asked this question which is
organizations would replicate the data
from one region to another region for
additional data durability and for
having data redundancy not only for that
they would also do that for Dr purposes
for disaster recovery if the whole
region is down you still have the data
available somewhere else and you can
pick and use it some organizations would
store data in different regions for
compliance reasons to provide low
latency access to their users who are
local to that region stuff like that so
when companies do replication how do you
make sure that there is consistency in
the replication how do you make sure
that the replication is not failing and
the data gets transferred for sure and
there are logs for that replication this
is something that the companies would
use where they're excessively using S3
and they're fully relying on the
replication in running their business
and the way we could do it is we can set
up a replication monitor it's actually
set up tools that we could use together
to make sure that the cloud replication
a region level replication is happening
properly so this is how it happens now
on this side on the left hand side we
have the region one and on the right
hand side we have region two and region
one is the source bucket and region two
is the destination bucket all right so
object is put in the source bucket and
it has to go directly to the region two
bucket or or made a copy in the region
two bucket and the problem is sometimes
it fails and there is no consistency
between them so the way you would do it
is connect these Services together and
create an cross replication or cross
region replication monitor that actually
monitors that actually monitors your
environment so there are Cloud watch
that make sure that the data is moved no
data is failing again there's Cloud
watch on the other end make sure that
the data is moving and then we have the
logs generated through cloud trail and
that's actually written in Dynamo DB and
if there is an error if something is
failing you get notified through an SMS
or you get notified through an email
using the SNS service so that's how we
could leverage these tools and set up
and cross region replication monitor
that actually monitors your data
replication some common issues that
company companies face in VPC is that we
all know that I can use Route 53 to
resolve an IP address externally from
the internet but by default the servers
won't connect to the other servers using
our custom DNS name that it does not do
that by default so it's actually a
problem there are some additional things
that as an administrator or as an
architect or as a person who uses it you
will have to do and that's what we're
going to discuss so the question could
be VPC is not resolving the server
through the DNS you can access it
through the IP but not through the DNS
name and what could be the issue and how
do you go about fixing it and you will
be able to answer this question only if
you have done it already it's a quick
and simple step by default VPC does not
allow that's the default feature and we
will have to enable the U DNS host name
resolution before now this is for the
custom DNS not for the default DNS that
comes along this is for the custom DNS
so we will have to enable the uh DNS
host name resolution so our we'll have
to enable the DNS host name resolution
so they actually resolve let's say I
want to connect to a server 1. simply
learn.com by default it's not allowed
but if I enable this option then I will
be able to connect to server one simply
learn.com if a company has vpcs in
different regions and they have head
office in a central place and the rest
of them are Branch offices and they are
connecting to the head office for Access
or you know for saving data or for
accessing certain files or certain data
or toring data all right so they would
actually mimic the huban spoke tropology
where you have the VPC which is
centrally in an accessible region a
centrally accessible region and then you
would have a local vpcs or Branch
offices in different other regions and
they get connected to the VPC in the
central location and the question is how
do you actually connect the multiple
sites to a VPC and make communication
happen between them by default it does
not do that we know that vpcs they need
to be paired between them in order to
access the resources let's look at this
picture right so I have like a customer
Network or branch office in different
parts and they get connected to a VPC
that's fine so what we have achieved is
those different offices the remote
officers they are connecting to the VPC
and they're talking but they can't
connect or they can't talk to each other
that's what we have built but the
requirement is the traffic needs to or
they should be able to talk to each
other but they should not have direct
connection between them which means that
they will have to come and hit the VPC
and then reach the other customer
Network which is in Los Angeles or which
is in New York right that's the
requirement so that's possible with some
architecting in the cloud so that's
using wepn Cloud Hub you look at this
dotted lines which actually allows
customers or which actually allows the
corporate uh networks to talk to each
other through the VPC Again by default
it doesn't happen cloudhub is an
architecture that we should be using to
make this happen and what's the
advantage of it as a central office or
as the headquarters office which is in
the VPC or headquarters data center
which is in the VPC you have control or
the VPC has control on who talks to who
and what traffic can talk to I mean what
traffic can be routed to the other head
office stuff like that that centralized
control is on the VPC the other question
you could get asked is name and explain
some security products and features
available in VPC well VPC itself is an
security service it provides security
service to the application but how do
you actually secure the VPC itself
that's the question and yes there are
products that can actually secure the
VPC or the VPC delivers those products
to secure the application access to the
VPC is restricted through a network
access control list all right so that's
an Security prodct in VPC and a VPC has
security groups that protects the
instances from unwanted inbound and
outbound traffic and network access
control list protects the subnets from
unwanted inbound and outbound access and
there are flow logs we can capture in
VPC that captures incoming and outgoing
traffic through a VPC which will be used
for later analysis as in what's the
traffic pattern what's the behavior of
the traffic pattern stuff like that so
there are some security products and
features available in VPC now how do you
monitor VPC VPC is a very important uh
concept very important Service as well
everything sits in a VPC most of the
service sits in a VPC except for Lambda
and S3 and Dynamo DB and couple of other
services most of them sit in a VPC for
security reason so how do you monitor
your VPC how do you gain some visibility
on your VPC well we can gain visibility
on your VPC using VPC flow log that's
the basic Service as you see it actually
captures what's allowed what's not
allowed stuff like that which IP is
allowed which IP is not allowed stuff
like that so we can gather it and we can
use that for analysis and the other one
is uh Cloud watch and Cloud watch logs
the data transfers that happen so this
is you know who gets allowed and who
does not get allowed I mean the flow
logs is who is allowed and who is not
allowed that kind of detail and Cloud
watch gives information about the data
transfer how much data is getting
transferred we can actually pick unusual
data transfers if there is a sudden hike
in the graph there's a sudden hike and
something happens at 12 on a regular
basis and you weren't expecting it
there's something suspicious it could be
valid backups it could be a malicious
activity as well so that's how you know
by looking at Cloud watch logs and Cloud
watch dashboard now let's talk about
multiple choice questions when going for
an interview you might sometimes find
yourself that the company is conducting
an online test based on the score they
can put you to a panelist and then they
would take it forward so we thought
we'll also include multiple choice
questions to help you better handle such
situation if you come across all right
when you find yourself in such situation
the key to clear them is to understand
the question properly read between the
lines that's what they say you know
there can be like a big paragraph with
three lines or 10 lines you really got
to understand what the question is about
and then try to find answer for that
question so that's a thumb rule number
one and then the second rule is try to
compare and contrast the services
mention or try to compare and contrast
the answers you can easily read out one
or two answers and then you'll be left
with only two answers to decide from you
know so that also helps you with time
and that's that also helps you with some
Precision in your answer so number one
read between the lines number two
compare and contrast the services and
you'll be able to easily weed out the
wrong ones so let's try answering this
question suppose you are a game designer
and you want to develop a game with a
single digit millisecond latency which
of the following database Services would
you choose so we know that the following
R database services are good enough all
right and it talks about millisecond
latency that's a key point and the third
thing is it's a game could be a mobile
game it's a game that you are trying to
design and you need a millisecond
latency and it has to be a database all
right so let's talk about the options
available auds RS is a database for sure
is it good for uh game design we'll come
back to that Neptune uh Neptune is a
graph a database service in Amazon so
that's kind of out of the equation and
snowball is actually a storage all right
it's it's a transport medium I would say
so that's again out of the equation so
the tie is between RDS and Dynamo DB if
we need to talk about RDS RDS is an a
platform as a service it provides cost
efficient resizable capacity but it's an
SQL database meaning the tables are kind
of strict you know it's good for Banking
and other type of applications but not
really good for anything that has to do
with gaming so the only option left is
Dynamo DB again it's a right answer
Dynamo DB is actually an fast and
flexible nosql database service and it
provides a single digigit millisecond
latency at any scale and it's a database
at the same time it's a key Value Store
model database so the right answer is
Dynamo DB all right let's look at the
next question if you need to perform
realtime monitoring of aw services and
get actionable insights which service
would you use all right let's list this
services so it talks about realtime
monitoring a firewall manager what does
it provide now firewall manager is not
really a monitor just like the name says
it's a manager it manages multiple
firewalls and A's guard duty is an
thread deduction service it does
monitoring it does continuously monitor
our environment but it monitors for
Threads all right only threads now let's
talk about about Cloud watch uh Cloud
watch is a service that helps to track
metrics it's a service that is used uh
to monitor the environment and give us a
systemwide visibility and also it helps
us to store logs so at the moment it
kind of looks like that could be the
right answer we don't know that yet but
I mean we have one more option left
that's uh EBS so what's EBS EBS is a
block storage elastic Block store if we
abate EBS it's elastic Block store so
all three of them are easily out of the
question the first one is to manage
second one is to find threats of course
it does monitoring so there's I mean if
there's one relation between Cloud watch
and guard Duty that's monitoring so
easily we can actually find oursel
slipped towards picking God duty but
know that God duty is only for gaining
security Insight but not about gaining
AWS service Insight so cloudwatch is a
service that helps us to get a system
wide or an AWS wide or an account wide
it has number of metrics we can monitor
and get a very good Insight of how a
service is performing be it uh CPU be it
Ram be it Network utilization be it uh
uh connection failures cloudwatch is a
service that helps us perform a realtime
monitoring and get some actionable
insights on the services all right let's
talk about this 33rd question as a web
developer you are developing an app
especially for the mobile platform all
right there is a mention that this is
especially for the mobile platform so a
lot of servic just gets filtered out
mobile platform right which of the
following lets you add user sign up sign
in and access control to your web and
mobile app quickly and easily all right
so this is all about signing in to your
mobile app so if we need to read between
the lines that's how we can read sign up
or sign in into an mobile platform all
right so we have like four options here
uh Shield aw
Massie AWS inspector Amazon Cognito so
let's try to we out Services which are
not relevant to it so what's aw Shield
aw Shield is actually a service that
provides a Dos mitigation or dos
protection denial of service protection
it's in security feature let's talk
about the second option AWS Maxi is
again a security service that uses
machine learning to automatically
discover and classify the data it again
talks about um security and this
security is all about encrypting or
saving the data does not come close with
signing up an mobile platform all right
let's talk about the other one AWS
inspector now AWS inspector has
something to do with apps it definitely
has something to do with apps so kind of
looks like that's relevant as of now so
it actually helps with um improving the
security and compliance of the apps that
we deploy in the cloud so kind of looks
like it could be because it has to do
with apps the last one Cognito now
Cognito is a service that actually lets
the administrator to have control access
over web and mobile apps and it's a
service that helps us to sign up and uh
sign in to an mobile and web app so that
very much looks like we found the answer
so Cognito is a service that helps web
app and mobile app for sign up and
signing in and also gives the
administrator to have control over who
has I mean access control over the web
and the mobile app pretty much we found
it so it's Cognito Cognito is a service
that helps us to set up sign up sign in
and have access control over the users
who would be using our mobile and web
app all right how about this question uh
you are an ml engineer or or machine
learning engineer who's on the look out
for a solution that will discover
sensitive information that your
Enterprise stores in AWS and then uses
NLP to classify that data and provide
business related insights which among
the following Services would you choose
so we have a bunch of services that's
going to help us achieve or one of it is
going to help us achieve the about
requirement so it's a service that deals
with machine learning you are a machine
learning engineer who's looking for a
service that uh will help you to
discover information at your Enterprise
store so we're talking about storage
discover information in store and then
classify uh the data depending on
severity sensitivity classify the data
so which service is that so firewall
manager just like the name says it's a
manager and AWS IAM if we Abate it it's
identity and access management so it's
identity and access management nothing
to do with identifying sensitive data
and managing it so the first two is
already out of the equation and then the
aw's Massie we already had a quick
definition description for AWS Massie
that it's actually a security service
that uses machine learning kind of looks
like it could be it it's a security
service that uses machine learning and
it discovers and classifies the
sensitive information not only that it
does not stop there it goes beyond and
protects the sensitive data AWS Massy
kind of looks like but we still have one
more option to look at which is cloud
HMS Cloud HMO is also a security service
kind of looks like that could be the
answer as well and it enables us to
generate encryption keys and save the
data so kind of 50% of it it's a
security service it encrypts helps us
protect the data but AWS Massi is right
on spot it's a machine learning service
it helps us to classify the data and
also to protect the data so the answer
for this question will be AWS Massy so
hope you kind of get it how this is
going so first we apply the thumb rule
identify the question that's being asked
read between the lines and then try to
find the service that meets your
requirement and finding the service is
by first weeding out the wrong ones
recollect everything that you've learned
about the service and see how well that
matches with those hints that you have
picked up and if that doesn't match weed
that out then you'll end up with two
just two to decide from at some point
and then it becomes easy for you to
decide click on the question Summit it
and then move on to the other question
in your interview all right so how about
this one uh you are a system
administrator in your company which is
running most of its infrastructure on
AWS you are required to track your users
and keep a look on how your users are
being authenticated all right so this is
where the problem statement starts right
you need to keep track of how your users
are being authenticated and you wish to
create and manage AWS users and use
permissions to allow and deny their
access to the AWS resources right you
are to give them permission number one
and then I mean if we put them in the
right order first giving them
permissions and then tracking their
usage let's see which of the service
will help us achieve it I am is a
service that uh helps us to looking at
the uh permissions we can actually
predict whether the user or the group
will have servers or not so that helps
us to get a track of who's able to use
who's not able to use certain servers
and all that stuff so it kind of looks
like but we have other three options
left let's look at aw's firewall manager
just like the name says it's actually a
firewall manager it helps us to manage
multiple Fireballs simple as that and
shield is a service it's a service
that's used to protect denial of service
or distributed denial of service an API
Gateway is a service that makes it easy
for developers to create publish
maintain and monitor and secure API so I
mean it's completely on the API side
very Less on user and how you
authenticate your user we can get that
by looking at the name itself right if
you Abate it or if you if you try to
find a definition for the name API
Gateway you would get it it has to do
with API but if you aate AWS am it's
identity and access management pretty
much meets the requirement for the
problem statement about it's AWS
identity and access management that's
the right answer all right let's look at
this one if you want to allocate various
private and public IP address in order
to make them communicate uh with the
internet and other instances you will
use this service which of the following
is this service so it talks about using
public and private IP address so this
service users IP address and then this
service helps us to allow and deny
connections to the internet and to the
other instances so you get the question
is it let's pick the service that helps
us achieve it Route 53 Route 53 is
actually a DNS service right it's not a
service that's used to allow or deny no
it does not do that VPC VPC uses public
and private IP address yes so kind of
looks like VPC helps us uh to allow I
mean the security in VPC the security
group the network access control list in
a VPC the routing table in a VPC that
actually helps us to allow or deny a
connection to particular IP address or
to a particular service within the VPC
or outside of the VPC so as of now it
kind of looks like it could be but let's
look at the other services what if if we
find a service that closely matches to
the above requirement than the Amazon
VPC Gateway API Gateway we know that
it's a manage service that makes it easy
for developers to create publish
maintain and monitor apis and secure API
so that has has completely do with API
not with IP Cloud front we know about
cloudfront that it's in content delivery
Network and it provides global
distribution of uh servers where our
content can be cached it could be video
or or bulk Media or anything else they
can be cashed locally so users can
easily access them and download them
easily all right so that's Cloud front
now at this point after looking at all
four it looks like VPC is the right
answer and in fact VPC is the right
answer VPC has public IP address VPC can
help us with private IP address VPC can
be used to allow deny connection based
on the security group Access Control
list and routing table it has so that's
right answer is VPC all right how about
this one this platform as a service or
platform as a DB service provides us
with a cost efficient and resizable
capacity while automating time consuming
administrative task so this question is
very clear it's a service we got to look
for and it's a service that can provide
um automating some of the time consuming
task it has to be resizable at the same
time so let's talk about Amazon rational
database it's a database kind of matches
the requirement we can resize it as in
when needed all right looks like it's a
fit as of now it actually automates some
of the timec consuming work looks like
it's a fit as of now let's move on to
elastic C and then try to see if that
matches the definition that we've
figured out about elastic cache it's
actually a caching service it's again an
inmemory data store which helps in
achieving high throughput and low
latency in memory data stores so it's
not a fullblown database and it does not
come with um any Amazon provisioned
Automation in it for automating any of
the administration task no it does not
come up with anything like that yeah we
can resize the capacity as in when
needed but automation it's not there yet
and moreover it's not at database so
that's out of the equation VPC is not a
recess one you know once we have
designed VPC it's fixed it can't be
resized so that's out of the equation
and uh Amazon Glacier Glacier is a
storage but not a database right so
that's again out of the equation so the
tie is kind of between Amazon rational
database service and Amazon elastic
cache because they both Aid the database
service but elastic cash is not a
full-blown database it actually helps
the database but it's not a full-blown
database so it's Amazon relational
database so that's the one which is a
platform as a service it's the one which
can be resized it's the one which uh can
be used to automate the um time
consuming administrative tasks all right
let's talk about this one uh which of
the is a means for accessing human
researchers or Consultants to help solve
a problem on a contractual or temporary
basis all right let's read the question
again which of the following is a means
for accessing human researchers or
consultant to help solve problems on a
contractual or a temporary basis it's
like assigning task or hiring AWS
experts for a temporary job so let's try
to find that kind of service in the four
services that are listed Amazon elastic
map reduce map reduce is actually an
framework service that makes it easy and
cost effective to analyze large amount
of data but that has um nothing to do
with accessing human researchers all
right let's talk about mechanical it's a
web service that provides a a human
Workforce that's the definition for it
for example automation is good but not
everything can be automated for
something to qualify for automation it
has to be an repeative task one time
task can't be automated or the time and
money that you would be spending in
automation is not worth it instead you
could have done it manually so that does
not qualify for Automation and anything
that requires intelligence all right
anything that's a special case all right
automation can do repeative task
automation can do precise work but it
has to be repeative task the scenario
you know it should have been there
already only then that can be executed
but if it's a new scenario and it
requires uh appropriate addressing then
it requires human so we could hire
researchers and Consultants who can help
solve a problem using Amazon Mechanical
turque the other two are already out of
the equation now Dev pay is actually a
payment system through Amazon and
multiactor authentication as it says
it's an authentication system so the
right answer is Amazon Mechanical turque
all right this sounds interesting let's
look at this one this service is used to
make it easy to deploy manage and scale
containerized applications using
kubernetes on AWS which of the following
is this AWS service so it's a service to
deploy manage and scale containerized
application so it deals with containers
it also should have the ability to use
kubernetes which is an container
orchestration service all right the
first one Amazon elastic container
service kind of looks like it's the one
the name itself has the word and the
relation we're looking for elastic uh
container service so this container
service is an highly scalable high
performance container orchestration
service let's look at the other one AWS
batch it's a service that enables it
professionals to schedule and execute uh
batch processing I mean the name itself
says that that's meant for batch
processing elastic beant stock that's
another service that helps us to deploy
manage and scale but it helps us with
easy do instances not with cont terized
uh instances so that's again out of the
equation would light sale be a good tie
for elastic container service what's
light sale now light sale is a service
it's called as virtual private server
without a VPC it's called as a virtual
private uh server it comes with a
predefined uh compute storage networking
capacity it's actually a server not a
container right so at this point that
also comes out of the equation so it's
Amazon elastic container service that's
the one that helps us to easily deploy
manage scale container services and it
helps us orchestrate the containers
using kubernetes all right how about
this one all right this service lets us
to run code without provisioning or
managing servers so no servers run code
select the correct service from the
below option all right so no servers but
we should be able to run code Amazon
easy to autoscaling easy to auto scaling
ec2 is elastic compute Cloud which is a
server and Autos scaling is a service
that helps us to achieve scaling the
server so that's the definition for it
could be that's out of the equation aw
is Lambda now Lambda is a service it's
actually event driven serverless
Computing platform and Lambda runs code
in response to the event that it
receives and it automatically manages
the computer source that's required for
that code as long as we have uploaded a
code that's correct and set up events
correctly to map to that code it's going
to run seamlessly so that's about Lambda
it kind of looks like it could be the
answer because Lambda runs code we don't
have to manage servers it manages
servers by itself but we can't conclude
as of now we have other two service to
talk about AWS batch all right batch is
service that U enables ID professionals
to run batch job we know that and about
inspector Amazon inspector it's actually
actually a service that helps us to
increase and identify any security
issues and align our application with
compliance well that's not the
requirement in the question the
requirement in the question was run code
without provisioning a server and
without any more space for confusion A's
Lambda is a service or is the service
that runs code without provisioning and
managing Services right the right one
would be AWS Lambda all right let's get
started so in an environment where
there's lot of Automation in
infrastructure automation you'll be
posted with this question how can you
add an existing instance to a new
autoscaling group now this is when you
are taking an instance away from the
autoscaling group to uh troubleshoot uh
to fix a problem you know to look at
logs or if you have suspended the Autos
scaling you know you might need to read
add that instance to the Autos scaling
group only then it's going to take part
in it right only then the auto scaling
is going to count it as part of it it's
it's not a straight uh procedure you
know when you remove them you know it
doesn't get automatically readded and
I've had worked with some clients so
when their developers were managing
their own environment they had problems
adding the instance back to the Autos
Skilling group you know irr respective
of what they tried the instance was not
getting added to the Autos scaling group
and whatever they fixed that they were
provided or whatever fix that they have
provided were not you know getting
encountered in the autoscaling group so
like I said it's not a straight you know
a click button procedure there are ways
we'll have to do it so how can you add
an existing instance uh to the Autos
scaling group there are a few steps that
uh we need to follow so the first one
would be to under the ec2 instance
console right under the uh instance
under actions in specific you know
there's an option called attached to
Autos Skilling group right if you have
multiple autoscaling groups in your
account or in the region that you're
working in um then you going to be
posted with the different Autos scaling
groups that you have in your account
let's say you have five Autos scaling
groups for five different application
you know you're going to be posted with
five different Autos scaling uh groups
and then you would select uh the Autos
scaling the appropriate Autos scaling
group and attach the instance to that
particular Autos scaling group while
adding to the Autos scaling group if you
want to change the instance type you
know that's possible as well sometimes
uh when you want to add the instance
back to the aor Skilling group there
would be the requirement that you change
the instance type uh to a better one to
a better family to the better instance
type you could do that at that time and
after that you are or you have
completely added the instance back to
the Autos scaling group so it's actually
an seven step uh process adding an
instance back to the autoscaling group
in an environment where they're dealing
with migrating the instance or migrating
an application or migrating an instance
migrating an VM into the cloud you know
if the project that you're going to work
with deals with a lot of migrations uh
you could be posted this question what
are the factors you will consider while
migrating to Amazon web services the
first one is cost is it worth moving the
uh instance to the cloud given the
additional bills and visz features
available in the cloud is this
application going to use all of them is
moving into the cloud beneficial to the
application in the first place you know
beneficial to the users who will using
the application in the first place so
that's a factor to think of so this
actually includes know cost of the
infrastructure and the ability to match
the demand and Supply transparency is
this application and high demand you
know is it going to be a big loss if the
application becomes unavailable for some
time so there are a few things that
needs to be considered before we move
the application to the cloud and then if
uh the application does the application
needs to be provisioned immediately is
that an urge is there an urge to
provision the application immediately
that's something that needs to be
considered if the U application requires
to go online if the application needs to
hit the market immediately then we would
need to move it to the cloud because in
on premises procuring buying an
infrastructure buying the bandwidth
buying the switchboard you know buying
an instance you know buying the
softwares buying the license related to
it it's going to take time at least like
2 weeks or so before you can bring up an
server and launch an application in it
right so if the application cannot wait
you know waiting means uh you know
Workforce productivity loss is it so we
would want to immediately launch
instances and put application on top of
it in those case if your application is
of that type if there is a urge in
making the application go online as soon
as possible then that's a candidate for
moving to the cloud and if the
application or if uh the uh the software
or if the product that you're launching
it requires Hardware it requires an
updated Hardware all the time that's not
going to be possible in on premises we
we try to deal with Legacy uh
infrastructure all the time in on
premises but in the cloud they're
constantly upgrading their Hardwares
only then they can keep themselves UPG
going in the market so they constantly
the cloud providers are constantly
updating their Hardwares and if you want
to be benefited of your application
wants to be benefited by the constant
upgrading of the Hardwares making sure
the hardware is as latest as possible uh
the software version the licensing is as
latest as possible then that's a
candidate to be moved to the cloud and
if the application does not want to go
through any risk if the application is
very sensitive to failures if the
application is very much tagged to the
revenue of the company and you don't
want to take a chance in um you know
seeing the application fail and you know
seeing the revenue drop then that's a
candidate for moving to the cloud and
business agility you know moving to the
cloud at least half of the
responsibility is now taken care by the
provider in this case it's Amazon at
least half of the responsibility is
taken care by them like if the hardware
fails Amazon makes sure that they fixing
the hardware immediately and uh
notifications you know if something
happens you know there are immediate
notifications available that we can set
it up and make ourself aware that
something has broken and we can
immediately jump in and fix it so you
see there are the responsibility is now
being shared between Amazon and us so if
you want to get that benefit for your
application for your organization for
the product that you're launching then
uh it needs to be moved to the cloud so
you can get that benefit from the cloud
the other question you could get asked
is what is RTO and RPO in AWS they are
essentially Disaster Recovery terms when
you're planning for Disaster Recovery
you cannot avoid planning disaster
recovery without talking about RTO and
RPO now what's the RTO what's the RPO in
your environment or how do you define
RTO how do you define RPO or some
general questions that get asked RTO is
recovery time objective RTO stands for
the maximum time the company is willing
to wait for the recovery to happen or
for the recovery to finish when an
disaster strikes so RTO is u in the
future right how much time is is it
going to take to fix and bring
everything to normal so that's RP on the
other hand RPO is recovery Point
objective which is the maximum amount of
data laws your company is willing to
accept as measured in time RPO always
refers to the backups the number of
backups the uh the frequency of the
backups right because when an outage
happens you can always go back to the
latest backup right and if the latest
backup was before 12 12 hours you have
lost the in between 12 hours of uh data
data storage right so RPO is the
acceptable amount if the company wants U
Less RPO RPO is 1 R then you should be
planning on taking backups every 1 hour
if RPO is 12 hours then you should be
planning on uh taking backups every 12
hours so that's how RPO and RTO you know
helps Disaster Recovery the fourth
question you could get asked is if you
would like to transfer huge amount of
data which is the best option among
snowball snowball Edge and snowmobile
again this is a question that get asked
if the company is dealing with lot of
data transfer into the cloud or if the
company is dealing with the migrating
data into the cloud I'm I'm talking
about huge amount of data data in
petabytes snowball and all of the
snowball series deals with PAB but sized
data migrations so there are three
options available as of now AWS the
snowball is an data transport solution
for moving high volume of data into and
out of a specified AWS region on the
other hand AWS snowball Edge adds
additional Computing uh functions
snowball is simple storage and movement
of data and snowball Edge has a compute
function attached to it a snowmobile on
the other hand is an exabyte scale
migration service that allows us to
transfer data up to 100 petabytes that's
like 100,000 terabytes so depending on
the size of data that we want to
transfer from our data center to the
cloud we can hire we can rent any of
these three services let's talk about
some cloud formation questions this is a
classic question how is AWS cloud
formation different from AWS elastic
bean stock you know from the surface
they both look like the same you know
you don't go through the console
provisioning resources you don't you
know you don't go through CLI and
provision resources both of them
provision resources through click button
right but underneath they are actually
different Services they support they aid
different services so knowing that is
going to help you understand this
question a lot better let's talk about
the difference between them and this is
what you will be explaining to the
interviewer or the panelist so the cloud
formation the cloud formation service
helps you describe and provision all the
infrastructure resources in the cloud
environment on the other hand elastic
bean stock provides an simple
environment to which we can deploy and
run application cloud formation gives us
an infrastructure and elastic bean stock
gives us an small contained environment
in which we can run our application and
cloud formation supports uh the
infrastructure needs of many different
types of application like the Enterprise
application the Legacy applications and
any new modern application that uh you
want to have in the cloud on the other
hand the elastic beanock It's a
combination of developer tools they are
tools that helps manage the life cycle
of a single application so cloud
formation in short is managing the
infrastructure as a whole and elastic
bean stock in short is managing and
running an application in the cloud and
if the company that you're getting hired
is using uh cloud form
to manage their infrastructure using or
if they using infrastructure or any of
the infrastructure as a code uh Services
then you would definitely face this
question what are the elements of an AWS
cloud formation uh template so it has U
four or five basic elements right and
the template is in the form of Json or
in yaml format right so it has
parameters it has outputs it has data it
has resource es and then the U format or
the format version or the file format
version for the cloud formation template
so parameter is nothing but um it
actually lets you to specify the type of
E2 instance uh that you want the type of
RDS uh that you want all right so ec2 is
an umbrella RDS is an umbrella and
parameters within that ec2 and
parameters within that RS are the
specific details of the ec2 or the
specific details of the RDS service so
that's what parameters in a cloud
formation template and then the element
of the cloud formation template is
outputs for example if you want to
Output the name of an S3 bucket that was
created if you want to Output the name
of the ec2 instance if you want to
Output the name of some resources that
have been created instead of looking
into the template instead of you know
navigating through in the console and
finding the name of the resource we can
actually have them outputed uh in the
result section so you can simply go and
look at all the resources created
through the template in the output
section and that's what output values or
output does in the cloud formation
template and then we have resources
resources are nothing but what defines
what are the cloud components or Cloud
resources that will be created through
this cloud formation template now ec2 is
a resource RDS is a resource and S3 buck
ET is a a resource elastic load balancer
is a resource and Nat Gateway is a
resource VPC is a resource so you see
all these components are the resources
and the resource section in the cloud
formation defines what are the AWS Cloud
resources that will be created through
this cloud formation template and then
we have version version actually
identifies the capabilities of the
template you know we just need to make
sure that it is of the latest version
type and the latest version is um
0909 uh 2010 that's the latest version
number you'll be able to find that on
the top of the cloud formation template
and that version number defines the
capabilities of the cloud formation
template so just need to make sure that
it's the latest all the time still
talking about cloud formation uh this is
another classic question what happens
when one of the resource in a stack
cannot be created successfully well if
uh the resource in a stack cannot be
created the cloud formation
automatically rolls back and terminates
all the resources that was created using
the cloud formation template so whatever
resources that were created through the
cloud formation template from the
beginning let's say we have created like
10 resources and the 11th resource is
now failing cloud formation will roll
back and delete all the 10 resources
that were created previously and this is
very useful uh when the cloud formation
cannot you know go forward cloud
formation cannot create addition
additional resources because we have
reached the elastic IP limits elastic IP
limit per region is five right and if
you have already used five IPS and your
cloud formation is trying to buy three
more IPS you know we've hit the soft
limit till we fix that with Amazon cloud
formation will not be able to you know
launch additional you know resources and
additional IPS so it's going to cancel
and roll back everything that's true
with a missing ec2 Ami as well if and
Ami is included in the template and but
the Ami is not actually present then
cloud formation is going to search for
the Ami and because it's not present
it's going to roll back and delete all
the resources that it uh created so
that's what cloud formation doeses it
simply rolls back all the resources that
it created I mean if it sees a failure
it would simply roll back all the
resources that it created and this
feature actually simplifies the system
administration and layer Solutions built
on top of AWS cloud formation so at any
point we know that there are no orphan
resources in the in in our environment
you know because something did not work
or because there was an you know cloud
formation executed some there are no
orphan resources in our account at any
point we can be sure that if cloud
formation is launching a resource and if
it's going to fail and it's going to
come back and delete all the resources
it's created so there are no orphan
resources in our account now let's talk
about some questions in elastic Block
store again if the environment deals
with a lot of automation you could be
thrown this question how can you
automate easy to backup using EBS it's
actually a six-step process to automate
the ec2 backups we'll need to write a
script to automate the below steps uh
using AWS API and these are the steps
that should be uh found in the scripts
first to get the list of instances and
then and then the script that we are
writing should be able to connect to AWS
using the API and list the Amazon EBS
volumes that are attached locally to the
instance and then it needs to list the
snapshots of each volume make sure the
snapshots are uh present and it needs to
assign a retention period for the
snapshot because over time the snapshots
are going to be uh invalid right once
you have some 10 latest snapshots any
snapshot that you have taken before that
10 becomes invalid because you have
captured the latest and 10 snap snapshot
coverage is enough for you and then uh
the fifth point is to create a snapshot
of each volume create a new snapshot of
each volume and then delete the old
snapshot anytime a new snapshot gets
created the oldest snapshot in the list
needs to go away so we need to include
options we need to include scripts in
our script lines in our script that make
sure that it's deleting the older
snapshots which are older than the
retention period that we are mentioning
another question that you could see in
the interview beat written interview
beat online interview or beat and
telephonic or face toase interview is
what's the difference between EBS and
instant store let's talk about EBS first
EBS is kind of permanent storage the
data in it can be restored at a later
point when we save data in EBS the data
lives even after the lifetime of the ec2
instance for example we can stop the
instance and the data is still going to
be present in EBS we can move the EBS
from one instance to another instance
and the data is simply going to be
present there so ABS is kind of
permanent storage when compared to
instance on the other hand instance
store is temporary storage and that
storage is actually physically attached
uh to the host of The Machine EBS is an
external storage an instant store is
locally attached uh to the instance or
locally attached to the host of The
Machine we cannot detach an instant
store from one instance and attach it to
another but we can do that with EBS so
that's a big difference one is permanent
data and uh another one is uh EBS is
permanent instant store is U volatile
data and um instant store with instant
store we won't be able to detach the
storage and U attach it to another
instance and another feature of instance
store is data in an in instance store is
lost if the dis fails or the instance is
stopped or terminated so instance store
is only good for storing cash data if
you want to store permanent data then we
should think of using EBS and not
instant store while talking about
storage on the same lines this is
another classic question how can you
take backups of EFS like EBS and if you
can take backup how do you take that
backup the answer is yes we can take EFS
to EF backup solution EFS does not
support snapshot like EBS EFS does not
support snapshot snapshot is not an
option for EFS elastic file system right
we can only take backup from one EFS to
another EFS and this backup solution is
to recover from unintended changes or
deletions of the EFS and this can be
automated any data that we store in EFS
can be automatically replicated to
another EFS and once this EFS goes down
or gets deleted or data gets deleted or
you know the whole EFS is for some
reason interrupted or deleted we can
recover the data from we can use the
other EFS and bring the application to
consistency and to achieve this it's not
an one-step configuration it's a cycle
there are series of steps that's
involved before we can achieve uh EFS to
EFS uh backup the first thing is to sign
in to the AWS Management console and
under EFS or click on EFS to E FS
restore button from the services list
and from there we can use the region
selector in the uh console navigation
bar to select the actual region uh in
which we want to work on and from there
ensure that we have selected the right
template you know some of the templates
would be you know EFS to EFS backup
granular backups incremental uh backups
right so there are some templates the
kind of backups that you want to take do
you want to take granular do you want to
take increment
backups stuff like that and then create
a name to that solution the kind of
backup that we have created and finally
review all the configurations that you
have done and click on Save and from
that point onwards the data is going to
be copied and from that point onwards
any additional data that you put uh is
going to copy it and replicate it now
you have an EFS to EFS backup this is
another classic question in companies
which deals with u data management there
are easy options to create snapshots but
deleting snapshots is uh not always an
you know click button or an single step
configuration so you might be facing a
question like how do you autod delete
old snapshots and the procedure is like
this now as best practice we will take
snapshots of EBS volume to S3 all
snapshots get stored in S3 we know that
now and uh we can use AWS Ops automator
the auto automatically handle all
snapshots the Ops automator service it
allows us to create copy delete EBS
snapshots so there are cloud formation
templates available for AWS Ops
automator and this automator template
will scan the environment and it would
take snapshots it would you know copy
the snapshot from one region to another
region if you want I know if you're
setting up a Dr environment and not only
that based on the retention period that
we
create it's going to delete the
snapshots which are older than the
retention period so life or managing
snapshot is made a lot easier because of
this Ops automator cloud formation
template moving into questions and
elastic load balancer this again could
be an question in the interview what are
the different types of load balancers in
AWS and what's their use case what's the
difference between them and as of now as
we speak there are three types of load
balances which are available in AWS the
first one being application load
balancer just like the name says the
application load balancer works on the
application layer and deals with HTTP
and https request and uh it it also
supports part-based routing for example
uh simply learn.com SL some web page
simply learn.com SL another website so
it's going to direct the path based on
the slash value that you give in the URL
that's path based based uh routing so it
supports that and not only that it can
support a port based colon 8080 colon
8081 or colon 8090 you know based on
that Port also it can take routing
decision and that's what application
load balancer does on the other hand we
have Network load balancer and the
network load balancer makes routing
decisions at the transport level it's
faster because it has very less thing to
work on it works on Lower OSI layer it
works on a lower layer so it has very
less information to work with than
compared with application layer so
comparatively it's lot faster and it
handles millions of requests per second
and after the load balancer receives a
connection it selects a Target group for
the default rule using the flow hash
routing algorithm it does simple routing
all right it does not do path-based or
Port based routing it does simple
routing and because of it it's faster
and then we have classic load balancer
which is uh kind of expiring as we speak
Amazon is discouraging people using
classic load balancer but there are
companies which are still using classic
load balancer they are the ones were the
first one to step into Amazon when
classic load balancer was the first load
balancer or the only load balancer
available at that point so it supports
HTTP https uh TCP SSL protocol and it
has a fixed relationship between load
balancer port and the container Port so
initially we only had classic load
balancer and then um at after some point
Amazon said instead of having one load
balancer address all type of traffic
we're going to have two load balancers
called as the child from the classic two
load balancer and one is going to
specifically address the application
requirement and one is going to
specifically address the network
requirement and let's call it as
application load balancer and network
load balancer so that's how now we have
two different load balancers talking
about load balancer another classic
question could be what are the different
uses of the various load balancer in AWS
elastic load balancing there are three
types of load balancer we just spoke
about it application load balancer is
used if we need flexible application
management and TLS termination and
network load balancer if we require
Extreme Performance and the load
balancing should happen on based on
static IPS for the application and
classic load balancer is an old load
balancer which is for people who are
still running their environment from EC
to Classic Network now this is an older
version of VPC or this is what was
present before VPC was created ec2
classic network is what was present
before ec2 was created so they are the
three types and they are the use cases
of it let's talk about some of the
security related questions you would
face in the interview when talking about
security and firewall and AWS we cannot
avoid discussion talking about w web
application fire wall and you would
definitely see yourself in this
situation where you've been asked how
can you use a AWS wav in monitoring your
AWS applications wav or web application
firewall protects our web application
from common web exploits and wff helps
us control which traffic Source your
application should be allowed or block
which traffic from certain Source know
which source or which traffic from a
certain Source should be allowed or
blocked your application with WF we can
also create custom rules that blocks
common attack patterns you know if it is
a banking application it has a certain
type of attacks and if it is simple uh
data management data storage application
it has uh I mean content management
application it has a separate type of
attack So based on the application type
we can identify a pattern and create
rules that would actually block that
attack based on the rule that we create
and WF can be used for three cases you
know the first one is all all request
and then block all request and count all
request request for a new policy so it's
also an monitoring and Management
Service which actually counts all the
policies or counts all the requests that
matches a particular policy that we
create and some of the characteristics
we can mention in AWS W are the origin
IPS and the strings that appear in the
request we can allow block based on
Origin IP allow block based on strings
that appear in the request we can allow
block or count based on the origin
country length of the request yeah we
can block and count the presence of
malicious scripts uh in an connection
you know we can count the request
headers or we can allow block a certain
request header and we can count the
presence of a malicious SQL code in a
connection that we get and that want to
reach our application still talking
about security what are the different
AWS IM categories we can control using
AWS we can do the following one is
create and manage IM am users and once
the user database gets bigger and bigger
we can create and manage them in groups
and in IM uh we can use it to manage the
security credentials kind of setting the
complexity of the password you know
setting additional authentications you
know like MFA and uh you know rotating
the passwords know resetting the
password there are few things we could
do with IM am and finally we can create
policies that actually grants access to
aw services and uh resources another
question uh you will see is what are the
policies that you can set for your users
uh password so some of the policies that
we can set for the user password is the
minimum length or you know the
complexity of the password by at least
having one number or one special
characters in the password so that's one
and then the requirement of a specific
character types including you know
uppercase lower case number and
non-alphabetic characters so it becomes
very hard for somebody else to guess
what the password uh would be and and
try to hack them so we can set the
length of the password we can set the
complexity in the password and then we
can set an automatic expiration of the
password so after a certain time the
user is forced to create a new password
so the password is not still old and
easy to guess in the environment and we
can also set settings like the user
should contact the admin I mean when the
password is about to expire so you know
you can get a hold of how the user is
setting their password is it uh having
good complexity in it is it meeting
company standards or there are few
things that we can control and set for
the users when the users are setting or
recreating the password another question
that could be posted in an interview so
to understand your understanding of uh
IM is what's the difference between an
IM role and an IM user let's talk about
IM user let's start small and then go
big or let's start simple and then talk
about the complex one the IM user has a
permanent long-term credential and it's
used to interact directly with AWS
services and on the other hand IM role
is an IM entity that defines a set of
permissions for making AWS service
request so IM user is an permanent
credential and role are temporary
credentials and IM IM user has full
access to all all AWS IM functionalities
and with role trusted entities such as
IM users application or AWS Services uh
assume the role so when an IM user is
given an permission you know it sticks
within the IM user but with roles we can
give permissions to Applications we can
uh give permissions to users in the same
account in a different account the
corporate ID we can give permissions to
uh ec2 S3 RDS VPC and lot more role is
wide and IM user is uh is not so wide
you know it's very constrained only for
that IM user let's talk about manage
policies in AWS manage policies there
are two types you know customer managed
and Amazon managed so manage policies
are IM resources that Express
permissions using the I am policy
language and we can create policies edit
them manage them manage them separately
from the IM user group and roles which
they are attached to so they are
something that we can do to managed
policies if it is customer managed and
uh we can now update policy in one place
and the permissions automatically extend
to all the attached entries so I can
have like three services four Services
point to a particular policy and if I
edit that particular policy it's going
to reflect on those three or four
services so anything that I allow is
going to be allowed for those four
services is anything that I denied is
going to be denied for uh the four
Services imagine what would be without
the IM managed policy will have to go
and specifically allow deny on those
different instances four or five times
depending on the number of instances
that we have so like I said there are
two types of managed policies one is
managed by us which is customer managed
policies and then the other is managed
by AWS which is AWS managed policy this
question can you give an example of an
IM policy and a policy summary this is
actually to test how well worsed are you
with the AWS console the answer to that
question is look at the following policy
this policy is used to Grant access to
add update and delete objects from a
specific folder know in this case name
of the folder is uh example folder and
it's present in a bucket called example
bucket so this is an I am policy on the
other hand the policy summary is a list
of access level resource and condition
for each service defined in a policy so
IM IM policy is all about one particular
resource and the policy summary is all
about multiple resources with IM policy
it was only talking about S3 bucket and
one particular S3 bucket here it talks
about cloud formation template Cloud
watch logs ec2 elastic bean stock
Services summary summary of resources
and the permissions and policies
attached to them that's what policy
summary is all about another question
could be like this what's what's the use
case of IM am and how does IM am help
your business two important or primary
work of IM am is to help us manage IM am
users and their access it provides uh
secure access to multiple users uh to
their appropriate AWS resources so
that's one it does and the second thing
it does is manage access for Federated
users Federated users are non am users
and uh through am we can actually allow
and provide secured access to resources
in our AWS account to our employees
without the IM user now they could be
authenticated using the active directory
they could be authenticated using the
Facebook credential Google credential
Amazon credential and a couple of other
credentials third party uh identity
management right so we could actually
trust them and we could give them access
to our account uh based on the trust
relationship that we have built with the
other identity uh systems all right so
two things one is manage users and their
access uh for uh manage IM am user and
their access in our AWS environment and
second is manage access for Federated
users who are non am users and more
importantly IM am is a free service and
with that uh will only be charged for
the use of the resources not for the IM
username and password that we create all
right let's now talk about some of the
questions in uh Route 53 one classic
question that could be asked in an
interview is what is the difference
between latency based routing and geodns
or Geo based DNS routing now the geob
based DNS routing takes routing
decisions on the basis of the geographic
location of the request and on the other
hand the latency based routing utilizes
latency measurement ments between uh
networks and uh data centers now latency
based routing is used where you want to
give your customers the lowest latency
as possible so that's when we would use
latency based routing and on the other
hand geob based routing is uh when we
want to direct customers to different
websites based on the country they are
browsing from you know you could have uh
you know two different or three
different websites for the same URL you
know take Amazon the shopping website
for example when we go to
amazon.com from in the US it directs us
to the US web page where the products
are different the currency is different
right and the flag and and a couple of
other advertisements that shows up are
different and when we uh go to
amazon.com from India it gets directed
to the amazon.com Indian site where
again the currency the product and the
advertisements there they're all
different right so depending on the U uh
country they're trying to browse if you
want to direct customers to two or three
different websites we would use geob
based routing another use case of geob
based routing is if you have a
compliance that um you should handle all
the DNS requests or if you should handle
all the uh request you know from a
country within the country then you
would do geob based routing now you
wouldn't direct the customer to a server
which is in another country right you
would direct the customer to a server
which is very local to them that's
another use case of geob based routing
and like I said for latency based
routing the whole goal or aim is to
achieve minimum end user latency if you
are hired for the architect role and if
that requires working lot on the DNS
then you could be posted with this
question what is the difference between
domain and a hosted Zone a domain is
actually a collection of uh data
described being self-contained
administrative and Technical unit on the
internet all right so for example you
know simply learn.com is actually a
domain on the other hand hosted zone is
actually an container that holds
information about how you want to Route
traffic on the internet to a specific
domain for example lm. simply learn.com
is an hosted Zone whereas simply
learn.com is an domain so in other words
in hosted Zone you would see the domain
name plus and and a prefix uh to it LMS
is a prefix here FTP is a prefix mail.
simply learn.com is a prefix so that's
how you would see a prefix in hosted
zones another question uh from another
classic question from Route 53 would be
how does Amazon Route 53 provide High
availability and low latency the way
Amazon Route 53 provides High
availability and low latency is by
globally distributed DNS servers Amazon
is a global Service and they have DNS
Services globally any customer doing a
query from different parts of the world
they get to reach an DNS server which is
very local to them and that's how it
provides low latency now this is not
true with all the DNS providers there
are DNS providers who are very local uh
to a country who are very local to a
continent so they don't they generally
don't provide low latency service right
it's always high latency it's low
latency for local users but anybody
browsing from a different country or a
different continent it's going to be
high latency for them but that's not
again true with Amazon Amazon is a
globally distributed DNS provider it has
DNS servers globalwide and like I said
it has optimal locations it has got
Global servers or in other words it has
got servers around the globe different
parts in the globe and that's how they
are able to provide High availability
and uh because it's not running on just
one server but on many servers they
provide High availability and low
latency if the environment that you're
going to work on is going to take a lot
of uh configuration backups
environmental backups then you can
expect questions in AWS config a classic
question would be how does AWS config
work along with AWS cloud trail AWS
cloud trail actually records user API
activity on the account and um you know
any HTP htps access or any any sort of
aess you know that's made to the cloud
environment that's recorded in the cloud
trail in other words any API calls the
time is recorded the type of call is
recorded and what was the response given
was it a failure was it successful they
also get recorded in cloud trail it's
actually a log it actually records uh
the activity in your Cloud environment
on the other hand config is an point and
time configuration details of your
resources for example at a given point
what are all the resources that were
present in my environment what are all
the uh resources or what are the uh
configuration in those resources at a
given point they get captured in AWS
config all right so with that
information you can uh always answer the
question what did my AWS resource look
like at a given point in time that
question gets answered when we use AWS
config on the other hand with cloud
trail uh you can answer the question I
mean but looking at the cloud trail or
with the help of cloud trail you can
easily easily answer the question who
made an APA call to modify this resource
that's answered by cloud trail and with
the cloud trail we can detect if a
security group was incorrectly
configured and who did that
configuration let's say uh that happened
to be in downtime and you want to
identify let's say there happened to be
a downtime and you want to identify who
made uh that uh change in the
environment you can simply look at cloud
trail and find out who made the change
and if you want to look at how the
environment looked like before the
change you can always look at AWS config
can AWS configure or AWS config
aggregate data across different AWS
accounts uh yes it can now this question
is actually to test whether you have
used AWS config or not and know some of
the services are very local is it some
of these services are availability Zone
specific some of them are Regional
specific and some of them are uh Global
uh services in Amazon and though some of
the services are region Services you
still can do some changes you know add
some configuration to it and collect
Regional data in it for example S3 is a
regional service but still you can
collect logs from all of the regions
into an S3 bucket in one particular
region that's possible and cloud trail
is an Cloud watch is an regional service
but still you can with some changes to
it with with some adding permissions to
it you can always monitor the cloud
watch that belongs to Cloud watch logs
that belongs to other regions you know
they're not global by default but you
can do some changes and make it Global
similarly AWS config is a service that's
a region based service but still you can
make it act uh globally we can aggregate
uh data across different region and
different accounts in an AWS uh config
and deliver the updates uh from
different accounts to one S3 bucket and
can access it from there AWS config also
works or integrates seamlessly with SNS
topic so you know anytime there is a
change anytime the new data gets
collected you can always notify yourself
or notify a group of people about the
new log or the new config or new edit
that happened in the environment let's
look at some of the database questions
you know database should be running on
reserved instances so whether you know
that fact or not the interviewer wants
to understand how well you know that
fact by asking this question how are
reserved instances different from ond
demand uh DB instances Reserve instances
and On Demand instances are exactly the
same when it comes to their function but
they only defer based on how they are
built reserved instances are purchased
uh for one year or 3E reservation and in
return we get a very low uh per hour
pricing because we're paying up front
it's generally said that reserved
instance is 75% cheaper than on demand
instance and I'm Amazon gives you that
benefit because you know you're
committing for one year and sometimes
you're paying in advance for the whole
year on the other hand on demand
instances are built on an early early
price talking about Auto scaling how
will you understand the different types
of Auto scaling the interviewer might
ask this question which type of scaling
would you recommend for RDS and why
there are two types of scaling as you
would know now uh vertical and
horizontal and in vertical scaling we
can vertically scale the master database
with a couple of clicks all right so
that's vertical scaling vertical scaling
is keeping the same node and making it
uh bigger and bigger if previously it
was running on T2 micro now we would
like to run it on M3 two * large
instance previously it had one virtual
CPU 1 gbit now it's going to have8
Virtual CPU and 30 GB of RAM so that's
vertical scaling on the other hand
horizontal scaling is adding more nodes
to it previously it was running on 1 VM
now it's going to run on 2 3 10 VMS
right that's horizontal uh scaling so
database can only be scaled vertically
and there are 18 different types of
instances we can resize our RDS to right
so this is true for RS MySQL post SQL
Maria DB Oracle Microsoft SQL servers
there are 18 type of instances we can
vertically scale up to on the other hand
horizontal scaling are good for replicas
so they are readon replicas we're not
going to touch the master database we're
not going to touch the primary database
but I can do horizontal scaling only
with Amazon Aurora and I can add
additional read replicas I can add up to
15 uh read replicas for Amazon Aurora
and up to five read replicas for ads
MySQL postgress SQL and Marb RDS
instances and when we add replica we are
horizontal scaling adding more nodes
right read only nodes so that's
horizontal scaling so how do you really
decide between vertical and horizontal
scaling if you're looking into increase
the storage and the processing capacity
we'll have to do a vertical scaling if
you're looking at increasing the
performance or of the read heavy
database we need to be looking for
horizontal scaling or we need to be
implementing horizontal scaling in our
environment still talking about
databased this is another good question
you can expect in the interview what is
a maintenance window in Amazon RDS will
your DB instance be available during the
maintenance uh event right so this is
really to test how well you have
understood the SLA how well you have
understood the Amazon RS uh the failover
mechanism of Amazon RS uh stuff like
that so RS maintenance window it lets
you decide when a DB instance
modification a database engine upgrades
or software where patching has to occur
and you you actually get to decide
should it happen at 12: in the night or
should it happen at afternoon should it
happen early in the morning should it
happen in the evening you actually get
to decide an automatic scheduling by
Amazon is done only for patches that are
security and durability related
sometimes Amazon takes down and does
automatic scheduling uh if you know if
there is a need for a patch update that
deals with security and durability and
by default the uh maintenance window is
is for 30 minutes and the uh important
point is the DB instance will be
available during that event because
you're going to have primary and
secondary right so when that upgrade
happens Amazon would shift the
connection to the secondary do the
upgrade and then switch back to the
primary another classic question would
be what are the consistency models in
Dynamo DB in Dynamo DB there is eventual
consistency read this eventual consist
ency model it actually maximizes your
read throughput and the best part with
eventual consistency is all copies of
data reach uh consistency within a
second and sometimes when you write and
when you're you know trying to read
immediately chances that you you would
still be reading the old data that's
eventual consistency on the other hand
there is another consistency model
called the strong consistency or
strongly consistent read where there's
going to be a delay in writing the data
you know making sure the data is written
in all places but it guarantees one
thing that is once you have done a write
and then you're trying to do a read it's
going to make sure that it's going to
show you the updated data not the old
data and you can be guaranteed of it
that it is going to show the updated
data and not the old data that's
strongly consistent still talking about
uh database talking about no SQL uh
Dynamo DB or no SQL database which is uh
Dynamo DB in Amazon you could be asked
this question what kind of query
functionality does Dynam DB support
Dynamo DB supports get and put operation
Dynamo DB supports or Dynamo DB provides
flexible querying by letting you query
on non primary key attributes using
Global secondary index and local
secondary indexes a primary key can be
either a single attribute partition key
or a composite uh partition sort key in
other words a Dynamo DB indexes a
composite partition sort key as a
partition key element and a sortkey
element and by holding the partition key
you know when doing a search or when
doing a query by holding the partition
key element constant we can search
across the sort key element to retrive
the other items in that uh table and the
composite partition sort key should be a
combination of user ID partition and a
Tim stamp so that's what the composite
partition s key is made of let's look at
some of the multiple choice questions
you know sometimes some companies uh
would have an written test or an McQ
type online test before they call you
for the first level or before they call
you for the second level so these are
some classical questions that uh
companies asked or companies ask in
their multiple choice online questions
let's look at this question as a
developer using this payper you service
you can send store and receive re
messages between software components
which of the following is being referred
here let's look at it right we have AWS
step functions U Amazon mq Amazon simple
Q service Amazon simple notification
service let's read the question again as
a developer using this payper use
service so the service that we are
looking for is a pay-per service you can
send store and retrive messages between
two software components kind of like a
queue there so what would be the right
answer it would be Amazon simple Q
service now Amazon simple Q service is
the one that's used to decouple uh the
environment you know it breaks the tight
coupling and then it introduces
decoupling uh in that environment by
providing a queue or by inserting a
queue between two software components
let's look at this other question if you
would like to host a realtime audio and
video conferencing application on AWS
right it's an audio and video
conferencing application on AWS this
service provides you with a secure and
easy to use application while what is
this service let's look at the options
they are Amazon uh chime Amazon
workspace Amazon mq Amazon appstream
right you might tend to look at uh
Amazon appstream because it's real time
and video conference but it's actually
for a different purpose is actually
Amazon chime that lets you create chat
and create a chat board and then
collaborate with the security of the AWS
services so it lets you do the audio
it's it let you do the video conference
all supported by AWS security features
it's actually Amazon Chim let's look at
this question as your company's aw
solution architect you are in charge of
Designing thousands of individual jobs
which are similar which of the following
service best serves your requirement AWS
ec2 Autos scaling AWS snowball AWS uh
fargate AWS badge let's read the
question again as your company's AWS
solution architect you are in charge of
Designing thousands of individual jobs
which are similar it looks like uh it's
batch service let's look at the other
options as well a snowball is actually
an storage Transport service ec2 auto
scaling is U you know in introducing
scalability and elasticity in the
environment and AWS fargate is container
services AWS batch is the one is being
referred here that actually runs
thousands of individual jobs which are
similar AWS batch it's the right answer
right let's look at the other one you
are are a machine learning engineer and
you're looking for a service that helps
you build and train machine learning
models in AWS which among the following
are we referring to so we have Amazon
Sage maker AWS deep lens Amazon
comprehend AWS device Farm let's read
the question again you are a machine
learning engineer and you're looking for
a service that helps you build and train
machine learning models in AWS which
among the following are referred here
the answer is uh Sage maker it provides
um every developer and data scientist
with the ability to build train and
deploy machine learning models quickly
that's what Sage maker does now for you
to be familiar with um you know the the
products I would recommend you to you
know simply go through the um product
description you know there's one page
available in Amazon that explains all
the products uh quick neat and simple
and that really helps you to be very
familiar with you know what the product
is all about and what it is capable of
you know is it a DB service is it a
machine learning service or is it a
monitoring service is it a developer
service stuff like that so get that
information get that details before you
attend an interview and that should
really help to answer or phase such
questions with great confidence so the
answer is Amazon sagemaker because
that's the one that provides developers
and data scientists the ability to build
the train and deploy machine learning
models quickly as possible all right
let's look at this one let's say that uh
you are working for your company's ID
team and you are designated to adjust
the capacity of the AWS resource based
on the incoming application and network
traffic how do you do it so what's the
service that's actually uh helps us to
adjust the capacity of the AWS resource
based on the incoming application let's
look at it Amazon VPC Amazon am Amazon
inspector Amazon elastic load balancing
Amazon VPC is a network working service
Amazon IM am is an username password
authentication Amazon inspector is a
service that actually does security
audit in our environment and Amazon
elastic load balancer is a service that
helps in scalability that's in one way
you know indirectly that helps in yeah
increasing the availability of the
application right and monitoring it
monitoring you know how much requests
are coming in through the elastic load
balancer we can actually adjust the uh
environment that's running behind it so
the answer is going to be Amazon elastic
load balancer all right let's look at
this question this crossplatform video
game development engine that supports PC
Xbox PlayStation IOS and Android
platforms allows developers to build and
host their games on Amazon's uh servers
so we have uh Amazon gam lift Amazon
Greengrass Amazon Lumberyard Amazon uh
suiran let's read the question again
this crossplatform video game
development engine that supports PC Xbox
PlayStation IOS and Android platforms
allows developers to build and host
their games on Amazon servers the answer
is Amazon Lumberyard this Lumberyard is
an free AAA gaming engine deeply
integrated with AWS and uh twitch with
full source this lumber yard provides a
growing set of tools that helps you
create an highest game quality
applications and they connect to lot of
games and vast compute and storage in
the cloud so it's that service they are
referring to let's look at this question
you are the project manager of your
company's Cloud architect team you are
required to visualize understand and
manage your AWS cost and usage over time
which of the following service will be
the best fit for this we have AWS
budgets we have AWS cost Explorer we
have Amazon workmail we have Amazon
connect and the answer is going to be
cost Explorer now cost Explorer is an
option in the Amazon console that uh
helps you to visualize and understand
and even manage the AWS cost over time
who's spending more who's spending less
and what is the trend what is the
projected cost for the coming month all
these can be visualized in AWS cost
Explorer let's look at this question you
are a chief Cloud architect at your
company and how can you automatically
Monitor and adjust Computer Resources to
ensure maximum performance and efficien
icy of all scalable resources so we have
a cloud formation as a service we have
AWS Aurora as a solution we have AWS
Auto scaling and Amazon API Gateway
let's read the question again you're the
chief Cloud architect at your company
how can you automatically Monitor and
adjust Computer Resources how can you
automatically Monitor and adjust
Computer Resources to ensure maximum
performance and efficiency of all
scalable resources this is an easy
question to answer the answer is
autoscaling all right that's a basic
service and solution architect uh uh
course is it autoscaling is the service
that helps us to easily adjust Monitor
and ensure the maximum performance and
efficiency of all scalable resources it
does that by automatically scaling the
environment to handle the inputs let's
look at this question as a database
administrator you will use a service
that is used to set up and manage
databases such as MySQL marad DB and
postgress SQL which service are we refer
to Amazon Aurora Amazon elastic cache
AWS RDS AWS database migration service
Amazon aora is uh Amazon's flavor of U
the RDS service and elastic cache is um
is the caching service provided by
Amazon they are not full-fledged
database and database migration service
just like the name says it helps to
migrate uh the database from on premises
to the cloud and from one database
flavor to another database flavor Amazon
RDS is the service is the console is the
service is the umbrella service that
helps us to set up manage databases like
my SQL Marb and postris SQL it's Amazon
RTS let's look at this last question a
part of your marketing work requires you
to push messages to onto Google Facebook
Windows and Apple through apis or AWS
Management console you will use the
following service so the options are AWS
cloud trail AWS config and Amazon chime
AWS simple notification service all
right it says a part of your marketing
work requires you to push messages it's
dealing with pushing messages to Google
Facebook Windows and Apple through apis
or AWS Management console you will use
the following service it's simple
notification service simple notification
service is an message pushing uh service
sqs is pulling similarly SNS is pushing
right here it talks about a pushing
system that pushes messages to Google
Facebook Windows and Apple through API
and it's going to be a simple
notification system or simple
notification service hello everyone this
is Samuel and I'm very excited that
you're watching this video and I would
like to welcome you to this Azure
interview preparation session knowing
Azure is one thing having worked on
Azure is another thing and being able to
answer interview questions in Azure is a
totally different thing although one
helps the other it's still different
skills and our aim through this video is
to prepare you with common product and
scenario based interview questions so
why wait let's get started a common
Cloud interview question is what's the
difference between SAS pass and is we
all know that a software as a service is
Thin Client model of software
provisioning where client in this case
usually is simply a web browser
providing the point point of access to
softwares running on the servers now SAS
is the most familiar form of cloud
service for customers SAS moves the task
of managing software and its deployment
to thirdparty Services meaning the
vendor actually gets to manage all that
so uh SAS is software as a service
involving applications being consumed
and used by organization so it's
generally using an application and
usually organizations pay for their use
of this particular application now some
examples of SAS would include Office 365
Salesforce is another very good example
of SAS and a lot of uh Google Apps and
Storage Solutions like box and Dropbox
are a very good example of software as a
service talking about platform as a
service or pass it actually functions at
the lower level than SAS now typically
it provides a platform on which software
can be developed veloped and deployed
now here we develop the software we
deploy the software now Pas actually
provides an abstract of much of the work
dealing with servers and giving client
an environment in which the operating
system and the server software and the
Hardwares and the network are managed
and taken care in other words with a
platform as a service all the things
that I've mentioned like the servers the
server software the hardware everything
is managed by the provider and we can
focus on business side of the
scalability and we can focus on
application development of our product
or the service so in short platform as a
service is a service that enables
developers to build and work with
applications without even having to
worry about the infrastructure or
management of the underlying hosting
environments and some examples of pass
in Azure is SQL and Azure storage
talking about infrastructure as a
service I as now this is moving down the
stack even further now we get to the
fundamental building block of the cloud
service which is infrastructure as a
service I now I is fully of Highly
automated scalable Computer Resources
IAS is full of storage I is full of the
network capability that's what is is now
is clients have direct direct access to
the servers and storage just as they
would to do traditional servers but in
this case it's going to be in the cloud
in this case it's going to be more
scalable so I is very similar to what
you would do in your on premises
physical data center but when we talk
about IAS we get to do everything but
it's stored in the cloud so if we need
to build a definition around I I or
infrastructure as a service provides
users with components it provides
components it does not give us and built
environment it simply provides a
component such as operating system uh
networking capabilities and a lot more
now this is a paid for based on the
usage and can be used to host
applications in other words this is pay
as you go type the more you use the more
you pay the less you use the less you
pay and some of the examples of IAS in
Azure is virtual machine that's a great
example for IAS and v-ets for networking
that's another good example for Ias in
Azure another common question in Azure
interview is what are the instant types
offered by Azure the main intention of
this question is how well have you
understood the different offerings in
Azure and how well are you trained to
pick the right offering for the right
service now one size does not fit all
and there are there are a lot of
services in Azure that under the carpet
it does the same thing but depending on
how different your requirement is we'll
have to pick the appropriate service so
this actually this question what are the
different instant types offered by Azure
it's to test how well have you used the
product and services available in Azure
and how well have you applied them for
the given requirement you shouldn't be
provisioning more you shouldn't be
provisioning less at the same time so
it's kind of matching the right service
to the right requirement so what are the
instant types offered by Azure as you
see in the list we have general purpose
computer optimized memory optimized
storage optimized GPU virtual machines
and high performance compute virtual
machines now answering just the names
won't be enough in an interview you'll
have to go further and explain why and
in What scenario you would use general
purpose and what are the use cases what
type of servers is a good fit for a
general purpose and what type is a good
fit for computer optimized so on and so
forth and that's exactly what we're
going to do now so the general purpose
VMS you know they provide a balanced CPU
to me memory ratio and it's very good
for testing very good for development
environment very good for small and
medium databases and also for low to
medium traffic web servers and some of
the use cases are like we said test
servers low traffic web servers small to
medium databases some Enterprise grade
applications it's also good for
relational database it's also good for
uh servers used for inmemory caching
it's also good for some small analytic
uh database very good for microservices
and if you're trying to build a proof of
concept for an idea that you just have
or just parked uh this is another good
server for doing proof of Concepts
because you're not going to send actual
traffic to it I just want to show that
you know your idea works so general
purpose server is a very good use case
for those scenarios and the largest
instance size uh we can get in general
purpose is standard d64 V3 which comes
with 256 GB of memory and, 1600 GB of
SSD temporary storage on the other hand
computer optimized VMS have an a high
CPU to memory ratio and are very good
for medium traffic web servers very good
for batch processing servers very good
for application servers now because it's
compute optimized and compute means a
CPU it's an excellent choice for
workloads that demand faster CPU but
does not need as much memory or
temporary storage virtual CPU some of
the workloads that run very well on
computer optimized are analytic
workloads uh gaming servers require more
CPU they run really well uh batch
processing are some of the applications
that can be placed in computer optimized
and by doing that we get the actual
benefit of the computer optimized
instance and the largest instance size
or the largest instance size type is
standard F7 72s V2 and here we get 144
GB of memory and 576 GB of SSD temporary
storage in compute optimized VMS in the
same lines memory optimized VM they
offer High memory to CPU ratio and that
are great for databases databases
require more memory so it's a great fit
for database and uh it's a great fit for
medium to large scale caches
applications that require inmemory
analytics so this memory optimized
memories more so it's very good for
inmemory analytics applications and the
largest instant size we get here is
standard m128 M and look at the um gigb
of memory it's uh
3892 GB of memory and uh look at the uh
temporary storage it's
,00
336 GB of temporary storage on the same
lines storage optimized now I guess I
don't have to explain to you what
storage optimized is used for you might
have easily guessed looking at the flow
yes storage optimized Wim offer High
disk through put and IO and are very
ideal for Big Data uh SQL no SQL
databases data warehousing servers large
transactional databases and lot more and
some of the examples of the applications
that can be launched on store storage
optimized are Cassandra mongodb Cloud
redis these are some familiar
applications that can get benefited when
we run them on storage optimized and one
difference between storage optimized and
the other servers are they are generally
optimized to use the local disc on the
Node attached directly to the VM rather
than using an durable disc which is
actually an a remote uh disk space now
what does this allow this allows for
greater input outputs per second or
throughput for the workload so that's
what we get a greater throughput a
greater input outputs per second is what
we get when we use storage optimized and
the largest instant size available in
storage optimized is uh standard uh L
32s and uh uh the memory is 256 GB and
look at the temporary storage it's a
5630 GB of temporary storage GPU type
VMS easy to guess uh GPU optimized VMS
are specialized virtual machines
available with uh multiple gpus attached
to them now these sizes are designed for
or these VMS are designed for computer
intensive graphic intensive
visualization workflows that require lot
of um graphical Processing Unit attached
to it so in short uh these are virtual
machines that specialize in heavy
graphic rendering and video editing it
also helps with the model training and
interferences with the a standard nd24
RS which has uh 448 GB of memory and
2948 GB of temporary storage and the
last but not the least but the best last
but the best is high performance
computer or Azure H series virtual
machines now they are the latest in high
performance Computing VMS and are aimed
to handle workloads like batch
processing analytic molecular modeling
and fluid dynamics lot of complicated
applications in this uh VM and this is
the fastest and Powerful CPU virtual
machine with the optional High
throughput interfaces and the largest
instance size that's available is
standard L 32s which comes with 224 GB
of memory and 20000 GB of SSD temporary
storage and a third common question is
what are the deployment ment
environments offered by Azure there are
two main deployment environments one is
the staging environment and the other
one is the production environment now in
staging environment let's talk about
staging first so when you're are
deploying a web app or web app on Linux
you can deploy them to a separate slot
instead of the default production slot
when running them in standard premium or
isolated app service plan tiers now the
deployment slots are actually actually
live app with their own host name and at
a later point the staging environment
can be swapped with the production
environment so why do we need an staging
environment what are the benefit of it
so the benefit of deploying our
application to a nonproduction or
staging environment it provides a
platform to validate changes to our
application before it can be made live
in the production environment and in the
staging environment the app can be
identified using the azures global
unique identifier also called as the
guid URL and it's very very similar to
the production URL except that it has an
custom name in front of it that
identifies it as the staging environment
and for production environment uh this
is the live uh production environment
that's serving customers's request
that's serving the customer content now
it can be slightly different from the
staging environment in a way that the
URL that's used to identify the
production environment that's more of an
DNS friendly name like the name of the
actual service. Cloud
app.net that way it differs in case of
staging environment you have an custom
name right before it so the custom name
and then the cloud app.net but in this
case you get the uh direct service name
as the name of the URL so this is live
production environment which receives
and handles and serves customer traffic
another commonly asked question in Azure
is what are the advantages of scaling in
Azure the actual thought behind the
question is to see how much have you
understood scaling how much have you
seen and how much have you applied the
scaling effect in the production
environment and have received benefits
in return so let's talk about it
advantages of scaling in Azure some of
the advantages are we get the maximum
application performance now autoscaling
is a built-in feature for the cloud
services be it AWS Azure Google and a
couple of other cloud service providers
it's a built-in feature for a cloud
service a cloud service should be Autos
scalable and that includes mobile
services virtual machines and um when we
run our applications uh on mobile
services or virtual machines the website
actually gets the best performance uh
during the change in the demand again a
different applications uh might require
different uh performance needs for
example for some apps the performance
measured based on memory and another
good example is the fluctuating demand
for example you could have a web app
that handles millions of requests during
the day and literally nothing at the
night and Autos scaling this environment
Autos scaling any of these environment
will automatically scale or fatten your
environment so to receive the all the
incoming traffic and during lean period
it actually actually get Slimmer and
Slimmer uh so to help you with the cost
so it actually maximizes uh the
performance that's what autos scaling
does and like we said Auto scaling
scales up and scales Down based on
demand it not only scales up but also
scales down so to help you with the cost
and if you know the particular pattern
in which the application is going to
receive uh traffic then we can very well
go ahead and schedule scaling to our
application or schedule scaling that
infrastructure based on time if we
already know that Monday to Friday
that's the traffic uh that I would get
and it's a constant one it's not a
public facing but you know it's an
internal application so I know all the
500 users or the Thousand or the 5,000
users who will be using it so at any
given point it's just 5,000 users it's
not going to go beyond that and during
Saturday and Sunday literally nobody's
going to be in office so no load at all
so uh in that case I pretty much know
how the pattern is going to be I can go
for schedules scaling if I know the
pattern and Autos scaling like I said
not only helps with keeping the
application highly available it also
helps with the cost effectiveness of our
infrastructure so anytime there's a VM
or a group of VMS running on less CPU
autoscaling is going to actually get the
environment Slimmer and Slimmer so we're
not unnecessarily running any resources
and paying for it if you're being
interviewed for the infra site in Azure
this is another common question that
gets asked how are Windows Active
Directory and Azure active directory
different let's talk about the Windows
Active Directory first the non-cloud
Windows Active Directory was the service
was released along with Windows 2000
server Edition and this active directory
is essentially a database that helps
organizations to organize the users
organize the computers and a lot more it
provides authentication and
authorization to the applications not
only to the application but also to file
servers to printers and a lot of other
on premises resources that's what the
basic non-cloud active directory does on
the other hand the Azure active
directory is not designed to manage
web-based services the Azure active
directory on the other hand was designed
to support webbased services that use
rest API interfaces for Office 365
salesforce.com Etc unlike the plain
active Direct Dory this uses an
completely different protocol so
protocol wise it's different and the
services that it support is quite
different now besides that it also has
couple of other differences as well and
let's look at them so the actual active
directory or the windows actual
directory is a directory service that
facilitates working with interconnected
complex and different network resources
in a very unified manner on the other
hand Azure active directory is
Microsoft's multi-tenant cloud-based
directory and identity management
service and the Windows Active Directory
has five layers to store data to store
user details and to issue the management
certifications on the other hand Azure
active directory integrates or
compresses the five layers into just two
layers here Windows Active Directory
works with on premises servers like
applications file servers and printers
Etc on the other hand Azure active
directory it uh works on web- Based
Services that use restful interfaces if
you're being hired for the development
environment or for the cloud devops
support environment or even for the
production support environment you might
find yourself being asked this question
what are the types of cues offered by
Azure now Azure supports two types of
queue mechanisms the storage queue and
the service bus queue Let's Talk About
Storage queue first now the storage
queue which are part of Azure storage
infrastructure it provides a simple rest
based uh interface simple rest based get
put and Peak interface it provides
reliable persistent messaging within and
between the services it follows the pub
sub model or Pub sub messaging
infrastructure and it's best suited for
users that need to store more than 80 GB
of messages in the cube it can provide
logs for all the transactions executed
against the users Q so that's what we
get with storage que and on the other
hand service bus queue the service bus
cues are built on top of broader
messaging infrastructure and they are
designed to integrate applications an
applications component that can span
multiple communication protocol so that
way it differs so this is good for
applications and components that may
span multiple communication protocols
and even different totally different
network environments so in short these
service buses or the service bus cues in
Azure are part of azure's messaging
infrastructure and they integrate
applications or application components
that can actually span multiple
different protocols and multiple
different network environments it also
provides an first and first out style
for delivery and the user's Q size has
to remain under 80 gbit another familiar
question is what are the advantages of
azure resource manager now the resource
manager helps us to manage the usage of
the application resources this question
is actually to test how well have you
tested how well have you used resource
manager and have gotten the benefit of
it this question actually tests how easy
it has become after the introduction of
resource manager compared to uh when
doing deployments or when provisioning
resources without the resource manager
so let's get into the answers for the
question what are the advantages of
azure resource manager the insur
resource manager is called a armm so the
armm helps deploy manage and monitor all
the resources for an application a
solution or a group so all the
interconnected application all the
interconnected Services can be monitored
as group using resource manager and uh a
users can be granted to access to
resources that they require within a
resource manager so in an account I can
have like 10 different resources created
by resource manager or a resource Group
created by resource managers and I can
allow deny connection to those services
or only to those Services based on
whether the user should be accessing one
and not accessing the other so that way
it becomes easy to give access to a
group of application it helps in getting
U billing details for the group of
resources now which group is using more
which group is using less and which
group has contributed more to this
month's bill stuff like that so those
details can be obtained using Azure zour
manager and provisioning resources is
made much easier
with the help of this resource manager
another question is how has integrating
hybrid Cloud been useful for Azure well
with the use of hybrid Cloud we get the
best of both the worlds so what's hybrid
Cloud it's nothing but combining the
public cloud and the private cloud and
allowing data and applications to be
shared uh between them so whenever the
compute or the processing demand
fluctuates hybrid cloud computing gives
businesses the ability to seamlessly
scale their on premises infrastructure
in the public cloud and handle any kind
of uh uh overflow in the requirement or
overflow in handling the application so
it really helps it helps it boost the
productivity of our on premises
application so with the hybrid uh Cloud
we get a greater efficiency with
combination of azure Services uh devops
processes and tools for the application
running in on premises and by having an
hybrid Cloud en onment users can take
advantage of a constantly updated Azure
service and other AWS Marketplace um
applications for their on premises
environment and the other benefit is uh
with hybrid Cloud environment we can
simply deploy applications regardless of
its locations in case of on premises
we'll have to worry about the location
but when we expand our on premises
environment in the cloud they can or we
can pick any of the locations and simply
deploy it in them and this enabl the
applications to be created at a greater
speed what's federating in Azure SQL now
this question is very specific about SQL
how can we scale the SQL database now
this is a very good question or a valid
question or an important question in the
interview because many customers or
companies have not been able to meet the
user demand because they could not scale
out uh the databases uh the theory of
scaling out or adding servers to
accommodate the The increased workflows
and traffic is not hard to understand
but uh the implications can be very
complicated the implications can be very
expensive we're well aware of scaling
the web servers that's very common but
how do we scale the database so
Microsoft provides the tools and
Technologies so we can scale out the
database in the cloud and that's what is
called SQL or Federation in Azure SQL so
the way we scale out the SQL database is
by shing shing the database so Shing
actually enables users to take
advantages of the resources in the cloud
not only that it allows users to have
their own database or shared database
amongst each other because we're
creating an highly available database
because we're having shards in a
database it actually reduces the
possibility of a single point of failure
for our database and more importantly
because we're sharting uh because we're
using Federation and azure SQL it
provides an cost effective scaling of
our databases by using Cloud resources
or by using billing only for the cloud
resources that we have used so no
pre-provisioning no over-provisioning it
Provisions the right amount and we pay
the right amount let's talk about this
one what are the different types of
storage offered by Azure now the
different types of storage offered by
Azure are as you already know and as you
can see they are Azure blob storages
table storages file storage and Q
storage so let's expand one after the
other now blob storage are nothing but a
massive scalable object storage and
that's very good for storing text and
binary data and Azure blob storage is U
Microsoft's object storage solution for
the cloud and blob storage is optimized
for storing massive massive amount of
unstructured data that can be in form of
text or or in form of binary data so in
short blob storage enables users to
store unstructured data and those data
can be in the format of pictures music
video files and lot more and it stores
them along with their metadata and
another advantage or another feature
benefit that we get from blob storage is
when object is changed it is verified to
ensure it is of the latest version
number one and number two it provides
maximum flexibility to optimize the
users's storage needs and this
unstructured data is available to
customers through an URL or an rest
based object storage so they are the
benefits that come along with The Blob
storage table storage on the other hand
is an a nosql store for schema Less
storage of secured data now this Azure
table storage is a service that stores
structured no SQL data in the cloud and
because this table is a schema less it's
very easy to save your data it's very
easy to adapt your uh data as the need
for your application grows and this
table storage is very fast and cost
effective for many type of applications
so some of the some of the type of data
that we can store is U table storage is
good for flexible databases like user
data for web applications address book
storage device information storage and
if you want to store metadata this is a
very good use case to store them in
Azure table storage Azure files is
another storage uh here it's an managed
file share for cloud or on premises uh
deployment so file storage provides file
sharing capabilities accessible by the
server messaging block protocol and this
can be accessed from the cloud and this
can be accessed from on premises as well
uh here in file storage the data is
protected by SMB uh 3.0 and https uh
protocols and the more important thing
is azure takes care of managing hardware
and the operating system deployments for
aure file storage so this additional
file storage can be used uh when we want
to burst the storage capacity in on
premises so on premises the primary and
cloud is the secondary or the extended
on premises storage so it actually
improves the on premises performance and
capabilities for our on premises Data
Center and then we have qes Azure cues
it's a messaging store for Reliable
messaging between the application
components we spoke a little about this
uh in the previous question so the Azure
Q storage is a service for storing a
large amount of messages that can be
accessed from anywhere in the world via
HTTP or htps uh protocol in here the uh
a single message can be up to 64
kilobits in size and in a queue we can
have millions of messages and the limit
can actually go up if we have not
reached the limit of the storage account
so it's m millions and millions of
requests that can be stored in the
storage que or the Q storage so the Q
storage in short provides message
queuing for large workloads and it
enables users to build flexible
applications and separate the functions
one from another so one failing doesn't
affect the other application which is
running healthy and this Q storage it
ensures the application is scalable and
less prone to individual component uh
failures because they are decoupled
separate now it also helps in monitoring
the queue which ensures the customers
demands are met so Q is a great place to
monitor or a great component to monitor
so we understand how much a peak can be
reached for a particular application
service or a container what is text
analysis API in Azure machine learning
now a text analysis is actually an
cloudbased analytics API and it provides
an advanced natural language processing
over the raw text and it has got uh four
main functions like the sentiment
analysis or and the keyphrase analysis
language uh deduction and and a few
other things now what do you mean by
sentiment analysis now sentiment
analysis is from the logs from the
comments from the text commments that we
receive do an analysis and find out
whether that an positive or an negative
statement now if it is a the API the API
returns and sentiment score between 0
and 1 and one is positive and 0er is
negative and then in text analysis we
have a key phrase extraction which is it
will automatically extract the key
phrase to uh quickly identify the main
points in that uh key phrase for example
if you're analyzing an text which says
the food was delicious and there were
wonderful stuff then the API Returns the
main talking points of that phrase like
food food is the main talking point and
wonderful staffs that was a main talking
point so that's another feature that
this uh text analysis has and then we
have language deduction in text analysis
right IR respective of what you paste it
can try to gauge and try to align it to
the 120 or up to 120 languages that it
supports so I can simply take text from
the internet and I can paste it and text
analysis software is going to identify
the language and then can run phrase and
sentiment analysis on those text right
so in short text analysis is an API a
set of web services that can be used for
text analysis it can be used to analyze
unstructured statement sentiment
analysis key phrase extraction and lot
more and the results are generally
between zero and one and one being
positive and zero being the negative
sentiment there is no much training or
another words this is not as complicated
as couple of other text analysis
softwares are available in the market we
can simply paste we can simply upload
the text and we can call the service and
it runs a sentiment analysis on it all
by itself let's look at this question
what are the advantages of azure Q
storage if you're going to work in a
development environment if you're going
to work in an environment that Embraces
devops this could be a question what are
the advantages of azure Q storage now
Azure Q storage is built to flexibly
operate the applications and separate
the functions between the applications
that run large workloads so when we
design applications for scale these
applications can be decoupled so that
they can scale independently you know a
thing happening on an application is not
dependent on another application and
anything happens to an section of the
application will not affect the other
application because they are now DEC
pulled and connected through the Q
storage so the Q storage gives us
asynchronous message queuing for
communication between the applications
irrespective of whether they are running
in the cloud or whether they are running
in desktop or whether they are running
on premises or on mobile devices so in
short this Q storage enables message
queuing for large workloads in a simple
and cost effective and a durable manner
talking about the advantages advantages
is it provides Rich client libraries for
Java Android C++ PHP Ruby and lot other
services getting added during every new
release from Azure and the main
advantage again is it enables users to
build flexible apps and uh separate the
functions for bigger or greater
durability again introduction of cues
into our application it ensures our
users applications are scalable and less
prone to individual component failures
meaning one component failing is not
going to take the whole application down
right if one component fails it's just
that component that stays fails the rest
are healthy and the rest are going to
function it also helps us to monitor the
cues and ensure the servers are
overhelmed by sudden traffic burst so
how much do I have in the queue kind of
determines the traffic for my
application and if the queue is more I
can always go and Auto scale my
environment and the queue is less I can
always go and Shrink or make my
environment thinner so it can save cost
and any time there is more data in the
queue I can Auto scale monitor the
metric and do autoscaling based on that
metric so the environment knows that
there are more datas coming in I need to
expand myself to handle that much amount
of data this is a very common question
what are the two kinds of azure web
service roles now a service Ro is a set
of managed and load balance bed virtual
machines that work to perform some task
and based on what it's going to run on
top of it is it going to run web service
or is it going to run worker service
defines what kind of roles that gets
attached or that goes on this virtual
machines so we have two types web Ro and
worker roles the web roll is a cloud
service role that's configured to run
web applications developed on
programming languages Technologies and
majorly they support I s internet
information service and they support
asp.net PHP uh Windows communication
foundation and so on so that's web roles
and these web roles it automatically
deploys and hosts application through
the users IIs internet uh information
service on the other hand worker roles
are roles that uh runs applications and
service level tasks which generally do
not require IAS so I is actually the
differentiate Shing Factor so in worker
roles is is not installed by default the
worker roles are mainly used to perform
supporting background process along with
web roles and do tasks automatically
compressing or uploading the images
running scripts and um or doing some
changes in the database getting new
messages from the Q and processing and a
lot more you know the work the
applications are the work that does not
require IAS that's what this worker Ro
does again the main difference between
the web Ro and the worker Ro is that the
web rooll automatically deploys and
hosts your application through is
whereas the worker role does not use IAS
and runs our application as Standalone
this is another classic question what is
azure service fabric so Azure service
fabric is actually a distributed system
platform that makes it easy to pack
deploy and manage a scalable and
reliable microservices and containers
now service fabric also addresses some
of the significant challenges in
developing and managing Cloud native
applications and the problem that IT
addresses and fixes is now developers
and administrators can avoid complex
infrastructure problems and focus on
implementing Mission critical and
demanding workloads that can be scaled
and that can be managed through the
console or from the single place in
short service fabric provides a platform
that makes the process of developing
microservices and managing application
life cycle lot easier and the advantages
of service fabric is that now we can
produce application with faster time to
Market because all the worry about the
infrastructure is taken away from us we
don't have to design an infrastructure
all that we need to worry about is
simply the application and the
application life cycle again the
advantage is it supports uh Windows it
supports Linux not only that it supports
servers on premises and in the cloud
with service fabric we can
scale up our environment to even
thousand machines in just a single
command or if there is a immediate need
for th000 machines I can immediately
scale them up 2,000 machines that's
possible with service fabric now let's
look at this question you can expect
this question if the customer is running
hybrid environment meaning having some
of the applications in on premises and
running some of the applications from
the cloud and for some reason when
classifying the application that goes to
the cloud and that stays on premises
they have decided to keep the database
inhouse so in that environment a lot of
customers do that so in that environment
this is a classic and a scenario based
question a client wants the front end of
their application to be hosted on Azure
in the cloud and wants the database to
be hosted in on premises for security
reasons or to have full control on their
databases how do we go about suggesting
a solution for this customer the ideal
solution in this scenario is to use um
the v-net based point to site VPN
solution so all the front end
applications will be in the cloud and
they'll be hosted in a vet and from the
wiet they'll be connecting to the
database through an point to site VPN so
the traffic and the writings and the
reads are not coming through the
internet but through a point to site VPN
link that's connecting the Azure vet and
the on premises environment and this uh
model or this approach or this solution
is best suited for SC arios where there
are only a limited number of resource
that needs to be connected between on
premises and the cloud this is a very
common question what's Azure traffic
manager of course we no more running
applications on a single server we no
more running applications on or or from
a single environment the same
application is being run from multiple
environments within Azure and it can be
running from Azure and on premise as
well so multiple environments between
Azure and on premises and a lot of
customers have such environment and if
you're facing an interview with such
customer this could be an ideal question
what is azure traffic manager now the
Azure traffic manager is a dns-based
traffic load balancer that actually
enables us to distribute traffic between
Services across Azure Global regions and
by doing this it provides a good
availability and a good responsiveness
to the application and this traffic
manager it uses DNS to direct client
requests to the most appropriate service
endpoint based on the traffic routing
logic and the health of the end points
that it maintains so in short this
traffic manager is a load balancer that
enables users to provide high avability
and responsiveness by Distributing
traffic in an optimal manner across the
Azure when we run the same application
in different regions so some of the
advantages or some of the use cases of
using Azure traffic manager is it
provides U multiple automatic failover
options it also helps with reduced
downtime it also helps with distribution
of user traffic across multiple
locations so one location is not
overloaded and then it helps with the
users knowing from where our customers
are getting connected from that's
another big use case with Azure traffic
manager let's look at this question
right this is an ideal question now
there are group of servers connected
together within an virtual uh Network
and now we need to move them or create a
separation between them how do you go
about achieving it so the question goes
like this you need to isolate Network
traffic among VMS in a subnet which is
part of a virtual network with little
downtime and impact on the user so
that's the given scenario and the best
way we can uh do it is create a new
virtual Network and move all the VMS in
that subnet to the new virtual Network
now this feature is not possible with a
lot of other cloud service providers
like AWS and a lot of other providers
now in those environments we might need
to shut down we might need to stop the
VM create a new VM based on the image
and it's an Hefty process but here in
Azure I can simply move the VMS from one
subnet to another virtual Network
without needing for any additional
security like the network security group
I can simply isolate them if I need to
by creating a simple new virtual Network
and moving the servers to the new
virtual Network look at this one this is
another common question with respect to
Azure what is public private and hybrid
Cloud so this is really to test how well
have you understood the different Cloud
offerings in the market public private
and hybrid or at least the three basic
offerings in the market public private
and hybrid Cloud now the public cloud is
the most common way of deploying Cloud
uh Computing applications and uh it has
resources like servers storage and are
owned and operated by third party cloud
service providers like Microsoft Azure
Microsoft Azure is a very good example
of public Cloud so here every component
that the user is using is running only
on Azure that's public Cloud right let
me talk to you about some of the
advantages of public Cloud some of the
advantages is low cost because there's
no need to purchase Hardware or software
and we pay only for the services that we
use in public cloud and there is
literally no maintenance because uh the
service provider maintains the
environment for us and uh with public
Cloud we have nearly unlimited
scalability meaning we can get resources
on demand and can meet our business
requirements on demand and the public
clouds are very highly uh reliable
because uh they have a vast network of
servers and they ensure that uh our
application does not fail so there are
some advantages of public Club let's
talk about private Cloud now private
Cloud uh consists of computer resources
used extensively by one business or one
organization now this private Cloud can
be physically located at our
organizations on-site data center or it
can be hosted by a third-party service
provider whichever the case the private
cloud services and infrastructure are
always maintained on a private Network
and they maintained on hardware and
software that are dedicated solely for
one organization or solely for your
organization so in short private cloud
in Azure is azure Services being run
within an on premises data center or on
premises Data Center used by the user to
host systems or applications and some of
the advantages some of the advantages is
it gives more security resources are not
shared with others so higher level of
control and security over our resource
and application is possible and then
then we have hybrid Cloud now hybrid
cloud is the best of both worlds so it
combines the features of both public and
private cloud and some of the user
components are being run on Azure and
others within on premises data center so
they kind of share the resources in
other words they kind of share the
application half of the application
would be running in on premises and half
of them would be in the cloud and they
will be working in harmony to support
the application and the business need so
that's hybrid Cloud this is one another
good example question that wants to test
how well you pick services or how well
have you understood a your uh products
and services and are picking the right
service for the need so the question
would go like this what kind of storage
is best suited to handle unstructured
data there are a lot of storage options
available and the requirement here is
what or which one would you choose for
unstructured data the answer for that
question is blob storage because blob
storage is designed to support
unstructured data it works in this way
it places the data into different tiers
based on how often they are accessed
different tier means different
performance different performance means
different cost associated with it so a
lot of add-on advantages will we get
when we use blob storage for
unstructured data in addition to it any
type of unstructured data can be stored
in Blob storage this is not true with
couple of other storage options that we
have in Azure only with blob storage we
can uh store any type of unstructured
data and the data Integrity is
maintained every time an object is
changed in the blob storage and the best
part is the blob storage helps increase
applications performance and reduces the
bandwidth consumption and reduces the
bandwidth consumption for that
application so they are the benefits
that we get for blob storage and blob
storage are the ones that are well
suited for unstructured data and that's
what your answer should be it's really
an five-step process and if you have
worked and if we have done some Labs
some basic Labs with Azure you can
easily answer this question so it's a
five-step process first step is to log
into the Azure the second one is to
create an uh resource resource or a
resource manager and within the resource
manager you would be selecting the
resource and then pick the U operating
system do you want windows or Linux and
within Windows what's the flavor you
want or within Linux what's the flavor
you want so decide on it and then U
entering the relevant information
relevant information like the U uh name
of the uh instance or the VM that we're
going to launch and the password uh the
URL that goes with it and couple of
other relevant information that goes
gets itself attached with the VM and
then select the size of the virtual
machine different size different uh uh
types available for the kind of
application and for the intensity of the
application that will be running on top
of it so select the virtual select the
size of the virtual machine review
everything whether they're good or not
if there are any changes required go
back and edit them and then come back
and launch and your VM is there for you
to start working within like 3 or 4
minutes not even 5 minutes within 3 or 4
minutes it gets ready and you can start
working on it so it's a quick and it's a
fstep process and you should be able to
answer it easily if you have done a few
labs in Azure let's now look at some
scenario based question you've been
posted with a scenario so we thought
through it and picked some common
scenario based question that are being
asked in interview and I thought we'll
present it for you with answers with
explanation so you can get benefited
through it so let's look at this
question you're asked to make sure your
virtual machines are able to communicate
securely with each other to ensure
security or to have good amount of
security what would you do and the
correct and the best answer for this
would be using virtual Network in Azure
which enables us to communicate with the
internet securely which enables us to
communicate with the on premises data
center in a secure fashion so the
advantage of using virtual uh network is
users can create their own private
Network users can pick their own private
IP ranges users can create their own
subnet users can create their own
routing between those two subnets a lot
more goes into that virtual Network so
it it's very customizable and the users
are provided with an isolated and highly
secure environment for applications it's
completely isolated from other customers
it's completely isolated from other
applications that are running in other
virtual Network that we own So within
our account we can have multiple virtual
networks and one application running on
a virtual machine is completely isolated
from other applications running on other
virtual machines and uh of course all
traffic stays within the Azure Network
Azure virtual machine or within the
azure Network depending on how you set
up the routing if you have set up
routing to go or reach the Internet it's
going to go otherwise it's going to stay
within Azure if you have set up routing
to reach on premises then it's going to
go and reach on premises otherwise it's
not going to go and reach on premises
it's going to stay within the Azure and
it also allows users to design their own
network like we already discussed
picking up IPS picking routing you know
picking subnets you know how many
servers should be present in that
particular subnet or how many servers
should that subnet accommodate the size
of the subnet the IP ranges the nting
the masking of ips creating of VPN all
that's possible with the virtual Network
so it really allows users to design
their own network and using virtual
machine is how we secure applications in
the cloud let's look at this other
scenario how do you ensure that every
time a user logs in they are not asked
to re-enter the password as as part of
authentication so you really don't want
your users to re-enter the password
every time they log in to a different
application well all the applications
have their authentication mechanism in
place all of them wants to authenticate
the user before they login ensuring the
user does not log in every time does not
mean that wiping away all the
authentication and authorization that's
present in that application you still
need that in place but how do you make
the user hasslefree so there not asked
to re-enter the password or the same
password again and again let's look at
the options available the first one is
to enable Microsoft account
authentication well it's not going to
fix because with that the user will
still need to re-enter the username and
password a deploy express route uh it's
not going to fix either because express
route is a network level service that
connects on premises to the cloud so
that has got nothing to do with
prompting or not prompting for password
and then we have uh setup VPN between on
premises Data Center and Azure set up ad
domain controller in VM and Implement
integrated Windows authentication well
uh you can use the same username and
password for on premises and the cloud
but this setup the the VPN and the ad
controller setup it's not going to stop
you asking for repeative passwords so
this is all about U using the same
password in on premises and in the cloud
and this has got nothing nothing to do
with the not prompting the user to
re-enter the password all right so
that's same password is different from
not prompting the user to re-enter the
password they are two different
scenarios so uh that is also out of the
equation and the last one is configure
ad sync to use single sign on that's the
right one so when we configure the ad to
use uh single sign on then uh it's going
it's not going to ask for the username
and password every time we access an
applic because we have logged in and
that login is going to stay active for
like 24 hours or so depending on how you
configure it and within that time you
can access a lot of other applications
and it's not going to ask for the
username and password because you
already have a single signed on and you
have signed in using the right
credentials let's look at this one you
need to ensure that virtual machines
remain available while migrating to
Azure what would be the appropriate
service to use right let's look at the
options traffic manage manager traffic
manager is um is literally an DNS
service and then let's look at the other
one update domains it again has to do
with traffic manager updating the URL so
the traffic manager gets updated and
then starts sending request to that
particular uh URL it's going to take
some downtime because when we update the
URL they will have to be populated to
all different places and it takes time
so within that time any user trying to
access it's going to fail and then we
have Express route and cloud services
express route could be the in fact it's
the right answer because express route
it's an extension of her on premises and
Cloud environment and in this question
it really comes out from a customer
who's having an hybrid environment so
they have applications running in on
premises they have applications running
in the cloud and they want to have a way
to migrate applications from on premises
to the cloud in other words kind of do a
cut over between on premises and the
cloud and this express route is a
service that connects between on
premises and the cloud uh so when you do
the cut over the traffic is now sent to
the cloud instead of being handled in on
premises in fact the services and the
application is getting down are getting
shut down in on premises so the request
will come in the same pattern instead of
they being handled in on premises they
are now routed to the cloud using
express route and the API calls get
addressed uh or the the queries gets
answered uh in the cloud through the
express route service look at this
question you are an administrator for a
website called Web game and you required
to validate and deploy changes made to
your website by your development team
with minimum downtime so the real
question is how do you validate the
deployment changes that's made by the
development team let's look at the
options create a new linked resource
create a staging environment for the
site enable remote debugging on the
website and then create a new website
well why would you want to create a new
website just to validate the changes and
doing a remote debugging is not going to
help because debugging only captures
logs of the changes happening it does
not do anything with validating the
changes create a staging environment
could be or is the right answer because
when we have staging environments
anything that we run on production can
be run on staging environment and uh any
failures that would happen in production
if we simply run it in production can be
captured when we run the application in
the staging environment so that way
staging environment is a very helpful
and useful service and that way I can
catch of any errors in other words I can
validate the changes that were done by
my development team uh before I move it
to production and that reduces the
downtime in the production environment
look at this one last question that we
have for you it's um a standard tier
application is used across the world and
uses azure website standard tier it uses
large amount of image files so you can
get it this could be an e-commerce
website which has a lot of pictures in
it and this is causing the application
to load slow how can we handle this
situation let's look at the options
given configure blob storage with custom
domain well this application has
pictures but the pictures only the
pictures is not all that the application
has all right so configuring blob
storage might not help this could be an
very Interactive website and that can't
be run from blob storage let's look at
the other options configure Azure
website autoscaling to increase
instances at high loads now it's the
picture that's causing issues for the
website it's not the CPU or it's not the
memory unavailable memory not enough
that's causing the application to be
slow so we need to identify what's
causing the application to be slow so
it's not the CPU it's not the memory so
configure Azure for Autos scaling is not
going to help and then what are the
other options let's see configure Azure
CDN to cash all responses from the
application's web endpoint CDN could be
the right answer but look at that it
says uh CDN to cach all responses from
the applications web endpoint CDN is not
designed for that though it can do it
that's not the best way to use CDN to
capture all responses from the
applications web endpoint the proper
design for CDN would be to Cache the
frequently used ones in other words cach
the static content which are are photos
videos logos and pictures and lot more
static content that never changes let's
look at the last option configure Azure
CDN to Cache site images and content
stored in Azure blob storage absolutely
correct so here we will have to redesign
the application uh to store the pictures
high quality lazy loading or slow
loading pictures because of the high
quality and the bigger size so store
them in CDN and then then the content
let it be stored in azzure Blob storage
that's the right way of Designing the
application and if we do it this
application is going to run faster or
the application is going to respond
faster to the users well this was all
about the cloud computing road map I
hope you found this video interesting
and informative also do share it with
your friends and if you have any
questions regarding this video then
please feel free to ask away in the
comment section our team will reach out
to you as soon as as possible thank you
and keep
learning hi there if you like this video
subscribe to the simply learn YouTube
channel and click here to watch similar
videos turn nerd up and get certified
click here