do you want to unre the power of cloud
computing and embark on a journey to
digital transformation cloud computing
Basics is your gateway to harnessing the
immense potential of this Cutting Edge
technology by leveraging the cloud
you'll Propel your business to new
heights of efficiency scalability and
Innovation cloud computing isn't just a
W it's a game changer with a seamless
blend of flexibility and cost
Effectiveness the cloud revolutionizes
The Way businesses operate say goodbye
to Hefty infrastructure costs and hello
to unlimited storage on demand resources
and lightning fast processing
speeds did you know that by 2023 the
global public Cloud Market is projected
to exceed a staggering $800 billion
that's right the demand for cloud
services is skyrocketing and the
opportunities are Limitless for those
with the right skills but cloud
computing is more than just numbers it's
a gateway to Endless Possibilities from
startups to multinational corporations
organizations of all sizes are embracing
the cloud to accelerate their digital
transformation Journey streamline
operations and enhance customer
experiences now let's talk about the
figures that matters cloud computing
professionals are earning top dollar
salaries with entry-level positions
commanding an impressive range of
$60,000 to $100,000 per year as you gain
expertise and experience you can unlock
even more Luc creative opportunities in
this rapidly expanding field so if
you're ready to embark on this exciting
career path look no further than simply
learn skel Tech postgraduate program in
cloud computing this comprehensive
program will equip you with the
knowledge and skills needed to navigate
the cloud landscape with confidence dive
deep into Cloud architecture deployment
model security and migration strategies
explore platforms like Amazon web
services Microsoft Azure and Google
Cloud platform to build your Cloud
expertise don't miss out on this chance
to transform your career and join the
ranks of successful Cloud professionals
click the link in the description box
below to discover more about the cloud
computing Basics course to know more
about this course click on the link
mentioned in the description box below
here inspiring success stories from most
satisfied Learners who have unlocked the
full potential of cloud
computing I will be permanently moving
to Europe with my family soon simply
learn course has helped me back a great
job offer there with 60% salary hike we
cannot wait to start our new life in
Finland we are all so excited hey I am
Salah quatra and I am currently living
in Nigeria I'm working as Chief
Information Technology officer at AR
ties after working for 23 years in it
sector in Algeria I felt that my career
had become stagnant here I wanted to
experience what is like to leave in
Europe so I started applying to various
jobs there as someone who is responsible
for making decision I wanted to upgrade
my skills I also realized that to get a
new job I needed to have a professional
certification in cloud computing so last
year I started the postgraduate program
in cloud computing in association with
ctech from SAR it's not easy to get
access to ctech but simply Lear provided
that with this course I had a choice to
study while I continued with my
job I learned Technologies like ews and
aure during the course luckily my new
employers were looking for someone who
knew these Technologies I have just
completed the course but my new
employers were aware that I was taking
this course and that is how I got this
new job offer with 60% salary high in
Finland I will be leading the cloud
computing unit of my new
company I'm really excited not just for
myself but for my family as well I have
$3 others I think I will be able to help
them with their higher studies in Europe
as a father you always want to make
decision that have a positive impact on
your children as for me I'm going to
live my dream now I think dreams come
true when you work hard to achieve them
the future is in the cloud and it's
waiting for you to seize it unleash the
magic of cloud computing and witness the
flood gate get open as your website
attracts a tidal wave of organic traffic
and enjoys unrivaled success in the
digital real imagine you're the owner of
a small software development firm and
you want to scale your business up
however a small team size the
unpredictability of demand and limited
resources are roadblocks for this
expansion that's when you hear about
cloud computing but before investing
money into it you decide to draw up the
differences between on premise and
cloud-based computing to make a better
decision when it comes to scalability
you pay more for an on- premise setup
and get lesser options too once you've
scaled up it is difficult to scale down
and often leads to heavy losses in terms
of infrastructure and maintenance costs
cloud computing on the other hand allows
you to pay only for how much you use
with much easier and faster Provisions
for scaling up or down next let's talk
about server storage on Perm systems
need a lot of space for their servers
not withstanding the power and
maintenance hassles that come with them
on the other hand cloud computing
Solutions are offered by cloud service
providers who manage and maintain the
servers saving you both money and space
then we have data security on premise
systems offer less data security thanks
to a complicated combination of physical
and traditional it security measures
whereas cloud computing systems offer
much better security and let you avoid
having to constantly Monitor and manage
security protocols in the event that a
data loss does occur the chance for data
recovery with on premise setups are very
small in contrast cloud computing
systems have robust disaster recovery
measures in place to ensure faster and
easier data recovery finally we have
maintenance on premises systems also
require additional teams for hardware
and software maintenance loading up the
costs by a considerable degree cloud
computing system sys on the other hand
are maintained by the cloud service
providers reducing your costs and
resource allocation substantially so now
thinking that cloud computing is a
better option you decide to take a
closer look at what exactly cloud
computing is cloud computing refers to
the delivery of on-demand Computing
Services over the internet on a pay as
youo basis in simpler words rather than
managing files and services on a local
storage device you'll be doing the same
over the internet in a cost-efficient
manner cloud computing has two types of
models deployment model and service
model there are three types of
deployment models public private and
hybrid Cloud imagine you're traveling to
work you've got three options to choose
from one you have buses which represent
public clouds in this case the cloud
infrastructure is available to the
public over the Internet these are owned
by cloud service providers two then you
have the option of using your own car
this represents the private cloud with
the private Cloud the cloud
infrastructure is exclusively operated
by a single organization this can be
managed by the organization or a third
party and finally you have the option to
Hell a cab this represents the hybrid
Cloud a hybrid cloud is a combination of
the functionalities of both public and
private clouds next let's have a look at
the service models there are three major
service models available es pass and SAS
compared to on premise models where
you'll need to manage and maintain every
component including applications data
virtualization and middleware cloud
computing service models are hassle-free
is refers to infrastructure as a service
it is a cloud service model or users get
access to basic Computing infrastructure
they are commonly used by it
administrators if your organization
requires resources like storage or
virtual machines is is the model for you
you only have to to manage the data
runtime middleware applications and the
OS while the rest is handled by the
cloud providers next we have pass pass
or platform as a service provides Cloud
platforms and runtime environments for
developing testing and managing
applications this service model enables
users to deploy applications without the
need to acquire manage and maintain the
related architecture if your
organization is in need of a platform
for creating software applications pass
is the model for you pass only requires
you to handle the applications and the
data the rest of the components like
runtime middleware operating systems
servers storage and others are handled
by the cloud service providers and
finally we have SAS SAS or software as a
service involves cloud services for
hosting and managing your software
applications software and Hardware
requirements are satisfied by the
vendors so you don't have to manage any
of those aspects of the solution if
you'd rather not wor wor about the
hassles of owning any it equipment the
SAS model would be the one to go with
with SAS the cloud service provider
handles all components of the solution
required by the organization so if
you're ready to embark on this exciting
career path look no further than simply
learn skel Tech postgraduate program in
cloud computing this comprehensive
program will equip you with the
knowledge and skills needed to navigate
the cloud landscape with confidence dive
deep into Cloud architecture deployment
model security and migration strategies
explore platforms like Amazon web
services Microsoft Azure and Google
Cloud platform to build your Cloud
expertise don't miss out on this chance
to transform your career and join the
ranks of successful Cloud professionals
click the link in the description box
below to discover more about the cloud
computing Basics course to know more
about this course click on the link
mentioned in the description box below
what is cloud computing as we learned on
what is cloud computing we will also be
learning about how things were before
cloud computing and benefits of cloud
computing different types of cloud
computing available and some of the
famous companies that are using cloud
computing and they're getting benefited
out of it we're going to learn all that
before cloud computing existed if we
need any it servers or application let's
say a basic web server it does not come
easy now here is an owner of a business
and I know you would have guessed it
already that he's running a successful
business by looking at the hot and fresh
brewed coffee in his desk and lots and
lots of paperwork to review and approve
now he had a smart not only smart
looking but a really smart worker in his
office called Mark and on one fine day
he called Mark and said that he would
like to do business online in other
words he would like to take his business
online and for that he needed his own
website as the first thing and Mark puts
all his knowledge together together and
comes up with this requirement that his
boss would need lots of servers uh
database and softwares to get his
business online which means a lot of
investment and Mark also adds that his
boss will need to invest on acquiring
technical expertise to manage the
hardware and software that they will be
purchasing and also to monitor the
infrastructure and after hearing all
this his boss was close to dropping his
plan to go online but before he made a
decision he chose to check if there are
any alternatives where he don't have to
spend a lot of money and don't have to
spend acquiring technical expertise now
that's when Mark opened this discussion
with his boss and he explained his boss
about cloud computing and he explained
his boss the same thing that I'm going
to explain to you in some time now about
what is cloud computing what is cloud
computing cloud computing is the use of
a network of remote servers hosted on
the internet to store manage and process
data rather than having all that locally
and using local server for that cloud
computing is also storing our data in
the internet from anywhere and accessing
our data from anywhere throughout the
internet and the companies that offer
those services are called Cloud
providers cloud computing is also being
able to deploy and manage our
applications services and network
throughout the globe and manage them
through the web management or
configuration port portal in other words
cloud computing service providers give
us the ability to manage our
applications and services through a
Global Network or Internet example of
such providers are Amazon web servers
and Microsoft Azure now that we have
known what cloud computing is let's talk
about the benefits of cloud computing
now I need to tell you the cloud
benefits is what is driving Cloud
adoption like anything in the recent
days if you want an IT resource or a
service now with Cloud it's available
for me almost instantaneously and it's
ready for production almost the same
time now this reduces the go life date
and the product and the service hit the
market almost instantaneously compared
to the Legacy environment and because of
this the companies have started to
generate Revenue almost the next day if
not the same day planning and buying the
rights Hardware has always been a
challenge in Legacy environment and if
you're not careful when doing this we
might might need to live with a hardware
that's undersized for the rest of our
lives with Cloud we do not buy any
hardware but we use the hardware and pay
for the time we use it if that Hardware
does not fit our requirement release it
and start using a better configuration
and pay only for the time you use that
new and better configuration in Legacy
environments forecasting demand is an
full-time job but with Cloud you can let
the monitoring and automation tool to
work for you and to rapidly scale SC up
and down the resources based on the need
of that R not only that the resources
Services data can be access from
anywhere as long as we are connected to
the internet and even there are tools
and techniques now available which will
let you to work offline and will sync
whenever the internet is available
making sure the data is stored in
durable storage and in a secure fashion
is the talk of the business and Cloud
answers that million dooll question with
Cloud the data can be stored in an
highly durable storage and replicated to
multiple regions if you want and uh the
data that we store is encrypted and
secured in a fashion that's beyond what
we can imagine in local data centers now
let's bleed into the discussion about
the types of cloud computing very lately
there are multiple ways to categorize
cloud computing because it's ever
growing now we have more categories out
of all these six sort of stand out you
know categorizing cloud based on
deployments and categorizing cloud based
on services and again under deployments
categorizing them based on how they have
been implemented you know is it private
is it public or is it hybrid and again
categorizing them based on the servers
it provides is it infrastructure as a
service or is it platform as a service
or is it software as a service let's
look at them one by one let's talk about
the different types of cloud based on
the deployment models first in public
Cloud everything is stored and accessed
in and through the internet and um any
internet users with proper permissions
can be given access to some of the
applications and resources and in public
Cloud we literally own nothing be it the
hardware or software everything is
managed by the provider AWS Azure and
Google are some examples of public Cloud
private Cloud on the other hand with
private Cloud the infrastructure is
exclusively for single organization the
organizations can choose to run their
own cloud locally or choose to Outsource
it to a public cloud provider as managed
services and when this is done the
service the infrastructure will be
maintained on a private Network some
examples are wmware cloud and some of
the AWS products are very good example
for private Cloud hybrid cloud has taken
things to the whole new level with
hybrid Cloud we get the benefit of both
public and private cloud organizations
will choose to keep some of their
applications locally and some of the
application will be present in the cloud
one good example is NASA it uses hybrid
Cloud it uses private Cloud to store
sensitive data and uses public Cloud to
store and share data which are not
sensitive or confidential let's now
discuss about cloud based on servers
model the first and the broader category
is infrstructure as a service uh here we
would rent the servers network storage
and we will pay for them in an early
basis but we will have access to the
resources we provision and for some we
will have root level access as well ec2
in AWS is a very good example it's a Wim
for which we have root level access to
the OS and admin access to the hardware
the next type of service model would be
platform as a service now in this model
the providers will give me a pre-built
platform where we can deploy our codes
and our application s and they will be
up and running we only need to manage
the codes and not the infrastructure
here in software as a service the cloud
providers sell the end product which is
a software or an application and we
directly buy the software on an
subscription basis it's not the infra or
the platform but the end product or the
software or a functioning application
and we pay for the hours we use the
software and in here the client
maintains full control of the software
and does not maintain any equipment
Amazon and Azure also sell products that
are software as service this chart sort
of explains the difference between the
four models starting from on premises to
infrastructure as a service to platform
as a service to software as a service
this is self-explanatory that uh the
resource managed by us are huge in on
premises that towards your left as you
watch and it's little less in
infrastructure as a service as we move
further towards the ride and further
reduced in platform as a service and
there's really nothing to manage when it
comes to software as a service because
we buy the software not any
infrastructure component attached to it
there are lots of famous well-known
organization around the world they have
moved or have migrated to the cloud
environment piny rest is one company
which is one of the world's largest
visual book marketing tool with more
than 7 70 million monthly active users
now Pinterest was able to scale its
business because it was all built on
Amazon web services with a company with
less number of employees Pinterest
decided that they do not want a
dedicated staff time to manage a data
center instead Pinterest users AWS or
they used AWS to manage their high
performance social application and store
more than 8 billion objects and 400
terab of data in AWS Cloud using a
service called Amazon simple storage
service or in short Amazon S3 and not
only that they are running 225,000
instance hours a month and they run that
on Amazon compute service called Amazon
ec2 or Amazon elastic compute Cloud
Spotify is an another company that got
benefited using AWS it's an online music
service offering and it offers instant
access to over 16 million licensed songs
Spotify needed a peculiar requirement it
needed a storage solution that could
scale very quickly without incurring
long lead times for upgrades long story
short Spotify used Amazon S3 which is uh
Amazon simple storage service and Amazon
S3 gave them the confidence in their
ability and to expand their storage
quickly while also providing High data
durability the third biggest company I
want to mention is Netflix it's the
world's largest internet television
network with more than 100 million
members in more than 190 countries
Netflix uses Amazon web services for
nearly all its Computing and storage
needs now that includes database
analytic recommendation Engines video
transcoding and a lot more not only that
this company is planning to use AWS
Lambda to build an automated or an
rule-based self-managing infrastructure
and replace some of their inefficient
process to reduce the rate of errors and
replace inefficient processes to reduce
the rate of errors and save their
valuable time xedia is another famous
company that got benefited by using
Cloud xedia provides travel booking
service through its Flagship site called
expedia.com and not only that they also
run 200 plus travel booking sites around
the world xedia is all on AWS and by
using AWS xedia has become more
resilient with an High High scalable
infrastructure and better cloud services
because it had offloaded the it
management to the cloud provider itself
in this case AWS and because of this
expedia's developers have been able to
innovate faster while saving the company
millions and millions of dollars so if
you're ready to embark on this exciting
career path look no further than simply
learn skel Tech postgraduate program in
cloud computing this comprehensive
program will equip you with the
knowledge and skills needed to navigate
the cloud landscape with confidence dive
deep into Cloud architecture deployment
models security and migration strategies
explore platforms like Amazon web
services Microsoft Azure and Google
Cloud platform to build your Cloud
expertise don't miss out on this chance
to transform your career and join the
ranks of successful Cloud professionals
click the link in the description box
below to discover more about the cloud
computing Basics course to know more
about about this course click on the
link mentioned in the description box
below we can categorize the different
types of cloud computing based on two
wide categories one being deployment
model and the other one being servers
model let's talk about the deployment
model first deployment model is
categorized into three types first one
is public and then private and then
hybrid cloud in other words public Cloud
private cloud and hybrid Cloud it'll be
easy for me to explain and also it'll be
easy for you to understand if I walk you
through this example consider the
different types of vehicles we use to
commute from one place to another for
example if I want to travel I can pick a
bus which is accessible to anyone I get
in and I pay for the seat that I occupy
and I pay for the time that I will be
traveling in it and I'm done cost is
very less here a similar kind of thing
happens in the public Cloud I pay only
for the resource that I use and I pay
for how long I use it if I use less I
pay less if I use more I pay more for
that month simply on the other hand
private cloud is like buying your own
car and using it for commuting purpose
here I pay a huge amount up front and it
is all owned only by me I do not pay for
it in an odly fashion but completely and
all upfront the cost here is very huge
and thirdly if I want the best of both
types like the comfort of the own car
and still don't want to pay all UPF
front otherwise want only to pay for the
time that I use the service I can rent a
car similarly I can have it in a hybrid
environment meaning if I already have a
DC I can integrate it with the cloud and
use both the DCS and that would become
an hybrid environment all right so that
was good of an uh learning let's
summarize the types of cloud based on
deployment models and as we know now
about the public Cloud public cloud is
an Cloud infrastructure that's made
available to the general public over the
internet and it is owned by the cloud
provider some of the major players as
Cloud providers are AWS Microsoft Azure
IBM's blue cloud and suncloud and
private Cloud now this Cloud
infrastructure is exclusively operated
by a single organization it can be
managed by organizations or third party
and may exist on premises or off
premises doesn't matter but the point
here is this is exclusively operated for
a single organization and some companies
that provide private Cloud are AWS and
VM and hybrid Cloud gives the best of
both public and the private Cloud for
example the federal agencies they opt
for private clouds for storing and
developing personal data and they use
public Cloud to share the non-sensitive
data with the general public or with
other government departments now let's
talk about different clouds based on the
service model if we need to categorize
them broadly we can categorize them as
infrastructure as a service IAS or
platform as a service P or software as a
service s they sometimes are referred to
as I Pas and SAS now at this moment you
could be like this guy thinking Sam I
thought you're done categorizing the
cloud now you're going to talk about
three more categories which one should I
pick well let me explain if all that you
want is just an Wim and you have all the
expertise to install the software on top
of it and make it work then go for is if
you only want a platform or an interface
to program PR or an interface to upload
a program and make it run then pick pass
or if all that you want is a finished
product hosted in the cloud and be able
to access it through the internet then
go for SAS here you get a username and
password for an application and you can
begin to customize the application based
on your needs all right let's talk about
um IAS in a bit more detail IAS it gives
basic Computing infra it's based on uh
pay for what you use model and some of
the cloud providers who are big players
are AWS Azure and Google and here the
users generally will be it admins in
pass the provider gives you a platform
or a runtime environment for developing
testing and managing application it's
platform ready you buy the platform you
upload the code and you start working on
it and it allows the software developers
to deploy applications without running
the underlying infrastructure and as you
might have guessed by now the
interesting candidates who would use
pass is software developers and in SAS
everything is managed by the vendor be
it the hardware or the software it's
managed by the vendor and we pay for the
service and we pay for it through a pay
as you go subscription model and as you
might have guessed the end users here
would be End customer itself all right
let's put together everything in the
same page and compare and contrast the
different types of service models in
this chart it explains the difference
between the four models starting from on
premises to IAS and then pass and says
it is self-explanatory that the
resources managed by us are huge in on
premises and little less in is and
further less or reduced in Pas and
nothing to manage when it comes to SAS
let me also explain the different types
of cloud services through an example
like this let's say that you have a
crush on cake and you're planning to
bake one yourself now let's look at the
options you can have you can make all
the ingredients yourself be the floor uh
butter and uh you know put together and
bake the whole thing yourself using your
own oven pan you know the needed water
and the rest you get an idea right
everything is yours and that's on
premises all that you use is owned by
you and nothing is managed by the vendor
the other options you can have is buy
the ingredients and mix and bake the
cake yourself now this would be like IAS
here the infra is managed by the
provider and we get to use it and
customize it the way we want it here the
cloud service is an shared
responsibility the other options you
still have on hand is simply pick a
phone and order a cake now this is lot
simpler than the rest we discussed so
far you know it's simply picking the
phone and ordering the cake and pay for
it when it arrives simple and when it
reaches home you will have to arrange
the table garnish the cake if that's
needed and then enjoy the cake it's the
same way with with pass just get the
platform in which you would run your
code and upload your code and start
running your application here you and
the vendor still share the
responsibility you still have one more
option left that is simply go out and
dine this is a lot lot simpler that it
requires no effort from us at all you
buy the fully finished and garnished
cake and pay for it and walk out no
responsibility on making the cake it's
the same way with SAS we buy the
finished product and pay for the
finished application
so if you're ready to embark on this
exciting career path look no further
than simply learn scel Tech postgraduate
program in cloud computing this
comprehensive program will equip you
with the knowledge and skills needed to
navigate the cloud landscape with
confidence dive deep into Cloud
architecture deployment models security
and migration strategies explore
platforms like Amazon web services
Microsoft Azure and Google Cloud
platform to build your Cloud expertise
don't miss out on this chance to
transform your career and join the ranks
of successful Cloud professionals click
the link in the description box below to
discover more about the cloud computing
Basics course to know more about this
course click on the link mentioned in
the description box below now let's
understand what do we mean by the cloud
computing
architecture so this diagram represents
the cloud computing architecture where
you can see there is a cloud
infrastructure which we call as a front
end front front end means the
infrastructure that is Network facing
that is internet facing and the back end
is where actually the application the
services and the devices are like
storage servers and all along with the
management and the security portals so
primarily the cloud computing
architecture has two components one is
the front end and the other one is the
back
end now with respect to the architecture
the cloud computing is architecture as
we discussed earlier is divided into two
parts front end and the back end it
provides applications and interfaces
that are required for the cloud-based
services so front end would be anything
which is facing the internet for example
the websites that you deploy they are
front end because they are accessed by
the public over the public
network these applications basically
such as web browser Google Chrome and
Internet Explorer over which you can
basically open up your web applications
your sites and also it includes client
and mobile devices along with some apis
so this is with respect to the frontend
architecture now let's look into the
further more concepts related to the
front end so in the front end the cloud
infrastructure consist of a hardware and
the software components that includes a
data storage server virtualization
software Etc also it provides the GUI we
call it as a a graphical user interface
to the end users so that they can
perform the respective task so it's a
GUI based access and those who are not
from the coding background or they don't
have uh familiarity with the CLI it is
an
advantage now let's understand the
backend
architecture so the back end is
basically it manages all the programs
that runs the application on the front
end so whatever is required to support
the applications for example web
applications which are running on a
front end would be available in the back
end it has the larger number of data
storage systems and server so it is
basically it comprises of the entire
infrastructure of a cloud provider and
it can also be a software or it can be a
platform as
well so based on the requirement the
application provides output to the end
users in the back end also it is one of
the most important components in the
cloud because it is you can say a
backbone of a cloud computing
architecture and its task is to provide
utility in the architecture and the few
services that are widely used among the
end users are storage application
development environments and the web
services in the back end with respect to
the storage it maintains and manages any
time of any amount of data over the
internet
some of the examples of storage services
on the cloud are S3 which is called as a
simple storage service Oracle cloud
storage and Microsoft Azure
storage uh the storage capacity varies
depending upon the service providers
available in the market and also it
allocates specific resources to a
specific task it handles functions of
cloud environment so this is with
respect to the management in the backend
architecture the management in the
backend archit Ure helps in the
management of components like
applications task service security data
storage and the cloud
infrastructure and in simple terms it
establishes coordination among the
resources coming to the security aspect
of a backend architecture it is an
integral part of a crow infrastructure
because uh since you it mostly relies on
the storage and the databases so it has
to be more secured it helps in
protecting Cloud resources system files
and the infrastructures also it provides
security to the cloud servers with
virtual firewalls and results in the
prevention data loss now the different
components of the cloud computing
architecture one is the hypervisor
second is the management software the
third one is the deployment
software fourth one is the
network fifth one is the Cloud Server
and you have the cloud storage now let's
look into what we have with with the
hypervisor hypervisor as the name
suggests is a virtual operating platform
and that is basically used by every user
uh it runs a separate virtual machine on
the back end which consists of a
software and the
hardware also it maintain objective its
main objective is to divide and allocate
resources so basically the hypervisor is
primarily used to virtualize the
physical machine so that it can be
shared across with many resources or
many
users the management software its
responsibility is to manage and monitor
the cloud operations so all the
operational task are basically done by
the management software it helps in
improving the performance of the cloud
Since U you can do the admin task as
well for example high security
flexibility full-time access and the
access given to other uh users who would
be working on the cloud platform the
deployment software consists of all the
mandatory installations and
configurations that are required to run
a cloud
service every deployment of cloud
service is performed using a deployment
software so it is primarily used for
deploying the applications or a software
so that basically saves the time of a
developer in terms of deploying the
codes now the three different models
which can be deployed are the software
as a service which we call as a SAS so
the software as a service means it hosts
the software and manage the application
of the end user example is G Gmail so
Gmail is an example of a SAS service
where it acts as a mailing service and
uh the users just have to create their
email accounts and start using the
service uh the pass is basically a
platform as a service and uh it helps uh
to develop and build and deploy the
applications on the software primarily
used by the coders they can concentrate
more on their development activities and
less focus on the infr structure part
example is Microsoft aure and uh the
infrastructure as a service IAS is
basically to provide services on pay as
you go pricing
model uh coming to the component of a
cloud computing architecture that is
Network so what is with respect to
network why do we need a network so it
connects the front end and the back end
together so the network can be the
internal private network of a cloud
computing provider as well as the public
network
and also it allows every user to access
the cloud resources over the
Internet uh it helps users to connect
and customize the route and protocol so
let's say an admin wants um a particular
IPS to be blocked so you can specify
them and customize them in the route and
the
protocols uh it is a virtual server
which is hosted on the cloud computing
architecture so it is just like a
virtual uh networking that is available
on the cloud computing
platform it is highly flexible secure
and coste effective and it is basically
uh you can say the backbone in terms of
connecting multiple Services
together the cloud storage is basically
where every data is stored and that can
be access by a user from anywhere over
the Internet of course it depends on how
do you provide the access to it it is
scalable at runtime and it is
automatically
accessed and the data can be modified
and retrieved from the cloud storage
over the Internet itself for a better
understanding let's consider a scenario
consider baking lasagna you have four
options you can either bake it at home
or you can go to a restaurant to eat
lasagna or walk into an event and bake
or get it delivered to your doorstep but
how is this related to cloud computing
well let's take a look we have four
boxes we have the traditional method we
have the infrastructure as a service we
have platform as a service and we have
software as a service in the tradition
method everything is made at home and
all the components are managed by us
that is Kitchen electricity microwave
lasna sheets then toppings meat and
cooking the lasagna but when it comes to
infrastructure service the main kitchen
appliances are managed by the vendor and
the other things are managed by us so
basically the infrastructure is managed
by the vendor when we look at platform
as a service the infrastructure and the
main ingredient for the software is
managed by the vendor and the other
things are managed by us but when we
look at software as a service everything
from the infrastructure till the end
product is managed by the vendor now
let's get into brief of all this when we
look at the traditional method
everything is done from the scratch from
choosing the right ingredients to the
mode of preparation and you have the
full control of the toppings this is
similar to traditional method where all
the hardware and software components are
built by our choice of requirements when
we look at infrastructure as a service
we can say kitchen electricity and
microwave is the infrastructure and this
is where the code runs the next step is
to alter the software as per our
requirements when you look at platform
as a service uh it's similar to going to
event and baking so you have the main
ingredient that is the lasagna sheet and
then you have all the appliances that is
Kitchen electricity and microwave and
the rest is managed by us you can either
put toppings or you don't want to put
meat or you want it to be Veg it's all
up to us so the components are altered
as per our requir
finally in software as a service the
entire thing is modeled by the vendor so
this is where you just given your
requirements and you get the software
delivered to you it's basically where
the deployment and framework of the
project is already set now that we have
a brief of all these Services let's dive
deep into each one of them first we have
infrastructure as a service
infrastructure cloud provider gives a
variety of infrastructures such as
storage Services Network hardware and so
on it also maintains and supports these
infrastructures customers can access
these resources over the Internet next
let's look at the benefits of
infrastructure as a service so the first
feature is that these resources can
easily be scaled up and down next the
cost depends on the consumption so
basically it's a pay as you go pricing
and you pay for what you use you pay for
the services you use a single piece of
server can give out a lot of information
to many users and finally the client has
complete control over the architecture
now let's look at the pros of
infrastructure as a service model
firstly it is highly flexible this is
because only the infrastructure is
provided and the rest depends on the
customer requirements next like I said
before it is cost effective and you pay
for what you use it is easy to use as
all the updates are deployed and all the
hardware is deployed automatically
management tasks are virtualized so that
the other employ have time for other
tasks now let's look at few of its G it
is a multi-tenant architecture due to
this there is an issue with data
security when a new infrastructure is
introduced team training is required to
learn all about this new infrastructure
and it consumes a lot of time if in case
the server crashes at the vendor side
the customers cannot access the data for
a while and they would have to wait for
quite a lot of time until the vendor
fixes this issue now that we know what
infrastructure as a service is let's
look at platform as as a service
platform as a service cloud computing
platform is a developer programming
platform which is used for the
programmers to develop test and run and
manage the applications a developer
writes the applications and deploys it
directly into this layer all the
infrastructure to run the applications
will be over the Internet let's look at
the benefits now firstly the resources
can be scaled Up and Down based on the
requirements of the user multiple users
can access the same application it
allows for testing and hosting apps in
the same environment the web services
and databases and servers are integrated
into one and finally the teams can
collaborate very easily next let's look
at the pros of paas firstly the
development process is quick and easy as
it is a developer programming platform
it is coste efficient you only pay for
the services you use when you use
platform as a service the coding is done
by the developer before so less coding
is required and then the migration to
hybrid cloud is very easy next let's
look at few of the cons of platform as a
service similar to IAS data security is
an issue because it has a multi-tenant
architecture there's a compatibility
issue with the existing infrastructure
pass is dependent on the vendor speed
reliability and support now that we know
about platform as a service let's go
ahead and dive deep into software as a
service in software as a service
everything is done by the vendors the
end users are only responsible to give
their requirements and everything is
done by the providers now let's go ahead
and look at its benefits the
installations and updations are done by
the providers resources are scaled Up
and Down based on the requirements of
the users the only requirement is that
there has to be a strong network
connectivity and finally the provider is
responsible for everything now let's go
ahead and look at the pros of SAS
upgrades are automatic firstly then next
it is again a pay as you go model it is
easier to customize in SAS rather than
the other service models it is
accessible from any location the only
constraint is that you need to have a
strong internet connectivity let's see
the cons of SAS the provider has entri
control the end users only have the
control of giving the requirements there
are only few solutions for software
crashes the devices should always be
connected for better performance now
that we've seen all the three models
let's see if you have the companies
providing these service models the
famous IAS providers are Amazon web
services Rackspace digital ocean lenoe
and Microsoft aure these are only a few
there are many more apart from these
Amazon offers many features such as
autoscaling Cloud monitoring and load
balancing features when it comes to
Rackspace the cloud computing platform
vendor focuses primarily on Enterprise
level hosting Services when you look at
Famous past providers you have hero
Apache Strat open shift Microsoft Azure
and many other providers going ahead in
SAS providers the most important one is
Google Apps then there's Salesforce
there is Cisco WebEx there's Dropbox and
many more finally let's look at the end
users of the cloud computing service
models we can picture this as a pyramid
so in IAS the end users are system
admins who are responsible for
maintaining everything except the
infrastructure then in past the end
users of the developers who code on the
plat platform provided by the vendors in
SAS the end users are the customers who
give only the requirements and the
software is built based on those
requirements by the vendors meet Rob he
runs an online shopping portal the
portal started with a modest number of
users but has recently been seeing a
surge in the number of visitors on Black
Friday and other holidays the portal saw
so many visitors that the servers were
unable to handle the traffic and crashed
is there a way to improve performance
without having to invest in a new server
wondered rob a way to upscale or
downscale capacity depending on the
number of users visiting the website at
any given point well there is Amazon web
services one of the leaders in the cloud
computing Market before we see how AWS
can solve Rob's problem let's have a
look at how AWS reached the position it
is at now AWS was first introduced in
2002 as a means to provide tools and
services to to developers to incorporate
features of amazon.com to their website
in 2006 its first Cloud Services
offering was introduced in 2016 AWS
surpassed its 10 billion Revenue Target
and now AWS offers more than 100 cloud
services that span a wide range of
domains thanks to this the AWS cloud
service platform is now used by more
than 45% of the global market now let's
talk about what is AWS AWS or Amazon web
service is a secure cloud computing
platform that provides computing power
database networking content storage and
much more the platform also works with a
PSU go pricing model which means you
only pay for how much of the services
offered by AWS you use some of the other
advantages of awsr security AWS provides
a secure and durable platform that
offers endtoend private and security
experience you can benefit from the
infrastructure management practices born
from Amazon's years of experience
flexible it allows users to select the
OS language database and other services
easy to use users can host applications
quickly and securely scalable depending
on user requirements applications can be
scaled up or down AWS provides a wide
range of services across various domains
what if Rob wanted to create an
application for his online portal AWS
provides compute services that can
support the app development process from
start to finish from developing
deploying running to scaling the
application up or down based on the
requirements the popular Services
include ec2 AWS Lambda Amazon light sell
and elastic beant stock for storing
website data Rob could use AWS storage
services that would enable him to store
access govern and analyze data to ensure
that costs are reduced agility is
improved and Innovation
accelerated popular services within this
domain include Amazon S3 EBS S3 Glacier
and elastic file storage Rob can also
store the user data in a database with
aw Services which he can then optimize
and manage popular services in this
domain include Amazon RDS Dynamo DB and
red shift if Rob's businesses took off
and he wanted to separate his Cloud
infrastructure or scale up his work
requests and much more he would be able
to do so with the networking Services
provided by AWS some of the popular
networking Services include Amazon VPC
Amazon Route 53 and elastic load
balancing other domains that AWS
provides services in are analytics
blockchain containers machine learning
and internet of things and so on and
there you go that's AWS for you in a
nutshell so if you're ready to embark on
this exciting career path look no
further than simply learn skel Tech
post-graduate program in cloud computing
this comprehensive program will equip
you with the knowledge and skills needed
to navigate the cloud landscape with
confidence dive deep into Cloud
architecture deployment models security
and migration strategies explore
platforms like Amazon web services
Microsoft Azure and Google Cloud
platform to build your Cloud expertise
don't miss out on this chance to
transform your career and join the ranks
of successful Cloud professionals click
the link in the description box below to
discover more about the cloud computing
Basics course to know more about this
course click on the link mentioned in
the description box below coming to the
AWS services so essential AWS services
are compute storage database migration
networking and content delivery
developer tools management tools Media
Services machine learning analytics
security identity and compliance mobile
services application integration arvr
which is augmented reality and virtual
reality customer engagement business
productivity desktop and app streaming
internet of things which is iot now
let's look into the compute service
which is one of the widely used service
on the AWS and what does the compute
service do these Services help
developers build deploy and scale an
application in the cloud platform that
is
ec2 Lambda elastic container service
elastic load balancer light sale and
elastic bean stock these are the
services which lie in the compute
service section only one of the most
widely used service within the compute
section is ec2 which stands for or
elastic Cloud compute it is a web
service that allows developer to rent
virtual machines and help to resize the
compute capacity so here what you can do
is you can run the virtual machines and
you have the Privileges to select the
type of operating system that you want
uh should be running on your instances
or on your virtual machines and likewise
later you can customize as per your
requirement Lambda is a serverless
computer service it is also responsible
to execute code for a specific
application so those who are from the
development background they can focus
more on creation of a code they don't
have to create a server manage it
instead they can use a Lambda where you
they can deploy their code directly onto
the Lambda server then comes the storage
service now couple of storage services
are S3 glacia EBS which is elastic block
storage
storage Gateway now AWS provides web
data storage service for archiving data
also its main advantage is disaster data
recovery with high durability let's look
into some of the essential storage
services and one of the most widely used
storage servic is S3 which stands for
simple storage service in the simple
storage service what you need to do is
you have to create a bucket and in that
bucket you have to put the files in it
so S3 gives open cloud-based storage
service which is utilized for online
data backup then comes the EBS which is
an elastic block storage now you can
understand EBS as a virtual hard drive
also which attaches with the ec2 and it
provides High availability storage
volume for persistent data it is mainly
used by Amazon ec2 instances then you
have the database services AWS database
domain service offers coste efficient
highly secure and scalable database
instances in the cloud and some of the
database services are RDS which is a
relational database service Dynam DB the
non-relational or no SQL or nosql
database service elastic and Amazon red
shift now one of the essential database
service is the Dynamo DV it is a
flexible nosql data database service
which offers fast and reliable
performance with no scalability issues
it is fast reliable highly scalable and
suitable for small scale applications
like mobile applications gaming
applications or anything with respect to
the Internet of Things devices there the
Dynamo DB is uh most widely used or
suitable then comes the relational
database service that is the RDS which
is a structure database service
it is a managed distributed relational
database cloud service that helps
developers to operate and scale database
in a simple manner so RDS has different
vendors platform with respect to the
database uh usage and that includes the
post gr SQL MySQL then you have Oracle
Microsoft or mssql and uh they have
their own
customized database uh as well that is
called as the Amazon Aurora along with
that they have a Maria database or Maria
DB as well so these are couple of
vendors that give their database engines
uh that you can use on the RDS now
coming to the networking Services it
offers a highly secure Cloud platform
and helps in connecting your physical
Network to your private virtual network
with high transfer speed now some of the
services in the networking and content
delivery or VPC which is a virtual
private Cloud a very important service
in order to make your applications or uh
Services more secure Route 53 which is a
DNS mapping Service Direct Connect which
directly connects with the AWS services
and with your data centers and the cloud
front that is basically a Content
delivery service now coming to the VPC
or a virtual private Cloud it helps
helps a developer to deploy AWS
resources such as Amazon ec2 instances
in a private virtual Cloud so that you
can actually make your ec2 isolated or
make it more secure and even you can
make it for a public access also depends
on the administrator that how they want
to customize it so the complete control
of a VPC and its networking is with the
admins then comes the root 53 service it
is a web service with highly available
domain name system or the DNS that helps
user to Route software by translating
text into IP address and that is why it
is called as a DNS mapping service and
that helps you to use your domains or
the external domains pointed to the AWS
services in case if you use AWS for
hosting your websites or the
applications note DNS translates text
into the IP address now coming to the
developer tool services it helps a user
build deploy and run an application
source code automatically it also
updates the server and instance on the
workload so first is the code star code
build code deploy code pipeline so codar
it is a service designed to manage
application development at a single
place here developers can quickly
develop build and deploy applications on
AWS so all the manage app development
can be done with the code star code
build removes the hassle of managing
physical servers and helps developer
build and test code with continuous
scaling so security identity and
compliance Services helps in monitoring
a safe environment for your AWS
Resources by providing limited access to
specific users so in case let's assume
that you have to give an access to
someone but with limited privileges you
can primarily use IM am in that case and
if you want to make U your applications
or um deployments more secure then you
can use uh these services like uh KMS IM
Cognito uh WF which acts as a firewall
now the IM IM service which is the
identity access management is a
framework that helps in maintaining
access to AWS services in a secure way
so what happens is that the admin who
has the complete access of the AWS
console provide access to users and
there can be different users and they
would have the privilege accesses uh
defined by the Admin so what type of
permissions the admin gives them uh they
would have those limited access on the
AWS console KMS enables users to create
and manage the encryption keys that are
used for encrypting data coming to
management tool services with the help
of management tools using the service an
individual can optimize cost minimize
risk and automate all the resources
running on the AWS infrastructure
efficiently so with the management tools
you can monitor the resources
application it's uh its tools and the
utilizations and along with that you can
scale up scale down the resources
likewise with the help of the management
tools you can also do the auditing task
so one of the essential service in the
management tool servic is the cloud
watch it is a monitoring tool for AWS
resources and customer applications
running on AWS platform so let's assume
that you have used ec2 Dynamo DB S3 RDS
and you want to monitor those resources
you can use the cloud watch that can
give you the results coming to the cloud
formation this service helps you in
monitoring all your AWS resources at one
place so that you can spend minimum time
in managing those resources and maximum
time on developing the application so
with the help of the cloud formation you
can deploy the entire solution with the
help of creation of a template you just
need to create one template and you have
to deploy it the rest of the things will
be done by the AWS and hence it is a
kind of an automation task only now
let's look into the demo of some of the
essential services so we'll start with
the ec2 and I have already logged in
into my AWS account so where exactly you
can find the E2 just click on the
services under the compute section you
can find the ec2 ec2 stands for elastic
Cloud compute service primarily used for
creating the virtual machines so I'll
click on the service and quickly I'll
show you how the virtual machine is
created
and how we can basically access it so I
would be creating one virtual machine or
an instance with the Windows operating
system so here you can see there are
three instances which are already
running let me create another
one you have to click on launch
instances and here you have to select
some configuration details so most of
the configuration details I'll be taking
as default and wherever it is necessary
I'll be making the
changes so first of all you have to
select the operating system in the form
of Ami and I would be looking for
Windows uh 2016 and then you have to
select the type of instance with respect
to the CPUs number of CPUs and the
memory capacity so I'll go with t2.
micro which is a free tier eligible
instance in the configure instance
details the rest of the things we'll
keep it as default as of now click on
add storage this is uh basically the
virtual hard drive or the EBS the
elastic block storage that is attached
with the ec2 instance so primarily it is
giving us 30 GB of space without any
additional
cost we can leave the tax as blank click
on configure security groups and here
you can see that the RDP Port is by
default open which will actually allow
us to RDP or to have a remote
connectivity of our
instance click on review and launch now
to give an authentication or to provide
an authentication we should have a key
pair with us so that the AWS can
understand or can tally the key pair and
give us the access so I already have a
key pair created what I'll do is I'll
create a new key pair for this instance
and put a random name let's say I put it
something like demo download the key
pair and make sure that you keep your
key pair in a safe and secure place
click on launch
instances now you will see that there is
an instance ID that has been created
which is a number alpha numeric number
that is randomly given by the
AWS you can name your
instances so let's assume let's say we
name our instance as Windows
2016 click on
Save and the AWS deploys our instance on
a respective infrastructure it gives us
the IP addresses the public IP and the
private IP which is an internal IP and
we have to access the instance from the
public IP only so now to access that
instance we have to open up the
RDP put the public IP click on
connect and when it asks you for the
authentications you put a username as
administrator and the password you have
to generate by providing the keepy so
click on
connect and then uh you have to click on
RDP client here you have to get a
password so click on get
password browse and when you click on
browse you have to provide demo do PM
file so it should be in the download
section here itself
just provide that keyp pair and it is
going to give you the password in the
encrypted format decrypt your
password copy that and then provide
those
details to the RDP client click on okay
and now it should allow you to log to
the instance let's wait for the windows
to appear so here you can see that we
have uh logged in into the Windows
instance the windows 2016 screen is
available in front of us if getting your
learning started is half the battle what
if you could do that for free visit
scaleup by simply learn click on the
link in the description to know more in
this particular demonstration I would be
explaining you about how to use a
storage service specifically the S3
service which is most widely used
service under the storage section now
the S3 stands for simple storage service
primarily used for storing the objects
and the files and uh what we need to do
is we just have to click on the S3
service under the storage
section so when you click on S3 service
um you have to create the buckets inside
the
S3 and the buckets are the places where
you keep your folders or you upload the
files that are available on your
systems
so here if you'll notice that the S3
service is a global Service that means
it is irrespective of the
region and uh the buckets when you
create they are created in a specific
region now what is the
benefit the benefit is that if you
create a bucket in different regions all
those buckets in different regions can
be viewed from a single
dashboard and uh you don't have to
change the region again and again to
view the S3 buckets so what you need to
do is you have to click on create bucket
and here you have to specify the name of
the buckets so let's say I put something
like demo
AWS and
uh that's the bucket name I going to
select now make sure that the bucket
name starts with the lowercase and it
should be always unique now why it
should be unique because since S3 is a
global Service so it may be that
somebody else could be using
your the name that you have provided so
it should be always unique otherwise it
will not be
allocated now you you have to select a
region and that would be let's say I go
with the Ohio
region and uh in the bucket settings you
can basically change and configure these
settings according to your requirement
by default uh when you create a
bucket it blocks all the public access
from the bucket so when you have all
public access blocked no object can be
viewed from the S3 from a public network
or from or by anyone
else and hence uh in order to view the
objects or the or the files in the
bucket you have to unblock or uncheck
this option so that first of all you
make the bucket accessible from the
public network likewise you can
customize as per the requirement and
then click on acknowledgement the rest
of the things we'll keep it as default
and click on create bucket now it says
that the bucket with the same name
already exists so that means it is not a
unique name somebody else might have
been using this name so I'll try to keep
it more unique and I'll try to assign
some number so let's say I put something
like
987 and it says it is already existed
let's say
9876 and then click on create bucket now
if it creates a bucket that means we
have been allocated with that bucket
name so let's wait for wait for a minute
to get that bucket created
so that happens quickly and you can see
there are a couple of buckets already
created here and these buckets can be
viewed in a single dashboard so some of
the buckets are in Mumbai region some of
the buckets are in Ohio region but they
are available in the same or a single
dashboard so I'll open up the bucket
that I have recently created and I'll
try to upload some documents now what
you can do is you can create a folder
also inside the S3 and when you create
the folder you can upload the objects
accordingly otherwise you can directly
also upload the objects so click on
upload and we will upload any random
file from a system onto the
S so I'll uh basic
file and then click on
upload now it is uploading my object
from my system onto uh the S3 bucket
and now it has successfully done so it
says the message is successful now in
order to validate I will click on the
bucket from the S3 service and view this
object now you can see here is my bucket
so I'll just open up this bucket and uh
these DNS records. CSV file is available
with us now the S3 is not only limited
till storing the objects or the files it
has many other functionalities and the
features also like you can enable
versioning you can host a static website
on the
S3 along with that uh you can have a
cross region replication enabled so that
you can have a high availability of your
objects or you can have a redundancy of
your critical objects in different
regions so likewise there are more
features um that would be covered up in
the detail section of an S3 service now
coming to another section of uh the
essential services that is the
database now here you can see I have a
database section in the AWS and it has
multiple service within
it uh the RDS is there Dynamo DB is
there elastication and the other
database services are there uh so I
would be showing a demo on the Dynamo DB
which is a nosql
database
now when we say it is a nosql database
that means it is a non- relational datab
Base Service where we can create a
database table directly from the web
console we don't require a separate
database engine uh like uh in the case
of
RDS and uh in the tables you can insert
the values and view those values
directly from the AWS dashboard
itself so it says Amazon Dynamo DB is a
fast and flexible no SQL database
service primarily suitable for iot and
web gaming and other mobile applications
so what you need to do is it is a
straightforward uh database service
which is which can be accessed while
creating a table itself and it's a
compute based database service that is
the reason that it is more fast so click
on create
table and what you need to do is you
just have to put a table name so I'll
just put something like
test and uh in the partition key so
these partition keys are unique entities
so what you need to do is you have to
specify a partition key so I'll put
something like
ID and the string instead of string I'll
use a
number likewise I can add sort Keys Also
let's say I put a
name and the name should be in the
string format now these are the unique
entries these are the fixed entries in
the table and after that we are going to
put the attributes and in the attributes
the data will be inserted so what you
need to do is rest of the things we'll
keep it as default as of now click on
Create
and here you can see the table has been
created the test table has been created
now if I click on the items so you would
see that it has the sort Keys available
the ID and the sort key associated with
that that is the name but it does not
have any entry because we have not added
any value or the attributes so how we
can add or insert the values in this
table that can be done many ways you can
enter manually you can use the help of
CLI to enter the large chunk of data
directly uh upload it onto the Dynamo DB
table and also you can use the apis also
in order to insert the data inside the
table so what you will do is we will
click on create
item and in the ID we will put some
value let's say number one string uh
let's say we put something
like uh we will go with a random name so
instead of putting any name we'll put a
value like ABC D that should be fine and
then we will insert some attributes so
let's say I put string as Rank and I'll
put something like rank
two and then click on save so here you
will see just refresh the database
table close it and open it up
again click on the
items now here you can see the ID one
name is ABCD got the rank two likewise
you can click on create items let's say
the serial number or the id2 name let's
say we put something like uh we can go
with XY Z any random
thing put it up as number rank and let's
say this particular value got a rank
three likewise you can add some more
items string let's say you put something
like
hjk and you put a rank let's say it's a
rank number one holder rank one
holder right so likewise uh this is just
an example likewise you can add the
attributes as per your need and the
table can be filtered out based on the
attributes also so if you have to search
some values in the Dynamo DB table so
you can always use
filters uh to basically search the
values uh inside the table apart from
that the Dynamo TB table has lot of
other
functionalities um uh it can be
basically uh you can have a backup of a
table created in the Dynamo DB table in
the Dynamo database and then you can
retrieve or recover the data by
restoring the backups from the Dynamo DB
this database can be created in the
cluster format also so these are couple
of features uh that you can use with the
Dynamo
DB now let's move into the next
section now coming to the networking
services so there are there are some of
the networking Services which are very
useful and uh that includes a VPC which
is a virtual private Cloud cloudfront
roote 53 API Gateway
Etc now I will uh basically demonstrate
about the roote 53 Service uh in this
demo so in the root 53 is basically a
DNS mapping service so what you can do
is let's assume that you are hosting any
web application on the server and you
want to Route the domain traffic onto
those servers you need to have the help
of root 53 to do that so what you need
to do is you just have to click on root
53 service and from this service you can
register your domains also otherwise if
you have domains purchased from any
external site you can point them to the
root 53 name servers also so first of
all in the roote 53 you have to create a
hosted zone so there is already one
hosted Zone all created now when you
create a hosted Zone you have to specify
the domain
name so let me show you I have one dummy
domain this is the domain uh that has
been defined so what you have to do is
when you click on create hosted Zone you
have to put a domain here you can see
example.com likewise you have to put
your own domain and uh click on the
public hosted Zone click on create
hosted Zone and it is going to give you
four name server now those four name
servers have to be
updated on the platform from where you
have purchase the domain so that is
mandatory in order to Route the traffic
to the roote 53
service right so here you can see I
already have a hosted Zone created for a
domain and it has given
me four name servers these are the name
servers and these name servers have been
updated in a record set from where the
domain has been purchased right
once it is done then you have to Route
the domain traffic to a server so what
you have to do is you have to click on
create
record and in the create record you have
to specify the IP address or you can use
the alas also where the traffic should
be routed to where your application is
hosted at so ideally it is a server
details and it exists with certain
policies also so you can see some view
existing records so here you can
see this particular domain is routed to
a DNS value which is hosted in the
elastic bean stock instead of that you
can put an IP address of the ec2
instance also you can use the S3 URL
also you can use the cloudfront URL also
so likewise what would happen is that
the domain traffic will be routed to the
server where actually the application or
a web application is hosted at now I'm
using a routing policy as simple routing
policy that means all the traffic should
be routed to that particular domain
whereas there are other routing policies
also in the Route 53 that includes the
weighted routing policy which acts as a
kind of a load balancing geolocation
routing policy multivalue answer routing
policy and then you have redundancy
based routing policy which is a failover
one so likewise you can select as per
your
requirement so what you need to do is
you just have to click on create records
uh you have to specify you have the
domain so you have to specify any uh
particular info you want to put before
the domain otherwise you can leave it as
blank and in the record type let's
assume that you are using an IP address
of a server where uh your web
application is hosted at so you can
basically use a routes traffic to an IP
V4 address and put an IP address make
sure that you put a public IP address or
the elastic IP address attached to your
instance in case if you're not using any
particular IP address or the URL you can
use the alas also so likewise the
records can be created along with that
um the Route 53 Services used for domain
verifications also like uh if you want
uh the email services on onto your web
application then you can basically
verify your domain directly from the
Route 53 service you can uh get the
verification done for the SSL
certificate creation for that also the
records will be directly created from
the root 53 service because it is
actually managing or hosting your uh
domain now with respect to the security
services uh the most widely used service
is the IM am which is identity access
management that lies under security
identity and compliance so in from the
IM you can create the users uh whom you
want to give an access to your AWS
console you can create groups and you
can add multiple users in that group
give them the permissions you can create
the rules also so that multiple Services
can inte interact or integrated together
so how the IM is use uh click on the IM
service and I'll show you how a
particular user can be created and U how
the user is basically uses the
credentials to access the AWS console
now the IM dashboard is open and when
you open up the IM dashboard it gives
you the URL so this is the URL through
which uh the user has has to actually
access the AWS console by providing the
user credentials now how the users are
created just click on the
users and U here you just have to click
on add user so I'll create one sample
user let's say I put something like
sample
user and what type of an access you want
to give that particular user do you want
to give a programmatic access which is
primarily the CLI access or you want to
give the AWS Management console so right
now we'll go with with the AWS
Management console access now do you
want an autogeneration of the password
or do you want to customize the password
so let's assume that we customize the
password so put any
value make sure the password meets all
the
criterias and uh then click on next
permissions now what kind of permissions
you want to give to that user let's
assume that you want to give an access
of a particular service only to that
user so you have to actually search you
have to actually search a policy for
that particular service um that can be
given an access to a user otherwise if
you want to give an admin policy or the
admin access to that user you can search
an admin policy there so the permissions
are important otherwise the user would
not have privileges to access um the AWS
console so we'll attach the existing
policies directly so click on it and
here let's assume that I want to give an
admin access to that user so I'll just
just click on the admin access now to a
particular user you can give multiple
policies also it is not necessary that
you have to give only a single policy so
you can provide a multiple policies to
the users also now click on next tags
let let's make the tags blank click on
review and create a
user now you'll see that our sample user
would be created and to access the
console we'll just copy this URL which
has the account information as well as
well that is the account
number so copy the link or can copy the
complete URL log out from the root
account and
then paste the URL that was copied from
the
console and then we have to give the
user credentials
so we'll put sample user as the username
and the password that we provided while
creating the
user click on sign in and if it is
correct then it should allow us to log
into the AWS console while asking
the password
change so we'll change the password
confirm password
change and now it should allow us to
login into the root accounts AWS console
with the admin
privileges now the next service is the
monitoring services and under the
monitoring Services uh primarily the
cloud watch uh the cloud trail the cloud
formation these are some of the services
that are most widely used now the cloud
watch is a service which is primarily
used for monitoring the metrics
primarily of the servers like for
example if you create an ec2 instance
and you want to uh
basically watch out for the metrics
associated with the CPU utilization or
uh the storage utilization the network
in network out all those information you
can get it from the cloudwatch now
cloudwatch is not
only related to monitoring the metric it
can generate the alarms also and and U
here you can get the events also
generated which uh or the events that
can be created which can trigger the
Lambda function as
well so what you have to do is you just
have to click on dashboard so iing
metrics are viewed uh with the help of
the cloud watch so first of all you have
to create a
dashboard now you have to put a
dashboard name let's say I put something
like
monitoring ec2
click on create dashboard now how do you
want the reports to be published you
have to actually select a widget I want
that okay the report should be visible
in the numeric form so I'll select a
number now click on the dashboard that
was created and
uh let's again add the
widget and and here uh we'll select the
metrix primarily for the ec2 for
instance metrix so we have one single
instance running now there are 14
metrics available for that particular
instance now I would be looking for the
CPU utilization for this particular
instance so I'll just select for the CPU
utilization and it is going to give me
some information about what is the
current CPU utilization of that
particular instance so that is somewhere
around
29.3% uh the CPU utilization has been
been done for the single instance that
is running in my ec2 dashboard so
likewise you can add some more metrics
and view them in this particular
dashboard and the cloudwatch will keep
on publishing the data uh at a refresh
interval of 5 minutes that is uh the
default value so if you're ready to
embark on this exciting career path look
no further than simply learn scel Tech
postgraduate program in cloud computing
this comprehensive program will equip
you with the knowledge and skills needed
to navigate the cloud landscape with
confidence dive deep into Cloud
architecture deployment models security
and migration strategies explore
platforms like Amazon web services
Microsoft Azure and Google Cloud
platform to build your Cloud expertise
don't miss out on this chance to
transform your career and join the ranks
of successful Cloud professionals click
the link in the description box below to
discover more about the cloud computing
Basics course to know more about about
this course click on the link mentioned
in the description box below so now what
is azure what's the big cloud service
provider all about so Azure is a cloud
computing platform provided by Microsoft
now it's basically an online portal
through which you can access and manage
resources and services now resources and
services are nothing but you know you
can store your data and you can
transform the data using services that
Microsoft provides again all you need is
the internet and being able to connect
to theum portal then you get access to
all of the resources and their services
in case you want to know more about how
it's different from its rival which is
AWS I suggest you click on the top right
corner and watch the AWS versus AO video
so that you can clearly tell how both
these cloud service providers are
different from each other now here are
some things that you need to know about
as Europe it was launched in February
1st 2010 which is significantly later
than when AWS was launched it's free to
start and has a pay per use model which
means like I said before you need to pay
for the services you use through aor and
one of the most important selling points
is that 80% of Fortune 500 companies use
Azure Services which means that most of
the bigger companies of the world
actually recommend using Azure and then
Azia supports a wide variety of
programming languages the cop nodejs
Java and so much more another very
important selling point of a z is the
amount of data centers it has across the
world now it's important important for a
cloud service provider to have many data
centers around the world because it
means that they can provide their
services to a wider audience now Azor
has 42 which is more than any cloud
service provider has at the moment it
expects to have 12 more in a period of
time which brings its total number of
regions it covers to 54 now let's talk
about azzor Services now Azor Services
have 18 categories and more than 200
services so we clearly can't go through
all of them it has services that compute
a machine learning integration
management tools identity devops web and
so much more you're going to have a hard
time trying to find a domain that Azure
doesn't cover and if it doesn't cover it
now you can be certain they're working
on it as we speak so first let's start
with the compute Services first virtual
machine with this service what you're
getting to do is to create a virtual
machine of Linux or Windows operating
system it's easily configurable you can
add RAM you can decrease RAM you can add
storage remove it all of it is possible
in a matter of seconds now let's talk
about the second service cloud service
now with this you can create a
application within the cloud and all of
the work after you deploy it deploying
the application that is is taken care of
by aure which includes you know
provisioning the application load
balancing ensuring that the application
is in good health and all of the other
things are handled by aure next up let's
talk about service fabric now with
service fabric the process of developing
a micros service is greatly simplified
so you might be wondering what exactly
is a microservice now a microservice is
basically an application that consists
of smaller applications coupled together
next up functions now with functions you
can create applications in any
programming language that you want
another very important part is that you
don't have to worry about any hardware
components you don't have to worry what
Ram you require or how much storage you
require all of that is taken care of by
Azure all you need is to provide the
code to Azure and it'll execute it and
you don't have to worry about anything
else now let's talk about some
networking Services first up we have
Azor CDN or the content delivery Network
now the Azor CDN service is basically
for delivering web content to users now
this content is of high bandwidth and
can be transferred or can be delivered
to any person across the world now these
are actually a network of servers that
are placed in strategic positions across
the world so that the customers can
obtain this data as fast as possible
next up we have expess now with this you
can actually connect your on promise
Network onto the Microsoft cloud or any
of the services that you want through a
private connection so the only
communication that happens is between
your on promised Network and the service
that you want then you have virtual
Network now with virtual Network you can
have any of the Azure Services
communicate with each other in a secure
manner in a private manner next we have
Azure DNS so azur DNS is a hosting
service which allows you to host their
DNS or domain name system domains in
Azure so you can host your application
using Azure DNS now for the storage
Services first up we have dis storage
with this storage you're given a cost
effective option of choosing HDD or
solid state drives to go along with your
virtual machines based on your
requirements then you have blob storage
now this is actually optimized to en
sure that they can store massive amounts
of unstructured data which can include
Text data or even binary data next you
have file storage which is a managed
file storage and can be accessible via
the SMB protocol or the server message
block protocol and finally you have q
storage now with Q storage you can
provide durable message queuing for an
extremely large workload and the most
important part is that this can be
accessed from anywhere in the world now
let's talk about how aor can be used
firstly for application development it
could be any application mostly web
applications then you can test the
application see how well it works you
can host the application on the internet
you can create virtual machines like I
mentioned before with the service you
can create these virtual Machines of any
size or Ram that you want you can
integrate and Sync features you can
collect and store metrices for example
how the data Works how the current data
is how you can improve upon it all of
that is possible with these services and
you have virtual hard drives which is an
EXT extension of the virtual machines
where these services are able to provide
you a large amount of storage where data
can be stored let's talk about a
Services as I told you Azure provides
services for a wide range of domains now
let's have a look at some of these
domains there's Ai and machine learning
compute containers database identity
management tools networking Security
Storage and so much more now let's have
a look at some of the individual
services within these domains firstly
you have aure virtual machines with azer
virtual machines what you get is the
opportunity to create Windows or Linux
virtual machines now all of this is
possible in a matter of seconds with a
large amount of customization now let's
have a look at some of its features
firstly you can choose from a wide
variety of virtual machine options then
you have a large amount of optimization
available to you for example what size
of operating system do you want how much
size do you want allocated to it what
version of the system is it and so much
more then it provides low cost and
permanent billing Azure provides you per
minute billing which means that you're
only charged for how much time you use
the service and finally you have
enhanced security and protection for
your virtual machines next we have
service fabric now with service fabric
you have a platform which enables you to
create microservices now this also makes
the process of application life cycle
management a whole lot easier as a
direct result you can create
applications with a faster time to
Market it supports Windows Linux on
promises or other clouds and it enables
you you to do a tremendous amount of
scaling up depending on your requirement
and finally we have functions now with
functions you can build applications
with the help of serverless computing
here the users only pay for the amount
of resources that they've used you can
create applications in any language that
you want and the only thing you need to
worry about is the code of the
application everything other than that
that is the hardware requirements are
taken care of by Azure now let's have a
look at the networking Services firstly
we have the Azor CDN of the content
delivery network with azo CDN what you
get is the ability to deliver your
content with reduced load times fast
responsiveness and less bandwidth now
CDN can be integrated with several other
AZ services so that the process can move
at a FAS rate it can handle heavy loads
and traffic spikes with ease it also
provides a robust security system now
with the content that's delivered you
can get Advanced analytic data with
which you can understand how customers
are using your content next we have
express route with express route you can
connect your on premisis network to aure
through a private Network Now by default
this lowest latency it increases the
emphasis on reliability and speed and it
can be of great use when you have to
transfer large amounts of data between
networks now another way this can be
useful is if it's used to add compute or
storage capacity to Data Centers next we
have Azure DNS domain name service or
Azure DNS can be used to host your
domain on aure this provides High
availability and great performance it
provides fast responses to DNS queries
by taking advantage of Microsoft's
Global Network it also provides High
availability next we have virtual
Network Azo virtual Network allows the a
your resources to communicate with each
other or other on promise networks via
the Internet and all of this is kept
extremely secure now with this users can
create their own private Network for
communication it provides users with an
isolated and extremely secure
environment for their applications to
run now all of the traffic stays
entirely within the Azure Network and it
also allows users to design their own
networks next we have traffic manager
now with traffic manager you can route
incoming traffic to improve your
performance and availability now one
thing it provides is multiple failover
options so if a particular situation
goes wrong there's always an option to
consider to salvage the situation it
helps reduce application runtime and
enables the distribution of user traffic
across multiple locations it also helps
the people who are using it to know
where the customers connecting from
across the world next we have load
balancer with this you have provided the
ability to instantly scale applications
at the same time providing High
availability and improve Network
performance for users applications it
can be integrated into virtual machines
and cloud services it provides highly
reliable applications it also allows
users to secure and integrate security
groups finally we have Azor VPN Gateway
now this allows users to connect their
on promise networks to Azure using a
sight tosite VPN now this allows users
to connect their virtual machine to
anywhere in the world through a pointto
site VPN and also it's very easy to
manage and is highly available now let's
talk about the storage Services first we
have data Lake storage now with this
what you get is a scalable data storage
with an emphasis on cost Effectiveness
and scalability now it comes of Max
maimum use when youve integrated with
other services so that you can get
analytics on how the data is being used
it is also integrated with other
services like the Azo blob storage now
it is also optimized for Big Data
analysis tools like Pache spark and
Hadoop next up we have blob storage now
blob storage provides a storage capacity
for data now depending on how often a
particular data is used it is classified
into different tiers now all the data
that is within the blob storage is UN
structured data now it has a way of
ensuring that the data Integrity is
maintained every time a particular
object is being changed or the data is
being accessed and it also helps improve
app performance and reduces bandwidth
consumption next we have q storage now
with this you have a message queuing
system for large workloads this allows
users to build flexible applications and
separate functions not to mention with
this you can be sure that your
individual components will not fail it
also makes Ure that your application is
scalable Q storage provides Q monitoring
which helps ensure that the customer
demands are met then we have file
storage now with file storage you can
perform file sharing with the help of
the SMB protocol or the server message
block protocol now this data is
protected by SMB 3.0 and the https
protocol in this CL like we mentioned in
functions AO takes care of all the
hardware needs and the operating system
deployments on its own it also improves
Onis performance and other capabilities
lastly we have table storage with table
storage you can deploy semi-structured
data sets and nosql key value store now
this is used for creating applications
which have a flexible data schema and
also considering how it has a very
strong consistency model it's mainly
aimed for Enterprises next let's have a
look at some web and mobile services
first we have the Azo search now with
azo search you get a cloud search
service which is powered by artificial
intelligence with this you can develop
web applications as well as mobile
applications now one big Advantage is
that you don't have to set up or manage
your search indices as your takes care
of that and by extension it increases
your development speed the artificial
intelligence also will provide insights
and structured information that you can
use to improve the search and structured
information next we have logic apps now
with this you can create integration
Solutions which can connect applications
that are important to your business now
with this you can visually create
business processes and workflows you can
integrate SAS or software as a service
applications and Enterprise applications
and more importantly it allows you to
unlock data within a firewall and
securely connect to services next we
have web applications now with web apps
you can create deploy and scale web
applications according to business
requirements now it supports both
windows and Linux platforms and it helps
with integration or deployment abilities
another very important aspect of this is
that the data can be deployed and hosted
across multiple locations in the world
and finally we have mobile apps with
mobile apps you can create applications
for iOS Android and Windows platforms
one advantage is that it automatically
scales Up and Down based on your
requirements now in situations where you
have network issues offline data syncing
ensures that your applications work
anyway and you can create crossplatform
applications or native applications for
iOS Android and Windows next let's have
a look at some container services first
let's talk about ACS or Azo container
services it is also known as the AZ
kubernets Services as it's a fully
managed kubernets container
orchestration service now what this
means is that it eases the process of
container integration and deployment it
also can be used with other resources
from security like virtual networks
cryptographic keys and so much more to
to ensure that your container is kept
secure next we have container instances
now this is similar to functions in a
way just that in this we're using
containers without having to manage
servers now applications can be
developed here without managing virtual
machines or learning new tools all that
is a Z's problem to take care of and it
enables building applications without
having to manage the infrastructure that
is all you need to worry about is
running the container next let's have a
look at some database services first we
have the SQL database now with SQL
database what you get is a relational
Cloud database service now this means
that it helps accelerate your app
development and makes it easier for you
to maintain your application now SQL
database is also used extensively in
migrating workloads to the cloud and
hence saves time and cost it also helps
improve your performance by integrating
machine learning and Adaptive
Technologies into your database next we
have Azure Cosmos DB now this is a
globally distributed multimodel database
service now what this means is that with
this you can create application with
support nosql it provides a high-grade
security system has high availability
and low latency now this is usually used
in situations where you have a diverse
and highly unpredictable workload now
let's have a look at some security and
identity Services firstly we have the
Azure active directory now if you want
to know more about azzor active
directory I suggest you click on the top
right corner and watch our video on the
Azure active directory this is just an
introduction so with this you can manage
user identities and you can make sure
the resources are kept safe with the
help of access policies most of these
are intelligence driven now one of the
main features is that you can have
access to your applications from any
location or device it helps increase
your efficiency and helps down cutting
costs when it comes to having a help
desk it can also help improve security
and can respond to Advanced threats in
real time next you have a your active
directory b2c it helps provide customer
identity and access management in the
cloud now protecting customer identity
is extremely important for an
organization and that's what as your ADB
to see does now it also enables the
application to be scaled to great
amounts even billions of customers next
we have the Azure security Center this
is basically like a command post with
which you get a complete View of the
security across users on your own
premises and Cloud workloads so with
this you're given threat protection
method that adapts to situations and
helps reduce exposing you to threats it
also has rapid threat response and makes
the process of finding and fixing
vulnerabilities a whole lot easier next
up let's talk about monitoring and
Management Services so first let's have
a look at Azure advisor now Azure
advisor is basically a guide for the
best practices when it comes to azure
now when you follow these it improves
performance security cost and increases
availability now it also learns from how
you use the services on your
configuration and usage pattern and the
adjustments that it suggests can be
implemented very quickly and easily next
we have Network Watcher now with this
you can monitor diagnose and understand
the working of your network now you can
monitor your network without actually
having to log in to your virtual machine
now you can also use something known as
network security flow logs to understand
the traffic pattern how much traffic is
coming towards you how much you're
giving and so much more it also helps
diagnose VPN problems that you might
have with detail logs and finally you
have the Azure resource manager now with
this you can ensure that the resources
that you have are managed and deployed
at a consistent rate now this makes it
extremely easy for you to manage and
visualize your sources that are used in
your applications or some other
requirements and you can control who can
access your resources as well as perform
actions on it so if you're ready to
embark on this exciting career path look
no further than simply learn skel Tech
postgraduate program in cloud computing
this comprehensive program will equip
you with the knowledge and skills needed
to navigate the cloud landscape with
confidence dive deep into Cloud
architecture deployment models security
and migration strategies explore
platforms like Amazon web services
Microsoft azure and Google Cloud
platform to build your Cloud expertise
don't miss out on this chance to
transform your career and join the ranks
of successful Cloud professionals click
the link in the description box below to
discover more about the cloud computing
Basics course to know more about this
course click on the link mentioned in
the description box below let's
understand why Google Cloud platform so
Google Cloud platform is popular for
many reasons now let us see few of most
important reason reasons why it stands
out when you talk about pricing pricing
is one of the significant factors that
make Google Cloud Stand Out Among the
other Cloud
providers it offers a monthly pricing
plan which is build according to monthly
usage and when we talk about billing
here the billing can be in hours it can
be in minutes and it can also be in
seconds there are different options when
you talk about your pricing which can be
found from your Google Cloud web page
now pricing could be based on preemptive
machines pricing could be based on
reserved instances or reserved resources
I'll show you the link where you can
find more details on pricing part of it
so Google Cloud really has various
pricing options which help customers in
their different requirements whether
they would go for any of the service
models such as as infrastructure as a
service platform as a service or even
software as a service one more
attractive thing about Google Cloud
pricing is that it provides committed
use discounts for example under this
scheme you can purchase a specific
amount of virtual CPU course and memory
for up to 57% Discount off regular
prices if you commit usage for either
one or 3 years now this is just one
option there are various such options
which you can learn about from the
Google Cloud's page and that really
suits different customers for their
different
requirements now when we talk about
speed we don't need to really challenge
this aspect when it comes to Google
services so Google provides its Google
cloud and Google app customer speed up
to 10 terabytes because of its faster
cable system there are different kind of
machines which can be used if you're
talking about computation if you're
talking about memory hungry applications
or even storage intensive workloads all
in all speed is one of the defining
characteristics of Google cloud services
the cable has connections over us West
coasts main cities in Japan and even
major hubs in Asia this speed enhances
performances and leads to customer
satisfaction now when we talk about
customers a any or every customer would
prefer to have low latency High
throughput Based Services they would
want to use higher speeds to process
their data in as less time as possible
Google provides a low latency Network
infrastructure in fact you can say that
when you are using Google cloud services
you are using the services from the same
infrastructure which Google uses for its
popular
services such as Google search or even
YouTube which is one of the second
largest repository which can be accessed
for videos now when we talk about Big
Data big data is data which is very
complex has lot of other characteristics
such as your volume you have velocity
you have variety you have veracity
validity volatility virality and so on
so if an organization has is working on
Big Data Google Cloud can be a better
choice because Google has many
Innovative tools for cloud warehousing
for example such as big query and even
realtime data processing tools such as
data flow big query is a data warehouse
that allows massive processing of data
at high speeds basically working on your
structured data Google also has launched
some new machine learning from from
artificial intelligence tools now there
are various other services which we can
which we can use from Google Cloud
platform but let's understand what is
Google Cloud platform and what are some
of the services even the services which
are not listed here can be found in your
console from Google Cloud so what is
Google Cloud platform gcp it is a set of
Cloud Computing Services provided by
Google that runs on the same
infrastructure as I men mention that
Google uses for its end user products
like YouTube Gmail and even Google
search the various set of services
offered by Google Cloud platform are so
you have Services which are specific to
Computing requirements and again in
Computing you have various different
options available you have machines
which are compute optimized machines
which are memory optimized machines
which are storage optimized and also so
we have certain machines such as preti
which basically means that you could get
a machine to work on at a far lesser
price than any other machine but when we
talk about preemptive these are the
machines which can be requested on
demand and they can be taken back by
Google at any time you have networking
related Services which can be very
useful when you are setting up your
applications or your services across
Globe you also have different Services
which are specific to machine learning
and organizations which would be
interested in working on machine
learning or artificial intelligence
would be really interested in using
these Services there are also innovative
solutions to work on big data and Big
Data related Technologies now when we
talk about Google Cloud platform domains
so we can break down the Services into
specifics such as you have compute now
the compute service allows for computing
and hosting the cloud now when you talk
about Computing here there are different
services such as app engine you have
compute engine you have kubernetes you
have Cloud functions and Cloud run when
you talk about storage and database so
the storage and database service allows
application to store media files backups
or other fil like objects now various
Services Under This are as follows you
have cloud storage Cloud SQL Cloud big
table for unstructured data you have
Cloud spanner cloud data store
persistent Diss and Cloud memory store
when we talk about networking the
networking service allows us to load
balance traffic across resources now as
I mentioned earlier resources could be
your different resources which you would
be using from a cloud platform such as
your devices your instances memory
optimized or CPU optimized instances or
other resources creating DNS records and
much more so various Services Under This
are VPC that stands for virtual private
Cloud you have Cloud load balancing
Cloud armor Cloud CDN you have Cloud
interconnect DNS and network service
years when we talk about the big data
service this allows us to process and
query big data in Cloud now various
Services under these are as follows you
have big query cloud cloud data proc
Cloud composer cloud data lab cloud data
prep Cloud Pub sub which is publish and
subscribing system you have cloud data
studio now you also have the developer
tools and developer Tools service
includes tools related to develop M of
an application now various Services
under these are as follows that is you
have Cloud SDK software development kit
you have deployment manager Cloud Source
repositories and Cloud test lab when we
talk about identity and security which
is one of the primary concerns for any
organization or any user who would be
interested in using a cloud platform
Google Cloud really has taken care of
this so when you talk about identity and
security domain this deals with Security
Services now various Services here are
Cloud identity you have identity and
access management that is cloud am you
have identity aware proxies you have
cloud data loss prevention API security
key enforcement Key Management Service
and many more you also have cloud
services which are related to internet
of things so very much would be used by
organizations who would be working on
iot devices or the data generated by
these devices so various Services here
are Cloud iot Core you have Edge TPU and
Cloud iot also when we talk about Cloud
AI that is artificial intelligence this
comprises of services related to machine
learning and much more so you have Cloud
autom ml Cloud TPU Cloud machine
learning engine job Discovery dialog
flow Enterprise natural language Cloud
text to speech and much more if you
would be interested in Services related
to API platform then there are different
Services Under This category or this
domain so you have Maps platform you
have APG API platform
monetization developer portal analytics
that is API analytics APG sense Cloud
endpoints and service infrastructure
so these are some of the listing of
services under each Cloud platform
domain now let's look at Ferrero use
case and let's also understand what was
done here so Ferrero is one of the
famous chocolate and ranks third among
worldwide chocolate and confectionary
producers it was found in 1946 in Italy
I'm sure you would have seen the Ferrero
chocolates when you would have gone out
to buy some chocolates so the challenges
here was that ferero as we know is sold
in every supermarket and is known for
its quality once the business grew some
issues arous right and that's what
happens when the business grows you have
issues popping up which could be related
to the volume of data the speed with
which the data is getting generated the
variety of data and also looking at your
platforms with support different Dynamic
applications or your scalability
requirements performance requirements
and so on so it needed data storage
processing and Analysis system for a
wide customer
database there was a huge gap between
the company and the people who bought
its goods because the company relied on
data given sales outlets now that's one
of the challenge ferero wanted to create
a digital ecosystem where there was a
point of cont contact with its customers
and also a foundation for an Innovative
datadriven marketing strategy what was
the solution here so one of the service
of cloud platforms or Google Cloud
platform is Big query and this was an
answer to fero's challenges since it was
capable of hyper fast and efficient data
analysis as a solution now as I
mentioned big query is a data warehouse
which allows you to store structured
data now this could directly be used as
a service where you could store in any
amount of data and you would not be
paying for storage so there are
different pricing models and for data up
to 1 terabytes you would not be charged
anything and if you would be accessing
the data that is reading the data or
processing the data from bigquery that's
where the pricing model kicks in
Now using Google Cloud's big query
business analysts of ferero were able to
store and analyze massive data sets in a
very reliable fast and affordable
manner consumer behavior and sales
pattern data reports were easy to build
and
automate and the analysis also followed
ferero to adopt advertising across
various marketing channels to serve the
customer needs in a better way what was
as a result they could divide their
database into realtime actionable
consumer clusters to generate more
accurate user profiles fero was also
able to personalize its marketing
strategies to match the user needs now
Google Cloud platform completely
tailored the website mobile content and
advertising and created a very
costeffective media bu strategy now
these were some Basics on Google Cloud
now as I said you can always find lot of
details about pricing about services and
also all the services are accessible in
your free trial account now let me just
walk you through here so one is you
could always find details on
documentation on each of these services
so if I would click on getting started
you have quick start which basically
shows you short tutorials
you have trainings and you have also
certifications now if we click on quick
start now that takes me to this page
which shows me quick starts or if you
would want to understand about different
projects if you would want to look into
the documentation of creating a Linux
virtual machine or storing a file and
sharing it deploying a container Docker
container image and so on so you have a
lot of quick starts here you can also
look at Cloud
minute on the same page on the right
side you have docs and once you click on
that it takes you to these links now
this shows you build Solutions which
shows you top use cases best practices
all the solutions it's always good to
learn from these use cases which are
available and here you have different
feature products and all the different
Services which Google Cloud offers now
you can click on featured products and
that basic basically shows you a list of
these products now here we have all the
solutions which you can look at
architecture database Enterprise level
big data and Analysis gaming related
internet of things and so on now if you
go down here it shows you featured
products and that shows you some of the
important products such as compute
engine which is belonging to the compute
domain you have Cloud run you have
anther which is for migration and basic
basically Cloud adoption when
organizations would want to move from on
premise to cloud-based Solutions you
have Vision AI you have cloud storage
now that basically allows you to store
any kind of data whether that's an
object so this is acting as an object
storage you have cloudsql which is
basically a ready to use service where
you would be using MySQL post or any
other SQL Server database Services you
have big query which is is a data
warehouse which basically allows you to
store your structured data and then you
have your AI and machine learning
related products so you have automl
Vision AI video AI text to speech speech
to text and so on now you also have
different platform accelerators which
can be used and in any of these cases
for example if I would click on compute
engine which is a featured product from
Google Cloud now that shows you
basically your quick starts using your
Linux machines how to guides which tells
you completely working on a VM instance
or working on storage working on
persistent Diss and so on and it shows
you the documentation here now you also
have products and pricing option which
you can see for GCB pricing and you
could straight away go to the pricing
you could be looking at Solutions which
talks about infrastructure modernization
now this is something which
organizations are interested in when
they would want to move from their on
premise solution to your Google Cloud
now here I can say for example I click
on infrastructure modernization you can
always find some case studies what are
the different solutions we have here
right when you talk about Google Cloud
so you can always click on C Solutions
and you can look at VM migration or sap
Cloud right why Google Google Cloud what
it can be used for VMware as a service
or HBC that is high performance
Computing and about these Services we
will learn in detail later now I can go
back on the same page where I was
clicking on the services so you have
quick starts you have how to guides you
have deep understanding of different
concepts right and here if I click on
all how to guides so that shows me what
are the different ways in which you can
work with compute engine and working
with different instances although it's
quite exhaustive content but then if you
follow steadily then you can learn a lot
about Google Cloud now here I can just
go back so this is just giving you some
idea on the different products which are
available from Google Cloud looking into
different sections finding right
documentation here right and you can
always look into each one of these in
detail for each product which Google
Cloud
offers now if we scroll down we could
see all the options or all the domains
which we see here right let me just go
back because we got into Solutions now
we have quick starts right and then you
can basically scroll all the way down to
look at Cloud SDK which can be set up on
your Windows machine like I have set it
up on my Windows machine plus when you
use Google console you have a GUI which
I'll show you in couple of minutes and
also a cloud shell where you can use
your command line options to work with
Google Cloud platform you have Cloud
console which is nothing but your GUI to
access your resources now you can also
look at in-depth tutorials pricing and
you have different other options so
let's just click on pricing here and
then we have your price list which
basically gives you details of different
Services what are available and what are
the services or what are the prices so
for example if I click on computer
engine right and this shows me the
pricing aspect of compute engine which
belongs to compute domain and here you
can see you have VM instance pricing you
have networking pricing so tenant nodes
which are specific to particular
organizations or if organizations would
want to have dedicated notes you have
GPU based pricing right so General
processing units you have disk and image
pricing and you can click on any of the
links and you can see pricing which also
shows you your different kind of machine
types so here you have different kind of
machine types which says N1 N2 n2d E2
you have memory optimized machine types
you have compute optimized you have
premium images and you can basically
look at all the categories you can look
at disk pricing which involves your
persistent disk pricing for ssds or sdds
what are the kind of images what are the
different network Services right and you
can always look at your machine types
you can choose a particular region right
there is the concept of region and
availability zones here and as per
region you could look at the prices you
can also look at standard prices you
could be looking for what are the free
machines if I'm specifically looking for
VM instance pricing I can click on this
one and that takes me to the VM instance
pricing what is the bilding module what
is the instance up time what is the
resource based pricing and then you can
also look at different kind of discounts
such as sustained use discounts
committed use discounts discounts for
preemptable FM instances and so on and
this is how you can be looking at
pricing for all different resources and
you can choose the resource which you
are interested in and then look for the
pricing
benchmarks reservations if you would
want to use and you would want to
benefit if you would want to look at
what are the quotas and limits and so on
so please explore this link and you can
find lot of information when it comes to
technical options looking at different
Google Cloud products which we briefly
discussed when it comes to domains and
what each product can be used for you
can always come back to the main page
page where I was showing you different
Services we went into pricing straight
away right now you can always come back
to this page on your cloud.google.com
and then you have your
Solutions which talks about different
products right and you can click on
these or you can look into technical
documentation so this talks about your
different featured Solutions
infrastructure Solutions you have data
center migration related and so on so I
could be talking more and more about
Google Cloud platform it's a ocean it's
a huge chunk of different services for
different organizational requirements so
look into this link and also what you
can do is create a account on Gmail I
mean you could create a free account or
you could go to cloud.google.com
and then you could create a free account
like I have created here and I can just
click on Console now that's my GUI or
Google Cloud console which basically
allows me to work with Google Cloud now
there are a lot of options here by
default when you create an account now
in my case on the top it says it's a
free trial account I have $300 credit
and out of that $251 is left and 237
days out of a year are left for my
account now here I can basically see the
project right and by default we can
create an project or or by default there
is a project existing for any user so
when you log in it creates a particular
project and you could create a new
project and project would be to dedicate
your different services or different
resources per different project so this
is your dashboard which basically shows
your project which shows you a project
number and a project ID which is always
unique now you can click on this and
this if you would want you can hide this
information you can also look into the
documentation part of it then it shows
you the different services or a
graphical information of services which
you might have used in past so you have
compute engine which shows you how much
percentage of CPU was used you can
always go to compute engine as a service
you can look at your Google Cloud
platform status and look at the Google
Cloud status now this is billing now
since this shows me the billing period
for April month and I can always look at
detailed charges I can look at reporting
I can look at different apis which
Google offers and for your different
kind of work you can always go to the
API overview or the API link and enable
or disable any API now once you enable
or disable any API then you can use that
so you have news section you have
documentation and you have getting
started guides which tells you how to
work or enable different API
if you would want to deploy a pre-build
solution at Dynamic logging monitoring
errors deploying a Hello World app and
so on now this is your dashboard I can
click on activity and that would show me
what kind of activity I would have done
in my cloud platform I can always choose
the kind of activities by saying
activity type I can choose the resources
now it shows me that I created some VM
instances I deleted them
I updated some metadata I basically
worked on instances I changed some
firewall rules here I have then also
worked on some other services or apis so
I created some buckets which is for
object storage and again I have been
working with some instances and creating
some firewall rules here I have granted
some permissions I am setting up a
policy right so this activity gives me a
history of what things I have done over
the past couple of months while working
on Google Cloud platform
now on the top left corner you have the
hamburger menu which you can click on
this so that's your navigation menu and
when you click on this this shows you
home it takes you to the marketplace it
specifically takes you to billing you
can always look at apis and services so
here in API Services I can pretty much
go to a dashboard code and I can see a
report on the traffic or errors or
latency and the kind of apis which are
available so you have compute engine API
you have big query API big query data
transfer API big query storage cloud
data proc so these are some of the apis
or Services I've used in past might be I
was evaluating a product might be I was
using a particular product so you have
whenever you would want to use a
particular service from Google Cloud
platform form you would be enabling
these apis so here we see some apis for
data proc you have logging monitoring
you have resource manager API you have
cloudsql which allows you to directly
use MySQL or postgress you have cloud
storage right and so many apis so if I
would want to enable a particular API
which is not right now required but then
it's good to know you can always click
on this one you can search for an API so
for example if I would say data proc
right and that shows me the cloud data
proc API which manages Hadoop based
clusters and jobs on Google Cloud
platform so I can spin up a Hadoop
cluster and I can start running some
jobs on a Hadoop cluster on demand and
as I'm done with it I can just get rid
of it so this is an API which I would
have to enable and then for every
particular service you also have an
admin API which you would enable now go
going back so coming out from this API
Library I got into API and services now
there is you can look into the library
you can look at credentials and you can
also look at different time intervals
for which you can see the usage of your
different apis now going back to the
menu you have support wherein you can
always reach out to the Google support
team if you are using a paid version
even with free trial you can try to
reach reach out and you will find
someone to help but it is always good
when you have a billing cycle reaching
out the customer care you have identity
access management in admin and this is
required when you're working with
different apis or Services when you
would want to have relevant access you
have getting started you have security
related options you have anthos which is
mainly for migration now here you can
look at your different domains such as
which we discussed so you have compute
and in compute you have different
services so you have app engine you have
compute engine kubernetes you have Cloud
functions and Cloud run you can look
into the storage aspect which shows you
big table which is usually and mainly
for your unstructured data big table
which is something which gave rise to
popular nosql databases like hbas and
cassendra you have data store which can
be used you have fire store file store
storage which can can be used to put in
data of any kinds you have SQL for
structured data you have spanner as a
service you have memory store and you
have data transfer now when it comes to
the networking domain you have all these
services such as VPC virtual private
network network related services for
your load balancing for using a
cloud-based DNS or Cloud defined Network
you have hybrid connectivity network
service tis security and intelligence
then you have other options for your
operations which can be used and here
you have different other tools which can
be used such as Cloud build you have
Cloud tasks container registry
deployment manager and many more big
data specific you have the services here
so you have data proc which can be used
to spin up your clusters you have
published subscribe messaging system
such as now Kafka which you might have
heard of originates its idea from here
so Pub sub you have data flow you have
iot core big query which is a data
warehouse package or data warehousing
solution from Google Cloud now then you
have your artificial intelligence
related services and other Google
Solutions so you can always find a huge
list of services or you can say at high
level Solutions offered by Google cloud
and we can use these to basically test
some of the solutions use them and work
work on them so I'll give you a quick
demo on different Services which can be
used here from your Google Cloud
platform now this is your Google Cloud
platform and this is your console now
this also gives you a cloud shell which
can be activated so that you can work
from command line and you can always
find lot of documentation on that so you
can also set up your Cloud shell that is
SDK on your Windows machine and if you
have set it up then basically you could
be doing something like gcloud right if
the cloud has been set up so in my case
I had set up the cloud SDK and basically
I can get into that by looking at what
path I have set up so Cloud SDK and then
I can be using it from my Windows
machine as per my comfort I can also
activate the cloud shell here which will
basically open up a terminal and at any
point of time you can open up this one
Cloud shell in a different window it is
preparing the cloud shell where it will
by default set up your project it will
set up the metadata and now I am logged
into my Google Cloud account from
command line and here I can basically
use gcloud right and that basically
shows you the different options which
are available which you can be using so
if you would want to use a particular
service you can also try giving a help
and that shows shows you how do you
manage your Google Cloud platform right
so you have different options for
billing to work with your different
services and basically you could be
working on Google Cloud using this Cloud
shell from your command line usually for
people who are learning Google cloud in
the beginning it is always good to go
for console and use your different
services from here in an easier way but
as I said you can always use the command
line for example if I would just go
ahead and type
gcloud create
instances and that will directly take me
to the cloud console documentation which
shows you different options which you
can use to work with instances so I
could do a g-cloud compute instances
create and then I can give my instance
name and so on and I'll show you some
examples on that so you can be using
your Cloud console right that is your
Cloud shell and you can straight away
start working from command line however
I would suggest using console in the
beginning and when you are well
experienced then you can start using
Cloud shell to do things from command
line and when you are fully experienced
you can always switch and certain things
are usually useful or easier when done
from command line and some are easier
when you do it from the console and you
can use any one of these options now we
can go to Google Cloud console now as of
now I can close this one I I still have
my cloud shell open if I would want to
look into it I can click on this one and
I can straight away go to compute engine
where I would want to work on creating
some instances on Google Cloud platform
using the compute engine service and
then basically connecting to those
instances and basically trying out some
basic things so you can click on VM
instances and then once this comes up I
can always create some instances now if
you see here I have some instances
already created right and I can continue
working on those I can create new
instances I can use different options
while creating instances and I'll show
you that in a demo in quick seconds so
let's have a quick demo on setting up
gcp instances now before that let's have
a quick recap so when you talk about
instance or a virtual machine it is
hosted on Google's infrastructure right
and you can create your Google Cloud
instance using this Google Cloud console
that is by clicking on this and then
going to compute engine and clicking on
VM instances now you can also do that
from Google Cloud command line tool that
is cloud shell and you can be doing that
using compute engine API so compute
engine instances can run the public
images for Linux or Windows servers that
go Google provides you also have option
of creating or using custom images that
you can create and import from your
existing systems you can deploy Docker
containers which are automatically
launched on instance running containers
optimized OS now when you talk about
instances and projects always remember
that in each instance belongs to a
Google Cloud console project and a
project can have one or more instances
when you talk about instances and
storage options each instance has a
small boot persistent dis which I will
show you in further screens that
contains the OS you can add more storage
space if needed and when you talk about
instances and network a project can have
up to five VPC networks so VPC network
is virtual private networks wherein you
can virtual private Cloud networks where
you can have your resources within your
own own subnet and each instance belongs
to one VPC Network now instances in same
network can communicate with each other
through local area network protocol an
instance uses internet to communicate
within any machine so that could be
virtual physical or outside its own
network when you talk about instances
and containers you should remember that
compute engine instances support a
declarative method for launching your
application using containers now you can
create a VM instance or a VM instance
template you can provide a Docker image
and launch the configuration so there
are different ways in which you can
create these instances and once you
create these instances you can say for
example you're creating a Linux instance
you can associate SSH keys with your
Google account or your G Suite account
and then manage your admin non-admin
access to the instance using IM roles if
you connect to your instance using
gcloud or SSH from console which we will
see later compute engine can generate
SSH keys for you and apply that to your
Google cloud or G Su account now what we
can do is we can see how we can create
your Google Cloud instances from your
console or from the command line let's
have a look in creating instances using
GCB console now that we have learned on
some basics of Google Cloud platform
what are the different Services what are
different domains basically looking at
your Google Cloud console or even Cloud
Shell let's go ahead and create some VM
instances now that's from your compute
engine service and let's try connecting
to these instances and see how this
works let's also see what are the
different options which are available
when you would want to create the
virtual machine instances here so when
you click on your drop- down from the
top left and choose compute engine so it
brings you to this page so I can show
that again so you can click on compute
engine click on VM instances and that
basically brings you to this page now
here it tells you compute engine lets
you use Virtual machines that run on
Google's infrastructure so we can create
microv VMS or large instances running
different
distributions of Linux or Windows using
standard images that is public images
and you can also have your own image so
let's create a VM instance by clicking
on create now that's basically helping
me to create an instance here so it
shows me the instance name I can give it
something so let me say C1 now I can add
labels so what is label it basically
allows you to organize your project at
arbitrary labels as key value pairs to
your resources this so this is basically
categorizing your labels and projects if
you have multiple projects now remember
if you have your Cloud console and if
you have created your free trial account
it will allow you to do these things if
not you may have to go back to the
billing section and see if the billing
is enabled which also means that when
you are creating your Google Cloud
account it will ask you to Keen your
credit card details but they do not
charge anything or they might charge
much might be $1 or one rupee depending
on your location and that's also
refunded but that's just to verify your
card now once I've given the name I can
choose a region so I would basically
choose Europe since I'm in Europe I
would be clicking on Europe West 3 and
here I can choose an availability Zone
availability zone is basically to make
your services or instances or any other
resources highly available so you you
can choose one of the availability zones
now I would choose savs 3 now this one
we can scroll down and here it says
machine configurations you have general
purpose machines you have memory
optimized machines which is M1 series
and you can always go back to the Google
Cloud page and see what a particular
kind of machine specializes in so I
would click on generals purpose and in
general purpose you have different
categories so you have N1 which is
powered by Intel Skylake CPU platform or
you have E2 which is CPU platform
selected selection based on availability
so let's have N1 selected now this one
shows me the machine type and if you are
using your free tier account then you
can start with correcting a micro
machine which is one virtual CPU core
you can go for a G1 small which is one
virtual CPU core and 1.7 GB Ram you can
even go up to a high-end machine and
then you can basically see see if you're
using a free account how many of these
machines you can use if I would be
selecting eight virtual CPU CES and 32
gigabyte of memory then it would allow
me to create at least two instances by
this configuration we will use N1
standard which is one virtual CPU core
3.75 GB memory now then we can also
deploy a container image to this VM
instance if you would be interested in
deploying a container image let's not
get into that right now here it shows
you the boot dis and it shows you dbn
gnu 9 Linux 9 what I would do is I can
go for this distribution or I can choose
a Linux distribution of my choice so
here you have public images you have
custom images you also have snapshots if
you have created backup of your previous
images here I can choose for example
ubben 2 and then I can choose a
particular version so let's go for ubben
2 18.0 4 you can go for the latest one
also 18.04 would be good enough and here
it tells me what is the boot dis so you
have ssds or you have standard
persistent discs now ssds are little
expensive in comparison to your standard
persistent discs or your sdds but then
ssds are faster so as of now we can
choose standard persistent dis as it is
and we can let the gigabyte be 10 now
depending on your requirement you can
can increase this you can even add diss
later that's not a problem click on
select now here I have access Scopes so
here I will say allow default access you
can also set access for each API or you
can give full access to all Cloud apis
so that based on your requirement you
can anytime change later also we will
also say allow sttp traffic and we can
also choose allow https traffic that b
basically allows me to access this
machine or Services which are HTTP based
accessible from this machine now I can
just click on create however it would be
good to basically enable connectivity to
this machine now we can do that in
different ways one is when you bring up
your machine it will have an SSH access
which you can log in from the cloud
platform here itself or what you can do
is you can create a private and a public
key using some softwares like puty or
puty gen so for example if you do not
have that on your machine you can
download you can just type in download
puty that takes you to the p.org page
and here you can click on download puty
and scroll down which shows you for your
64-bit machine which I have in my case
you can download putty.exe which is
basically your SSH inet client to
connect to your machines you can also
use puty gen which will be allowing you
to create a a private and a public key
which I have done in my case let me show
you how so what you can do is you can go
to puty gen to begin with and here you
can click on generate now then to have
this key generated just move your cursor
on the top here in the empty space and
that creates your key you can give it a
name so for example let's give a
username I would give hdu now I can give
a password for this one so let me give a
simple
password and what I can also do is I can
copy this public key from here and for
my later usage I can just keep it in my
notepad file which I can use later and
I'll show you when so now we can save
this private key and this will basically
allow me to save my private key I can
choose desktop and I can give it a name
so let's say new key new key and that
will be getting saved in a PPK file so
let's save it and that's done so we also
have our public key and we have saved
our private key now we know that when
you would want to connect using SSH you
need your private keys to the client and
public key also has to be existing so
let's take this public key so let's do a
contr a I'm going to copy this and I'm
going to come back to my Google Cloud
console and here you can click on
security so you can click on the
security tab here scroll down and just
give your public key once you give that
it resolves and shows you the name and
this is good enough so that I can use my
SSH client to connect to this machine I
can click on Create and this will
basically create my VM instance it will
take some time and then your instance
will have an internal IP which will show
up here external IP and it will also
show you options to connect to these
machines so this is is my internal IP
this is my external IP which I can use
to connect from a client I can easily
connect from the option here which says
SSH and I can say open in a browser
window I can even open this in a custom
Port I can look at the g-cloud command
which you can give from cloud shell or
you can use another SSH so let's first
do a open in browser window and let's
see if this connects so we can easily
connect to our instance
the U 28 instance which I just set up
here easily in couple of seconds now
this is trying to establish a connection
using your SSH keys and when you do that
it also basically brings up this web
browser so I'm already connected it
shows my username which is my cloud
account username and I have been
connected to this machine here using SSH
it did not ask me for any password and
basically now I can just check what do I
have in my Linux file system right and I
can anytime log in as root by doing a
Pudo Su for example let's try installing
a package and I can say app get install
whm or app get install WG get or aptg
install open SSH and all these packages
are already existing so not an issue now
I can start using this instance I can
just look at the disk what is available
okay now we gave around 10 GB out of
which we see 8.3 GB here for the dev SDA
1 and then 1.8 GB available and you can
continue using this machine this was the
easiest way of connecting to a VM
instance using
SSH now what we can also do is I can
just leave this and I will now try to
connect using an external SSH client
right and here you can copy the public
IP so when you want to connect to an
instance
you will have to get the public IP also
remember that if you select and stop
this machine which will stop your
billing counter and if you start it
again the internal IP will remain same
but the external IP is the one which
will change I can obviously select this
machine anytime and I can do a cleanup
and I can delete it I can do a start of
the machine if it is stopped and I can
even import the virtual machine to be
used later later so there are different
options which you can always use so this
is my instance and if you would want to
look at the details click on this one C1
and that should basically allow you to
look at the details so it shows you what
is the instance ID what is the machine
type is it reservation specific what is
the CPU platform what's the zone and all
the other details at any point of time
if you would want to edit you can always
click on edit and you can change the
details as you need now you can also
look at the equivalent rest command to
basically use the rest API to connect to
this instance for now I have copied the
public IP and I would want to connect it
using puty so let's go in here and let's
give it the host name so I can give
Ubuntu I can give my IP address so
that's in my session now I will click on
SSH I would go into authentication I'll
click on browse and this is where I need
to choose the PPK file so this is the
one which we created new key let's
select this and then I can come back to
session I can even save this and I can
call it as my instance one let's save it
and you can create any number of
instances so you see I have created
different instances here for my Google
cloud or Amazon related instances and I
can click on open it says the servers
host key is not cast in the registry
that's fine just click on yes and
basically it says no authentication
method supported now this could be
because we have not enabled your SSH
access so let's look at that so now
let's see if we were trying to connect
using puty what was the issue here so if
I go back to my puty select my instance
load it it says Port 22 I'm giving the
username which is window or sorry that's
the wrong username we gave and that
might be the reason we had set up the
user as s duu so let's save this again
and now let's try connecting to this one
and it asks for my password and you are
able to connect this right now if there
was any other issue related to network
connectivity then we could look at the
rules the inbound and outbound rules
which allow us to look into the machine
now we are connected to our machine here
using hdu user I can log in as root and
I can continue working so not only from
the SSH within the cloud console but you
can use an external SSH client and
connect to your machine so this is your
open to machine and we can basically
look at the space and that basically
confirms we are connecting to the same
machine which shows 8.3 GB here and 1.8
GB here which we were seeing from the
ssh in the browser now let's close this
and let's go back back to our instance
page now here you can always look at the
network details and this will show you
your different kind of rules that is
ingress or egress rules which basically
allows to connect to this machine from
an external network or for this machine
to connect to an external network so
here we have different firewall rules
which shows default allow HTTP that's
your Ingress Rule and it tells you apply
to all it shows me what are the IP
ranges where I can specifically give the
IP of my machine it shows the protocols
it shows what are the different ports
which you have used for these services
for example RDP or SSH which shows 22
you have icmp HTTP and https now anytime
if you would want to make a change to
these rules that can be done by going
into your network details and say for
example you would want to work on
firewall rules so we have these
firewall rules here you can click on
this one so right now we are looking
into the network domain and we are
looking into VPC Network right and this
shows me what are the different rules we
have now if I would want to create a
different firewall rule for a different
protocol I can always click on create
firewall rule I can give it a name okay
I can say what if you would want to turn
all the firewall logs you can basically
say what is the kind of traffic traic so
Ingress applies to incoming traffic and
egress applies to outgoing traffic and
you can then basically choose what are
the IP ranges from where you want that
connection to be coming in or to going
out you can choose a particular protocol
you can give a protocol here with comma
separated values and you can create a
firewall rule so this might be required
depending on the services which you are
running wherein you might want to enable
your access to your machine from an
external service or to an external
service so you can always go to network
details from here you can then go into
firewall rules create a firewall rule
apply that to your instance and restart
your instance so as of now we don't need
to create any network details here
because my Ingress or egress rules are
already available right now I can
basically then have my instance stopped
and removed mov so I can just do a stop
or since this is running the ideal wave
would be to do a stop I could also do a
reset now what is reset do reset does
not basically delete the machine what it
does is it does a cleanup of the machine
and it brings it to the initial state so
sometimes we might have installed
certain things on our machine we would
want to clean them up and at that time
reset can be useful I can basically
click on delete right and I can select
this and I can do a cleanup and this is
good always when you're are using a free
trial account try to use different
Services play around with them and then
you can clean up so that you do not
waste your free billing credit right and
you can use it for Meaningful stuff now
I have clicked on delete and within few
seconds my instance which I had created
will be deleted also to remember is if
you are creating multiple instances then
you can connect from one machine machine
to other machine using SSH by using the
private file so for that we can learn in
detail later so this is just a simple
example of using your compute engine
creating your instances connecting to it
from an internal SSH or from an external
SSH client such as puty where you have
already created your private and public
Keys now I can click on the browser here
and then I can basically come out and I
can basically be looking into any
particular service so we just looked
into compute engine right you have
different other options you have
instance groups you have instance
templates for example let's click on
instance templates here and that
basically shows you that you don't have
any instance template and this basically
facilitates say for example you are
working as a admin and you would want to
create an instance template so that
using that you can describe a VM
instance and then you can basically
use this template to create different
instances you can go for soul tenant
nodes you can look for machine images
you can also look at your disks you can
create a snapshots and you can look at
different options here now let's come
back here and let's click on home and
that should take you back to your
homepage which basically shows you if a
particular API which you have used
recently which shows me in the graph
here so I can go to the API overview
right right and that basically shows me
if there were any errors if I was using
the compute engine API to basically
create a VM instance and that's why we
were seeing some spike in the graph so
this is a quick demo of using your
compute engine service provided by
Google Cloud wherein you can create VM
instances and use those VM instances for
your application installation for any
other purpose now that we have seen how
you use your Cloud console to create an
instance and also clean it up let's also
understand how you can do using your
command line options and let's see what
it takes or what are the different
commands which you can use to create
your instances now you can always when
when you're creating an instance you can
use compute engine which Provisions
resources to start the instance so
instance basically has has different
states which we can see when we are
creating the instance so you basically
start the instance instance moves into
staging that is prepared for your first
boot finally it boots up and then it
moves into running so when you look at
instance states which we will create
instance and see it will basically have
different states such as provisioning
where resources are being allocated for
instance but instance is not yet running
then it goes into staging where
resources have been acquired and
instance is being prepared for your
first boot then instance is booting up
and running and if you are stopping an
instance it goes into being stop status
and it would be moved to the terminated
option you can also do a repairing of
instance and finally you can terminate
your instance or clean it up by stopping
and then deleting it now when you say
stop and resetting an instance you can
stop the instance as I showed earlier if
you no longer need it but if you need
for future use you can just use the
reset option which will basically wipe
the contents of instance or any
application State and then finally you
can stop it and have it terminated now
when you would want to do that using
your Cloud console uh we have seen the
options now let's also see from the
command line tool how you can do it it
so here I have the cloud shell which I
brought up from here and I basically
opened it in a new window so commandline
tool enables you to easily manage your
compute engine resources in a friendlier
format than using your compute engine
API now g-cloud which is part of cloud
SDK is the main command here and then
you can always autocomplete the
different options here so when you would
want to create or work on gcloud you can
just type in gcloud here and then for
example I could just say help to see
different options of g-cloud which will
show me different options which you can
use here now we would be interested in
compute instances so I could also do a
gcloud
compute compute instances and then I can
basically say create and then I can do a
help now that should show me different
options which work with gcloud compute
instances create command which is
expecting an instance name so your
Google Cloud SDK which we can set up on
our Windows machine or even on your
Linux machine is set of tools that helps
you to manage resources and applications
hosted on your gcp that is your Google
Cloud platform now here you have options
such as g-cloud which I'm showing you
right now you you have Gs util and then
you have BQ so that also can be used so
you can set up a Google Cloud compute if
using g-cloud now what we can do is if
we are setting up our SDK on our Windows
machine then we would have to do a
gcloud in it which basically initializes
your configurations for
gcloud now here we are using a cloud
shell which was started from the console
and we don't have to basically give your
gcloud init command because it's already
initialized now you can always look at
your default Zone you can look at your
region what is being used all those
things are coming from the metadata
which is being used so for example I
could be looking at the metadata for my
particular project by just doing a
gcloud and then I can say
compute and I would be interested in
Project info so I can just do a project
minus info and then I can do a describe
and then I need my project ID so I can
say minus minus project and I can get my
project ID from here so you can click on
this one and that's my project ID so I
can click on this one and here I can
just do a right click and if it does not
paste then you can do a control V and
then I can try to look at my project
info so this basically will give me the
metadata which is by default set and we
can always look at what are the regions
or what is the Zone which has been set
so if it has been set so I'm looking at
my details it is showing me my SS keys
and then it can be using your default
region and your def default available
zones it also shows my username and
other details so this is basically to
look at the metadata which is available
now at any point of time I can basically
say add metadata I can basically choose
metadata option and I can say my default
region should be Europe which I was
choosing earlier so I can just bring up
this command again and what I can do is
I can say here where I have gcloud
compute project info where I did a
describe earlier now what I can also do
is I can just say add
metadata and then I can specify what is
the metadata I would be interested in
adding I can then say Google
compute
default region and then I can basically
give a region for example Europe and
then I can say West
3 and if you are not well experienced
you can always do it from console or you
can be doing it from here so I'm giving
Google Cloud compute Google compute
default region then I can also give a
Google compute default
Zone and then I can pass in a value for
default zone so I can say Europe West 3
and then basically I can give an
availability zone so if it is basically
giving me some error where I'm trying to
passing these values so I can just give
it this way and then it basically says
that if you can look into particular
help to see what is the command which
you would have to do now I can basically
do a
gcloud in it here initial configuration
and this basically says that it is
initializing my default configuration it
says reinitialize this configuration
from cloud shell you want to create a
new configuration so if I had updated my
metadata then basically I could just do
a cloud in it and I could be
reinitializing my default configuration
or properties which I have passed in so
as of now I will not activate or change
the default region let's go for a simple
way in which you can create your compute
engine so for example I'll just say one
and it is reinitialized izing it asks me
what is the username and let's select
that it says what is the project and
let's select that and do you want to
configure a default compute region and
zone right and I will just say Yes And
basically then it shows me different
options which we have here so there are
too many options here and then here we
were interested in Europe West 3 so
let's choose 21 right
and then that basically allows me to
choose my region and my zone so it also
gives you some specification so it says
your project default compute Zone has
been set to Europe West 3A you can
change it by running g-cloud config set
and you can give a compute zone right so
I can always give these commands I can
get help information here so I can just
say gcloud config set and I can be
specifying the compute zone so I can say
compute SL Zone and I can give a Zone I
can say compute SL region and I can give
a region name if I would want to do it
or the easier ways like what I did right
now so you can basically do a command
g-cloud in it and then basically it
allows you to change your configuration
or set default things here you can all
the times you can say gcloud config
unset to basically basically remove a
compute zone or a compute region now
there are different ways so if you were
working on a Linux machine you could
always use an export command something
like this so you could do export compute
sorry Cloud
SDK and then you can say compute uncore
Zone and then give your Zone name or
compute _ region and give you your
region or you could add it in your D RC
file right now that is when you have
your Cloud SDK set up on your Linux
machine or on Windows machine and you
would want to specifically set a Zone
and a region for all your compute
related resources so we don't need to do
that the default settings are already
given here right and what we can do is
we can start by quickly looking into
g-cloud compute instances options so I
can say gcloud compute
instances and then I can just do a list
at any point of time if you would need
help you can just do a gcloud compute
and then say minus minus help or I could
just do a g-cloud compute and that shows
me different options which I have here
from which I use instances I can always
type instances and again hit enter and
it shows me different options what you
would want to do so I can initially just
type list which should show me what are
the list list of what are the instances
available and as of now we don't have
any instances I can always do a list and
then I can specify minus minus format
and then try to get the information in a
Json format or EML or minus minus format
text so you can always do a list you can
do a filter so there are different
options with your list and you can you
can try doing a help here and that
basically shows you what are the options
so for example if I do a help and it
shows me with list what are the things
you can do so you can give a name you
can give a regular expression you can
say in particular Zone you can use a
minus filter so there are different
commands which are available and you can
always find all those options here as I
showed you earlier so now what we would
be interested in is basically going for
your compute instances I can always do a
SSH and I can create an instance I can
add and remove meta data right for my
instances by giving a particular Zone by
giving a particular region and if you
would want to do that now here what we
can do is we can basically create an
instance by just giving a name to that
particular instance and we can then go
back to our console and see what has it
done so I can say here create so that's
an option let's see what does the create
do so it says okay you are giving a
create option but you would have to give
a name so let's say let's call it E1 and
that will be the name of my instance and
this one is an easy command from your
Cloud shell which basically creates an
instance you see the Zone which has been
set it is the standard machine type it
is not preemptable has an internal IP
and it has an external IP now I have
created an instance and here I can just
go back and then I can just do a Refresh
on this page and that already shows me
the instance which I have created and
then you can use the same method to
connect to it using an SSH so I have an
instance created from my cloud shell and
what I can do is I can basically look
into instances and see what are the
different options with instance so if we
did a create right you have an option
delete we did a create you have an
option delete you can be then deleting
the instance from the command line or
you can use other options so you can do
a list you can do a stop you can start
so I can basically do a stop and let's
say even let's go ahead and do a stop
commands are pretty easy here to
remember or you can always use the help
op option and now I'm trying to stop the
instance and then basically I can go
ahead and delete it so this is a simple
way where I created a instance from the
command line or from the console which I
showed earlier and similarly you can be
working with other options so now I've
created stop the instance let's do a
listing to see if my instance shows up
it shows up right and it says the state
status is terminated so you have stopped
it it's in the terminated status and now
what I can do is I can go ahead and
delete
it so it says this will be lost are you
sure you would want to continue just say
yes and that should take care of
deleting your instance so this is a
quick demo on creating your instance we
have already seen how you can connect to
these instances using SSH now that we
have created instances
let's also see how to use Google Cloud's
storage service which can be used to
load data or upload data so for this we
will have to look into your Google cloud
storage options and here you can look in
cloud storage so let's go back here on
the top which shows me different
Services which we have here and let's
look into storage so this one shows me
your storage option now you can click on
browser and that basically shows me your
storage browser which shows me on the
top you have options for creating a
bucket now Google Cloud Storage allows
you to store any kind of data here the
easiest and the simplest way would be by
using Cloud console although you can
again use cloud shell and in that you
can use your GS util command and GS util
basically has has different options
where you can be using say for example I
would want to work on buckets so I can
be using MB and then I can use my
command line option to create buckets I
can put in data there I can browse it
and I can access the data from command
line so let's create a bucket here let's
click on this let's give it a name so
let's say my data important that's the
name now I can click on continue
straight away I can look into all of
these options if I'm interested in so
you can basically be looking at your
monthly cost estimate in the beginning
now I can click on continue or you can
say choose where to store your data and
this one shows you different options so
you have region
specific so let's also give the bucket
name with all lower case that's what is
required yeah so coming back to the
location type you can choose multi-
region which which basically allows High
availability so your bucket or your
storage option will be accessible across
regions you can also give dual region
and high availability and low latency
across two regions I can also say region
specific so for our use case we can just
give region specific which can keep our
cost low but in business use cases you
would be going for multi- region now
here you have location and I would again
go for say Europe and let's choose
Europe west3 Frankfurt it is always a
good practice that when you create your
instances when you create your storage
or you use different Services try to
have a geographical region Chosen and
then you would try to put things or your
services within the particular region
within a particular Zone unless you
would want to make it accessible and
available across regions now I can then
choose a default storage class so when
you say default storage class there are
different storage class and each one is
for a different use case so you have
standard which is best for short-term
storage and frequently accessed data you
have nearline so this is basically best
for backups and data access less than
once a month you can also have cold line
so these are basically like your cold
storage or freezing storage which you
might have heard generically as terms so
you can choose one of these storage
class classes depending on what will be
the use case for this particular storage
bucket so let it be standard now how to
control access to objects so you can
basically say specify access to
individual objects by using object level
permissions now you can give permissions
to the bucket you can just say uniform
access to all objects in the bucket by
using only Bucket Level permissions so
you can choose that you can also go into
advanced settings and here you can see
different ways in which you can have
configuration set up now you can also
have a retention policy to specify the
minimum duration where that this buckets
object must be protected from deletion
and you can set a retention policy we'll
not get into all that we will just first
try creating a bucket so just click on
Create and that should create your
bucket wherein I have my bucket now I
can click on overview to see the details
what is the region which region it
belongs what is the storage class
anytime you can always click on edit
bucket and make some changes here you
can look at the permissions so bucket
users F Grand access allowing you to
specify access to individual objects and
then you can basically look at who has
access to this so in my case editors of
the project they basically are the
bucket owners owners of project viewers
of the project right and you can
basically choose what kind of access you
need so for this you can always go into
cloud storage and then you can decide
what kind of access you would want to
give whether that's a storage admin it's
an object admin object Creator object
viewer and so on you can always look at
storage Legacy and for any other
services depending on what apis you have
enabled right you can always control
your per missions so right now it is
storage Legacy bucket reader and that's
fine and this one is bucket owner and
then might be I was using some other
services like data proc which uses cloud
storage and that's why I've given data
proc service agent also so these are
some of the members you can remove you
can view by specific members you can
view by roles so what are the different
roles which have access to this so it
says storage Legacy bucket owner there
are two owners based on this particular
project so these are autocont controlled
but then you can add or remove machines
you can save storage cost by adding a
life cycle rule to delete objects after
the duration of current retention policy
so you can add different policies and
you can basically control your bucket
now my bucket is already created right
so I can go back and then I see my
bucket is already here I can click on
this option and you can anytime edit the
bucket permissions you can edit the
labels the default storage class you can
just go ahead and delete the bucket you
can export it to Cloud pup sub so
basically if you would want to have the
content from this bucket being
accessible in a message queuing system
you can go for Pub sub you can process
with Cloud functions and you can scan
with cloud data loss prevention so there
are different options which are
available we can always select this
bucket and delete it now I can click on
the bucket and that basically shows me
different ways in which I can upload
some data here so I can just click on
upload files and here then I can choose
some files so for example I'll go in
here I'll go into data sets and I have
different data sets so for example let's
choose this one which is a CSV file and
then I'm just uploading this to my cloud
storage right it's as simple as this so
you can drag and drop your files or you
can just upload your files and my file
is uploaded here now I can basically
edit permissions for this one right so
this is in the bucket so anyone who has
access to this bucket can basically
download this file it can they can copy
move or rename this you can export it
and you can look at the permissions of
this file so let's look at edit
permissions and it says for this project
whoever is the owner it has access I
also given a specific user my Gmail ID
and I've given access so at any point of
time you you can just say add item and
then you can start giving different kind
of accesses so let's click on cancel
here now my data is already uploaded
into this particular bucket and that's a
simple usage of your cloud storage now
what we can also do is I can basically
select this and I can delete it I can
also create specific folders and then
basically uh load data into it it I can
click on this one I can just do a
download and then I can download it
anywhere on my machine so let's go to
desktop and let's download this file so
we not only uploaded some content in the
bucket but we also downloaded that in a
different location which will be
accessible now what I could have also
done is I could have created a folder
here and I could have specified say for
example immediate immediate data
okay and I'm clicking on this one so
that's my immediate data I can click on
this one and now I can upload my data
specifically to this particular folder
by using the same mechanism you can just
do upload file let's choose air
passengers let's do a open and my file
will be
uploaded so you can always choose what
is the retention expiry date for this
one so as of now there is nothing right
but you can be deleted objects can be
deleted or modified until they reach
their minimum duration you can control
all of that you can basically download
it right you can copy it and you can
move it and rename it so this is a
simple example where I created a
particular bucket right now if for
example you click on this transfer so it
says cloud storage data transfer
products have moved you can now find
storage transfer service on premise data
and transfer Appliance a new data
transfer section right so you can always
go back to cloud storage you can also
look at transfer options which are
mainly when you are using a on premise
service and you would want to upload
data in a Google Cloud right so this is
my bucket here now I can go to Cloud
console and here what I can do is if I
would be interested in working so I can
just say GS util right and then we have
uh for example let's try a help okay and
that basically shows me my GS util now
you can always go to Quick Start GS util
tool and this is one more way wherein
basically you can do it from the command
line so working with buckets so you can
do a GS util MB minus B and then on a
particular Zone if you would be
interested in and then you can say GS
colon and give a name so my awesome
bucket this is how you will create a
bucket which will show you it is
creating a bucket and then basically you
can upload an image or some data from
internet you can just do a w getet
download the file and then you can just
do a GS util copy command and that
basically will pick up the file from
your Cloud shell location put it in your
bucket once you have done that you can
always do a copy right so here you're
doing a copy from your local machine
that is your cloudshell machine to your
bucket
and you can do the reverse of that that
is you can do a copy and you can point
your bucket and the file and download it
to your desktops so you can just
download that using the command line and
you can copy the object to a folder in
the bucket so that is by creating a
particular folder and you pushing the
file into a particular bucket you can
list the contents of a bucket using LS
and then give your bucket name so GS
colon so we can just try this one to be
simple and rest you guys can try so here
you can just do a GS util you can do a
LS GS colon SL slash and then I need to
give my bucket name so in my case the
bucket name was my data important so
let's try that so let's say my data
important and I'm trying to list the
bucket and the content it has right and
then you have a folder and then you can
look into the folder and look into the
files so this is a simple quick option
where in you can use your Cloud shell
you could be using your Google Cloud SDK
from your local machine or you can be
using Cloud console to create a bucket
upload some data on it download the data
see if the data is accessible and that
basically shows you the power of cloud
storage where you can easily upload any
kind of data now what we can also do is
as you're using a free account or even a
paid account unless and until you would
want to keep the bucket you can select
it and you can just go ahead and delete
it so this will basically ask you to ke
the bucket name and let's say my data
important you need to confirm your
bucket name click on confirm and you
could have done that using GS util and a
delete command from the command line
that is from cloud shell so we have now
created a bucket we have uploaded some
data into it we saw how you can download
it or create a folder and upload some
specific data into it and also you can
do the same thing using GS util tools
wherein you can list your bucket create
your buckets delete it create some
folders into it and do everything from
the command line so this is in simple
way you can use your gcp where either
you can spin up your machines or you can
use cloud storage to to basically use a
storage or a easy to use instance on
Google Cloud platform so if you are
ready to embark on this exciting career
path look no further than simply learn
skel Tech postgraduate program in cloud
computing this comprehensive program
will equip you with the knowledge and
skills needed to navigate the cloud
landscape with confidence dive deep into
Cloud architecture deployment models
security and migration strategies
explore plat forms like Amazon web
services Microsoft Azure and Google
Cloud platform to build your Cloud
expertise don't miss out on this chance
to transform your career and join the
ranks of successful Cloud professionals
click the link in the description box
below to discover more about the cloud
computing Basics course to know more
about this course click on the link
mentioned in the description box below
the cloud is much more than just a
reliable storage solution the year 2021
like the year before proved to be a
watershed even for cloud computing it
gave businesses more freedom to operate
in the face of
covid-19 cloud computing according to it
experts will be at the Forefront of all
Technologies used to address key
businesses concerns in the coming
years cloud computing has generated more
anticipation excitement and investment
than any other it area in the last
decade according to IDC the cloud will
increase at a rate of 20 2% next year
with a market value of $277
billion as a result there will surely be
a significant demand for cloud
professionals therefore a right
certification in cloud computing can
help you earn a handsome salary of
$45,000 to
$227,000 in the United States and close
to 16 lakh to 24 lakh rupees in India so
let's have a look at the top 10
certification in cloud computing
the first one is AWS certified Solutions
architect
associate AWS certified Solutions
architect associate is a set of
technical certifications offered by
Amazon web services for beginners and
professionals working in Enterprise
architecture and solutions
architecture this certificate AIDS in
the identification and development of
personnel with crucial capabilities for
cloud
implementation AWS certified solution
architect associate certification
verifies your competence to build and
deploy distributed systems on
AWS so this certification is for persons
who can do solution architecture such as
deploying and securing web applications
and who have worked with AWS services
for at least a year and its difficulty
level is
easy skills required for this
certification is understanding of
specific programming or scripting
languages like Java Python chash and
many other programming language
available data storage fundamentals
networking AWS service selection Cloud
specific patterns and
Technologies moving on here are a few
certification details you will need to
proceed with its
examination cost of examination is 150
USD and the average annual salary is
$3,883 the duration of this examination
is 130 minutes with number of questions
65 you have multiple choice and multiple
response questions and the passing score
is
70% and the renewal time of the
certification is 2
years the company's hiring are Amazon
IBM Cap Gemini M tree and equia these
are the top companies that
High second is AWS certified Cloud
practitioner the aw certified Cloud
practitioner certification is a
foundational level test designed for
people who can successfully show an
overall understanding of the AWS Cloud
according to
Amazon this exam verifies a candidate's
understanding of essential Cloud
infrastructure and Architectural
Concepts as well as key AWS services
the certification provides an overview
of AWS key Services as well as security
and network so this is the idle C Cloud
certification for beginners or anyone
interested in learning more about cloud
computing and the AWS Cloud
platform so the difficulty level is
easy the skills required for this
certification
is oversight on creating architecture
for AWS platform ability to deploy AWS
Solutions and applications building
Cloud
Solutions developing plans for the
adoption of cloud Solutions management
and monitoring of cloud
platforms moving on here are a few
certification details you will need to
proceed with this examination the cost
of examination is 100 USD average annual
salary is
$3,930 examination duration is 90
minutes number of questions is
65 types of questions are multiple
choice and multiple response
question passing score 70% and again the
renewable time for the certification is
2 years and the famous company hiring
are Amazon net app enture Deo and solal
LLC moving on third is AWS certified
developer
associate AWS C certified developer
associate is an Amazon web service
examination that measures a person's
ability to successfully demonstrate
deploying and maintaining applications
on the ews
platform this is the ideal Cloud
certification for programmers and
software developers interested in
building Cloud native applications and
the difficulty level is
intermediate skills required for the
certifications are use the AWS
Services API CLI and software
development kits to write
applications identify key features of
AWS Services understand the AWS shared
responsibility model use a continuous
integration of continuous delivery
pipeline to deploy application on AWS
and use and interact with AWS
services so here are the few
certification
details cost of examination is 150
USD average annual salary is
$130,200
exam duration is 130 minutes number of
questions is 65 type of questions
multiple choice and multiple response
questions the passing scor is 70%
renewal time is 2 years and the company
hiring are Amazon IBM Cap Gemini TCS and
Oracle
fourth is aw
certified system operation administrator
associate the AWS
certified CIS Ops administrator
associate certification is designed to
demonstrate technical skills for system
administrators and Cloud operations jobs
this certificate assist organizations in
identifying and developing personnel
with crucial ability ities for cloud
implementation the ability to develop
manage and operate workloads on AWS is
demonstrated by earning the
certification this associate
certification is for professionals who
have at least one year of experience
with AWS deployment management and
operations it teaches you how to
identify the right service for your
needs and the difficulty level is
intermediate so these are the skills
required for the certification
understanding of AWS tenets hands-on
experience with the AWS CLI and sdks
tools understanding of Network
Technologies understanding of security
concept with hands-on experience in
implementing security controls and
compliance
requirements understanding of
virtualization
technology moving on here are a few
important details related to this
certification so cost of examination is
150 USD
average annual salary is
$1,966 the duration of examination is
130 minutes and the number of questions
is 65 which are multiple choice and
multiple response
questions with passing score of 70% and
renewal time of 2 years and here are the
companies hiring Amazon IBM Cap Gemini
TCS and Oracle
fifth is Microsoft certified Azure
fundamentals Azure fundamental
certifications allows you to demonstrate
your understanding of cloud Concepts
Azure Services Azure workloads Azure
security and privacy and Azure pricing
in support the Azure Foundation
certification intended for people who
already have a basic understanding of
cloud services it will explain you Cloud
Concepts as well as how to use them and
the difficulty level is
easy skills required for this
certification is the different cloud
computing
concepts mean Azure Services describing
Azure security private privacy
compliance and
Trust as your pricing in
support and here are a few certification
details required for the
certification cost of examination is 99
USD which can
vary average annual salary is
$110,000 the duration of this
examination is 85
minutes and the number of questions
varies between 40 to 60 and the type of
questions are multiple choice and
multiple response
questions the passing score for this
examination is 70% and the renewal time
is 6 months and the top companies hiring
are Microsoft Dell ESS
and
cognizant sixth is Microsoft certified
Azure administrator
associate an Azure administrator is in
charge of deploying monitoring and
managing Microsoft aure Solutions which
includes significant compute storage
Network and Security Services by earning
these this certification you'll be able
to demonstrate that you can deploy and
manage is your compute
resources the certificate will prepare
you to develop administer and monitor
cloud services such as Storage security
and virtual environments among other
things and the difficulty level is
intermediate so the skills needed for
this certification
is mean asure Services describing asure
security private and compliance and
Trust knowledge of azure pricing and
support and knowledge of different cloud
computing
Concepts and here are the further
important details needed for the
certification cost of examination is 165
USD average annual salary is
17,682
exam duration is 120 Minutes with number
of questions
varying between 40 to
60 and the type of questions are
multiple choice and multiple response
questions with the passing score of
70% renewal time is 6 months and the top
companies hiring are Microsoft asentia
TCS and
Yahoo seventh is Google associate Cloud
engineer an associate Cloud engineer
delivers and protects
applications and infrastructure overseas
various projects operations and
maintains corporate solutions to ensure
that they fulfill performance goals this
person has worked with both public
clouds and on premises
systems for programmers developers and
software Engineers this is the greatest
Google Cloud certification its Holder
will be responsible for deploying web
applications in the cloud as well as
monitoring and managing operations
and the difficulty level is
intermediate here are the some important
skills required for you to excel this
certification basic understanding of
Google Cloud platforms products and
services and basic understanding of
cloud Concepts such as virtual machines
containers and
networking and these are the few
important certification details that you
need to take care of cost of examination
is15 USD with average annual salary of
$119,450 exam duration is 120 Minutes
with number of questions 50 and the type
of questions are multiple choice and
multiple response questions with the
passing score of
70% and the renewal time is 2 years and
the top companies hiring a Google
Goldman
sets here comes the e one that is
Microsoft certified as your solution
architecture
expert to implement Solutions and as
your solution architect work with Cloud
administrators cloud dbas and clients
these this credential displays the
ability to provide advice to
stakeholders and translate business
requirements into safe scalable and
dependable
Solutions this certificate is for
experienced programmers developers and
devops Engineers who who wish to become
ashure
professionals this is the idle Cloud
certification and the difficulty level
is
hard and these are the skills required
for this Advanced
certification deploying and configuring
infrastructure implementing workloads
and security creating and deploying apps
implementing authentication and securing
data developing for the cloud and for
the Azure
storage and these are the details you
need to remember remember cost of
examination 165
USD average annual salary
$135,000 with exam duration of 150
minutes and number of questions varies
between 40 to 60 type of questions are
multiple choice and multiple response
questions with the passing score of 70%
and the renewal time is 6 months and the
company's hiring are IBM Microsoft
infosis and
medine coming to the ninth one is Google
professional Cloud
architect a Google Certified
professional Cloud architect means you
demonstrate the ability to design and
plan A Cloud solution
architecture manage and provision the
Cloud solution
infrastructure designed for security and
compliance the professional Cloud
architect exam measures your abilities
to design and plan A Cloud solution
architecture manage and provision Cloud
solution infrastructure and design for
security and
compliance this is the idle Google Cloud
certification for experienced it
professionals interested in becoming
solution Architects for Google Cloud
technology such as big table big query
and other GCB platform services and the
difficulty level is hard
and these are the skills you need to
focus
on proficiency with command command line
Linux operating system and system
operations and three plus years of
Industry
experience and here are the further
details you need to take take care of
cost of examination is 200 USD with
average annual salary of
$140,000 the examination duration is 120
Minutes with number of questions 40 the
type of questions are multiple choice
and multiple response questions with a
passing score of
70% and the renewal time is 2 years and
the company hiring are Google and
Goldman
SATs and here comes the last but not the
least 10th certification that is AWS
architect
professional the AWS certified Solutions
architect professional exam verifies
Advanced technical knowledge and
experience in designing distributed
applications and systems on the Amazon
web services platform this certification
AIDS in the identification and
development of personnel with crucial
capabilities for cloud
implementation the AWS certified
Solutions architect
[Music]
credential verifies your ability to
develop Implement and evaluate
applications on AWS under a variety of
conditions this Advanced certification
teaches you how to create and deploy
scalable web applications on Amazon AWS
servers as well as how to choose the
right service and power for your
application and the difficulty level is
hard and the skills required for this
certification
is familiarity with AWS CLI AWS apis AWS
cloud formation templates and windows
and Linux environments ability to
provide best practice guidance on the
architectural design across multiple
applications and projects of the
Enterprise ability to evaluate Cloud
application requirements and ability to
design a hybrid architecture using key
AWS
Technologies and here are the details
you need to know before applying for the
exam cost of examination is 300 USD with
average annual salary of
8,266 the examination duration is 180
minutes with number of questions
75 types of questions are multiple
choice and multiple response questions
with the pass in score of
70% and the renewal time is 2 years and
the top companies hiring are Amazon
centure IBM and M
tree so this was all about top 10 Cloud
certification so if you're ready to
embark on this exciting career path look
no further than simply learn sktech
postgraduate program in cloud computing
this comprehensive program will equip
you with the knowledge and skills needed
to navigate the cloud landscape with
confidence dive deep into Cloud
architecture deployment models security
and migration strategies explore
platforms like Amazon web services
Microsoft Azure and Google Cloud
platform to build your Cloud expertise
don't miss out on this chance to
transform your career and join the ranks
of successful Cloud professionals click
the link in the description box below to
discover more about the cloud computing
Basics course to know more about this
course click on the link mentioned in
the description descrition box
below let's have a look at some of the
skills required to become a cloud
administrator first off you need
experience with programming languages
like C andn Net you'll also need to be
experienced with devops tools like
Jenkins Docker anible and Chef you'll
need to have an understanding of
database configuration so that you can
take advantage of all the relevant
information about the hardware and
software components used by the
organization you'll also need to have
experience with Cloud infrastructure
systems like servers storage Network and
visualization software finally you'll
also need to configure virtual machines
VPN and Cloud servers now let's have a
look at the salary offered to Cloud
administrators now in the United States
the average salary of a cloud
administrator is approximately $65,000
perom similarly in India it's
approximately 7 lakh rupees perom now
let's have a look at some of the
companies hiring for cloud
administrators we have companies like
Vio infosis accent IBM and so on so here
I see a comment which says I'm a fresher
and want to learn about AWS how can I
start so actually any fresher can make a
career in AWS as long as you have
interest towards the subject now if you
are from a non-technical background you
need to put in a lot more hard work and
have a lot of patience so I would
recommend that before you take up the
AWS course you have a look at the course
curriculum types of AWS courses opportun
unities in the market for AWS certified
candidates and so on so now let's go to
number six Cloud application developer
now a cloud application developer mainly
focuses on implementing and maintaining
an organization's Cloud infrastructure
now they're involved with designing
building creating analyzing and
maintaining Cloud systems now these
individuals are also involved with
ensuring that there's an effective
design of business processes in the
cloud they're also involved with a
number of different tasks s like
optimizing efficiency and performance
scaling application components and
security issues now let's have a look at
some of the skills required to become a
cloud application developer first off
you need to have experience with
database languages like MySQL SQL and
mongod DB then you need to have
experience with programming languages
like python Ruby and pearl so that you
can code and create cloud computing
applications you'll also need to have
experience with Linux now this is
because most Cloud infrastructures are
created with Linux servers you'll also
need to have experience with cloud
service providers like Amazon web
services Google Cloud platform and
Microsoft your you'll need to have
experience with information security
with the help of certifications you'll
also need to know how to create
microservices and to create Cloud
applications now let's have a look at
the salary offered to a cloud
application developer in the United
States it's approximately $70,000 per
anom in India the average salary of a
cloud application developer is
approximately 8 lakh rupees per anom now
let's have a look at some of the
companies hiring Cloud application
developers you have companies like Bosch
mecafe sap and so on so now let's go to
number five Cloud network engineer a
cloud network engineer is responsible
for implementing supporting maintaining
and optimizing the network Hardware
software and communication Links of the
organization's Cloud infrastructure
Hoshi basically focuses on Automation
and security while building the cloud
infrastructure enhancing Network tooling
visibility and improving productivity
now let's have a look at some of the
skills required to become a cloud
network engineer first of obviously you
need to have experience with networking
which means the familiarity with the
internet and Van communication
Technologies protocols and best
practices you need to have an
understanding of cloud security and how
you can design a public cloud with
multiple options you'll need to have an
experience with data center
Administration which basically means an
understanding on infrastructure design
operations and life cycle management and
finally you need to have experience with
cloud computing platforms like Amazon
web services Microsoft as your and
Google Cloud platform next let's have a
look at the salaries offered to a cloud
network engineer firstly the average
salary of a cloud network engineer in
the United States is approximately
$72,000 per anom in India the average
salary of a cloud network engineer is
approximately 4 lakh rupees perom now
that we're done with this let's have a
look at the company companies hiring
Cloud Network Engineers we have
companies like Amazon web services
Rakuten Cisco and so much more now for
number four we have Cloud automation
engineer a cloud automation engineer
focuses on cloud Automation
orchestration and integration he or she
implements optimizes and supports the
cloud infrastructure and ensures it has
high availability they also have to
increase the cost Effectiveness and
availability of the cloud now let's have
a look at some of the skills required to
become a cloud automation engineer first
off since the role is cloud-based
experience with a cloud service platform
like Microsoft is your AWS or Google
Cloud platform is an absolute must
you'll also need to have experience with
programming languages like Python and go
that will help you make the process of
automation easier next experience with
devops tools like chef anible and puppet
are seen as a huge plus you'll also need
to have an understanding of Docker and
containers experience with databases
like post SQL and MySQL that can handle
multiple workloads would be very useful
and finally you need to have experience
with virtualization which means you need
to know how you can work with virtual
servers applications storage and
networks with this you can reduce the
amount of resources required by the
organization now let's have a look at
the salary offered to Cloud automation
engineers in the United States the
average salary of a cloud automation
engineer is approximately $79,000 perom
the average salary of a cloud automation
engineer in India is approximately 5
lakh rupees perom now that we're done
let's have a look at some of the company
hiring Cloud automation Engineers we
have companies like Oracle Google Capa
Gemini Disney and so on and now to
number three Cloud security manager a
cloud security manager is someone who's
responsible for providing security for
cloud-based digital platforms and
protecting the organization's data he or
she may be involved with creating new
security methods or to analyze existing
ones they may also have to create
cloud-based applications performing
threat simulations and providing
security recommendations now let's have
a look at some of the skills required to
become a cloud security manager first
off you'll need to have experience with
at least one of the popular cloud
service providers like Amazon web
services Microsoft a your and gcp you'll
also need to have experience in
programming languages like python
experience with commonly used devops
tools like jenin so that you can
Implement continuous integration or
continuous deployment models would be
very helpful you'll also need to be well
wored with TCP IP protocols and other
networking Concepts you need to be well
versed with pki SSL SSH https and so on
experience with web-based analytics and
services would also be very helpful now
let's have a look at the salary offered
to a cloud security manager in the
United States the average salary of a
cloud security manager is approximately
$99,000 perom in India the average
salary for cloud security manager is
approximately 11 lakh rupees perom now
let's have a look at some of the
companies hiring Cloud security managers
we have companies like deoe VMware Cisco
Dell and so on now let's move on to
number two Cloud engineer a cloud
engineer is an individual who is
responsible for any technological duties
that are associated with cloud computing
including design planning man management
maintenance and support they're also
involved with orchestrating and
automating cloud-based platforms
throughout the organization let's have a
look at the skills required to become a
cloud engineer first off you'll need to
have experience with at least one of the
popular cloud service providers like AWS
Microsoft asure or the Google Cloud
platform you'll need to have an
understanding of networking Concepts
like building and accessing servers
virtual networks and so on this enables
Cloud engineers make sure that the
network is responsive to the users next
you need to have experience with
virtualization with virtualization you
can reduce how many Hardware units you
need with the help of virtual machines
it also makes resources scalable and
fall tolerant in an organization
experience with the Linux operating
system would also be very helpful
considering how 30% of the servers that
powers your are Linux based you'll need
to know about apis to design restful
Services experience with devops is also
a major skill to have since it'll be
able to to help handle work dependencies
between the development and operation
teams and finally you need to have
programming experience with languages
like Java python C++ and Ruby next let's
have a look at the salary offered to a
cloud engineer in the United States the
average salary of a cloud engineer is
approximately
$105,000 per anom the average salary in
India is approximately 5 L rupees perom
now let's have a look at some of the
companies hiring Cloud Engineers we have
companies like me fee IBM JP Morgan visa
and so on now I see a pretty good
question in the chat how do you become a
cloud engineer so to become a cloud
engineer you need to have experience
with the programming language experience
with at least one cloud service platform
which is Amazon web services or
Microsoft is your or Google Cloud
platform the choice is yours and you
need to specialize in a particular
service be it storage networking
disaster recovery and so on and now for
number one One Cloud architect a cloud
architect is responsible for managing
cloud computing architecture in an
organization he or she handles
everything to do with front-end
platforms servers storage delivery and
networks now let's have a look at some
of the skills required to become a cloud
architect first off you need to have
knowledge in programming knowledge about
Pearl python Ruby PHP Java and net can
provide users with the ability to build
deploy and manage applications quickly
you'll need to know about the basics of
networking since most of the work what
you'll be doing would be web related
knowledge about networking can be really
helpful knowledge about data storage
fundamentals are also really important
this provides you with the knowledge to
determine which data storage option to
use and when being experienced with
cloud service platforms is also really
important platforms like AWS Google
Cloud platform and Microsoft as your are
what you are going to be basing most of
your work on experience with them is
pretty important and finally Cloud
security this will help you make sure
that your data is secure and only
authorized code is run and the right
people are allowed to run it now let's
talk about the salary of a cloud
architect the average salary of a cloud
architect is approximately $107,000
perom in India the average salary of a
cloud architect is approximately 16 lakh
rupees perom and there you go those are
the top job roles in the field of cloud
computing now let's have a look at some
of the companies hiring Cloud Architects
we have companies like ey weo Huawei
hulet Packer Enterprise and so on and
today I'm going to tell you how you can
become a successful cloud computing
engineer now cloud computing is one of
those Technologies that's rapidly rising
and with any technology that's growing
rapidly it comes with several job
opportunities for the people who are
skilled in it so before we get into it
let's have a brief look at what is cloud
computing cloud computing refers to
services like storage databases software
Analytics itics machine learning
artificial intelligence and so much more
all of which made accessible via the
Internet the cloud tech services Market
is expected to grow
17.3% in the span of 2018 to 19 which
means there's a growth from1 75.8
billion to a whopping $26 billion in
2019 and as of 2020 it's expected that
90% of all organizations in the world
would be using cloud services not to
mention several organiz ganizations
around the world suggest that using
Cloud Computing Services has enabled
their employees to experiment a lot more
with Technologies like machine learning
and artificial intelligence so here's
what we'll be going through today
firstly we'll be talking about who is a
cloud computing engineer the steps you
need to take to become a cloud computing
engineer and the cloud computing
engineer salaries so first off who is a
cloud computing engineer now a cloud
computing engineer is an IT professional
who takes care of all the technical
aspects of cloud computing now be it
design planning maintenance and support
now a cloud computing engineer can take
up a number of different career paths
this could be that of a cloud developer
security engineer a full stack developer
Sops administrator Solutions architect
Cloud architect and so much more now
let's have a look at some of the major
cloud computing roles first off we have
Solutions architect now these are
individuals who are responsible for
analyzing the technical environment in
which they are going to produce the
solutions the requ requirements and the
specifications secondly they are
required to select an appropriate
technology that satisfies set
requirements they need to estimate and
manage the usage and the operational
cost of the solutions they provide and
they need to support project management
as well as solution development next we
have ssops administrators they are
involved in deploying managing and
operating highly scalable and fall
tolerant systems they need to select an
appropriate service based on compute
security or data requirements they need
to estimate and manage usage and
operational costs and they need to be
able to migrate on premisis workloads
onto an appropriate cloud computing
platform so among both of these roles
there are certain requirements that are
remaining constant now let's have a look
at the steps you need to take to become
a cloud computing engineer your first
step is to gain Proficiency in a cloud
computing platform now the first step is
to become proficient in at least one of
the three major cloud computing
platforms bws Azure or the Google Cloud
platform now there are a huge number of
resources that you can find on the
internet it could be YouTube videos
articles virtual or physical classrooms
and so much more now after you're done
learning you can get certified by
Microsoft as your AWS or the Google
Cloud platform now for AWS you have a
number of different certifications which
can be divided into three categories
which are the foundational which is just
the basics the associate level
certifications the professional level
certifications and the specialty
certifications similarly with Microsoft
aure you have certifications that enable
you to become an Azure developer
associate an Azure administrator
associate an Azure architect
professional and a devops engineer now
most cloud computing platforms have a
free tier that you can take advantage of
these provide a number of free services
for a period of time some of which are
free forever so you can use these
platforms to your advantage and do as
much practice as you can on them now if
you want to learn more about cloud
computing you can also check out Simply
learn YouTube channel then you can go
onto the playlist section right here and
you can find comprehensive videos on a
number of different cloud computing
platforms AWS and Microsoft aure our AWS
tutorial videos talk about what exactly
is AWS how you can become an aw
Solutions architect Amazon ec2 S3 some
of the other services and so much more
we also have detailed tutorials on aor
which talks about what exactly is aor
the certifications provided by aor some
of the servic like machine learning a
your active directory and so much more
and now we're at step two being
experienced in at least one programming
language unlike general purpose
programming languages like C C++ cop and
so on cloud computing requires ones that
are a lot more data oriented now some of
the major programming languages that are
used in cloud computing are go Python
clure and Java now as I said before
there is a wealth of resources that you
can learn from there are free websites
that you can can practice your code on
like quick code code academy and several
others there's also resources like
YouTube videos as well as there's the
option of online or offline classes now
we're at step three specialization
you'll also need to be well wored with a
number of key Concepts these are storage
and networking now with storage you need
to know how data can be stored and where
it can be accessed from you need to know
how it can be access from multiple
different resources you'll also need to
have some experience with the services
provided by Azure and AWS like the
Amazon S3 in AWS and the appropriately
named azzor storage from Microsoft Azure
with networking you need to have a
strong understanding of the networking
fundamentals as well as virtual networks
next up we have virtualization and
operating systems with virtualization
you need to know how virtual networks
which is just a combination of different
virtual machines can be used to emulate
different components in a particular
system with operating systems you need
to have a very strong understanding
operating systems like Windows and Linux
next up we have security and Disaster
Recovery now you need to understand how
data application as well as
infrastructure can be protected from
malicious attacks With Disaster Recovery
you need to be prepared for any
unexpected circumstance by making sure
your systems are always safe and are
regularly backed up to prevent any sort
of loss of data then we have web
services and devops now you need to have
a strong understanding of apis or
application a program interfaces and web
services some amount of experience with
web design also can be of great help
with devops you need to have a strong
understanding of how cloud computing is
able to provide a centralized platform
on which you can perform testing
deployment and production for devops
automation moreover with devops you
understand the Synergy that the
operations as well as the development
teams have with each other and for the
success of any project and finally
you're a cloud computing engineer now
let's have a look at the salaries of
cloud computing engineers in the United
States cloud computing Engineers earn
around
$116,000 perom in India a cloud
computing engineer is paid approximately
6 lak 66,000 rupees perom now how can
simply learn help you become a cloud
computing engineer so let's head on to
Simply Lo's website here we have the
cloud architect Masters program now this
deals with a number of different courses
all of which that can help you get
started in your journey to becoming a
cloud computing engineer this Masters
program covers a number of different
courses like AWS technical Essentials
Microsoft a your fundamentals AWS
developer associate and so much more it
provides you 40 plus in demand skills
and 25 plus Services provides you a
master certification it has 16 plus real
life projects and helps you get a salary
that ranges between 15 to 25 lakh rupees
perom it also covers a variety of tools
like Amazon ec2 Azo data Factory virtual
machines and so much much more so why
don't you head on to Simply learn.com
and get started on your journey to
getting certified and getting ahead here
we wrap up with the cloud computing
Basics if you like this video then hit
the like button consider subscribing to
our Channel and hit the Bell icon to
never miss any updates from Simply Lo
till then keep watching and keep
learning staying ahead in your career
requires continuous learning and
upskilling whether you're a student
aiming to learn today's top skills or a
work professional looking to advance
your career we've got you covered
explore our impressive catalog of
certification programs in cuttingedge
domains including data science cloud
computing cyber security AI machine
learning or digital marketing designed
in collaboration with leading
universities and top corporations and
delivered by industry experts choose any
of our programs and set yourself on the
path to career success click the link in
the description to know
more hi there if you like this video
subscribe to the simply learn YouTube
channel and click here to watch similar
videos to nerd up and get certified
click here