in today's data Driven Landscape scale
data analysts are in high demand and
this course is your key to unlocking
Limitless opportunities welcome to
Simply lens YouTube channel and today we
have the data analyst crash course for
you it's your Expressway to an exciting
career in the world of data analysis
this intensive crash course is designed
to equip you with the essential skills
and knowledge in the shortest time
possible this crash course Dives deep
into the crucial job roles showcasing
the dynamic field of data analysis our
video series will help you explore vital
data analysis tools like Tableau power
bi SQL Excel Python and gaining
proficiency that employers covert as you
navigate this crash course you will not
only Master the technical aspects but
also encode the art of transforming raw
data into actionable insights this
immersive video tutorial will Empower
you to excel in this Dynamic profession
don't miss out on this chance to take
the first step towards becoming a highly
sought after data analyst embrace the
crash course embrace your future let's
dive in and seize those promising data
analyst career prospects together that's
it if these are the types of videos you
would like to watch then like share and
hit that subscribe button and the bell
to get notified
if you are an aspiring data analyst with
minimum one year of experience in the
domain and looking for online
professional certification programs from
prestigious universities to upskill and
get ahead in your career then search no
more simply learns IIT can't put
professional certificate course in data
analytics should be a right choice for
more details use the link in the
description box below
also if you are a professional data
analyst with minimum one year of
experience in the domain online bootcamp
programs and certifications from
prestigious universities and in
collaboration with leading experts then
search no more simbilance data analytics
bootcamp from Caltech University in
collaboration with IBM should be a right
choice for more details use the link in
the description box below with that in
mind over to our training experts
a civil engineer turned data scientist
who decided to Simply learn why a
possible
with a course from a premier University
[Music]
true champion who upskilled to win big
how big a massive hike that transformed
my life upon his change gears pretty
early in the race
but Russian wanted to explore more to
get ahead isilio snicara simply learned
from mechanical engineering to a data
analyst and a podcaster in his free time
Sr career transformation
industry expertsika live
expert coach difficult
with a well-structured course it felt
like a piece of cake that is simply
awesome what's also awesome is that
nitin didn't choose a quick fix
we just added data science into the mix
nithin how did you change the game
worked on real industry problems to
become the real deal a joint family a
regular job responsibilities but nothing
could stop nitin from getting ahead what
an all-rounder de Hoya Knight with
flexible learning you can always make it
right crashing your situations
you too will find your way to get ahead
when you simply learn
simply learn get ahead with simply learn
[Music]
hello everyone we have an interesting
topic for today and that is data
analytics jobs career and salary I will
run you through the top 6 data analytics
job roles so before I dive deep into the
various job rules let's quickly
understand how important a career in
data analytics is and what the future
holds for Professionals in this domain
let's take a look at the growth of data
so back in the early 2000s there is
relatively less data generated but with
a rapid rise in Technologies and with
the increase in the number of various
social media platforms and multinational
companies across the globe the
generation of data has increased by
Leaps and Bounds
did you know that according to the IDC
the total volume of data is expected to
reach 175 zettabytes in 2025
now that's a lot of data let's take a
look at how organizations leverage all
of this data
as you know there are zillions of
companies across the world these
companies generate loads of data on a
daily basis when I say data here it
simply refers to business information
customer Data customer feedback product
Innovations sales reports and profit
loss reports to name a few
companies utilize all of this data in a
wise way they use all of this
information to make crucial decisions
that can either hamper or boost their
businesses you might have heard of the
term data is the new oil well it
definitely is but only if organizations
analyze all the available data very well
then this oil is definitely valuable
and for that we have data analytics
organizations take the help of data
analytics to convert the available raw
data into meaningful insights
so what is data analytics technically
you can say it is a process wherein data
is collected from various sources then
cleaned which involves removing
irrelevant information and then finally
transformed into some meaningful
information that can be interpreted by
humans
various Technologies tools and
Frameworks are used in the analysis
process
as you might have heard of the term data
never sleeps well it surely doesn't
every millisecond some of the other data
is generated and this is a constant
process this process is only going to
increase in the near future with the
Advent of newer Technologies the data
analytics domain holds Paramount
importance in every sector
companies want to leverage on all the
generated big data and boost their
businesses
they need professionals who can play
with data and convert them into crucial
insights organizations are constantly on
the lookout for such candidates and this
opportunity will only increase as data
is only going to grow every second
so if you want to start your career in
this field or if you want to switch your
job role into a role in the data
analytics domain then we have a set of
job profiles that you can look at
we will look into six job roles in the
data analytics field and learn what each
job role is all about the
responsibilities of a professional
working in that particular role the
skills required to get that particular
job the average annual salary of a
professional working in that role and
finally the company is hiring for that
role so let's start off
first we have the job role of a data
analyst
a data analyst is a person who collects
processes and performs statistical
analysis of large data sets
every business generates and collects
data be it marketing research sales
figures Logistics or Transportation
costs a data analyst will take this data
and figure out a variety of measures
such as how to price new materials how
to reduce Transportation costs or how to
deal with issues that cost the company
money they deal with data handling data
modeling and Reporting
now talking about their responsibilities
data analysts recognize and understand
the organization's goal they collaborate
with different team members such as
programmers business analysts engineers
and data scientists to identify
opportunities for solving business
problems
data analysts write complex SQL queries
scripts and store procedures to gather
and extract information from multiple
databases
they filter and clean data using
different modern tools and techniques
and make it ready for analysis they also
perform data mining from primary and
secondary data sources
data analysts identify analyze and
interpret Trends in complex data sets
this is done using statistical tools
such as R and SAS
another key responsibility of a data
analyst is to create summary reports and
build various data visualizations for
decision making and presenting it to the
stakeholders
next let us discuss the important skills
that you need to know to become a data
analyst
firstly you should have a bachelor's
degree in computer science or
information technology a master's degree
in computer applications or statistics
is also preferable
you must have a good understanding of
programming languages like R python
JavaScript and also understand SQL
in addition to that it is beneficial if
you have hands-on experience with
statistical and data analytics tools
such as SAS Miner Microsoft Excel and
ssas
basic understanding of machine learning
and its algorithms would be an advantage
acquaint yourself with descriptive
predictive prescriptive and inferential
statistics
most importantly you need to have a good
working knowledge of various data
visualization software along with
presentation skills this will help you
pitch in your ideas and viewpoints to
the clients and stakeholders better
now talking about their salaries a data
analyst earns nearly 5 lakhs 23 000
rupees per annum in India while in the
United States they earn around 62 000
453 dollars per annum
let's now look at a few of the companies
hiring data analysts so as you can see
we have the American e-commerce giant
Amazon then we have Microsoft the
American online payment company PayPal
then we have Walmart Bloomberg and
Capital One so that was all about data
analyst
the next job role is of a business
analyst
business analysts help guide businesses
in improving products services and
software through data-driven solutions
they are responsible for Bridging the
Gap between I.T and business using data
analytics to evaluate processes
determine requirements and deliver
data-driven recommendations and reports
to Executives and stakeholders
business analysts are responsible for
creating new models that support
business decisions and come up with
initiatives and strategies to optimize
costs
now let us look at the various
responsibilities of a business analyst
business analysts have a good
understanding of the requirements for
business their vital role is to work in
accordance with relevant project
stakeholders to understand their
requirements and translate them into
details which the developers can
understand
they frequently interact with developers
and come up with a plan to design the
layout of a software application
they also run meetings with stakeholders
and other authorities they engage with
Business Leaders and users to understand
how data-driven changes to products
Services software and Hardware can
improve efficiencies and add value
they ensured that the project is running
smoothly as per the requirements and the
design planned through user acceptance
and validation testing
they make sure all the features are
being incorporated into the application
Bas rely on different software to write
documentation and design visualization
to explain all the findings it is
extremely critical for any ba to
effectively document the findings where
each requirement of the client is
mentioned in detail
now let us look at the skills required
for a ba
a bachelor's degree in the field of
science engineering or statistics or any
related domain will suffice
knowledge of programming languages such
as Python and Java is beneficial you
should be really good at writing complex
SQL queries and you should also have
knowledge of various business process
models
along with knowledge of programming
languages ideas about statistical
analysis and predictive modeling is
necessary
decision making strong analytical and
problem solving skills are necessary to
solve software and business issues you
also need to have excellent presentation
and communication skills both oral and
written
moving on to their salary a business
analyst is expected to earn around 7
lakh rupees per annum in India in the US
they earn nearly 68 000 346 dollars per
annum
iqia Dell Phillips Honeywell the famous
American messaging platform WhatsApp the
UK based company Ernest and Young a few
of the companies hiring for business
analysts
up next we have the job role of a
database administrator
a database administrator is a
specialized computer systems
administrator who maintains a successful
database environment by directing or
performing all related activities to
keep the organization's data secure
they are responsible for storing
organizing and retrieving data from
several databases and data warehouses
their top responsibility is to maintain
data Integrity this means that database
administrator will ensure that the data
is secure from unauthorized taxes
moving on to their responsibilities
a database administrator develops
designs and maintains a database to
ensure that the data in it is properly
stored organized and managed well
they maintain data Integrity by avoiding
unauthorized taxes and they keep
databases up to date
they run tests and modify the existing
databases to ensure that they operate
reliably they also inform end users of
changes in databases and train them to
utilize systems
they need to cooperate with programmers
data analysts and the IT staffs to
ensure smooth running and maintenance of
databases
database administrators are responsible
for taking system backups in case of
power outages and other disasters so
they should have an efficient Disaster
Recovery plan
now let's have a look at their skills
to become a database administrator you
should have a bachelor's degree in
computer science or information
technology
knowledge of programming languages such
as python Java and Scala is important
you need to carry at least three to five
years of experience in data management
you need to have an understanding of
different databases such as Oracle DB
mongodb MySQL server and postgresql also
they should have an idea about database
design and writing SQL queries
finally you need to have a good
understanding of operating systems such
as Windows Mac OS and Linux along with
storage Technologies
talking about their salary a database
administrator in India can earn up to 4
lakh 97 000 rupees per annum in the US
they earn around 78 000 per annum
let's have a look at the companies
hiring for database administrators
so as you see here we have bookmyshow
Oracle the American MNC Intel Amazon
Robert Half and the New York Times to
name a few
fourth in the list of job rules we have
data engineer a data engineer is someone
who's involved in preparing data for
analytical and operational uses a data
engineer transforms data into useful
format for analysis they build and test
scalable Big Data ecosystems for
businesses a data engineer is an
intermediary between a data analyst and
a data scientist
now let's jump into their
responsibilities
data Engineers develop test and maintain
architectures they are responsible for
managing optimizing and monitoring data
retrievals storage and distribution
throughout the organization
they discover opportunities for data
acquisition find Trends in data sets and
develop algorithms to help make raw data
more useful to the Enterprise
data engineers build large data
warehouses using ETL for storing and
retrieving data
they also recommend ways to improve data
quality and efficiency along with
building algorithms to help give easier
access to Raw data
data Engineers often work with big data
and submit their reports to data
scientists for analysis purpose they
need to recommend and sometimes
Implement ways to improve data
reliability efficiency and quality
moving on to the skills of a data
engineer
a data engineer should hold a bachelor's
degree in computer science or
information technology
they should have good hands-on
experience with python R and Java
also data Engineers should be well
versed with big data Technologies such
as Hadoop Apache spark Scala Cassandra
and mongodb
data warehousing and detail experience
are essential to this position along
with in-depth knowledge of SQL and other
database Solutions
basic knowledge of statistical analysis
will be an advantage along with idea
about operating systems
here is what a data engineer can earn so
in India a data engineer can earn up to
8 lakhs 85 000 rupees per annum while
they can earn around 103 000 dollars a
year in the USA
we have capgemini shot a stock the
American provider of stock photography
Spotify Accenture genpact and Facebook
hiring data engineers
the next exciting job role is of a data
scientist
a data scientist is a professional who
uses statistical methods data analysis
techniques machine learning and related
Concepts in order to understand and
analyze data to draw business
conclusions they make sense to messy and
unstructured data and bring value out of
it they employ techniques and theories
drawn from many fields within the
context of mathematics statistics
computer science and information science
a data scientist understands the
challenges in business and comes up with
the best Solutions using modern tools
and techniques to analyze visualize and
build prediction models to make business
decisions
let us now look at their
responsibilities in the industries
data scientists clean process and
manipulate data using several data
analytics tools they perform ad hoc data
mining collect large sets of structured
and unstructured data from disparate
sources
they design and evaluate Advanced
statistical models to work on Big Data
they also create automated anomaly
detection systems and keep constant
track of their performance
data scientists interpret the analysis
of big data to discover Solutions and
opportunities
a data scientist takes input from data
analysts and Engineers to formulate the
results
they use visualization packages and
tools to create reports and dashboards
for Relevant stakeholders they also
adopt new business models and approaches
apart from this they regularly built
predictor models and machine learning
algorithms
now moving on to the skills of a data
scientist
a bachelor's degree in computer science
or information technology will be fine
but a master's degree in the field of
data science will hold a major advantage
you also need to have a good experience
in the analytics domain
you should be proficient in programming
languages such as python Java and C plus
knowledge of Perl will also be an
advantage
familiarity with Apache Hive Pig and
Apache spark is necessary along with the
knowledge of Hadoop
in addition to knowing programming
languages you also need to know SQL
machine learning and deep learning
data visualization and bi skills are
necessary for creating reports and
dashboards you should also be able to
communicate and present information and
ideas properly
now talking about their salary a data
scientist in India can expect an annual
salary of 10 lakhs 47 000 rupees per
year
meanwhile in the US they can earn up to
113 000 dollars per annum that's a lot
of money
from the many companies hiring for data
scientists here we have a few companies
named they are yet again Amazon Citibank
Apple Google the Japanese electronic
Commerce and online retailing company
Rakuten and Facebook
and finally we have machine learning
engineer machine learning Engineers are
professionals who develop intelligent
machines that can learn from vast
amounts of data and apply knowledge
without human intervention
they use different algorithms and
statistical modeling to make sense of
data they design and develop machine
learning and deep learning algorithms
their main goal is to create
self-running software
let's have a look at the
responsibilities of a machine learning
engineer
machine learning Engineers research
design and develop machine Learning
Systems they use exceptional
mathematical skills in order to perform
faster computations and work with
algorithms to create sophisticated
models
they perform a b testing and use data
modeling to fine-tune the results
they use data modeling and evaluation
strategy to find hidden patterns and
predict unseen instances
machine learning Engineers work closely
with data Engineers to build data
pipelines and interact with stakeholders
to get a Clarity on the requirements
most importantly they analyze complex
data sets to verify data quality perform
model tests and experiments choose to
implement the right machine learning
algorithm and select the right training
data sets
moving on to their skills
a machine learning engineer should have
a degree in computer science and
information technology they should have
an advanced degree in computer science
or maths
in addition to this they should also
have experience in the same domain
they should be proficient in programming
languages such as python RC plus and
Java
knowledge of Statistics probability and
linear algebra is necessary as all the
machine learning algorithms have been
derived from mathematics also having an
idea of signal processing would be
beneficial
machine learning Engineers need to have
a good understanding of data
manipulation and machine learning
libraries such as numpy Panda
scikit-learn Etc
they should have good oral and written
communication skills
let us now have a look at their salary
structure a machine learning engineer
earns 8 lakh rupees per annum in India
while in the US they can earn around 114
000 a year now that's a whopping amount
isn't it
let's have a look at the company's
hiring machine learning engineers
so as you see we have Amazon Microsoft
Oracle Salesforce Rapido and Accenture
to name a few
that was all about the job role of a
machine learning engineer
now that we have seen the different job
roles in the field of data analytics
let's also go ahead and see how an ideal
resume of a data analyst should look
like
seen on your screens is a sample
resuming of a data analyst you can grab
some ideas from this and incorporate
them in your resume
nowadays it's quite common to have a
professional photograph of yours on the
resume you can go ahead and have that
then your name in bold followed by your
contact details like email ID and phone
number
then moving on you would have to write a
summary briefly explain your current job
role and what you're looking for in the
future having a LinkedIn profile link
works well these days employers can just
go ahead and look at your profile and
gauge you well
make sure to have an active LinkedIn
profile
in addition to LinkedIn profile it's
also good to have a guitar profile link
which can show your coding or other
technical skills
if it's impressive enough then a lot of
times the rest of your resume is just
secondary
as I mentioned this is a resume of a
data analyst so as you can see in the
summary here we have just spoken about
the basic responsibilities of a data
analyst
moving on to the experience part you
have to write the job title and below
that you can mention the company and the
tenure accordingly here you would have
to give a brief description of
achievements in the organization any
relevant accomplishments related to the
job you're applying for the tools and
the various Technologies you have worked
with
so in the sample you can see we have
spoken about data visualization using R
in Tableau next we have spoken about how
the candidate has worked with other
teams for a Better Business outcome
most of the data analysts use SQL and
Excel to handle data for reporting and
database maintenance and we have
mentioned that here as well
do make sure that you always specify the
tools you use
then you can also mention if you have
worked on improving data delivery for
example here we have spoken about
developing and optimizing SQL queries
data aggregations and ETL to improve
data delivery
finally you can speak a bit about your
reporting skills and if needed elaborate
on it
usually professionals would have worked
in a similar domain before becoming a
data analyst here we have taken the role
of a statistical assistant as the first
job since it's easier for a candidate
with this job role to shift into the
data analytics field nevertheless you
all can still mention your prior
experience here be it in any domain
under the responsibilities for this job
role we have given Basics such as coding
data prior to compute entry compiling
statistics from various reports
Computing and analyzing data and find me
some visualization and Reporting
moving to the education here you can
mention the name of your degree and the
university name if you have a post
graduation well in good you can list
both the degrees here also if you have
any certifications you can mention them
here under the education category
now moving to the skills depending on
your skills and your choice you can
either shift this part to the beginning
of the resume or have it here
as you see on your screens this is just
a different way of displaying your skill
sets you can have all the five stars
colored if you are excellent in that
particular tool or language
as you see it's crystal clear as to what
the candidates strong areas are
you can have various categories like
shown
for example under software development
you can list the languages that you know
and how proficient you are in those
particular languages
it's clear that the candidate knows
python better than JavaScript here so
the employer gets a clear idea about the
skills you possess and the depth of it
similarly you can mention the databases
as well the few mentioned here are more
or less a requirement to become a data
analyst at least SQL is a must
not to forget data visualization is also
very important when it comes to the job
role of a data analyst mention the tools
you know here and similarly give
yourself a rating out of five five stars
shaded being the highest
here we have mentioned Tableau and Excel
which are more than sufficient to become
a data analyst
moving to the non-technical skills you
can mention the languages you know here
here we have taken English and German in
addition to the languages you can also
feel free to mention the extracurricular
activities that you are good at
so this is how an ideal resume of a data
analyst should look like you can alter
it according to your achievements skills
and experience a study from new Vantage
Partners suggests 97.2 percent of
companies are now investing in data and
its analysis nowadays every company
needs a data expert do you also want to
become a part of this Market if yes how
to become a part of it what are the
essential skills one should have
this video will answer all these
questions but before watching this video
please subscribe to Simply learns
YouTube channel and press the Bell icon
to never miss any updates first of all
we are going to discuss who is a data
analyst working of a data analyst skills
required to become a data analyst two is
required and companies hiring and
finally we are going to discuss about
salary of a data analyst let me tell you
how simply learn can help you in your
journey to become a data analyst check
out the course on data analytics in
collaboration with IBM with real-time
project and business case studies you
will learn tools like SCI pipe pandas
and programming languages like python or
R2 enroll Now link is in the description
box below question for you which one of
the following is not a python library
for visualization
my plot lip sci-fi pandas Jupiter
notebook please leave the answer in the
comment section below moving on who is a
data analyst a data analyst collects
analyzes and interprets data a data
analyst will convert raw data into
useful information data analysts are in
high demand because every industry uses
data analysis work of a data analyst as
a data analyst you will work closely
with the raw data and generate valuable
insights to help companies decide their
future goal if you like thinking out of
the box you are the perfect fit for this
domain data analyst help maximize output
when it comes to generating Revenue
working closely with both business and
data nevertheless this field boasts
handsome salaries for all levels of
expertise can become a data analyst
without prior experience
yes anyone can become a data analyst if
they enjoy solving real world problems
have a strong background in statistics
and have a creative mind if you feel you
don't have it you can definitely develop
it so let us know the skills in detail
what are the basic skill sets required
for a data analyst data analyst must
know
basic mathematics and statistics
programming skills machine learning and
also data visualizations tools so let us
know what are the basics that you need
to learn as a data analyst
mathematics it is always better to know
basic mathematics like linear algebra
and probability fundamentals linear
algebra is used in data pre-processing
and transformation which is the critical
process of every data analyst
statistics a branch of mathematics that
deals with collection analysis
presentation and implementation
probability we know that probability is
the study of How likely something will
happen which is essential for concluding
both probability and statistics are the
backbones of data analysis it is
feasible to become a data analyst with
only a basic understanding of these
three areas of mathematics but in order
to remain relevant and grow as a data
analyst once mathematical knowledge
should not be restricted compulsively
use some of the tools as a data
analystic what are that
first is Microsoft Excel it is the most
well-known spreadsheet software in the
world it also has computation and
graphic features that are excellent for
data analysts no matter your area of
expertise or additional software you
might want Excel is a standard in the
industry it's useful built-in features
include form design tools and pivot
table it also generate a wide range of
additional features that help simplify
data manipulation
as a programming language every data
analyst should know python it is easy to
learn and has a simple syntax python is
quite adaptable and includes a vast
variety of resource libraries that are
appropriate for a wide range of diverse
data analytics activities these
libraries help in numerical and data
computation the pandas and numpy
libraries for instance are excellent for
supporting standard data processing and
stabilizing highly computational
operations you can also choose between
Python or RR is a well-known open source
programming language much like python
data visualization tool as we previously
mentioned data visualization tool is
also necessary to become a data analyst
power bi is a user-friendly interface
makes building interactive visual
reports and dashboard simple its most
vital selling point is its superb data
integration it works flawlessly with
Cloud sources like Google and Facebook
analytics as well as text files SQL
servers and exit
blue is one of the best commercial data
analysis tool available it handles huge
amounts of data better than many other
bi tools and as is effortless it has a
visual drag and drop interface however
because it has no scripting layer there
is a limit to what Tableau can do for
example it could be better for
pre-processing data or building more
complex calculations
you might have heard about MySQL a lot
of time it is a standard language for
interacting with databases and it is
very helpful when working with
structured data SQL creates
user-friendly dashboards that may
present in various data ways and since
it is so simple to send complex commands
to databases and change data in seconds
it has commands like add edit delete
data in addition SQL is an excellent
tool for creating data warehouses
because of its Simplicity Clarity and
interactivity
overall I would suggest that to become a
data analyst you should work on
programming languages like python or R
plus MySQL to work on databases adding
to that Excel plus visualization tools
like Tableau or power bi you now know
what are the skills are and how it is
used what are you up to in an
organization as a data analyst
to create and evaluate the report using
automated tools like Tableau or power bi
to troubleshoot the reporting database
environment and reports data analyst you
will use statistical method to analyze
data sets and spot any valuable trends
that may develop over time
evaluate companies functional and
non-functional requirements data analyst
Access Data warehousing in inspecting
and Reporting needs these are all the
responsibility of a data analyst in an
organization coming to companies hiring
a data analyst IBM Accenture Capital
mini TCS Facebook Amazon Flipkart meta
these are the top companies hiring a
data analyst but data suggests that
every small and medium-sized company
needs a data analyst therefore demand of
a data analyst is in every company so
there is no network job and salary of a
data analyst this is the final part the
salary of a data analyst is high all
over the world when it comes to the USA
the average salary for a data analyst as
a beginner is going as high as 70 000
plus dollars per annum for experienced
professional it is going as high as 120
000 per annum in India for a fresher it
is going as high as 8 lakh per annum and
for experienced professionals it is 20
lakh plus per annum such as the demand
for data analyst now that we have
covered every important skill it's time
for you to start working on it
certifications have become an essential
Benchmark for professional growth and
recognition in the dynamic field of data
analytics they not only validate your
expertise but also open doors to
exciting new career opportunities
and when it comes to Top Notch
certifications simply learns has
established itself as a trusted provider
of choice so let's embark on a journey
discover the best data analyst
certifications available for you are you
eager to step into the exciting world of
data analytics look no further than
simply learns post graduate program in
data analytics
this comprehensive program is designed
to equip you with the essential skills
and knowledge needed to thrive in this
rapidly evolving field let's look into
the extraordinary features and benefits
that make this program truly stand out
from the cloud
first and foremost simply learns Career
Services is here to ensure that your
talent are noticed by top hiring
companies giving you a Competitive Edge
in the job market upon successfully
completion of the program you will
receive a prestigious postgraduate
program certificate powerful Testament
to your commitment and expertise in the
field of data analytics this certificate
holds a value that can open several
career opportunities to further enhance
your learning experience we have
introduced an exclusive partnership with
industry giant IBM through this
collaboration we bring you unpalid
opportunities such as exclusive
hackathons and ask me anything sessions
with IBM experts this unique expertise
allows you to engage directly with
industry professionals gain invaluable
insights and Tackle real world
challenges faced by data analysts this
collaboration ensures that you receive
Cutting Edge knowledge and stay ahead of
the curve and simply learn we believe in
the power of Interactive Learning that's
why our live online classes offer an
astonishing 8X higher level of live
interaction compared to other programs
delivered by industry experts these
engaging sessions provide you with a
platform to ask questions participate in
discussions and gain practical insights
that will deepen your understanding of
the subject matter one of the defining
feature of our program is the Hands-On
approach to the learning through our
Innovative applied learning model you
will have the remarkable opportunity to
work on a variety of real world projects
using industry data sets for reputable
sources such as Google Play Store and
the World Bank with over 14 data
analytics project about you will gain
valuable practical experience and
develop an impressive portfolio that
showcases your skills to potential
employers to enrich your Learning
Journey even further we present Master
Class delivered by esteemed facility
from Purdue and IBM experts their
immense knowledge and expertise will
provide you with the valuable insights
and unique perspective ensuring that you
receive a well rounded in in data
analytics now you may be wondering if
this program is suitable for you the
answer is yes our postgraduate program
in data analytics is thoughtfully
designed to the need of all working
professionals whether you are an
experienced data analyst looking to
upskill or someone new to this field
this program is perfect fit no prior
programming knowledge is required as we
cover everything from the fundamentals
to Advanced Technologies throughout the
program you will acquire a wide range of
skills essential for Success career in
data analytics they includes data
analytics statical analytics using Excel
data analysis with python and R data
visualization using Tableau and power bi
model on linear and logitic recursion
clustering using k mean
and supervised learning Technologies our
comprehensive curriculum ensures that
you are equipped with the necessary
tools to excel in this rapidly growing
field so why wait any longer join simply
learns post graduate program in data
analytics and unlock the world of
opportunities prepare to dive deep into
the realm of data analytics collaborate
with industry experts and gain hands-on
experience with real world projects your
journey to become a data analytics
professional starts right here
so the link of this program will be in
the description box below do check it
out and enroll now next we have data
analytics boot camp
stay ahead of the data Revolution with
the Caltech data analytics bootcamp a
collaborative program offered by Caltech
designed specifically for working
professionals and students of the US
this bootcamp adapts an applied learning
approach providing integrated labs and
real-world projects for the business
environment experience academic
Excellence with the Kel-Tec data
analytics boot camp while also enjoying
the benefits of Caltech Campus Connect
the program offers highly Interactive
Learning ensuring active participation
and engagement this provides ample
hands-on experience to reform your
skills the Caltech data analytics
bootcamp caters to individuals from
diverse backgrounds offering substantial
benefits to working professionals gain a
safe search as Excel proficiency data
driven presentation Technologies data
manipulation with SQL data analytics we
using Python and data visualization
using Tableau Additionally you will
learn data analytics with the tools like
AWS and other industry relevant
Technologies covering a comprehensive
curriculum the Celtic data analytics
bootcamp dive into key Concepts
including data analytics with Excel
python-based data analytics database
management with SQL Tableau for data
visualization and data analytics on AWS
by completing this bootcamp you will be
equipped with the range of tools and
Technologies by choosing this bootcamp
you open doors to exciting career
opportunities with renowned companies
such as Microsoft Google Amazon IBM
apple and many more the Caltech data
analytics bootcamp has successfully
empowered numerous experience data
analysts and their testimonials are
available on the course page accessible
throughout the link in the description
box now if you aspire to become a data
analyst and acquire job ready skills
don't miss out on this intensive
training program join the Caltech data
analyst boot camp and embark on your
journey to excel in the world of data
analyst the link for this bootcamp will
be in the description box do check it
out now we have another professional
certification course in data analytics
provided by the IIT kanpur for Indian
professionals and students are you ready
to unlock the secrets hidden within vast
amount of data and gain a comprehensive
Edge in today's Cutthroat business world
simply learns data analyst course
delivered in collaboration with IIT Khan
pool will provide you with extensive
expertise in the booming field of data
analytics this course is designed to
provide a deep understanding of the
principles Technologies and applications
of data analytics empowering you to
efficiently analyze interpret and
extract the actionable insights from the
data the course follows and structured
learning path that covers various
aspects of data analytics including
business analytics using Excel SQL
programming Foundation using python data
analytics with r programming and taboo
training some of the key features of
this program includes master classes
delivered by distinguished IIT kanpur
facility Hands-On lab experience to help
you master 14 plus tools and Frameworks
and Industry ready projects designed to
advance your career trajectory simply
learns job assistance Services is here
to help you get noticed by top hiring
companies increasing your chances to
secure a rewarding position with
renowned companies like Microsoft Google
Amazon IBM Goldman snacks and many more
upon successful completion of the
program you will receive a professional
certificate from IIT kanpur adding
immensely value to your credentials so
what are you waiting for roll now and
embark on this transformative Journey
with IIT Khan post data analytics course
unlock the boundless potential of data
countless inspiration data analysts have
benefited from the data analytics
program you can find their testimonial
by following the link in the course page
in the description box below in today's
fast-paced digital landscape businesses
face a daunting challenge extracting
valuable insights from massive amounts
of data enter the edl pipeline the
backbone of data processing and
analytics in this tutorial we will
embark on an accelerating Journey
unveiling the secrets of building a
powerful ETL pipeline whether you are a
seasoned data engineer or just starting
your data driven Adventure this video is
your gateway to unlock the full
potential of your data together we will
demystify the ETL process step by step
we'll dive into the extract phase where
we retrieve data from multiple sources
ranging from databases to apis and then
we'll seamlessly transition into the
transformation phase where we clean
validate and reshape the data into a
consistent format but wait there's more
we will explore Cutting Edge techniques
for handling large data sets leveraging
cloud-based Technologies and ensuring
quality we aim to equip you with tools
and knowledge to create robust and
scalable ETL pipelines to handle any
data challenge so buckle up and get
ready to revolutionize your data
workflow join us in this accelerating
journey to master the art of ETL
pipelines having said that if an
aspiring data analyst looking for online
training and certifications from
prestigious universities and in
collaboration with leading experts then
search no more simply learns
postgraduate program in data analytics
from Purdue University in collaboration
with IBM should be a right choice for
more details use the link in the
description box below with that in mind
over to our training experts hey
everyone so without further Ado let's
get started the ETL pipeline so ETL
basically stands for extract transform
and row so ETL pipelines fall under the
umbrella of data pipelines a data
pipeline is simply a medium of data
extraction filtration transformation X
protein and loading activities through
which the data is delivered from
producer to Consumer to make it a little
simpler the data is produced in two type
let's say you run a vehicle showroom and
you are being a data producer so the
data that you produce is very less and
that could be basically fit into an
Excel sheet this type of data might need
update once in 24 hours or based on your
audit cycle here we call it match data
and this data is processed using the
oltp model and the batch processing
tools but now let's say you're running
an entire vehicle manufacturing plant
now the data you're dealing with is
voluminous and includes various types of
data it can be structured data
semi-structured data ranging from space
inventory to all the way up to robotic
assembly sensors data based on
requirements this type of data needs
updates maybe every hour every minute or
even every subtle such type of data is
called real-time data and needs
real-time data streaming Frameworks and
the data is processed using o l a p
models now ETL is involved in both these
approaches now let's dive in and
understand what exactly is an ETL
pipeline ETL stands basically for
extract transform and load and
representing these three core steps in
data creation and transformation process
let's dive into each phase and explore
their significance firstly extract the
first step in ETL pipeline is extracting
data from various sources these sources
can range from relational databases data
warehouses apis or even streaming
platforms the goal is to gather raw data
and bring it into centralized location
for further processing tools like Apache
Kafka Apache nifi or even custom scripts
can be used to perform the extraction
efficiently next is transform once the
data is extracted it often requires a
significant cleaning validation and
restructuring this is transformation
phase the transformation phase ensures
that the data is consistent standardized
and ready for analysis Transformations
can include tasks such as data cleansing
filtering aggregating joining or
applying a complex and business rules
tools like Apache spark Talent OR python
libraries like pandas are commonly used
with these Transformations lastly we
have the load phase the final step is
loading the transform data into Target
systems such as data warehouse data lake
or database optimized for analysis this
allows business users and analysts to
access and query the data easily loading
can invote batch processing or real-time
streaming depending upon the requirement
of the Business Technologies like Apache
Hadoop Amazon redshift or Google
bigquery are often employed for
efficient data loading now that he
understood the core phases let's explore
some key Concepts and best practices for
building robust ETL pipelines firstly
data quality ensuring data quality is
crucial for Reliable analysis
implementing data validation checks
handling missing values and resolving
data and consistencies are vital to
maintaining data Integrity throughout
the pipeline next is scalability as data
volumes grow exponentially scalability
becomes essential distributed computing
Frameworks like Apache spark enable
processing lowest date assessing hello
allowing the pipelines to handle
increasing data loads efficiently
thirdly we have error handling and
monetary robust error handling
mechanisms such as retry logging and
alerting should be implemented to handle
failures gracefully additionally
monitoring tools can provide a real-time
insights into pipeline performance
allowing quick identification and
resolution of issues
we have incremental loading for
continuously evolving data sets
incremental loading strategies can
significantly improve pipeline
efficiency rather than processing the
entire data set each time only the new
or modified data is extracted and
transformed reducing processing time and
resource consumption and lastly we have
a data garments and security
incorporating data gun statuses and
adhering to security protocols is
crucial for protecting sensitive data
and ensuring compliance with regulations
like gdpr or hip AAA now that we have
covered what exactly is ETL and ATF
stages and also the best practices for
18 pipelines less proceeding with
understanding the popular ETL tools so
the first one amongst the popular ETL
tools as the Apache airflow Apache
airflow is an open source platform that
allows you to schedule Monitor and
manage complex workflows Apache airflow
provides a red set of operators and
connectors enabling seamless integration
with various data sources and
destinations next is Thailand a
comprehensive ETL tool that offers a
visual interface for Designing data
integration workflows Talent provides a
vast array of pre-built connectors
Transformations and data quality
features making a an ideal choice for
Enterprises and lastly we have
Informatica formatica is a widely used
complex data integration scenarios Power
Center offers a robust set of features
like metadata management data profiling
and data lineage and powering
organizations so what is data analysis
data analysis is not just a single step
but a set of processes it is the process
of collecting data then cleaning it when
I say cleaning it simply means removing
the a11 data and then this data is
transformed into meaningful information
we can simply relate this process to how
you make a jigsaw puzzle just like how
you gather all the pieces together and
fit them accordingly to bring out a
beautiful picture
data analysis also works on almost the
same grounds
to achieve the goals of data analysis we
use a number of data analysis tools
companies rely on these tools to gather
and transform their data into meaningful
insights so which tool should you choose
to analyze your data which tool should
you learn if you want to make a career
in this field we will answer that in
this session after extensive research we
have come up with these top 10 data
analysis tools here we will look at the
features of each of these tools and the
companies using them so let's start off
at number 10 we have Microsoft Excel all
of us would have used Microsoft Excel at
some point right it is easy to use and
one of the best tools for data analysis
developed by Microsoft Excel is
basically a spreadsheet program using
Excel you can create grids of numbers
text and formulas it is one of the
widely used tools be it in a small or
flat setup
the interface of Microsoft Excel looks
like this
let's now move on to the features of
excel
firstly Excel works with almost every
other piece of software in office we can
easily add Excel spreadsheets to Word
documents and PowerPoint presentations
to create more visually appealing
reports or presentations
the windows version of excel supports
programming through Microsoft's Visual
Basic for applications VBA
programming with VBA allows spreadsheet
manipulation that is difficult with
standard spreadsheet techniques
in addition to this the user can
automate tasks such as formatting or
date organization in VBA
one of the biggest benefits of excel is
its ability to organize large amounts of
data into orderly logical spreadsheets
and charts by doing so it's a lot easier
to analyze data especially while
creating graphs and other visual data
representations the visualization can be
generated from specified group of cells
those were few of the features of
Microsoft Excel
let's now have a look at the companies
using it most of the organizations today
use Excel few of them that use it for
analysis are the uk-based company Ernest
and Young then we have Urban Pro Wipro
and Amazon
moving on to our next data analysis tool
at number nine we have rapidminer
a data science software platform
rapidminer provides an integrated
environment for data preparation
analysis machine learning and deep
learning
it is used in almost every business and
Commercial sector rapidminer also
supports all the steps of the machine
learning process
seen on your screens is the interface or
rapidminer
moving on to the features of rapidminer
firstly it offers the ability to drag
and drop it is very convenient to just
drag drop some columns as you are
exploring a data set and working on some
analysis
rapidminer allows the usage of any data
and it also gives an opportunity to
create models which are used as a basis
for decision making and formulation of
strategies
it has data exploration features such as
graphs descriptive statistics and
visualization which allows users to get
valuable insights
it also has more than 1500 operators for
every data transformation and Analysis
task
let's now have a look at the companies
using rapidminer we have the Caribbean
Airline Leeward Islands Air transport
next we have the United Health Group the
American online payment company PayPal
and the Austrian Telecom company
MobileComm so that was all about
rapidminer now let's see which tool we
have at number eight
we have talent at number eight
Talent is an open source software
platform which offers data integration
and management it specializes in Big
Data integration Talent is available
both in open source and premium versions
it is one of the best tools for cloud
computing and Big Data integration
the interface of talent is as seen on
your screens
moving on to the features of talent
firstly automation is one of the great
Boon's Talent offers it even maintains
the tasks for the users this helps with
quick deployment and development
it also offers open source tools Talent
lets you download these tools for free
the development costs reduce
significantly as the process is
gradually speed up
Talent provides a unified platform it
allows you to integrate with many
databases SAS and other Technologies
with the help of the data integration
platform you can build flat files
relational databases and Cloud apps 10
times faster
those were the features of Talon the
companies using Talent are Air France
L'Oreal cab Gemini and the American
multinational Pisa restaurant chain
Domino's
next on the list at 7 we have nine
Constance information Miner on nime is a
free and open source data analytics
reporting and integration platform
it can integrate various components for
machine learning and data mining through
its modular data pipelining concept nime
has been used in pharmaceutical research
and other areas like CRM customer data
analysis business intelligence text
Mining and financial data analysis
here is how the interface of nime
application looks like
now coming to the nine features
9 provides an interactive graphical user
interface to create visual workflows
using the drag and drop feature
use of jdbc allows assembly of nodes
blending different data sources
including pre-processing such as ETL
that is extraction transformation
loading for modeling data analysis and
visualization with minimal programming
it supports multi-threaded in-memory
data processing 9 allows users to
visually create data flows selectively
execute some or all analysis steps and
later inspect the results models and
interactive views
9 server automates workflow execution
and supports team-based collaboration
nime integrates various other open
source projects such as machine learning
algorithms from Becca H2O Caris Park and
our project
9 allows analysis of 300 million custom
addresses 20 million cell images and 10
million molecular structures
some of the companies hiring for nime
are United Health Group asml fractal
analytics atos and LEGO Group let's now
move on to the next tool we have SAS at
number six
SARS facilitates analysis reporting and
predictive modeling with the help of
powerful visualizations and dashboards
in SAS data is extracted and categorized
which helps in identifying and analyzing
data patterns
as you can see on your screens this is
how the interface looks like
moving on to the features of SAS
using SAS better analysis of data is
achieved by using automatic code
generation as a SQL
SAS allows you to access through
Microsoft Office by letting you create
reports using it and by Distributing
them through it
SAS helps with an easy understanding of
complex data and allows you to create
interactive dashboards and reports
let's now have a look at the companies
using SAS we have companies like genpact
iqria Accenture and IBM to name a few
that was all about SAS
so for all those who joined in late let
me just quickly repeat our list at
number 10 we have Microsoft Excel then
at number nine we have rapidminer at
number eight we have talent at number
seven we have nine and at number six we
have SAS so far do you all agree with
this list let us know in the comment
section below let's now move on to the
next five Tools in our list
so at number five we have both R and
python yes we have two of them in the
fifth position
R is a programming language which is
used for analysis as well it has
traditionally been used in academics and
research python is a high level
programming language which has a python
data analysis Library it is used for
everything starting from importing data
from Excel spreadsheets to processing
them for analysis
this is the interface of r
next up is the interface of the Python
Jupiter notebook
let's now move on to the features of
both R and python
when it comes to the availability of R
and python it is very easy both are and
python are completely free hence it can
be used without any license
I used to compute everything in memory
and hence the computations were limited
but now it has changed both are in
Python have options for parallel
computations and good data handling
capabilities
as mentioned earlier as both R and
python are open in nature all the latest
features are available without any delay
moving on to the companies using R we
have Uber Google Facebook to name a few
python is used by many companies again
to name a few we have Amazon Google and
the American photo and video sharing
social networking service Instagram
that was all about R in Python
at number 4 we have Apache Spark
Apache spark is an open source engine
developed specifically for handling
large-scale data processing and
Analytics
spark offers the ability to access data
in a variety of sources including Hadoop
distributed file system htfs openstack
Swift Amazon S3 and Cassandra
it allows you to store and process data
in real time across various clusters of
computers using simple programming
constructs
Apache spark is designed to accelerate
analytics on Hadoop while providing a
complete Suite of complementary tools
that include a fully featured machine
learning library a graph processing
engine and stream processing
so this is how the interface of Apache
spark looks like
now let's look at the important features
of Apache Spark
stores data in the ram hence it can
access the data quickly and accelerate
the speed of analytics spark helps to
run an application in a Hadoop cluster
up to 100 times faster in memory and 10
times faster when running on disk
it supports multiple languages and
allows the developers to write
applications in Java Scala r or python
Spar comes up with 80 high-level
operators for interactive querying spark
code for batch processing join stream
against historical data or run ad hoc
queries on stream state
analytics can be performed better as
spark has a rich set of SQL queries
machine learning algorithms complex
analytics Etc Apache spark provides fall
tolerance through spark rdd spark
resilient distributed data sets are
designed to handle the failure of any
worker node in the cluster thus it
ensures that the loss of data reduces to
zero
conviva Netflix IQ via Lockheed Martin
and eBay are some of the companies that
use Apache spark on a daily basis
at number 3 we have another important
growing data analysis tool that is Click
View
click view software is a product of
Click for business intelligence and data
visualization click view is a business
Discovery platform that provides
self-service bi for all business users
and organizations
with click view you can analyze data and
use your data discoveries to support
decision making
clickview is a leading business
intelligence and analytics platform in
Gartner magic quadrant
on the screen you can see how the
interface of Click view looks like
now talking about its features
clickview provides interactive guided
analytics with in-memory storage
technology during the process of data
Discovery and interpretation of
collected data the clickview software
helps the user by suggesting possible
interpretations
clickview uses a new patent in-memory
architecture for data storage all the
data from the different sources is
loaded in the ram of the system and it
is ready to be retrieved from there
it has the capability of efficient
social and mobile data discovery
social data Discovery offers to share
individual Data Insights within groups
or out of it
a user can add annotations as an
addition to someone else's insights on a
particular data report clickview
supports mobile data Discovery within an
HTML file enabled touch feature which
lets the user search the data and
conduct data Discovery interactively and
explore other server-based applications
clickview performs olap and ETL features
to perform analytical operations extract
data from multiple sources transform it
for usage and load it to a data
warehouse
the companies that can help you start
your career and click view are
Mercedes-Benz cab Gemini Citibank
cognizant and Accenture to name a few
at number two we have power bi
power bi is a business analytics
solution that lets you visualize your
data and share insights across your
organization or embed them in your app a
website
it can connect to hundreds of data
sources and bring your data to life with
live dashboards and reports
power bi is the collective name for a
combination of cloud-based apps and
services that help organizations collate
manage and analyze data from a variety
of sources through a user-friendly
interface
power bi is built on the foundation of
Microsoft Excel and has several
components such as Windows desktop
application called Power bi desktop and
online software resist service called
Power bi service mobile power bi apps
available on Windows phones and tablets
as well as for IOS and Android devices
here is how the power bi interface looks
like as you can see there is a visually
interactive sales report with different
charts and graphs
moving on to the features of power bi
it has an easy drag and drop
functionality with features that make
data visually appealing you can create
reports without having the knowledge of
any programming language power bi helps
users see not only what's happened in
the past and what's happening in the
present but also what might happen in
the future
it offers a wide range of detailed and
attractive visualizations to create
reports and dashboards you can select
several charts and graphs from the
visualization pane power bi has machine
learning capabilities with which it can
spot patterns in data and use those
patterns to make informed predictions
and run what-if scenarios
power bi supports multiple data sources
such as Excel Tech CSV Oracle SQL Server
PDF and XML files the platform
integrates with other popular business
management tools like SharePoint Office
365 and Dynamics 365 as well as other
non-microsoft products like spark Hadoop
Google analytics sap Salesforce and
MailChimp
some of the companies using power bi are
Adobe AXA Carlsberg capgemini and Nestle
moving on to the next tool so any
guesses as to what we have at number one
you can comment in the chat section
below
finally on the top of the pyramid we
have tableau
Gartner's magic quadrant of 2020
classified Tableau as a leader in
business intelligence and data analysis
Tableau interactive data visualization
software company was founded in Jan 2003
in Mountain View California
Tableau is a data visualization software
that is used for data science and
business intelligence it can create a
wide range of different visualization to
interactively present the data and
showcase insights
the important products of Tableau are
Tableau desktop Tableau public Tableau
server Tableau online and Tableau reader
this is how the interface of Tableau
desktop looks like
now coming to the features of tableau
data analysis is very fast with Tableau
and the visualizations created are in
the form of dashboards and worksheets
Tableau delivers interactive dashboards
that support insights on the Fly
it can translate queries to
visualizations and import all ranges and
sizes of data writing simple SQL queries
can help join multiple data sets and
then build reports out of it you can
create transparent filters parameters
and highlighters
Tableau allows you to ask questions spot
Trends and identify opportunities with
the help of Tableau online you can
connect with Cloud databases Amazon
redshift and Google bigquery
the company is using Tableau are
Deloitte Adobe Cisco LinkedIn and the
American e-commerce giant Amazon to name
a few
and there you go those are the top 10
data analysis tools
let's now have a question and answer
session please feel free to post your
queries in the comment section and we'll
respond in the chat
before the question answer session let's
recap quickly in the meanwhile you all
can post your questions in the comment
section below
so at number 10 we have Microsoft Excel
then at number nine we have rapidminer
at number eight we have talent at number
seven we have nine at number six we have
SAS R and python at number five Apache
spark at number four
click View at number three power bi at
number two and finally we have Tableau
topping the list at number one if you
are an aspiring data analyst with
minimum one year of experience in the
domain and looking for online
professional certification programs from
prestigious universities to upskill and
get ahead in your career then search no
more
professional certificate course in data
analytics should be a right choice for
more details use the link in the
description box below also if you are a
professional data analyst with minimum
one year of experience in the domain
online bootcamp programs and
certifications from prestigious
universities and in collaboration with
leading experts then search no more
simbilance data analytics bootcamp from
Caltech University in collaboration with
IBM should be a right choice for more
details use the link in the description
box below with that in mind or to our
training experts hi everyone welcome to
this tutorial on Microsoft Excel so we
will learn about functions and formulas
we will learn about conditional
formatting data validation pivot chart
and pivot table
now let's look at the scenario here so
one day in a startup
One Professional speaks that their
business is growing and they would need
an efficient way to work with the data
they would have to find a way to work
faster with storing and analyzing data
now to that another colleague response
well we can make use of Microsoft Excel
to do this job
the question is will excel be able to
cater to their business needs
now
the colleague response well we can make
use of excel in several ways and it also
is a cost efficient option
now in that case the colleague who posed
the question says let's go ahead with
Excel and let's train our employees in
Excel
and the suggestion is welcomed which
would make the job easier for them
and they would basically decide on using
Excel so they decide on taking a
training right away and basically
starting to learn Excel
now
before we move to excel one of the
question is why should we use Excel
so let's look at some of the points here
so Excel proves to a be a great platform
to perform various mathematical
calculation on large data sets which is
one of the biggest requirements of
various organizations these days various
features in Excel like searching sorting
filtering makes it easier for you to
play with the data and Excel also allows
you to beautify your data and present it
in the form of charts tables and data
bars
now when it comes to reporting reporting
accounting and Analysis can be performed
with the help of excel
it can help you with your task lists
your calendars and goal planning
worksheets
Excel also provides good security for
your data Excel files have the feature
of password protection this way your
information can be safe
now when we talk about what is Excel and
how it can be used
so Excel or you might have heard a
spreadsheet can be basically used for a
lot of different tasks than just storing
the information in so-called tabular
format
now Microsoft Excel is an application
that is used for recording analyzing and
visualizing data it is in the form of a
spreadsheet
let's have a look at few of the
functions and formulas used in Excel and
before we do that we can also quickly
take a small tour to understand how to
work with Excel now to do that what we
can do is we can type in in our search
say for example Excel and just select
your Excel app which is installed and
here you see you have lot of options
which says take a tour drop down list
get started with formulas make your
pivot table going forward with pie
charts and much more so we can click on
this one which says take a tour
and that basically pops up a window
which says welcome to Excel and if you
have always wanted to be better at Excel
you have this which can help you so
let's click on Create and that takes us
to the store window now that says
instructions for screen readers which
basically talks about 10 different steps
in which we can learn Excel and using
the spreadsheet app
so there are more than 11 sheets which
we see here at the bottom end and each
one gives us a simple example which we
can work on so for example if I click on
ADD now that takes me to this page which
says how do we add numbers now you might
be provided data which we can upload by
loading a file from our machine or
getting data from a web Source or even
connecting to a database so there are
various options which we will see in
some time so here we have an option
which is called Data you can click on
this one and this basically has
options where you can use existing
connections if you have created some you
can always click on from other sources
and you can get your data from SQL
Server from analysis services from odata
data feed you can get in from XML from
data connection Wizard or also from
Microsoft query you can be running in
different queries here which shows up in
the option which says new query there
are connections which you can use and
that basically will display all the
connections for this particular workbook
which we do not have as of now but we
can create them but let's look at simple
examples now you can follow these
instructions here which says basically
adding up the numbers and that could be
easily done by just placing your cursor
here and what you could do is either you
can type in the formula that is from
which row to which row you would want to
add the data so for example I could just
do a sum here and that shows up all the
different functions which are available
then we can open up a parenthesis and we
can say I would be interested in
totaling the amount
from
column D and I would select for example
D4 so I could be doing this and then I
could say D4
onwards till d 7 so that's the data
which I'm interested in you can close
your parenthesis and hit enter and that
gives you the total
there is also a shortcut for this which
you can always do is we can first delete
this and you can just place your cursor
here and just use your alt and equals
that automatically selects the
numericals which we can anytime expand
or basically collapse so I will
basically select this which says this
function needs two numbers which is
number one and number two and then you
can hit on enter and that gives you the
total so similarly we can be getting in
the data here by selecting all the
fields so here it also says that you can
use a shortcut now what we can also do
is we can add numbers over 50 by
selecting the yellow cell here and then
giving a condition
such as so I can basically use something
like sum if and then open a parenthesis
I can select I would be interested in
this row and then I can even drag and
drop
till here so that tells me D 11 to D15
you can then put in a comma here and you
can give your condition say for example
we would say I would be interested in
numbers only above 50 and we can select
this
close your codes and then just close
your parenthesis and that's your formula
so you can do this and that basically
gives me the total is hundred now
similarly we could do that for the
amount here I could select this now
there is also an option I can click on
home and I can go for something like
Auto sum so that's one more way of doing
it which anyway says sum is alt plus
equals so it automatically adds up your
values and I can try doing a auto sum
that automatically selects my rows and
then I can get my total now as for this
activity here it says try adding another
sum F Formula here but add amounts that
are less than 100 and the result should
be 160. so what we can do is we can
basically select all the numbers which
are lesser than 100 so the way we did
earlier here there can be always a
shortcut so you can always for example
if you would want to avoid typing in the
formula you can always copy it from here
and then just hit on enter so you are
back into this cell and then I can
basically go here and paste the number
and then as per the requirement we are
required to select anything which is
lesser than 100 so what I could do is I
could select here I could say let's say
G and then I can change this value to
g15 and that's one more way now we see
our selected rows have been changed so I
can hit on enter and I can check what is
the result so we would be interested in
looking for numbers which are lesser
than 100 so I will have to also change
this one to a lesser sign and that
basically gives me the total which is
160. so that's how you can simply add
numbers you can use autosum you can type
in the formula you can select the fields
or you can just place your cursor where
you would be looking for a sum and then
you can just do a alt equals and that
basically populates the sum
now let's look at some easy options of
filling your cells or automatically
populating the values in your cells
within your Excel sheet now here we have
an option which says 100 now we can
click on this and that basically says it
is making a sum of column C4 to D4 so if
I click on this one I can check that
this is row number four which shows up
here and I also know this is column C I
also have D so this equals is basically
giving me a sum of C4 to D4 now what we
can do is we can always place our cursor
here at the right corner and then we can
just drag and drop and this basically
gives me a total of all the numbers for
all different rows so this is one
shortcut which we can do to get the
total Excel will automatically give the
totals which we call as filling down now
what we can do is in the same way if we
would want to get the totals here we can
first check what is this 200 and this
tells me this C11 to c14 total so it is
totaling the rows from C11 so column C
and 11th row till 14th row and that's
the sum now what I can also do is I can
similarly like above we can do a filling
right which basically means bringing
your cursor here and then just dragging
and dropping it all the way where you
would need the totals and this basically
gives me the total there is one more
quick way to check if this is right so
the easiest option would be to select
this cell now what I can also do is I
can just select all of these fields by
just highlighting and selecting all the
fields once it is selected press on Ctrl
R and that gives you the total now if we
would be doing this stop down then I
could select all these rows for this
particular column and then I could do a
control D so that's your filling down
and this one was filling right so this
is an easier option of doing a fill when
you would want to have the formula
applied to every row as it occurs in the
first row or the last row we could test
this by for example selecting these
fields I could delete them and I have
here which says 130 I could just place
my cursor here and I could drag it all
the way up and that should also do the
same magic which we were seeing from top
down so this is a simple way wherein you
can fill up your cells and you can also
automatically really
propagate or move your computation to
all the cells
let's look at the split option which
basically helps us in splitting the data
when we have some kind of pattern or
when we have some kind of delimiters in
our data in say one particular column
and we would want to derive the values
out of it so we can always use the
splitting option now the easiest option
would be so for example we have our
email column which has the email IDs and
which we can clearly see has a first
name dot last name now I see that there
is a last name Smith filled up here
first name is empty so what I can also
do is I can just type in say Nancy here
now that's the first name I can again
start typing the second name and as soon
as you do that you would see a faded
list of numbers and that's your clue to
hit enter and once you do that you would
see all the first names have been filled
in here if you would want to maintain
the case sensitiveness you can just go
ahead and delete these and let's type in
as it occurs so let's say Nancy as the
first name go down to the next cell and
just type in Andy and there is your
grade list so just hit on enter and that
basically fills up your first name what
we can also do is
we can just select this particular field
and either we can type in control e
which basically fills up all the options
now I can just do a undo by typing in or
clicking Ctrl Z and that's basically
gone what I can also do is I can select
a particular field and then I can go
into home option and under home you have
an option here which says fill so you
can select this and then you can do a
Flash Fill which is what we are doing
here so click on Flash Fill and that
automatically fills up the values so in
this way you can work within your
spreadsheet and you can be filling up
the values where a delimiter by default
is understood and we can split the data
now however sometimes you might have
some data which has a different kind of
delimiter and there is again a smarter
way of splitting your data so you can
always scroll down here and that says
splitting a column based on delimiters
so we have some values in the data
column and these values in each row are
separated by comma so
select this your data is already
selected text to columns delimited comma
selected and now click on next so it
basically says what is the destination
let's select this one
and I can choose what would you want to
have so that shows me this would be my
data preview now I can basically select
this one I can say finish and say okay
and now if you see our data has been
placed in in the columns appropriately
so this is how you can split your data
based on a delimiter and then organize
your data in a better way now there are
some Advanced options which we can learn
later but this basically tells about
using a formula so this is something if
say if we have some name in one cell and
if you would want to split it into first
name your helper column your middle name
last name so that can also be done using
formulas and this basically tells how
would you extract characters from your
left cell and how would you place them
in your right cell so you can try this
activity which is a little more of
advanced option the benefit is that you
can always use this
wherein if you do some kind of
transformation using your formulas if
your original data gets updated then the
split data will also get updated and
that's the benefit of using formulas
where you can place values from one cell
into multiple cells based on execution
of your details in the formulas
how about using the transpose option now
you might have heard of situations where
you would want to switch or turn your
rows into columns and your columns into
rows and that's where transposing comes
into picture it might be useful when you
have your data in your X and Y axis or
as I would say in rows and columns and
you would want to switch your rows to
become the columns and columns to become
your rows so what we can do is the
simplest way is you can select all your
values so here we basically have six
columns and I would say two rows now I
can select all of these and then I can
select an empty field for example the
one which is highlighted here well you
can always do a control alt V that's a
shortcut what you can also do is once
you have selected all your Fields you
can just copy them so just do a Ctrl C
and then click on an empty cell and then
what you can do is you can do a special
paste or paste special so under your
home you have the paste option and here
you can go for paste special and once
you do that you need to select the
transpose option over here and click on
OK and now you will see that the columns
and the rows have been transposed so
your row name was item and that has
become the column heading you had row
name as a mount and that has become the
column heading and and all your values
have been transposed in this particular
format now there is another way of doing
that and again that's using your
formulas so what you can do is you can
transpose with a formula also and that
basically works when you have similar
kind of data so this has six columns and
basically two rows so you can basically
do this so you can select this and
earlier we were doing a copy but now
what we would want to do is we would
want to just look at the row numbers
which tells me it is c33 c34 and it
starts with c and ends in with your H
column so what we can do is we know that
we have six columns and two rows so
transposing that would actually give me
two columns and six rows so what we can
do is we can select two columns and six
rows in our Excel sheet I can then
basically start typing in the message or
I can just go to the address bar and
here I can say
transpose
let's go for c33 h34 it basically
selects my data and now I can just do a
control shift and enter and now if you
see all the values have been populated
now you can just place your cursor in
one of the cells but if you see the
address bar the formula Remains the Same
this is because this is an array formula
so we can read more about an array
formula here it's basically something
which performs calculations and on more
than one cell in an array and in the
example here the array is the original
data that is c33 to h34 so your
transpose is just changing the
horizontal orientation to the vertical
orientation so this is a very simple way
in which you can basically use the
excel's capability to transpose your
data and convert your rows into columns
and columns into rows apart from working
on
additions subtractions filling up your
data sorting the data or basically
splitting your data transposing your
data one of the other requirements is
sorting and filtering your data so that
can be very handy when you're working on
huge data and you would want to sort it
in a particular order say ascending or
descending or might be based on a
particular field or if that field was or
if the cell was highlighted with a
particular color sorting the data so
let's look at how Excel can be used for
sorting and filtering examples are
pretty simple here so let's check that
so if we're going to sort and filter and
say this is the data I have say for
example I would want to sort the values
in the department column alphabetically
so what I can do is I can select
Department column and I'm already in the
Home tab I can straight away go here
which says sort and filter I can then
say sort A to Z and that's basically
alphabetically sorting your department
column and once once I do this you would
see the data has been sorted but it's
not just this data we can just do a
control Z and check what are the values
we have so here we have meet which is
beef and ninety thousand hundred ten
thousand the values then you have Bakery
which should ideally be the first row if
we sort it in an alphabetical order
which goes with Bakery as desserts you
have the values so we can check this
again so select department and then just
do a sort and filter and let's say sort
A to Z and if you see the data has
changed but it's not just in changing
your First Column but then it has taken
care of all the data however the data
has been sorted based on the department
column so you have Bakery which aligns
with deserts which has the values and
now now we have all the data which has
been filtered now what we can also do is
we can sort December's amounts from
largest to smallest so what we can do is
we can basically click any cell in the
December column let's say 20
000 and then what I can do is I can go
into sort filter and then I can say sort
largest to smallest so if you see Bakery
breads is the row which has the smallest
data or maybe you have Delhi sandwiches
so that one looks also smaller so let's
do a larger to smallest and if I do this
you would see the values have been
shifted now so it is no more based on
the department column
because now the data is being sorted
based on the values in the December
column and you see Bakery which was
alphabetically the first one has become
second last
so either you can sort the data based on
a department column which goes based on
the values these are all string values
or words so it sorts alphabetically if
you have numbers might be you can give
some values and you can sort the data
you could anytime do a custom sort and
you could basically select if you would
want to select the data so I could do a
custom sort and then I could choose
which is the column which we would want
to use for sorting what is the Sorting
needs to be done is it cell values is
its cell color font color conditional
formatting and then you can also choose
the order so that's one more way to do
that now if you scroll down that also
shows how you can sort by date or a
color so for example if you would want
to sort based on the expense date so
there are different options so what I
can do is I can select this date field I
can just do a right click I can go into
sort and then I can choose I would want
to sort oldest to newest so since I
selected the date field it basically has
sorted all the data and it has taken the
expense date into consideration now
there are these filters which you see on
the row headings we could have also used
those so I could have selected this and
that basically says or mentions which
are the dates I would be interested in
looking at I also have sort by color
here I can do a sort oldest newest or
newest to oldest so I could also use
these filters which have been applied
here now we have the data which is in
color so if I would want to basically
select the color columns or color cells
I could select this I can basically do a
right click here and when I go into sort
I could choose put selected color or
cell color on the top and that basically
will make sure that my data is sorted
and it has also sorted that in a
descending order so in this way you can
sort or or basically filter your data
what we can also do is we can add
filters so sometimes we can go for
formulas which we would want to use what
we can also do is we can basically
select the filter which has been applied
here now how does the filter come in
there so if I would select a particular
row I could select a particular row and
then I could decide if I would want to
just add a filter to this one and that's
how the filter has come in so we have
the filter what we can do is we can
basically click on this drop down and
then you have something like number
filters so we can always go here we can
basically choose one of these so we can
basically choose above average so I
could select this and then basically it
shows me the values we could also delete
the filter by clicking on this one and
we could say well I'm not interested in
this filter anymore so I could clear the
filter and that shows me all the values
or I could say
that let's click on some other field for
example food I can go in here I can go
into number filters and then I could say
well I'm interested in values which are
below average above average might be
greater than and then I can choose what
is the value so for example if we say I
am interested in food which is greater
than 25 dollars I could give a value
here I could say okay and now I have
applied the filter similarly you can
select this and then you can just clear
your filter and your data is back so
remember no data is lost it is just
hidden or basically based on the filter
not shown so that's good enough for us
and in this way you can sort and filter
the data so for more details obviously
in all the sheets you have the links
which point to more information on the
web and you can always refer to these so
this is simple way in which you can sort
and filter any amount of data which has
been stored within your Excel within a
particular sheet now that we have
learned about add fill split transpose
sorting and filtering it will also be
good to learn how to work with tables or
basically converting your data into a
tabular format and then doing some easy
computations so click on this tables
option here now here we see there is
some data which is in five columns and N
number of rows so I can basically select
this data and then what I can do is I
can insert choose the table option and
then it says my table as headers and
we'll be okay with that I'll say okay
and now if you see this is the table
created it basically has different
filters which we have learned earlier
how to use and this is basically my
table which is a collection of cells
which has some special features so we
can easily add rows to this table we can
add columns to this table and we can
even do some calculations so for example
here I can click on this one I can
basically enter some field and then I
can hit on enter and we see that this
row has been inserted wherein we can
easily fill in values for example I
would say chocolates
I could give some value here size 25
000 might be 35
000 and then basically I can given some
values here now what you can also do is
you can continue adding rows in this way
and say for example you would want more
columns so you can select this
option here in the top bottom right
corner you can just drag it towards the
right and that basically has
automatically created columns for my
next months wherein I can feed in the
data so this is a simpler way wherein
you can keep adding more rows and
columns to your data if that has been
converted in a tabular format now let me
just do a control Z that basically
deletes the columns again Ctrl Z deletes
the last row which we added and I can
stop here or I can even remove my values
by doing multiple control Z and removing
my rows so this is how I converted my
data into a table and then I can easily
work on this what I can also do is I can
do some calculations so what we can do
we have a table here we have a total
field and what we can do is we can just
select one cell here now as we have
learned earlier we can do a alt and then
equals and that basically says what is
this doing so it says it is calculating
the sum of the last three months and if
that's what you would want to do just
hit on enter and it has automatically
calculated the totals for all your rows
for these three columns so the sum
formula is getting filled up now I can
select any particular cell and I can
look in my address bar so it has already
given me the formula where it has
started calculating the sum from the
October column till the December column
and has given me the calculated values
of the columns what we can also do is we
can get total rows in the table now
that's a simpler option so what we can
do is we can select any l in this
particular table
and then we see that there is a table
tools design option showing up here now
I can select this and then it says well
let's get a total row so let's select
this and it automatically populates the
total here and if you would want the
average then we could select this and
from the drop down I can select what I'm
interested in so for example I would
want the average values and not the
total I could just select this and that
gives me the average of these values so
we can always do simpler computations
here by converting our data into table
format let's learn about one more
efficient way
of working with the data and that's
using your drop downs so let's see how
drop downs work here now say for example
you have this data which has the values
in the food column and department is
empty and say for example you would want
to enter the values in Department
however you would want to select the
department should either have produce or
meet and bakery and these are the only
three options which should be available
for any user to fill in the values how
do we do that so we can basically create
a table by pressing Ctrl D so what I can
do is under my department
here I can select one of the cells and
then I can do a control T that basically
converts this into a table I can say
okay and my table is created now what I
can do is once this part is done
we can select all the blank Fields here
where we would want this drop down to be
applicable now under your data tab you
can go in and select data validation and
this has an option called Data
validation click on this which basically
says allow any value so here I will
select I would want to give a list of
values and then I can type in my values
here which I can say produce
say for example meet and then say Bakery
now these are the values so we can click
on okay
and once we have done that we basically
have a drop down here next to Apples
which will only show us the values which
we can feed in under the department
column so I can go into every cell and
then I can basically choose what is the
department which handles this and then
basically I can select one of these from
the drop down so this is an easier
option of creating your drop down and
then feeding in the values from the set
of values which you have defined here on
the right so this is a simple example of
using your drop downs working with your
tables working with your sort and filter
transpose split filling up your data
adding in some data here and similarly
you can use Excel for more than one use
case using its inbuilt features to
easily work with your data let's see how
we can import data or bring in data into
our Excel from your local machine or
from an external web source so what we
can do is we can open up a blank Excel
sheet and say for example you have been
provided a text file or a CSV file and
you would want to import that data into
your Excel sheet that can be easily done
so right now I've opened an Excel sheet
now I can click on data and here I have
an option which says existing
connections from other data sources so
or you can click on connections if you
have already created some so we can
click on from other sources so this is
one option where you can connect to your
different data sources and you can get
the data from one of these what we can
also do is I can click on connections
now it says there is none I can click on
ADD it says well show the connections
where connection files or Network
connection files on this computer so I
can say let's get some files from this
computer now if that does not show up
something so say browse for more and
that basically shows you different
options so let's basically select a
folder where I have some data sets I'll
click in here and this is basically a
folder where I have some data sets now
let me select this particular file and I
know it is a CSV file so let's click on
open now if you would want to verify
this you could have gone and looked into
the properties of the file and it says
it is a DOT CSV file which is what we
are interested in so I'll take this file
I'll say open now this basically shows
me the text import wizard option which
says is the file delimited I'll say yes
click on next so I will select comma as
my delimiter I can say text qualifier is
none now this is my data so my data
preview is already showing me the data
is what is the data in the CSV file you
can click on next and then you have an
option which says data format is General
you can go for date format you can go
for advanced options so I'll just say
finish
and basically now this has been created
here so we basically have this and now I
can click on
close now once you have done that you
can click on existing connections it
shows me the data which we have here the
connection which we have created say
open and then it says do you want to
import this data or bring this data into
existing worksheet
you can also say add this to a data
model if you are doing some data
modeling so click on OK and now this
data is automatically inserted in my
Excel file I can basically save it
into
this particular sheet now what we can
also do is we can also start a new sheet
and that does not have a data and we can
get some other data from web so what I
can do is I can go into my GitHub and
let's say I would be interested in this
CSV file so I can select this and this
is my GitHub path a path on web so I can
click on draw and that basically gives
me the raw path where this particular
file is now you can select this copy
this particular path and here you can
come back to your Excel sheet we would
be interested in getting the data from
web might be from a text file where we
will have to specify the delimiters or
let's go to web and here I can given the
web path from where I would be
interested in getting the file let's
give the GitHub path which is publicly
available and then click on import now
once you click on import it tells me
that two Fields data and value
these are
within double quotes separated by comma
so first let's click on import
now once we do this it will basically
get the data from web and put in here it
says existing worksheet so we had
already created a new worksheet so let's
click on OK and now you have the data
coming in but then this basically shows
me in one particular field so what we
can also do is we can just do a control
a that selects all my columns here and
that's my data so we can then basically
filter this out so we can say text to
columns it's a delimited file click on
next we can select comma and let the
text qualifier be codes
it shows me data preview click on next
so you have the general format it shows
the destination that's the column click
on finish and now your data has been
split and you have the data which you
have imported from web so this is the
data which is coming in from web this is
the data which came in from my local
machine and similarly we can even create
connection with an existing database so
I can basically click on connections if
I would want to do that so I have an
option called connection here and it
says where the selected connections are
used I can basically click on ADD I can
basically choose if I would want to get
the files from Network or from computer
like we did earlier I can click on
browse for more which should show me
different other options to create
connections say you would want to create
a new SQL Server Connection you can
connect to a new data source coming in
from different place you could basically
choose what kind of connection would you
want so these are all the different
options which we can go for and we can
basically connect to a database for
example if I have some database and say
for example access database
I can see if there are some files with
that particular database and I can
import it so similarly we can also uh
click in here which says new query and
that also gives you an option of getting
the data from your files from all these
folders from databases so you can
basically click here and then you can
import data from a mySQL database
provided that is set up on your local
machine or on a particular server you
can go from cloud you can get it from
online services you can get it from
other sources which says from web from
your Hadoop file system from active
directory from a blank query and you can
even combine queries wherein you can run
a power query editor you can get the
data from different sources and then you
can bring it into your Excel so in this
way you can get your data from different
sources into your Excel into your
spreadsheet and then you can continue
working on those data sets
we have uh already learned some basic
operations which you can do in Excel and
let's Implement our knowledge by working
on this particular data which is coming
in from housing data set now here if we
see some fields we have agent date
listed area list price and this is
basically the data which has been sorted
in newest to oldest order of date listed
so how do we
arrive at this so what I can do is I can
just click on data listed and then I can
either go in here I can select sort I
can get into custom sort and then I can
choose the column based on which I would
want to sort the data so I would look
for the newest data to the oldest data
that means that would mean a descending
order of dates or you could say the
oldest state or the earliest month will
be towards the lower side of your sheet
so here we can select date listed now I
can say let it sort based on Cell values
and the order what we have here so we
have newest to oldest so let's select
this I can say okay and now if you see
the date has been sorted so we have your
10 18 2007 on the top so that seems to
be the latest date and as we go down we
will see an earlier month hour and
earlier month than that in the state
listed so we have sorted our data into
newest to oldest order and that's based
on your date column so the result shows
up here now what we can also do is we
can have different questions which we
would want to answer so for example I
would want to sort the data in ascending
order of area and descending order of
agent name how do we do that so let's
look into this so this is here I already
have the result here and how did I get
this so I'm looking for ascending order
of area and descending order of agent
name so we can start with any particular
column that does not matter so for
example if I look into this Excel sheet
I have my agent name select this which
we want in a descending order so we
could either do a sort and then go for
descending sort Z to A we could also use
the filter option here on the top right
and we could do it or I could just say
sort Z to A and then it has arranged the
data based on the agent column being in
descending order now I can go into area
and then I can again do a sort and I
wanted my area column to be used for
sorting the data and ascending to
descending and that basically not only
changes the order of this particular
column but for my complete data so let's
do that and now if you see we have the
data which has been sorted so we can see
how many values we have here and the
area values which we see and this is how
you get your result so I'll just do a
control Z and again and I'm back to my
original data and this is the sorted
result which we are seeing at similarly
we can answer other questions for
example sort the data according to the
following order of area that is we are
saying counties
Central and then your county so we can
basically choose in which particular way
we would want to do it so it is County
Central and then again County so if I
look into my sheet 3 so here I basically
have my data which is having some South
County then you have your Central and
then you have your North County so we
would want to sort the data to solar
problem which is according to the
following order so first we go for area
then we go for South County Central and
North County so what we can do is we can
basically have area field selected and I
would want to sort this particular data
so I have South County Central and North
County so I can basically go for custom
sort
and then I can choose which is the value
or column which I'm interested in let's
go for area
we will go for something like cell
values well you can also try to explore
conditional formatting icon if this is
what you would want to use or we can
basically go for just cell values and
here we can say if I would be interested
in first getting my values for South
County so for example I can say custom
list and then I can basically given the
new list here so I can say s
Dot County
and then I would want Central and then I
would want North County
so let's select this
as it exists we can basically say add
and that's basically the order which we
want to say okay and then say okay here
and now what we would want is we would
want our data so we can compare that
with the values which we see here it
starts with Kelly you have in the 12th
row something like Lang and that's what
we are doing so we can basically arrange
the data in a particular order by
choosing a custom list and then sorting
your data so that's one more simpler
task what we have done where we have
sorted the data in the order where
under our area column we first wanted
South County then we wanted Central data
and then we wanted North County so this
is how you can do it now let's look into
one more problem so it says find all the
houses in the central area and we would
want to basically apply a regular filter
let's let's see how do we do that so we
can click on this and here we have the
data so the problem statement is we
would want to find all the houses in
Central Area now how do we do that we
can do a sorting but we would want to
use the filter which you see here is
implemented so how do you do it so you
can select this area and say for example
I would want to apply filter I can just
go in here and I can say let's get a
filter on my first row and now I have
filters applied so we are interested in
looking into the Central Area houses
let's go in here it says all these
fields are selected that means it shows
everything wherein your area has all
these values let's unselect this and
then I will only be interested in the
central so let's say okay and then say
okay so now you see that the area filter
has been applied and we are looking at
the central column so what we have done
is we have applied a simple filter and
we are looking at our data at any point
of time if you do not want the filter
then what I can do is I can select this
and I can say well I'm interested in all
the data so I could do this or you can
clear the filters from area and you get
your data back so that's in one way you
can filter out your data so let's look
at an example of sort and filter where
we might have to filter the data based
on two columns or multiple columns with
different kind of values where it could
be and and or condition now say for
example this is the data I have and this
is the question which we need to answer
such as find the list of all houses in
the central region with pool and South
County without pool now if it was a
simple filter based on one cell I could
have just selected my header row I could
have then applied the filter
and once I have the filter I can look in
area where I have three regions so I'm
only interested in Central and South
County so I can get rid of North County
and that's fine but then we have two
different conditions here so we need the
data in central region to have the value
for pool being true
and for South County the value has to be
without pool now how do we do that so
what we can do is we can first create a
copy of these headers here so let me do
that now the area has to be South County
so basically I can either just select
this and I can choose this value
and then I can select this and then I
can choose Central so that's the
criteria which I have and the pool value
has to be so central region should be
with pool so then this one
basically has to be true
and this one has to be basically false
so south county is without pool so let's
select one of the values here and this
is my criteria now to get my result uh
we can always place your cursor here and
you can check this is M column and
eighth row okay so we would want the
result here so let's go ahead and now
click on data and then in filter you
have an option called Advanced and here
what I can do is I can say I would want
to filter the list in the place but
that's not what I would want to do so
I'll say copy to another location and
here if you see the list range will tell
me that this is the data so A1 to J 126
so a to J column selected and all the
rows criteria range is basically based
on what I have given here so that is m
from 1
to V which is 3
so I am selecting these columns and then
I am saying all the way whatever
criteria I have given and copy 2 I am
saying M8
to V8 so that basically will give me my
filtered result so you could basically
just say okay and now I have my data
which has been filtered and I have my
area which is South County that is
without Pool Central with pool again
South County without pool and then if
you look at your central value that's
pool so this is an advanced filter which
we have applied where simply we have
filtered the data based on two columns
and then we have our result so in this
way you can have your customized filter
applied on two different columns and get
your data which can be either replacing
the existing content or in the same
sheet in different set of columns and
rows you can have your result let's look
at one more example of filtering where
you are trying to filter the data based
on a and condition
condition being met in two different
columns and then you would want to
filter out the data for only specific
columns so the situation is the agents
with a house in North County that should
be County area having two and a single
type family so we are talking about two
bedrooms and we would basically have a
single type family and here the criteria
is that if we would want to only
populate these columns which is Agent
area bedroom and type now what you can
do is as I explained earlier that you
can get your result in the same sheet in
a different location so here I have
created these headers which says agent
area bedrooms and type now this is
basically a copy of all the columns what
we have here agent data listed area list
price bedrooms bath square feet feet and
so on so you can basically create a copy
of the headers here and this is where we
will give our Advanced criteria to
filter the data so the conditions which
need to be met is we need to look at
North County so for example here in area
I can basically go ahead and select one
of the values North County now the
criteria is having two bedrooms only so
let's say bedrooms and let's say the
value should be 2
and then basically I am saying a single
type family so when you would want the
single type family so here under type I
can give the criteria single type so
this is my and condition so we are
saying North County area having two
bedrooms and the type is single family
now this is the criteria which basically
means if I select this this one tells me
that this is m one row onwards till V
2 so this is what we have and we would
want to filter based on this so let's go
ahead and then go for data filter
advanced and here in advanced it says
filter the list in place now that's not
what we would want to do so I'll say
copy to another location this basically
selects the list range so which is
telling me A1
to J 126 so that's the
columns and rows selected criteria range
is based on M1 V2 which we have given
here and copy to I would say for example
from M7
2
P 7 now this is the area where I would
this is the place where I want the
result let's say okay and now I get my
data which is based on the question
which has been asked that you would want
the agents with a house in North County
area having two bedrooms and single type
family so in this way you can basically
do Advanced filtering get your data and
get it stored in the sheet anywhere at a
different location well I could have
also done filtering in place and that
would have replaced the data
which we have but that's not what we
want we would want the filtered result
in a different place so this is how you
can do some Advanced filtering we can
also use Excel to filter out the data in
one particular column which might be
conditional or say using some numerical
filters now here say for example the
problem statement is that you would want
to display all the houses whose list
price is between
45
000 to 600 000 or say for example we
would want to filter out the data to
something else say for example let's say
I have I would want to filter out the
data between 300 000 and 400 000 so we
can basically
update this
say for example I am saying I'm
interested in 300
thousand
two
to four hundred thousand and that's the
criteria to filter out the data now
there are two different ways or there
are two easier ways to do it one is I
would want to
look at the list price so I can select
this I can go ahead and do a filter here
and in the list price now this is where
we would want to do the filtering so
it's pretty easy you can click on this
one and then you can go into number
filters and you can choose between now
that's one easier way of doing it so I
could basically select this I could say
I'm looking for Value which is greater
than or equal to three hundred thousand
and then is less than or equal to 400
000 so if I just do this I have applied
my filter and I have my data which is
filtered based on my criteria right so
that's one easier way of doing it or let
me do a control Z
now let the filter be there which you
can anyways use but what we can also do
is as we have seen earlier methods so
get a
set or get your column headers here
and then you are giving two columns here
now the only difference between
my
this set of columns which I have one two
three four and then you have seven and
ten columns and if you see here we have
4 5 6 7 8 9 10 11 right so whenever you
want a and condition you will basically
add the columns where I can give add
condition if it is the same column if it
was a different column then it would be
same number of columns but and
conditions will lie in the same line and
or condition would lie in a different
line now here I can give this value so I
am looking for listed price being
between three hundred thousand so I am
saying it should be greater than or
equal to three hundred thousand and then
I can say less than or equal to 400
000 now that's my criteria and then I
need my result here which is in M 7 so
what I can do is once I have given my
criteria which I will be using to filter
I can get into Data I can get into
advanced and then I can say copy to
another location so it is selecting my
A1 to J 126 criteria range is based on
M1 to
W2 and then I would want my result from
this particular column so let's say okay
and now you have your data filtered out
in a different location in the sheet
which has been filtered based on your
and condition so you can filter out the
data in this way or you could just apply
a filter on a column and give the
conditions
now let's solve one more interesting
problem and here we would want to use
Excel where we would have an and and an
or condition so say for example this is
the data given to you and the question
is that you would want to find all the
houses in North County again that's a
spelling mistake but then they are North
County area with a list price greater
than 300 000 and having three or four
bedrooms so the bedroom has conditional
so it has R 3 and 4 and then basically
you have list price which is greater
than three hundred thousand now I could
have obviously selected The Columns and
then basically gone for a filter so I
can just do a filtering here and then
I'm looking for list price being greater
than 300 000 so which we can always give
a number filter and I can say great
greater than and then I can say greater
than or equal so I can say greater than
and then I can give 3030 300 000 and
that's basically the filter which we
would want and here I would want to
select the bedrooms which should be just
either three or four so if for example
here I go in here and I unselect this
and then I say 3 and 4 right so I am
getting my data which is greater than
300 000 and it should have the bettering
values which will be either 3 or 4
selected now that's one way of doing it
let's do a control Z and get it back
2 as we were or you can even just say
clear filter so you get your data back
as it was so what we can do is we can
hear
give the criteria
so for example I have my list price now
this is what I would want as a condition
so let's say greater than
three hundred thousand
three hundred thousand and bedrooms
should be three
and then I can say greater than three
hundred thousand
and then I can say four so this one
basically gives me a situation where
your list price has to be greater than
three hundred thousand and bedroom
should be either three or four so we
have given our filtering criteria now to
get the result what we can do is we can
go into Data we can go into advanced and
we can say copy to another location so
our list range is selected which is
columns a to J row number 1 to 126 your
criteria range is given in M1 to V3
where we have specified and we are
saying the result would be in M 7 to V7
so if I do this now I have got the same
data which we were seeing earlier and
here the bedroom values are three or
four and basically the list price is
greater than three hundred thousand so
this is a simpler way in which you can
create your filters and all this
Advanced filtering what we are seeing it
will be saved with your sheet you can
always go back and change this value or
you could do filtering where one person
has to look into the filter to see what
values have been selected
now that we have looked into some
operations which we can perform in Excel
using filter or sorting the data
creating your tables let's also quickly
look at functions and formulas which can
be used for doing some easy calculations
or computations now Excel can be used in
different kind of data analysis so for
example you have different inbuilt
functions which can be used and we can
always check for a particular function
so for example if I had if I wanted to
look at a particular function I could
just type in here something for example
is and then it shows me all the possible
functions and you can always have a look
at the detail of the function for
example you have is even which will
return true if the number is even if we
would say is logical so I could search
for is logical and that tells me whether
a value is logical value true or false
and returns your value true and false
now we can obviously
say subtotal so you can search for any
of these useful functions and that tells
me what this function can be used for so
returns a subtotal list or a database
you have many other such functions such
as integer sum average you may be
interested in working on truncating
some data getting the absolute value
getting the square root basically
getting a count or getting a max value
you can look for any particular
functions within your Excel sheet now
you also have other functions such as
now or time for example let's look at
Now function so I can search for
now
and here it is so this is Returns the
current date and time formatted as a
date and time so this is the function
which we would want to use and if I just
give the function it tells me what is
the current time let's first look at the
description of time here so say for
example I would want time it says
converts hours minutes and seconds given
as numbers to an Excel serial number
formatted with a time format so for
example if I would say two hours and
then 30 minutes and 30 seconds and if I
do this it has basically converted this
into your time format so you can always
use different inbuilt functions for your
work now we will also look at some
Advanced functions like sumf or some ifs
you have countif and countifs and you
can be working on various
functionalities of excel to easily help
you in doing some calculations
computations working with your data
working with your different cell values
so let's look at some example of using
functions like sum or sum if so for that
let's go to this sheet and here we have
some data now I have already applied a
filter which can allow me to filter out
the data so it says find the total units
that were sold in the east region now we
know that in region we have east
and
I have multiple regions I could
basically be saying unselect all and
select only East
and say OK and that basically gives me
the units which were sold and if I
placed my cursor here and then if I did
a auto sum so it would basically give me
the function which is being used so
something like subtotal and it is
basically working on your rows which is
E2 to e44
and here we can just do this so that
gives me the total but this is this is
fine you could do that but
it would be good if we know how do we
use a function like sumif to do that so
here I am seeing this is the subtotal
where I am looking at the values and
basically what I have done is I have
filtered out the region and then
basically I am getting a count but this
does not give me clearly how a sum was
calculated from all the values which
were listed what we can also do is let's
do a control Z and let's get it back so
now we have our data and we would want
to get the total units that were sold in
the east region so what I can do is I
can start typing in my formula and for
that I'll use an inbuilt function so for
example I would be interested in going
for sumif now it says sum if adds the
cells specified by a given condition or
criteria when you talk about some ifs
this is when you could give set of
conditions or multiple criteria so let's
look at some if let's do this now
obviously this gives me an error because
the formula
is not right so we have to basically
come in here and let's start with sum if
now when I say sum if it shows me there
is a function with sum if which we would
want to use and here once I open up the
bracket it tells me okay what is the
range of data which you are interested
in so I am interested in all the units
that were sold in the east region so we
are interested in the region
which is here so I can basically be
selecting this and this tells me
you are interested in the data here so
let's not take the header value so let's
say B2 and then we can go all the way to
the end so we can basically select this
way
that's the data we have select this and
hit enter so now here it has selected B2
to B4 but we need to basically now give
the criteria so the criteria is either a
value or you can point it to a cell
which has that particular value so as
per our problem statement we are looking
for the units which are sold in east
region so I can select the value East
here and then my sumif needs the range
on which you want to
calculate a sum so
let's select this and now we are
interested in finding out the sum of
units so that's basically this column e
column so I can basically type in
instead of selecting so I can say e and
I'm interested in e 2 2 e 44 so that
basically selects the area or all the
values and now let's do this so that
basically gives me the sum is 691 right
now this is the criteria where I have
pointed it to a cell and whatever value
that cell has well I could have done
something like this so I could have
selected East giving the value and then
doing it it still does the same thing
and in this way you have more clarity
that you are using some if you are
filtering the data so you have given the
rows
you are given the criteria and then you
have given the range on which you would
want to sum up the values now similarly
if the question was what was the total
revenue generated from binder now we
would want to find out what is the total
revenue generated from binders that
means my filtering criteria will be
binder
and then I want to find out the total
revenue generated so we have the revenue
generated field also here and we have we
don't have any region to be filtered we
are just looking for binder so let's
again start doing the same thing so we
can go for some if we can open the
bracket now it needs the range so we are
interested in revenue generated now
that's the summation we want and we
would want to
get the range of data so here we can
basically select
uh d
2
D 44
so that's the data selected now I would
want to give the filtering criteria so
let's say binder and then we need to
give the range on which the sum needs to
be calculated so that's my Revenue
column so that's G so I can say G to
2G 44 and that basically selects the
column and then you get your sum so it
tells me what is the total revenue
generated from binder
now I could be doing this for other
things also so say for example if you
would want to filter out something else
you could basically just drag and drop
here and then I could come here and
change this to say instead of binder I
would be interested in say
pencil
if that's the criteria you are
interested in remember to change this so
that you take all the values
and here we will change
it to select the relevant rows and then
this is the date I am getting so I know
that this is the revenue generated
from pencil this is the revenue
generated from binder now this is a
simple use case where we are using some
if what if we would want to use some IFS
so sum ifs let's have a look at how we
get to some ifs so sumif says where you
would want to work on
doing some calculation but then you
would want
multiple criterias to be met so let's
see how we get this so here what I can
do is let's work on this problem
statement which says what is the total
revenue generated from central region
where the item is a pencil so that's
something which I would want to check
now when we are answering this question
we can also look at the order in which
things have been asked in the question
so it says what is the total revenue
generated from central region so we need
the total revenue generated we know
there is a revenue column we are
interested in getting the total revenue
generated
we are saying the filtering criteria is
central region and we say in that we
would be interested only in the item if
it is pencil how do I do it so I can use
sumifs where you can pass in multiple
criteria so let's start with some IFS
and when I start with some ifs let's
open up the bracket so it says sum range
it says criteria range then it gives one
criteria and you can given any number of
criterias so for example we are
interested in total revenue generated
now that's my G column so let's follow
in the same order so let's say G2
so that's my first value and then I know
there are 44 rows here so I can say G 44
and you can obviously check if that has
selected all the rows now that's my
total revenue generated so I would want
the total revenue generated so I'm
saying setting this sum range
then I need to give the criteria range
so it says from central region so
central region comes into column two
that's B so let's say b 2 to B 44 so
that's my criteria range then you have
to give your criteria but we need to
filter out the region being Central so
let's select this now either I could
point to a value in the cell or I can
just give the exact value here
we can also give a
wild card or matching pattern so that
also works now this one is fine we are
now also interested in finding the total
revenue generated when the region is
Central and the item is pencil how do we
do that so for
item we know the columns the column is
D2 so let's select D two to D 44 so that
basically selects all the rows in the D
column and we need to give the
filtering criteria so let's do a comma
and then just given our value so let's
say pencil and then let's close your
bracket and that basically gives you the
result
so we need to just follow the order of
our question which says
what is the total revenue generated so
we are looking at the revenue column we
are selecting all the rows
then it says from the central region so
we need to select the region column and
give the filtering criteria Central or
point to a cell which contains that
value and then it says we would be
interested only in item being pencil so
then you select the column which has all
the items and provide you a filtering
criteria that is pencil so that's your
easy calculation of using some if which
we compare with sum if here so sum if
here was just having
your criteria so basically you are
selecting your rows giving your
filtering criteria and then your sum
range in some ifs we are giving multiple
condition now same thing can be done
here it says how many units were sold by
sales representative Johns or Jones
where the cost of each item was greater
than 4. so how many units were sold by
sales representative
so when we talk about how many units
that's your e column
so let's start with that so let's say
sumifs I would be interested in E column
then let's give the range so it says sum
range so those are the number of units
on which we would want to find
the sum then it says you need to give
the criteria range so we say sales
representative where the name is
Jones so sales representative is in
sales rep column C so let's say C2 to
c44
now
then we need to give our filtering
criteria so let's say Jones
is the sales representative where we are
interested about whom we are interested
in and then we the question says where
the cost of each item
so cost of each item is what we are
interested in you have unit cost
so that's what we are interested in so
that would be f and then say F2 to f44
and then you need to give your cost so
it says where each item is greater than
4 so let's select this
and let's
do this so this tells me 3 0 1. now
similarly let's answer our third
question which is how many units did
Jones sell excluding
pencil item so we would want to find out
what was the total number of units units
that were sold
and that units or that should not
include the pencil item how do we start
doing this so let's start with some IFS
now we know that you start with some ifs
you need to give the sum range so we are
interested in the number of units so
let's basically go in and select our
number of units which were sold so
that's your column e so I can say E2 to
e44 that's where I would want to perform
the sum now I am saying
how many units that were sold where
we are talking about sales rep being
zones so let's see let's select the
columns
C and then give
the range
after that we need to give our giving
filtering criteria which is Jones and
then we are interested in the items but
excluding pencil so items is in column D
so let's say d to d44 and then we have
to give
our criteria so we can say well that
should exclude pencil
so I can basically say
pencil
and let's close this
and let's check so that's my formula
which says that these are the number of
units which the sales representative
whose name is Jones had sold and that
does not include pencil as an item let's
also look at an example of using countif
or countifs now both of these can be
very useful when you would want to
calculate certain values so for example
if I would want to work on count if
let's try solving this problem now
remember you can answer these questions
using filters and that can be an easier
way but then sometimes you may want to
get the formulas so that you can make
your spreadsheet and your calculation
more
dynamic in nature and that will
basically depend on the values in the
columns or rows so for example if I have
find the total number of times Gill has
made a sale now if I look at my data
here it tells me that for every sales
representative there is some value in
the sale and it says sales has greater
than 3 so for example Jones you have
sales greater than three or you have
Jardine which is sales greater than 3
and so on so what we are interested in
is doing a quick count and finding out
the total number of times Gill has made
a sale how do we do that so we can use
this count if function and if I go into
countif it says counts the number of
cells within a range that meet the given
condition now what's our condition our
condition is Gill and we would want to
find out how many times the name say
Gill appears or kill has made a sale now
I could just say count if and then open
up a bracket I need to give a range so
let's say we are interested in looking
at the range so let's say we will choose
sales rep so I can say C and then I can
say C2 to c44 now that's my range
let's not give that in quotes
so you have to give a range so let's do
a count if that selects the data and
then we need to give the condition so
for example let's here give the name
which is Gill and then close this so
that basically tells me it is five times
kill appears here we can check this so I
can go in here I can add a filter and
then might be I would be interested in
looking at only Gill
and that basically gives me 5 right so
we can always do that and we can be
using formulas like this now what about
this question so which basically says
with sales representative made a sale
more than three times now we it might be
looking little confusing when I say for
example let me clear out this filter
now we have sales greater than 3 and we
would want to find out which sales
representative made a sale more than
three times now I could basically check
for every sales representative here if
they have made a sale more than three
times and what I can do is I can just
say equals I can start with count if
then I need my filtering criteria so
that's your range so first thing is we
will choose for example is choose C2 to
C 44 and then we need to
give and criteria what is the criteria
we need basically a sales representative
so I can choose the value here in C2
and then I can close this and then I can
say the sale has to be greater than 3
and let's check so it tells me the
Boolean value that yes this guy has made
sales more than three times and what we
can do is we can just drag and drop
which basically gives me the value for
other sales rep you can always check the
value is automatically changing to this
value in cell and for example let's go
in here so this is obviously 2 so it
saves me false right and you can
basically get the values for all your
values so that basically tells me which
sales representative has made a sale
more than three times
now like sumifs we also have countifs
where you can give multiple criterias so
for example the question is how many
orders were placed from the east region
after this particular date so we have
a date criteria we also have the region
criteria and we need to basically get
the count of number of orders which were
placed now I can in this case use count
ifs
and this basically says that you can
start with an criteria so it says how
many orders were placed from east region
after particular date so date is in my
First Column so for example I could say
a
start with 2 and say for example let's
go a44 that should have selected all the
rows
and then I need to
once I have given the criteria range I
need to give the criteria so we are
saying the date has to be greater than
10th Feb so let's give it
2
10
2019
and then you need to say
how many orders were placed so you need
to give the criteria second criteria
range
so we are looking at the number of
orders which were placed
from the east region so when I would
want to look at the region that's your
column B so I can basically say B2 to B
44
and here
I would basically give my criteria so
the criteria is East
let's give that
and once you have done this you would
want to find out the total number of
orders so let's select this and if I do
this it tells me 13 now is that right so
we are looking for your date
your region being East and then getting
the total number of orders so here I can
just do a count if I'm saying A2
to a44
wherein I have given the date criteria
that it should be greater than
10th Feb because I do not want to count
10 Feb it says after 10 February and
then you are saying the region has to be
East so we would want to find out the
total number of orders so my region is
east and that gives me the result
now similarly you can also find out how
many times Gill
sold pencils so here we will have to
give the range so
let's start with count
ifs
now here I would want that item is
pencils so we can as well select column
D two
D 44
then you have to give your criteria so
that's your
pencil
and then we are looking for sales rep
which is Gill so that is my column C so
let's say c 2 2 C 44
and the value should be
just kill
so it tells me
it's twice where Gill has sold pencils
so we can obviously check this by going
in here
choosing my filter and then let's search
for rep being just Gill
okay and now we are interested only in
the item being pencil so I can say well
let's get to pencil only and that tells
me twice so you can obviously re-verify
using filters but using functions or
using formulas it is always good to
calculate and that can be making your
computation and calculation more dynamic
let's look at one more interesting
feature of Excel and that's your
conditional formatting now as you see on
the screen conditional formatting has
different rules which can be applied on
your data and that allows you to
basically differentiate or easily
identify data values which are
based on certain criterias or rules so
when you talk about conditional
formatting you have different options
such as you can highlight sell rules you
can get top and bottom values you can
apply different rules apply different
color scales and you you can easily
manage these rules so conditional
formatting is very useful for people who
would want to work on huge amount of
data and easily perform some data
analysis
it's easy to use as it is shown here and
with your conditional formatting
you can format cells based on a preset
condition you can perform conditional
formatting to identify cells you can
highlight a few significant cells and
you can easily perform conditional
formatting
as shown on the left side
now how do we work with conditional
formatting let's have a quick look so
say for example we have our Excel sheet
and if you see here I am highlighting
the sales person who have generated
Revenue greater than 10 000. so we can
be looking at the values where the
revenue generated by a particular sales
person is greater than 10 000 it has a
particular
color and how do we get here so for
example let's select this data
and what I could do is
I could go into conditional formatting
now I could basically highlight cell
rules and we could just say greater than
that's an easier way I could also go
ahead and create a new rule but then I
can use one of this option I can say
greater than and let's give some value
might be we would be interested in
looking at any value greater than 12 000
so let's choose 12
000
and here it says what color would you
want to select so for example I would
say something like
yellow filled with dark yellow text
and let's say okay so right now what I'm
doing is I have all the values where the
revenue generated was greater than 10
000 but then I have also selected all
the sales people who have made or who
have generated Revenue greater than 12
000. so I can just do a control Z to see
the previous result now here I had the
values which were greater than 10 000
and the one which we did just now
basically
highlighted the values which are greater
than twelve thousand so this is one
simple example now we can look at some
other examples say for example you want
to format cells using three color scale
so if you look at the values here I have
a three color scale mainly in green
yellow and red and how do you do this so
for example I can go in here and I can
go to conditional formatting so I would
want to go for color scales and here you
can create different rules so we can set
up a two color scale so we can say
format only values that are above and
below average I can format only cells
that contain something I can get the top
and bottom value so these are different
ways in which I can have a three color
based scale now what I will do is I will
select this and let me show you the rule
which which I have so for example I can
go into manage rules and if you see here
there are certain rules which have been
specified now what does that mean so you
would want to specify a three grade
scale so for example if I would want to
look at my first rule it tells me that I
am choosing three color scale I can
choose lowest value percentile and
highest value and that basically will
select the cells based on their values
so what we could have done is I can
basically
use one of these values I can delete
these rules which I have created so for
example I have all these rules but you
should always carefully remember that
the rules will be applied in the order
shown so for example if I just delete
these rules
and then say apply and say okay my data
is back now it does not have any
highlighting now I can go in here I can
say condition sorry conditional
formatting I could go for color scale so
I could basically go into
new rule so I would want
the
cells to be using three color scale so
let's
choose three color scale now when you
say three color scale it says what will
be the color of lowest value
and we could choose might be any one of
this let's choose red I can say midpoint
is percentile 50 and then the highest
value is green and if that looks good
let's say okay and now if you see the
lowest values have been highlighted as
read you have mid values and then you
have the positive value so this is the
three color scale and that easily helps
me in identifying the data based on the
cell values
now in conditional formatting what you
can also do is you can basically color
the cells based on their value so what
we are seeing here is if the revenue
generated is greater than average then
that shows in green and if the revenue
generated is lesser than average that's
shows in Orange now how do we do that so
we can basically again manage some rules
so I can basically create a new rule now
here I can select one of the options
which says format only values that are
above or below average and that's the
option I would want to select now I can
select this and it says format values
that are above average so in our case we
had it in green so for example I'll say
above average and then here I can go for
a particular color
so you can go for a particular size so
let's go and look into
the formatting so for example let's
choose yellow
say okay now I am saying wherever the
cell values are above average it would
be yellow instead of green
and let's go in here let's go and look
into manage rules so this is basically
the rule which we are applying now we
can also add a new rule
and I need to select the values so for
example I will say
here so we had gone for above now we'll
go for below we'll go for format we will
choose red we'll say okay we'll say
now these are basically
the rules which we have created and here
it says applies to your data so right
now it has not been applied so for
example if I select this and then I
could basically choose my area just hit
on enter and similarly you can go in
here and then select your area hit on
enter and say apply say okay and now if
you see I have really chosen bright
colors but then I have said wherever my
revenue generated is above average it
should be in yellow and
below average should be in Red so we
wanted above
average to be in green and below average
to be in Orange so
that's what we have here right so you
can always
color code your cell values based on
some rules which you are setting up now
similarly you can also find the top 10
and bottom 10 values and that's pretty
easy so you can just select this and
then you can go into conditional
formatting you can go for top and bottom
values top 10 items bottom 10 items or
you can go in for more rules so you can
say format only top or bottom ranked
values so you have top 10 now you can
choose the color and for example I'll go
for blue
and
I'll say okay so now if you see my top
10 values are blue now similarly I can
add one more rule so I can say new rule
and I can say let's go for top or bottom
let's go for bottom let's go for format
let's say orange
say okay say okay and that's it so now
you have your values which are top or
bottom 10 values so you are using
conditional formatting where you are
basically highlighting your cell values
based on different colors and here
easy conditional formatting based on
different rules helps us to do that now
similarly you can also have the values
which is basically
showing you how the values are
increasing so what we can do is we can
select our columns either you could
apply this to all the columns now here I
have applied this only to Jan and April
now I could apply this for June so let's
say June so you can go for gradient fill
you can go for solid fill you can
obviously just select the color and that
takes care of the things you can say for
example select this and now this is
selected what I would want to might be
format this so I can go in here I can go
into manage rules now that will tell me
what rule has been applied
in the order so I can just do a edit
Rule and that basically says this is a
solid fill which is color you have no
border this is basically color is black
now I can go for something like gradient
fill
and I can say okay and now if I say
apply and okay so this basically is Like
Your First Column so you can use
conditional formatting for various use
cases and you can highlight the values
so anyone who would look at the value
would automatically notice which are the
higher values which are lower values
might be here the revenue is getting
generated or was getting generated but
did not grow Beyond a particular value
and so on now similarly you can also go
in for different options say for example
here we would want to
see if the revenue was dropping
or if the revenue was
if the revenue decreased or say for
example if the revenue was going up for
this particular sales person so here we
are looking at Carol so in Jan the
revenue Generation by sales was very
high then in Feb it was falling down
in March it was kind of stable then in
April it went way below so we can
obviously work on this wherein we can
grade our cell values so what we can do
is we can go in for highlighting the
cell values now you can go for color
scales you can go for Icon sets and this
is where you can choose your different
shapes
so you could choose one of these shapes
so for example I would be interested in
looking at the indicators like
directional I could go
using this three arrows I can go in for
this color I can choose directional and
then my values are
automatically using directional now what
we can also do is we can then go into
manage rules and that basically tells me
what rules have been applied so for
example the latest one is the icon set
which I have chosen it shows the
selected columns I can obviously do a
edit Rule and then I can choose so I'm
saying the format style is icon sets I'm
not using a data bar I'm not using color
scale now here
I have chosen the style of icons
and then here you can basically give
some values so you have icon which is
green when the value is greater than or
equal to 67 percentage
when I say hyphen or minus it is less
than 67. it's way below 33 percentage
then you give this value so you can
obviously edit and easily highlight your
cell values based on this icon set so I
can apply this and that's how I use
conditional formatting so conditional
formatting can be very useful if you
would want to use icon set if you want
to use your data bars if you would want
to highlight particular values if you
would want to color code based on some
calculation if you would want to
use a three color or a two color scale
or if you would want to just find out
values based on some simple calculation
so conditional formatting is used
extensively by data analysts or people
who are working in business intelligence
teams or people who would want to use
Excel to easily identify the data
easily identify the cells which contain
particular value or finding out less
significant or more significant cells to
then pull out values and carry out your
computations calculations or analysis
so far we have understood the important
fundamentals of data analytics moving
further we will discuss the important
tools and Frameworks you need to become
a professional data analyst but before
that let's hear from our Learners about
the personal experience and the success
story after graduating from the simply
lens postgraduate program in data
analytics that is offered by Purdue
University upskilling is extremely
essential for any working professional
nowadays after completing the
professional certificate program in data
analytics from Simply learn in
partnership with Purdue University my
career took a significant turn
I was able to change my career domain
from teaching kids to providing
Supportive Services to adults at the
Department of Rehabilitation in San
Francisco the experience that I have
would simply learn was amazing The
Faculty was very encouraging excited
about my future and I encourage all
professionals feeling inspired already
not what but we have multiple success
stories to share if you are inspired
consider checking the simply lens
postgraduate program in data analytics
offered by Purdue University for more
details use the link in the description
box below the link should redirect you
to the official course landing page that
will give you a complete overview of the
course being offered also if you are a
complete beginner and an aspiring data
analyst looking for online training and
certifications in collaboration with
leading experts then search no more
simple lens data analysis Masters
program should be a right choice for
more details use the link in the
description box below
applications of data analytics now the
sky's the limit on this in today's world
almost every business Act of Life your
music on your Spotify are driven by data
analytics but some of the big players
when you go in there job hunting are
going to be your fraud analysis if you
want to go make a lot of money and
you're good at it and you like dealing
with numbers go join the banks and track
down the criminals who are stealing
money it's a lot of you know it's a big
thing to protect credit cards predict
sales purchases bad checks any of those
things when you can track them down is
huge
Healthcare exploding there is everything
from trying to find cures for the covet
virus or any of the viruses out there
using your cell phone to diagnose
different ailments that way you don't
have to go and see the doctor you can
actually just go in there and take a
picture of the funky growth on your arm
hopefully it's not too big and then they
send it in there and the data analytics
goes in there looks at it and says oh
this is what this is this is a
professional you need to go see or don't
need to see
and that's just one aspect of Health
Care the database is being generated by
Healthcare and getting the right doctors
and helping the doctors analyze whether
something is benign or malignant if it's
cancerous all those things are now part
of the ongoing Health Care growth in
data analytics
Inventory management
think one of those huge warehouses where
they're shipping out all the goods how
do you inventory that in such a way so
that you maximize the stuff that's being
purchased the most near the entrance and
all the other stuff towards the back or
even pre-ship it so it's huge to be able
to inventory the manage your inventory
and pretty soon they'll just have a
drone come in there and start picking up
some of those boxes and move them around
also
deliver your Logistics again this goes
from getting from point A to point B you
can combine it with our inventory so you
pre-ship stuff if you know a certain
area is more likely to purchase it how
do you get it the delivery to the most
destinations the quickest in the short
amount of time and then they even
pre-stack the trucks going out and
that's all done with data analytics how
do we stack all that stuff so it comes
out in the right order
targeted marketing huge industry any
kind of marketing whether you're
generating the right content for the
marketing who are you targeting with
that marketing researching the people
what they want so you know what products
to Market out there all those things are
huge
and these are just a few examples you
can probably go Way Beyond this from
tracking forest fires to astrology and
studying the stars all of this is part
of data analytics now and plays a huge
role in all these different areas
City Planning is another one you know
you can see a nice organized City like
this one where you can get in and out of
the neighborhoods if you're a fire truck
police officers need to be able to get
in and out you want your tourists to be
able to come in you still want the place
to look nice and you have the right
commercial development the right
Industrial Development like enough
residents for people to stay all those
things are part of your City Planning
again huge in data analytics
so sky's the limit on what you use it
for let's take a look at types of data
analytics
and this can be broken up in so many
ways but we're going to start with
looking at the most basic questions that
you're going to be asking in data
analytics and the first one is you want
descriptive analytics what has happened
hindsight how many cells per call ratio
coming out of the call center if we have
500 tourists in a forest and you have a
certain temperature how many fires were
started how many times did the police
have to show up to certain houses all
that's descriptive the next one is
predictive Predictive Analytics is what
will happen next we want to predict this
is great if you want to have a ice cream
store and you want to predict how many
people to work at the ice cream store in
a certain day based on the temperature
coming up in the time of the year
and then one of the biggest growing and
most important parts of the industry is
now prescriptive analytics and you can
think of that as combining the first two
we have descriptive and we have
predictive then you get pre-scriptive
Analytics
how can we make it happen foresight what
can we change to make this work better
in all the industries we looked at
before we can start asking questions
especially in City development there's a
good one
if we want to have our city generate
more income and we want that income to
be commercial based what kind of
commercial buildings do we need to build
in that area that are going to bring
people over do we need huge Warehouse
cells Costco sales buildings or do we
need little mom pod joints that are
going to bring in people from the
country to come shop there or do you
want an industrial setup what do you
need to bring that industry in there is
our car industry available in that area
if it's not a car industry what other
Industries are in that area all those
things are prescriptive we're guessing
we're guessing what can we do to fix it
what can we do to fix crime and area
with education what kind of education
are we going to use to help people
understand what's going on so that we
lower the rate of crime and we help our
communities grow better that's all
prescriptive it's all guessing we went
foresight into how can we make it happen
how can we make this better
and we really can't not go into enough
detail on these three because a lot of
people stumble on this when they come in
and are doing analytics whether you're
the manager shareholder or the data
scientist coming in you really need to
understand the descriptive analytics
where you're studying the total units of
furniture sold and the profit that was
made in the past
uh here we go into Predictive Analytics
predicting the total units that would
sell and the profit we can expect in the
future gear up for how many employees we
need how much money we're going to make
and prescriptive analytics finding ways
to improve the sales and the profit so
we can sell maybe a different kind of
furniture we're going to guess at what
the area is looking for and how that
marketing is going to change
data analytics process steps so let's
take a look at some of the basic
processing and what that looks like when
you're working with this data
so there's five basic steps the five
steps of processing and this changes and
there's a lot of things that go on when
they talk about agile programming the
whole concept of agile is you take some
kind of framework like this and then you
build on it depending on what your
business needs
so the first step is data collection
and usually with a large company you
might have somebody who is responsible
for the database management you may have
another one where they're pulling apis
they're pulling data off of maybe the
Census Bureau maybe something very very
um specific domain specific so if you're
analyzing cancerous growths and how to
understand them then the data collection
is going to be those measurements they
take from the MRI or it might be even
the MRI images they've used those also
so there's a lot of things with data
collection and how to control that and
make sure it has what you need and is
clean and you don't have misinformation
coming in
once you have the data collected there's
a data preparation
so stage two is we take that data and we
format it into something we can use
probably one of the biggest formats that
you see is when you're processing text
how do you process text we'll use what
they call a one hot encoder and each
word is represented by a yes no kind of
setup so it'd be like a long array of
bits that's one way to prepare it and so
you know bit number one is the bit
number two is has or whatever it is
other preparations might be if you're
using neural networks you might be
taking integers or float numbers and
converting them to a value between 0 and
1. that way you don't have one of them
creating a bias in there so there's a
lot of different things that go into
Data preparation that is 80 percent of
data science so when we talk about the
data analytics which is a little bit
more on the math side and they usually
talk about a data scientist kind of
being the overall
prepare this stuff you're going to spend
80 percent of your data preparation
data exploration that's the fun part
this is where you're exploring things
and it is maybe 10 to 15 percent of what
you do with the data you spend with the
data exploration it is probably the most
important step because this is where you
got to start asking questions if you ask
your questions wrong you're going to get
some wrong information if you're working
with a company and they want to know the
marketing values then you really got to
focus on hey how do we generate money
for this company or fraud how do we
lower the fraud rate while still
generating a profit for data modeling
this is where we start actually getting
into the data code which model to use
that predicts what's going to happen
uh and then result interpretation we
want to be able to interpret those
results usually see that in your matplot
library where you create nice beautiful
images so it shows up on their dashboard
for the marketing manager or for the CEO
so they can take a quick look and say
hey I can see what's going on there you
want to reduce it to something they can
easily read they don't want to hear the
scientific terms they want to see
something they can use and we'll talk
about that a little bit more when we
start looking at some of this in a demo
since this is data analysis with python
we've got to ask the question why python
for data analytics I mean there's C plus
plus there's Java there's dot net from
Microsoft why do people go to python for
it
so the number of reasons one it's easy
to learn with simple syntax
you don't have a very high type set like
you do in Java and other coding so it
allows you to kind of be a little lazy
in your programming that doesn't mean
that it can't be set that way and that
you don't have to be careful it just
makes means you can spin up a code much
quicker in Python the same amount of
code to do something in Python A lot of
times is one two or three or four lines
where when I did the same thing say in
Java I found myself a 10 12 13 20 lines
depending on what it was
it's very scalable and flexible so
there's our flexibility because you can
do a lot with it and you can easily
scale it up you can go from something on
your machine to using a pi spark under
the spark environment and spread that
across hundreds if not thousands of
servers across terabytes of data or
petabytes of data so it's very scalable
there's a huge collection of libraries
this one's always interesting because
Java has a huge collection of libraries
C has a huge collection of
libraries.net does and they're always in
competition to get those libraries out
Scala for your spark all those have huge
collection libraries this is always
changing but because Python's open
source you almost always have easy to
access libraries that anybody can use
you don't have to go check your
licensing and have special licensing
like you do in some packages
graphics and visualization they have a
really powerful package for that so it
makes it easy to create nice displays
for people to read
and community support because python is
open source it has a huge community that
supports it you can do a quick Google
and probably find a solution for almost
anything you're working on
python libraries let's bring it together
we have data analytics and we have
python so when we're talking data
analytics we're talking python libraries
for data analytics and the big five
players are numpy pandas matplot Library
scipy which is going to be in the
background so we're not going to talk
too much about the scientific formulas
inside pi and PSY kit
so numpy supports in dimensional arrays
provides numerical Computing tools
useful for linear algebra and Fourier
transform
and you can think of this as just a grid
of numbers and you can even have a grid
inside a grid or data it's not even
numbers because you can also put words
and characters and just about anything
into that array but you can think of a
grid and then you can have a grid inside
a grid and you end up with a nice
three-dimensional array
if you want to talk three-dimensional
array you can think of images you have
your three channels of color four if you
have an alpha and then you have your X Y
coordinates for the image we're looking
at so you can go x y and then what are
the three channels to generate that
color
and numpy isn't restricted to three
dimensions you could imagine watching a
movie well now you have your movie clips
and they each have their X number of
frames and each of those frames have X
number of X Y coordinates for the
pictures in each frame and then you have
your three dimensions for the colors so
numpy is just a great way to work within
dimensional arrays
now closely with numpy is pandas useful
for handling missing data perform
mathematical operations provides
functions to manipulate data
pandas is becoming huge because it is
basically a data frame and if you're
working with big data and you're working
in spark or any of the other major
packages out there you realize that the
data frame is very Central to a lot of
that and you can look at it as a Excel
spreadsheet you have your columns you
have your rows or indexes and you can do
all kinds of different manipulations of
the data within including filling in
missing data which is a big thing when
you're dealing with large pools or lakes
of data where they might be collected
differently from different locations
and matplot Library
we did kick over the sci Pi which is a
lot of mathematical computations which
usually runs in the background of the
for of numpy and pandas although you do
use them they're useful for a lot of
other things in there but the matplot
library that's the final part that's
what you want to show people and this is
your plotting library in Python several
toolkits extend matplot Library
functionality there's like a hundred
different toolkits to extend matplot
Library which range from how to properly
display star constellations from
astronomy there's a very specific one
built just for that all the way to some
very generic ones we'll actually add
Seaborn in when we do the labs in a
minute several tool kits extend matplot
Library functionality and it creates
interactive visualization so there's all
kinds of cool things you can do as far
as just displaying graphs and there's
even some that you can create
interactive graphs we won't do the
interactive graphs but you'll see you'll
get a pretty good grasp of some of the
different things you can do in matplot
library
let's jump over to the demo which is my
favorite roll up our sleeves get our
hands in on what we're doing now there's
a lot of options when we're dealing with
python you can use pie charm as a really
popular one
uh and you'll see this all over the
place so it's one of the main ones
that's out there and there's a lot of
other ones I used to use netbeans which
is kind of lost favor I don't even have
it installed on my new computer
but the most popular one right now for
data science Now pycharm is really
popular for python General development
for data science we usually go to
Jupiter notebook or anaconda and we're
going to jump into Anaconda because
that's my favorite one to go to because
it has a lot of external tools for us
we're not going to dig into those but we
will pop in there so you can see what it
looks like so with Anaconda we have our
Jupiter lab we have our notebook these
are identical Jupiter lab is an upgrade
to the notebooks with multiple tabs
that's all it is and we'll be using the
notebook and you can see that pycharm is
so popular with python that we even have
it highlighted here in Anaconda as part
of the setup
Jupiter notebook can also be a
standalone so we're actually going to be
running Jupiter notebook and then you
have your different environments I have
we're going to be under main Pi 36
there's a root one and I usually label
it Pi 36
the reason is is currently as they're
writing this tensorflow only works in 3
6 and not in three seven or three eight
for doing neural networks but you can
actually have multiple environments
which is nice they're they separate the
kernel so it helps protect your computer
when you're doing development and this
is just a great way to do a display or a
demo especially if you're looking for
that job pull up your laptop open it up
or if you're doing a meeting get a
broadcast up to the big screen so that
the CEO can see what you're looking at
and when we launched the notebook it
actually opens up a file browser in
whatever web browser you have this
happens to be Chrome and then you can
just go under new there's a lot of
different options depending what you
have installed Python 3 and this just
creates an Untitled version of this and
you can see here I'm actually in a
simply learn folder for other work I've
done for simply learn
and that's where I save all my stuff and
I can browse through other folders
making it really easy to jump from one
project to another
and under here we'll go ahead and change
the name of this and we'll go ahead and
rename it
data analytics data analytics
just so I can remember what I was doing
which is probably about 50 of the
folders in here right or files in here
right now uh so let's go ahead and jump
in there and take a look at some of
these different tools that we were
looking at
and as we go through the demo let's
start with the numpy uh the least
visually exciting and I'm going to zoom
in here so you can see what we're doing
and the first thing we want to do is
import numpy
and we'll import it as NP that is the
most common numpy terminology
and let's go ahead and change the view
so we also have the line numbers I don't
know why we probably won't need them but
I'm looking for easy reference and then
we'll create a one dimensional array we
just call this array one
and it equals NP dot array and you put
your array information in here in this
case we'll spell it out you can actually
do like a range and other ways there's
lots of ways to generate these arrays
but we'll just do one two three so three
integers
and if we print
our array one
we can go ahead and run this
and you can see right here it prints one
two three you can see why this is a
really nice interface to show other
people what you're doing with the
Jupiter notebook
so this is the basic we've created an
array this is a one-dimensional array
and then an array is one two three one
of the nice things about the Jupiter
notebook is whatever ran in this first
setup
is still running it's still in the
kernel so it still has the numpy
imported as in p and it still has our
variable
arr1 for array 1 equal to NP array of
one two three
so when we go to the next cell
we can check the type of the array we're
just going to print
we say hey what's what what is this
setup in here and we want type
and then we want what is the type of
array one let's go ahead and run that
and it says class numpy ND array so it's
its own class that's all we're doing is
checking to see what that class is
and if you look at the array class
probably the biggest thing you do I
don't know how many times I find myself
doing this because I forget what I'm
working on and I forget I'm working with
a three-dimensional or four-dimensional
array and I have to reformat somehow so
it works with whatever other things I
have and so we do the array shape the
ray shape is just three because it has
three members and it's a one-dimensional
array that's all that is
and with the numpy array we can easily
access stick with the print statement
if you actually put a variable in
Jupiter notebook and it's the last one
in the cell
it will the same as a print statement so
if I do this where array one of two it's
the same as doing print
array of two that's those are identical
statements in our jupyter notebook
we'll go and stick with the print on
this one
and it's three so there's our print
Space 2 and we have 0 1 2
2 equals three we can easily change that
so we have array one of place two
equals five
and then if we print our array one
you can see right down here when it
comes out it's one two and five
and there I left the print statement off
because it's the last variable in the
list it'll always print the variable if
you just put it in like that
that's a Jupiter notebook thing don't do
that in pie charm I've forgotten before
doing a demo
and we talked about multiple Dimensions
so we'll do an array two-dimensional
array
and this is again a numpy array
and in the numpy array
we need our first Dimension we'll do one
two three and our
second dimension uh three four five and
you can see right here that when we hit
the uh
we'll do this we'll just do array two
and we can run that and there's our
array two one two three three four five
we can also do array two
of 1
and then we can do let's do a zero it
doesn't really matter which one actually
let's do two there we go and if I run
this it'll print out five because here
we are this is zero zero one two three
is under zero Row three four five is on
our one row now we start with zero and
then the two zero one two goes to the
five
and then maybe we forgot what we were
working with so we'll go do array two
dot shape
and if we do array two of shape
uh we'll go and run that we'll see we
have two rows and each row has three
elements a two-dimensional array two
three if you looked up here when we did
it before I just had three comma nothing
when you have a single entity it always
saves it as a tuple with a blank space
but you can see right here we have two
comma three
and if you remember from up here we just
did this array 2 of oh let's go what is
it one
comma two
we run that we get the five you can also
count backwards this is kind of fun
and you'll see I just kind of Switched
something on you because you can also do
one comma two to get to the same spot
now two is the last one zero one two
it's the last one in there we can count
backwards and do minus one and if we run
this we get the same answer whether we
count it as uh let's go back up here
whether we count this as 0 1 2
or we count backwards as minus one minus
two minus three and you can see that if
I change this minus one to a minus two
and run that
I get 4 which is going backwards minus 1
minus two so there's a lot of different
ways to reference what we're working on
inside the numpy array
it's really a cool tool it's got a lot
of things you can do with it
and we talked about the fact that it can
also hold things that are not values and
we'll call this array s for Strings
equals NP dot array
and put our setup in there brackets and
let's go
China
um
India
USA
Mexico doesn't matter we can make
whatever we want on here and if we print
that out
we run this you can see that we get our
numpy of Ray China India USA Mexico it
even gives us our D type of a U6
a lot of times when you're messing with
data we'll call this array R for range
just to kind of keep it uniform NP dot a
range
so this is a command inside numpy to
create a range of numbers
and if you're testing data Maybe you
want maybe you have equal time
increments that are spaced a certain
point apart but in this case we're just
going to do integers
and we're going to do a setup from 0 20
skipping every other one and we'll print
it out and see what that looks like
and you can see here we have 0 2 4 6 8
10 12 14 16 18 like you expected it
skips every one
and just a quick note
there's no 20 on here uh why well this
starts at zero and counts up to 20. so
if you're used to another language where
explicitly says less than or less than
equal to 20 like for x equals zero X
plus plus X is less than 20. that's what
this is it just assumes X is less than
20 on here
if we want to create a very uniform uh
set you know zero two four six what
happens if I want to create numbers uh
from 0 to 10 but I need 20 increments in
there we can do that with line space so
we can create an R we'll call this l
equals I don't think we'll actually use
any of this again so I don't know why
I'm creating unique identifiers for it
but we'll do NP
Lin space
and we're going to do zero
to 10 or 0 to 9. remember it doesn't it
goes up to 10.
and then we want to let's say we have 20
different
um
increments in there so we're creating a
we have a data set and we know it's over
a certain time period and we need to
divide that time period by 20 and it
happens to just have 10 pieces in it and
here we go you can see right here we
have 20 or has 20 pieces in it but it's
over 10 years we got to divide it in the
middle and you can see it does it goes
0.52 remember yeah there's our 10 on the
end so it goes up to 10.
and then we can also do random there's
NP dot random if you're doing neural
networks
usually you start it by seeding it with
random numbers
and we'll just do NP dot random and
we'll just call this array
we'll stop giving it unique numbers
we'll print that one out and run it
and you can see we have random numbers
they are zero to one so you'll see that
all these numbers are under one and you
can easily alter that by multiplying
them out or something like that if you
want to do like zero to a hundred you
can also round them up if it's integer 0
to 100 there's all kinds of things you
can do but generates a random float
between 0 and 1.
and you have a couple options you could
reshape that or you can just generate
them in whatever shape you want and so
we can see here we did three and four
and so you can see three rows by four
variables
same thing as doing a reshape of 12
variables to three and four
and if you're going to do that you might
need an empty data set I have had this
come up many times where I need to start
off with zero and I don't know you know
because I'm going to be adding stuff in
there or it might be 0 and 1 or 1 is if
you're removing the background of an
image you might want the background is
zero and then we figure out where the
image is and you set all those boxes to
one and you create a mask so creating
masks over images is really big and
doing that with a numpy array of zero
and we can also uh
give it a space
and we'll just do this all in one shot
this time
and we'll do the same thing like we did
before
zeros and in this case we'll do a two
comma three
and so when we run this
forgot the asterisks around it I knew I
was forgetting something there we go
so when we run this you can see here we
have our 10 zeros in a row and maybe
this is a mask for an image and so it
has uh two rows of three digits in it so
it's a very small image a little tiny
pixel
and maybe you're looking to do something
the opposite way instead of creating a
mask of zeros and filling in with ones
maybe you want to create a mask of ones
and fill them in with zeros and we'll
just do just like we did before with the
three comma four and when we run this
you'll see it's all ones and we could
even do this even we'll do it this way
let's do
10.
10 by 10 icon and then you have your
three colors and you can so creates
quite a large array there for doing
pictures and stuff like that when you
add that third dimension in
if we take that off it's a little bit
easier to see
we'll do 10 again
and you can easily see how we have 10
rows of 10 ones
and you can also do something like
create an array
and we'll do 0 1 2.
and then in this array we actually print
right out we want a repeat so you can
actually do a repeat of the array and
maybe you need this array
um let's repeat it three times
so there's our repeat of an array repeat
three times
and if we run this
you'll see we have zero zero zero one
one two two two
and whenever I think of a repeat I don't
really think of repeating being the
first digit three times the second digit
I really always think of it as zero one
two zero one two zero one two it catches
me every time but the actual code for
that one is going to be tile and again
if we do arrange three
and we run this you can see how you can
generate one zero one two zero one two
zero one two
and if you're dealing with an identity
Matrix we can do that also if you're big
on you're doing your matrixes and we'll
just identity
I guess we'll go ahead and spell it out
today any tricks
and the command we're looking for is um
i e y e and we'll do three and then
we'll just go ahead and print this out
there we go there's our identity Matrix
and it comes out by a three by three
array because there's our Matrix
and then it puts the ones down the
middle and for doing a different Matrix
math
and we can manipulate that a little bit
too
we talk about
Matrix is
we might not want ones across the middle
in which case we now have the diagonal
so we can do an NP dot diagonal
and we do a diagonal let's put in the
diagonal
one two three four five and when we run
this
again this generates a value and by just
putting that value in there's the same
as putting print around it or putting
array equals and then print array and
you can see it generates a diagonal one
two three four five and there's your uh
your beginning of your Matrix array for
working with matrixes
and we can actually go in reverse let's
create an array equals remember our
random
random.random and we'll do a five by
five array oops there we go
five five
and just so you can see what that looks
like
helps if I don't mistype the numbers
which in this case I just need to take
out the brackets and there you go you
have your your five by five array set up
in there and we can know because we're
working with Matrix is we might want to
do this in reverse and extract the
diagonals which would be the 0.79 the
0.678 and so on
and we simply type in
NP dot diagonal
and we put our array in there
and this will of course print it out
because it returns it as a variable and
you can see here here's our diagonal
going across from our Matrix
and we did talk about shape earlier if
you remember you can do print the shape
out you can also do the dimensions so in
Dimensions very similar to shape it
comes out and just has two Dimensions we
can also look at the size so if we do a
size on here we can run that and you can
see it has a size of 25 two dimensions
and of course five by five and that was
from the shape from earlier that we
looked at there's our five by five shape
and if you remember earlier we did
random well you can also do uh random I
talked a little bit about manipulating 0
to 1 and how you can get different
answers you can also do straight for the
integer part and we'll do minus 10.
210
4
and so we're going to Generate random
integers between minus 10 to 10 we're
going to generate four of those so when
we run that we have 7 minus three minus
six minus three they're all be between
minus 10 and 10 and there's four of them
and now we jump into some of the
functionality of arrays which is really
great because this is where they come in
here's the array and you can add 10 to
it and if I run this there it takes my
original array from up here
with the integers and adds 10 to all of
those values so now we have oh this is
the decimal that's right this is a
random decimal I had stored in Array
but this takes a random decimal the
random numbers I had from 0 to 1 and
adds 10 to them and we can just as
easily do uh
minus 10
. we could even do
times 2
and we could do divide by two
and it would it'll take that random
number we generated and cut it in half
so now all these numbers are under 0.5
another way you can
change the numbers to what you need on
there
and as you dig deeper into numpy we can
also do exponential so as an exponential
function which would generate some
interesting numbers off of the random
so we're taking them to the power I
don't even remember what the original
numbers in the um array were because we
did the random numbers up there here's
our original numbers and if you build an
exponential on there this is where you
get e to the X on this and just like you
can do e to the X you can also do the
log so if you're doing logarithmic
functions
that reinforced learning you might be
doing some kind of log setup on there
and you can see the logarithmic of these
different array numbers
and if you're working with a log base 2
you can do you can just change it in
there in P log 2. you have to look it up
because this is not log one two three
four five it is Log and log 2. so just a
quick note that's not a variable going
in that is an actual command there's a
number of them in there and you'll have
to go look and see what the
documentation is but you can also do log
10. so here's log value 10.
some other really cool functions you can
do with this is your sign
so we can take a sine value of all of
our different values in there
and if you have sine you of course have
cosine
we can run that
so here's the cosine of those and if
you're doing activations in your lumpy
array and you're doing a tangent
activation there's your tangent for that
and the tangent activation is actually
from neural networks that's one of the
ways you can activate it because it
forms a nice curve between from whether
you're generating 1 to negative one with
some discrepancy in the middle
just jumping a little bit in there into
neural networks
and then we get into we just put the
array back out there so we can see it
when we're doing this
as we're getting into this you can also
sum the values so we have NP sum
and you can do a summation of all the
values in this array and you'll see that
if you added all these together they'd
equal
12.519 and so on I don't know what the
whole setup is in there
but you can see right here the the
summation of this one of the things you
can also do is by axes so we could do
axes equals zero
and if we run the summation of the axes
equals zero
and you can think of that in numpy as
the rows so that would be or
you can think of that in numpy as being
the columns we're summing these columns
going across
and you can also change this to one
and now we're summing the rows
and so that is the summation of this row
and so forth and so forth going down
and maybe you don't need to um
know the summation maybe what you're
looking for is the minimum
so here's our minimal you're looking for
and this comes up a lot because you have
like your errors we want to find the
minimal error inside of this array and
just like the other one we can do axes
equals zero
and you can see here
0.0645 is the smallest number in this
First Column is 0.0645 and so on
and if you have a minimum well you might
also want to know the max maybe we're
looking for the maximum profit
and here we go you can see maximum 0.79
is a maximum on this first column and
just like we did before you can change
this to a 1 on axes you can take the
axes out of here and just find the max
value for the whole array and the max
value in here was 0.8344 so on so on
and since we're talking data analytics
we want to go ahead and look at the mean
pretty much the same as the average this
is the mean across the whole thing and
just like we did before we could also do
axes equals zero
and then you'll see this is the mean of
this axis and so on
and we have mean we might want to know
the median
and there's our median our most common
numbers if we have median we might want
to know the standard deviation or if we
have the average a lot of times you do
the means in the standard deviation
we can run that and there's our standard
deviations along the axis we can also do
it across the whole array
if we're going to do standard deviations
there's also variance
which is your VAR
and there's our variance across the
different levels
and so if we looked at that we looked at
variance we looked at standard deviation
the median and the means there's more
but those are the most common ones used
with data analytics and then going
through your data and figuring out what
you're going to present to the
shareholders
and some other things we can do is we
can actually take slices you'll hear
that terminology and a slice might be
like we have a five by five array but
maybe we don't want the whole array
maybe we want from one on we don't want
the zero in there so we got up to four
and maybe on the second part we just
want
two to row three and see this notation
right here says 1 to the end and if we
run this you can see how that generates
a single row to the end and then row two
and three now remember it doesn't
include three that's why we only get the
one column so if we wanted two and three
you would need to go ahead and go two to
four so it goes up to four
we could also do this in reverse
just like we learned earlier we can go
minus one whoops
and when we go to minus one
it's the same thing because we have 0 1
2 3 4 this is the same thing as two to
four it goes two to the last one
also very common with arrays is you're
going to want to sort them so we still
have our array up here that we randomly
generated and we might want to um
sort it and we'll go and throw an axis
back in there uh
axis equals one if we run this
you can see from the axis that it sorts
it
the point two being the lowest value to
the highest value by the row we can also
change this of course to axis zero if
you're sorting it by columns so maybe
your values are based on columns
and then of course you can do the whole
array
and we can sort that I don't usually do
that but you know I guess sometimes you
might come up
and so you can see right here we have a
nice sorted array
something now let's just go ahead and
reprint our array so we can look at it
again starting to get too many boxes up
there something else you can do with an
array
is we can take and transpose it
this comes up more than you would think
when you transpose it you'll see that
the rows and the column are transposed
so where
0.79.57 0.064 is a column now we've
switched it and we have
0.79.42 as the index
you can see this really more dramatic if
we take a slice
and we'll just do a slice of the first
couple
and then we'll just do all the other the
full rows and if we run this you can see
how it comes up a little bit different
and we'll just do the same slice up here
so you can see how those two look next
to each other
there we go there's our slice run
and so you can see the slice comes up
and it has a one two three four five
columns now we have one two three four
five rows and three columns versus three
rows
and the original version when they first
started putting this together was a
function so the original version was
transpose and this still works you can
still see it generates the same value as
just a capital T
so many times we flip this data because
we'll have an XY value or we'll have an
image or something like that and it's
being read one way into the next process
and the next one needs it the opposite
so this actually happens a lot you need
to know how to transpose the data really
quick
and we can go ahead oh let's just take
here's our transpose we'll just stick
with the transpose on here
and instead of doing it this way we
might need to do something called
flattening why would you flatten your
data if this is an array going into a
neural network
you might want to send it in as one set
of values instead of two rows and you
can see here is all the values as a
single array it just flattens it down
into one array
so we covered our scientific means
transpose median some different
variations on here some of the other
things we want to do is what happens if
we want to append to our array so let's
create a new array
you're getting tired of looking at the
same set of random numbers we generated
earlier so we'll go ahead and create a
new array here something a little
simpler so it's easier to see what we're
doing
and four five six seven eight uh that's
good enough we'll just do four five six
seven eight
and if we print this array
there it is four five six seven eight
and we might want to append something to
the array so we have our array we need
to extend it you got to be very careful
about appending things to your array and
there's a number of reasons for that
one is run time because of the way the
numpy ray is set up a lot of times you
build your data and then push it into
the numpy array instead of continually
adding on to the array
and then it also usually it
automatically generates a copy for
protecting your data so there's a lot of
reasons to be careful about appending
this way but you can certainly do it and
we can just take our array we're going
to create a new array array one
and if we print array one and we append
eight to it you'll see four five six
seven and then there's our a depended on
to the end
and if you want to append something to
an array you'd probably also want to
whoops
array one let's try that again there we
go now we have the a dependent on to the
end
so you can see four five six seven eight
and then we pinned it another eight on
there
and if you're going to append something
you might want to um
go ahead and insert instead of appending
it might be you need to keep a certain
order and we can do the same thing we do
our array
and we're going to pin or insert at the
beginning and let's go ahead and insert
uh one two three one two three and we go
ahead and print our array two we run it
and you can see one two three a pin is
inserted at the beginning
inserts a lot more powerful and that you
can put it anywhere in the array we can
move it to the one spot and there we go
one two three we can do a minus one
just for fun and you'll see it comes up
one two three and we're counting
backwards by one
I imagine you can do minus zero
and run this and it turns out that minus
zero puts it back at the beginning
because that's why it registers a zero
just takes a minus sign off
and just like we add numbers on we might
want to delete numbers and so let's do
an NP dot delete well let's keep it a
little bit make it a little easy here to
watch we'll go ahead and create an array
three
then we'll do NP delete and we're just
working with array 2
and we want to do is delete zero space
so if we look at this here's our array 2
our Raid 2 starts with one and when we
delete the space on here
and print that out we deleted the one
right out of there
and we can also do something like this
where we can do it as a slice and we can
do let's do one comma three
and if we run one comma three you'll see
we've deleted the one space
and the three space out which deleted
our two and four
now keep in mind when you're messing
with adding lines and deleting lines
you have to be really careful because
there's a time element involved as far
as where the data is coming from and
it's really easy to delete the wrong
data and corrupt what you're working on
or to insert stuff where you don't want
it so there's always a warning when we
talk about manipulating numpy arrays
and just like anything else we're doing
uh we'll create an array C which equals
we'll just do our our numpy array that
we just created our Olympia array 3 and
we can do copy so you can make a copy of
it maybe you want to protect your
original data or maybe you're making a
mask and so you copy the array and then
the new array make all these alterations
and change it from values to zero to one
to mask over the first one and of course
we if we do array C since it equals a
copy of array three it's the same thing
one three five six seven eight
and now we're getting into combine and
split arrays
I end up doing a lot of this
and I don't know how many times I end up
fiddling with this and having a mess
so but but you do it a lot you know you
combine your raise you split them you
might need one set of data for one thing
another set of data for the other
so let's go and create two arrays array
one array two
and I want you to note
in the terminology we're going to look
for is concatenate what that means is
we're going to take
um
we'll call this a ray cat I like a ray
cat there we go our array cat our
concatenated array
we're taking array one and two
and it's very important to really pay
attention to your axes and your counts I
can't merge two arrays that have like
the if their axes are messed up and I'm
merging on axis zero it's going to give
me an error and I'll have to reshape
them so you got to make sure that
whatever you're concatenating together
works
and what that means
as you can see here we have one two
three four one two three four and then
five six seven eight five six seven
eight along the zero axes
these each are four values so it's a two
by four value and if we go ahead and
switch this to one you can see how
that's that flips it a little bit so now
we have one two three four five six
seven eight
it's interesting that we chose that one
if I did something like this
where this is now
there we go and we concatenate it we run
this and it gives me an answer okay
because I have two by two and I'm using
axes one but if I switch this to axis
zero where now it's got three and five
it gives me an error so you got to be
really careful on that to make sure that
your whatever axes you are putting
together that they match
um so like I said this one oops X is one
axis one has two entities and since
we're going on axis one or by row you
can see that it lets it merge it right
onto the end there
and you could imagine this if this was a
x y plot of value or the x value going
in and the predicted y value coming out
and then you have another prediction and
you want to combine them this works
really easy for that
we'll go back and let's just put this
back to where we had it
oops I forgot how many changes I made
there we go we'll just put it whoops I
messed up in my concatenation order here
[Music]
there we go
okay so you can see that we went through
the different concatenation axes is
really important when you're doing your
concatenation values on here
we'll switch us back to one just because
I like the looks of that better there we
go two rows
now there are other commands in here so
we can do cat V
equals npv v stack
this is nothing more than your
concatenation
but instead we don't have to put the
axes in there because it's v stands for
vertical
and so if we print out
cat
V and we run this
you can see we get the one two three
four one two three four and that would
be the same as making this axis zero for
vertical stack
and if you're going to have a vertical
stack you can also have an H stack
so if we change this to from v stack to
oops here we go H stack
and we'll just change this from cat to
cat
and I run this
it's the same as doing axis zero the
process is identical in the background
this is like a legacy setup your v-stack
and your H stack most people just use
concatenate and then put the axes in
there because it's much has a lot more
clarity and is more more commonly used
nowadays
the last section in numpy we're going to
cover is
underst is kind of uh data exploration
um and that'll make a little bit more
sense in just a moment sometimes it
comes set operations but let's say we
have an array one two three four five
six three whatever it is uh things we
generate an actual array here and what I
want to go ahead and do is find the
unique values in that array
so maybe I'm generating what they call
it one hot encoder and so these values
then I'll become I need to know how long
my bit Ray is going to be so each word
how many how many each word is
represented by a number and then I want
to know just how many of those words are
in there if we're doing word count very
popular thing to do
and you can see here when we do unique
uh we have one two three four five six
those are our unique values
some of the things we can do with the
unique values is we can also instead of
doing just unique we can do uniques
our unique values and counts of each
unique value
and this is very similar to we just did
up here where we we're doing NP unique
but we're going to add a little bit more
into there
and it's just part of the arguments in
this and we want to do return
count equals
true so instead of just returning the
unique values we want to know how many
of those unique values are in each one
and we'll go ahead and print
our uniques
and print
our counts
let me run that you can see here we have
our unique value one two three four five
six just like we had before and then
there's two of the first of two ones two
twos two threes two fours one five two
sixes and so on and you can go through
and actually look at that if you want to
count them but a quick way to find out
your distribution of different values so
you might want to know how often the
word the is used versus the word and if
each word is represented as a unique
number
and along the set variables we might
want to know let me just put a note up
here
we're going to start looking at
intersection
and we might want to also know
differentiation
and neither
so when we're whoops neighbor
neither so what we're looking at now is
we want to know hey where do these two
arrays intersect and we have one two
three four five three four five six
seven we might want to know what is
common between the two arrays
and so when we do that we have NP
intersect
and it's a 1D array one dimensional
array
and then we need to go ahead and put
array 1 array two
and if we run this
we can see they intersect at three four
five that's what they have common
and because we're going to go ahead and
go through these and look at a couple
different options let's change this from
intersect 1D
and we'll do the same thing we'll go
ahead and print this
so we might want to know the
intersection where they have
commonalities
another unique word is Union of 1D so
instead of intersect
we want to know all the values that are
in both of them so here's our Union of
1D when we run that you can see we have
one two three four five six seven so
it's all the different values in there
and the last one of the last words we
have two more to go as we want to know
what the set difference is
uh and so that's where the you'll see
that if you remember set we talked about
that being the what they call these
things so the set difference
of a 1D array when we run that you can
see that one is only in one array and
two is only in one array
and if we want to know uh what's in
Array one but not in Array two we might
want to know what is in Array one but
not two and what's in two but not one
and this would be the set X or 1D on
here so we have the four different
options here where we can do an
intersection what do they both have in
common we can do a union what are all
the unique values in both arrays we can
see the difference what's in Array one
but not array two so set diff 1D and
then set X or what is not in one but is
in two and what is in not in two but in
one
so we dug a lot in numpy because we were
talking there's a lot of different
little mathematical things going on in
numpy a lot of this can also be done in
pandas although usually the heavy
lifting is left for numpy because that's
what it's designed for let's go ahead
and open up another python 3.
setup in here
and so we want to explore what happens
when you want to display this this is
where it starts getting in my opinion a
little fun because you're actually
playing with it and you have something
to show people and we'll go ahead and
rename this we're going to call this uh
pandas and Pi plot
so pandas pipelot just so we can
remember for next time and we want to go
ahead and import the necessary libraries
we're going to import pandas as PD now
remember this is a data frame so we're
talking rows and columns and you'll see
how pandas work so nicely when you're
actually showing data to people and then
we're going to have numpy in the
background numpy works with pandas so a
lot of times you just import them by
default
Seaborn sits on top of the matplot
library so sometimes we use the Seaborn
because it kind of extends it's one of
the 100 packages that extends the
matplot library probably the most common
used because it has a lot of built-in
functionality almost by default I
usually just put Seaborn in there in
case I need it and of course we have
matplot Library as pipelot as PLT and
note we have as PD as NP as SNS as PLT
those are pretty standard so when you're
doing your Imports I would probably keep
those just so other people can read your
code and it makes sense to them that's
pretty much a standard nowadays
and then we have the strange line here
uh it says Amber sign matplot Library
inline
that is for Jupiter notebook only so if
you're running this in a different
package you'll have a pop-up when it
goes to display the matplot library you
can with the most current version of
Jupiter usually leave that out and it
will still display it right on the page
as we go and we'll see what that looks
like
and then we're going to go ahead and
just do the Seabourn the sns.set and
we're going to set the color codes
equals true let them just keep the
default one so we don't have to think
about it too much
and we of course have to run this the
reason we run this is because these
values are all set if we don't run this
and I access one of these afterward
it'll crash
the cool thing about Jupiter notebooks
is if you forgot to import one of these
you forgot to install it because you do
have to install this under your anaconda
setup or whatever setup you're in you
can flip over to Anaconda and run your
install for these and then just come
back and run it you don't have to close
anything out
and we'll go ahead and paste this one in
here real quick where we have car equals
PD dot read underscore CSV and then we
have the actual path
this path of course will vary depending
on what you are working with uh so it's
wherever you saved the file at and you
can see here I have um like my OneDrive
documents simply Learn Python data
analytics using python slash car CSV
it's quite a long file
when we open that up what we get is we
get a CSV file and we have the make the
model the year the engine fuel type
engine horsepower cylinders and so on
and this is just a comma separated file
so each row is like a row of data think
of it as a spreadsheet
and then each one is a column of data on
here and as you can see right here it
has the make model so it has columns for
a header on here
now your pandas just does an excellent
job of automatically pulling a lot of
this in so when you start seeing the
pandas on here you realize that you are
already like halfway done with getting
your data in I just love pandas for that
reason numpy also has it you can load a
CSV directly into numpy but we're
working with pandas and this is where it
really gets cool is I can come down here
and I can print remember our print
statement we can actually get rid of it
and we're just going to do car head
because it's going to print that out the
head is going to print the top values of
that data file we just ran in
and so you can see right here it does a
nice printout it's all nice and in line
because we're in Jupiter notebook I can
scroll back and forth and look at the
different data and just like we expected
we have our column and it brought the
header right in
one thing to know is the index it
automatically created an index 0 1 2 3 4
and so on and we're just looking at the
head so we've got zero one two three
four
you can change this you might want to
just look at the top two
we can run that there's our top two BMWs
another thing we can do is instead of
head we can do tail
and look at the last three values that
are in that data file and you can see
right here it numbered them all the way
up to
11913. oh my goodness they put a lot of
data in this file I didn't even look to
see how big the file was so you can
really easily get through and view the
different data in here when you're
talking about Big Data
you almost never just print out car in
fact let's see what happens when we do
if we run this and we just run the car
it's huge in fact it's so big that the
pandas automatically truncates it and
just does head plus tail so you can see
the two
um so we really don't want to look at
the whole thing I'm going to go back to
let's stick with the head
displaying our data there we go so
there's a head of our data it gives us a
quick look to see what's actually in
there I can zoom out if we want so you
can actually get a better View
although we'll keep it zoomed in so you
can see the code I'm working on
and then from the data standpoint we of
course want to look at
um
data types what's going on with our data
what does it look like now this you know
you show your when you're talking to
your shareholders they like to see these
nice easy to read charts they look like
a spreadsheet so it's a nice way of
displaying pieces of the chart
when you talk about the data types now
we're getting into the data science side
of it what are we working with well we
have make model we have an integer 64
for the year engine fuel type is an
object if we go up here you can see that
there most of them are
like you know it's a set manual rear
wheel drive so they might be very
limited number of types in there
uh and so forth and you'll it's either
going to be a float64 an integer or an
object is the way it's going to read it
on here
and the next thing you're going to know
is like your columns
and since it loaded the columns
automatically we have here the make the
model the year the engine the size all
the way up to the MSRP
and um
just out of something you'll see come up
a lot is whenever you're in pandas and
you type in dot values it converts it
from a pandas list to a numpy array
and that's true of any of these so then
you end up in a numpy array so you'll
see a little switch in there in the way
that the data is actually stored and
that's true of any of these
in this case we want car dot columns
you have a total list of your car
columns
and like any good data scientist we want
to start looking at analytical summary
of the data set what's going on with our
data so we can start trying to piecemeal
it together so we can do car
uh describe
and then we'll do is we'll do include
equals all
so a nice Panda command is to describe
your data
if you're working with r this should
start looking familiar
and we come down here and you can see
count there's a make the model of the
year how many of each one how many
unique values of each one the top value
of each one what's most common the
frequency the mean clearly on some of
these it's an object so really can't
tell you what the average is it'd just
be the top ones the average I guess
the year what's the average year on
there all this stuff comes down here
your standard deviation your minimum
value your maximum value what's in the
lower quarter fifty percent Mark where's
that line at and what's in the upper 75
percent the top 25 percent going into
the max
now this next part is just cool this is
what we always wanted computers be back
like in the 90s instead of 5 000 lines
of code to do this maybe not five
thousand all right I built my own plot
Library back in 95 and the amount of
code for doing a simple plot was um
I don't know probably about 100 lines of
code this is being done in one line of
code we have our car which is our pandas
we generated that it's our data frame
and we have dot hist for histogram that
is the power of Seaborn now it's still
going to generate a numpy graph but
Seaborn sits on top and then we can do
the figure size this is just um so fits
nicely on the paper on here and we do
something simple like this and you can
see here where it comes up and it does
say matplot library and does subplots
and everything
but we're looking at a histogram of all
the different pieces in our database and
we have our engine cylinders that's
always a good one because you can see
like they have some that are they had a
null on there so they came out as zero
maybe a couple maybe one of them had a
two cylinder engine away back when four
is a common uh six a little less common
and then you see the eight cylinder 12
cylinder engines whether it's got to be
a Speedster or something
uh but you can see right here just
breaks it down so now you have how many
cars with how many whatever it is
cylinders horsepower and so on and it
does a nice job displaying it
you can see if you're working with your
uh um you're going into your demo it's
really nice just to be able to type that
in and boom there it is it can see it
all the way across
and we might want to zero in and use
like a box plot and this time we'll go
ahead and call the Seaborn SNS box plot
and we're going to go ahead and do
vehicle size in versus engine horsepower
XY plot and the data comes from the car
so if we run this we end up with a nice
box plot
you see our mid-size Compact and large
you can see the variation there's our
outlier showing up there on the compact
that must be a high-end sports car a
large car might have a couple engines
and again we have all these outliers and
then your deviation on them
very powerful and quick way to zero in
on one small piece of data and display
it for people who need to have it
reduced to something they can see and
look at and understand and that's our
Seabourn box plot or sns.box plot
and then if we're going to back out and
we want a quick look at what they call
pair plotting we can run that and you
can see with the Seaborn it just does
all the work for you
uh it takes it just a moment for it to
pull the data in and compile it
and once it does it creates a nice Grid
in this grid if you look at this one
space here which is you might not be
able to see the small number it says
engine horsepower this is engine
horsepower uh to the year was built and
it's just flipped so everything to the
right of the middle diagonal is just the
rotation of what's on the left and as
you expect the engine horsepower gets
bigger and bigger and bigger as time
goes on so the the year it was built the
further up in the year the more likely
you are to have a heavy horsepower
engine
and you can quickly look at trends
with our pair plot coming up and look
how fast that was that was it took a
couple a moment to process but right
away I get a nice view of all these
different information which I can look
at visually in in kind of see how things
group and luck
now if I was doing a meeting I probably
wouldn't show all the data
one of the things I've learned over the
years is people myself included love to
show all our work you know we were
taught in school show all your work
prove what you know the CEO doesn't want
to see a huge grid of graphs I guarantee
it so we want to do is we want to go
ahead and drop
um the stuff that might not be
interested in and we're gonna I'm not
really a car person a guy in the back is
obviously so you have your engine fuel
type we're gonna drop that we're going
to drop Market category vehicle style
popularity number of doors vehicle size
and we have the axes in here if you
remember from numpy we have to include
that axis to make it clear what we're
working on that's also true with pandas
and then we'll look at just the what it
looks like um from the head and you can
see that we dropped out those categories
and now we have the make model year and
so forth and we took out the engine fuel
type Market category Etc
and this should look familiar to you now
when you start working with pandas I
just love pandas for this reason look
how easy it is it just displays it as a
nice spreadsheet for you you can just
look at it and view it very easily it's
also the same kind of view you're going
to get if you're working in spark or Pi
spark which is python for spark across
Big Data this is the kind of thing that
they they come up with this is why
pandas is so powerful
and we may look at this and decide we
don't like these columns and so you can
go in here and we can actually rename
the columns
simple command car equals car rename
columns equals engine horsepower equals
horsepower this is just your standard
python dictionary
so it just Maps them out and you know
instead of having like a lengthy if it
here we had engine horsepower we just
went horsepower we don't need to know
it's the engine horsepower
engine cylinders we don't need to know
that it's for the engine because there's
only one thing we're describing if we're
talking about cars and that cylinders
and we'll go ahead and just run this and
again here's our car head and you can
see how that changed we have model year
and horsepower versus model year engine
horsepower engine cylinders and just
cylinders
again we want to keep reducing this so
it's more and more readable the more
readable you get it the better and of
course we can also adjust the size a
little bit
so that when it prints out instead of
splitting it on two lines we get like a
single line we can do that also that's
just your control Mouse app or plus sign
you use in Chrome that's a chrome
command
and if you remember from numpy we had
shape well pandas works the same way we
can look at the shape of the data so we
now have 11 914 rows and 10 columns so
you'll see some similarities because
pandas is built on numpy
and questions that come up just like you
did in numpy we might want to know
duplicate rows and so we can do car and
look at this switch here
um we're doing a selection this is a
panda selection with the brackets
but we want to select it based on
car.duplicated so how many duplicates on
there
so it's starting to look a little bit
different as far as how we access some
of the data in here this can be a
logical statement and we get the number
of duplicate rows we have 989 rows by 10
columns again
and this is one of those troubleshooting
things that we end up doing a lot more
than we really feel like we should we
might go ahead and do like a car count
just to see how many rows we're dealing
with and then right after that we might
want to go ahead and say hey let's drop
duplicates so remember we did all the
duplicates on there so car equals car
dot drop duplicates and then we can
print the head again we'll just do car
head here and you can see the data on
there looks the same as before
and just note that we did car equals car
draw duplicates there are commands in
here where you can do where it changes
the actual value and it works on some of
them and not on others depending on what
you're doing but by default it always
returns a copy so when we do this we're
reassigning it to car
and you can see it's the same header but
we want to go ahead and do count and see
how the count changes let's go ahead and
run this and you can see here instead of
11 914 we have 10
925. so we've removed about a hundred
cars that were duplicated just slightly
under 100 there
and then as we're prepping our data we
might want to know
um car is null so it's going to count
the values of null and then we want to
sum that up
and when we do that we do the car is
null function dot sum we end up with HP
the horsepower 69 have null values and
30 have cylinders have no values now if
you don't put the sum at the end it's
just going to return a mask with the
true false of is it null or is it not by
the zero and one so you're summing up
the ones underneath each column
and this of course then you have to
decide what you're going to do with the
null values there's a lot of different
options it might be that you need to put
in the average or means
maybe you want to put in the median
value there's a lot of different ways to
fill it usually when you first start out
with the data a lot of them you just
drop your null values and you can see
here car dot drop in a
which is equal to all and then we're
going to go ahead and count it and you
can see that we've dropped almost
another 100 values so from 10 1925 to 10
8 27.
and maybe 75 or so values
so we cleaned that this is really a big
part of cleaning data you need to know
how to get rid of your null values or at
least count them and what to do with
them
and of course if we go back to um
counting our null values we should now
have null null values
there we go and you'll see there's zero
null values
I don't know how many times I've been
running a model that doesn't take null
values and it crashes and I just sit
there and look at it trying to get why
did that crash it should have worked
it's because I forgot to remove the null
values
so even jumping around a lot we're going
to go back to finding outliers and let's
go ahead and bring that back into our
Seabourn and if we remember we did a box
plot earlier this time we're going to do
a box plot just on the price and you can
see here our price value
and we have the deviation with the two
thinner bars on each side of the main
value and then as we get up here we have
all these outliers in fact we have one
way out here that's probably a really
expensive high-end car is what we're
looking at
if you were doing fraud analysis you
would be jumping on all over these
outliers why are these deviation from
the standard what are these people doing
again this is probably like I said a
really high-end expensive car out here
that's what we're looking at and we can
also look at the box plot for the
horsepower
and we'll put that in down here
and run that
and you can see again here's our
horsepower and it just jumps and there's
these really odd huge muscle cars out
here that are outliers
and we're going to jump into making this
a little bit more as you started
displaying your data or your information
to your shareholders we're going to look
at plotting a histogram for the number
of cars per brand
and the first thing we want to go ahead
and do is we have with our car go back
over here here we go we have our make
value counts largest plot and we want to
do a kind equals bar
fig size 10-5
and right off the bat we jump up here
and we see Chevrolet it's going against
what was it it's um figure resolution
the value counts and we want the largest
value so here's our value counts and
compared to what the different cars are
Chevrolet puts out a lot of different
kinds of cars I didn't realize that they
made that many cars or different types
and then for readability let's go ahead
and add a title number of cars by make
number of cars and make if you looked at
this the first time you would have been
like well what the heck am I looking at
well we're looking at the number of cars
by make and then you can see here now
we're talking about the type of cars and
the different ones are put out Lotus I
guess only had a few different kinds of
cars over there very high-end cars
and then as uh doing data analytics and
as a data scientist one of the things I
am most interested in is the
relationship between the variables
so this is always a place to start we
want to know what's going on with our
variables and how they connect with each
other
so the first thing we're going to do is
we're going to go ahead and set a figure
size because we want to make sure it
fits our graph we'll just go ahead and
set this one plot Figure Set to figure
size 2010. if you never use the matplot
library which is sitting behind Seaborn
whatever is in the PLT this is what's
loaded it's like a canvas you're
painting on so the second you load that
Pi plot as PLT anything you do to that
is affecting everything on it
and then we want to go ahead since we're
using Seaborn
we'll go ahead and create a variable C
for relationships or correspondence
and car dot c-o-r-r that's a correlation
in Seabourn on top of pandas again one
line and you get the whole correlation
on there and because we're working with
Seabourn let's put it into a nice heat
map if you're not familiar with heat
maps that means we're just using color
as part of our
setup so we have a nice visual
and we can see here that the Seaborn
connected to the pandas prints out a
nice chart
we'll talk a little bit about the color
here in a second it prints out a nice
chart this is a chart I look at as a
data scientist these are the numbers I
want to look at and we'll just highlight
one of them here's cylinders versus
horsepower the closer to one the higher
the correlation so 0.788 pretty high
correlation between the number of
cylinders and how heavy the horsepower
is
I'm betting if you looked at the year
versus horsepower we just look at that
one here's year and horsepower 0.314 not
as so much but if you combine them you
don't actually add them but if you
combine them you'll start to see an
increase in Horsepower per year and
cylinders you could probably get a
correlation there and just like 0.78 is
a positive correlation you might notice
if we look at cylinders
and or let's look at horsepower and
mileage so if we go here to horsepower
to mileage you get a nice negative we'll
do cylinders that's a bigger number
with cylinders to the miles per gallon
it's a minus 0.6 so it's a negative
correlation the closer to -1 the more
the negative correlation is
and then the chart you would actually
show people is a nice heat map this is
all our colors and it's just those
numbers put into a heat map the darker
the color the higher the correlation you
can see straight down the middle
obviously the year correlates strictly
with the year horsepower with horsepower
and so on that's why it's a one the
closer to the one the higher the
correlation between the two pieces of
data
now this is a good introduction pandas
goes Way Beyond this most the
functionality in numpy since pandas sits
on it is also in pandas and then it even
has additional features in it and we use
Seaborn pretty extensively sitting on
top over our pie plot so keep in mind
that our PI plot has a ton of other
features in it that we didn't even touch
on in here we couldn't even if you had a
soul course in it there's just so many
things hidden in there depending on what
your domain you're working on but you
can see here here's our Seabourn and
here's our matplot library that's all
our Graphics that we did and then the
Seaborn works really nicely with the
pandas we really like that feeling
inspired already not what but we have
multiple success stories to share if you
are inspired consider checking the
simply lens postgraduate program in data
analytics offered by Purdue University
for more details use the link in the
description box below the link should
redirect you to the official course
landing page that will give you a
complete overview of the course being
offered also if you are a complete
beginner and an aspiring data analyst
looking for online training and
certifications in collaboration with
leading experts then search no more
simple lens data analysis Masters
program should be a right choice for
more details use the link in the
description box below
So currently I am on my MySQL workbench
let me connect to the local instance
so I'll give my password
and click on OK
all right so this is my MySQL workbench
query editor so first we are going to
learn sub queries let me give a comment
and write sub queries
all right so first of all let's
understand what a sub query is so a sub
query is a query within another SQL
query that is embedded within the where
Clause from clause or having clause
so we'll explore a few scenarios where
we can use sub queries so for that I'll
be using my
database that is SQL underscore intro so
I'll write my command use SQL underscore
intro now this database has a lot of
tables I'll be using the employee stable
that is present inside SQL underscore
intro Let me just expand this and you
can see here we have an employee stable
so let me first show you the contents
within this table I'll write select star
from employees
let me execute it
okay you can see here we have the
employee ID employee name age gender
there's date of joint Department City
and salary and we have information for
20 employees if I scroll down you can
see there are 20 employees present in
our table
so let's say you want to find the
employees whose salary is greater than
the average salary
in such a scenario you can use a sub
query so let me show you how to write a
sub query
I'll write the select statement
in the select statement I'll pass
my column names that I want to display
so the column names I want are the
employee name
that I want the department of the
employee and the salary of the employee
from
my table name that is employees
next I'll use a where condition where
my salary should be greater than the
average salary of all the employees so
I'll write salary greater than
after this I am going to write my sub
query
so I'll give select
average of salary
from
my table name that is employees
and I'll close the bracket and give a
semicolon
so what it does is
first it is going to find the average
salary of all the employees that are
present in our table
once we get the average salary number
we'll use this where condition where
salary is greater than the average
salary number
so
the inside sub query let me run it first
if I run this
this gives you the average salary of all
the employees which is 75 350 dollars
now I want to display all the employees
who have salary greater than 75
350 dollars so let's run our sub query
there you go so there are eight
employees in our table who have a salary
greater than the average salary of all
the employees
all right
next
let's see another example
suppose this time you want to find the
employees whose salary is greater than
John's salary
so we have one employee whose name is
John
let me
run the table once again
okay if I scroll down
you see we have an employee
as John
you see this
our employee ID 116 as John and his
salary is sixty seven thousand dollars I
want to display all the employees whose
salary is greater than John's salary so
basically all the employees who are
earning more than 65 000 I want to print
them
so let's see how to do it I'll write
select
I want the employee name comma the
gender of the employee
I also want the department and salary
from my table name that is employees
I'll write where
salary is greater than
I'll start my
opening bracket inside the bracket I am
going to give my inner query that is
Select
salary
from employees
where
the employee name is John
So within single quotations I'll give
John as my employee
and end with a semicolon
so
let me first run my inner query
so this will give us the salary that
John has which is sixty seven thousand
dollars now I want the employees who are
earning more than sixty seven thousand
dollars so let's run our
sub query
okay so you can see
12 rows returned which means there are
12 employees in our table who are
earning more than sixty seven thousand
dollars you see here all these employees
have a salary greater than sixty seven
thousand dollars
okay
now
you can also use sub queries
with two different tables so suppose you
want to display some information that
are present in two different tables you
can use sub queries to do that
so
for this example we'll use
a database that is called classic models
you can see the first database
so let me use this database called
classic Model so I'll write use classic
models
now this database was actually
downloaded from the internet there's a
very nice website I'll just show you the
website so this is the website that is
MySQL tutorial.org
you can see here they have very nice
articles blogs from where you can learn
MySQL in detail so we have
downloaded the database that is classic
models from this website you see here
they have a MySQL sample database if you
click on this
it will take you to the link where you
can download the database so they have
this download link which says download
MySQL sample database and the name of
the database is classic models all right
so we are going to use this classic
models database throughout our demo
session if I expand the tables
section you can see there are a lot of
tables that are present inside this
classic models database we have Cricket
customers as employees
office this orders order lines and many
more so for our sub query we'll be using
two tables that is order details and
products table first let me show you the
content that is present inside
the products table first
if I run this
you see here it says 110 rows return
which means there are 110
different products that are present in
our table which has the product code the
product name
product line we have the product vendor
description quantity in stock Buy price
MSRP
the other table we are going to use is
order details which has the details of
all the orders
let me show you
the records
or the details tables has okay so there
are thousand records present in this
table you have the order number the
product code quantity ordered price of
each item you have the order line number
as well
okay
now
we want to know the product code the
product name and the MSRP of the
products whose price of each product is
less than hundred dollars for this
scenario we are going to use two
different tables and we are going to
write a sub query
okay
so
if you see here in the order details
table we have a column called price each
I want to display the product code the
product name and the MSRP of the
products which have a price of each
product less than hundred dollars
so the way I'm going to do is
I'll write select
product code comma
product name now one thing to remember
that this product name is actually
present inside our products table
and product code is present in both the
tables that is production order details
here you can see this is the product
code column
comma MSRP which is present inside the
products table again
from my table that is
products
where
I'll write
product
code
I'm going to use the in operator
next I'll write my inner query that is
Select
product code
from my table
order details
where
my price of each product
is less than 100 dollars
let me run this
okay so you can see there are total 83
products in our table which have
a price less than hundred dollars you
can see the
price here
okay
now we learn another Advanced Concept in
SQL which is known as stored procedures
I'll just give a comment saying
stored procedure
okay
so first let's understand what is a
stored procedure
a stored procedure is an SQL code that
you can save so that the code can be
reused over and over again
so if you want to write a query over and
over again save it as a stored procedure
and then call it to execute it
so in this example I want to create a
stored procedure that will return the
list of players who have scored more
than six goals in a tournament
so I have a database called SQL
underscore IQ
these are a few databases that I've
already created so this database has a
table called players if I expand the
tables
option you see we have a table called
players and you can see the columns
player ID the name of the player the
country to which the player belongs to
and the number of goals each player has
scored in a particular tournament
so I'll write a stored procedure that
will return the list of top players who
have scored more than 6 goals in a
tournament
so first of all let me Begin by
using MySQL underscore IQ database
will run it
so now we are inside the SQL underscore
IQ database
let me
select
star from players to show the
values that we have in the players table
you can see there are six players in our
table
we have the player ID
the names of the players the country to
which these players belong to and the
goals they have scored
so I'll write a stored procedure
so the stored procedure syntax is
something like this it should start with
a delimiter
okay
in the delimiter I'll write
ambition ampersand
next I'll write
create
procedure
followed by
the procedure name
let's say amount to
name my procedure as top underscore
players
okay
next statement is begin
after begin I'll write my select
statement
I want to select the name of the player
the country
and the goals
each player has scored
from my table that is
players
where
I'll write goals is greater than
6.
will give us semicolon
then
I'll end my
procedure with a delimiter that was
double ambison
next
I'll write
delimiter
and give
a semicolon
now the semicolon suggests
this is a default delimiter
and there should be a space okay
now let's run our stored procedure
there you go so you have successfully
created a store procedure now the way to
run a store procedure is
you need to use the
call method and give the procedure name
that is top underscore place in our case
with brackets and a semicolon
let's execute it
okay there is some problem here
so we made a mistake while creating a
procedure
the name of the column is goals and not
goal
let me create that procedure again
okay it says the procedure top
underscore player already exists let's
just
edit the procedure name instead of top
player we'll write it as top players and
similarly we'll edit here as well
now let's create it again
okay
now to
call my procedure I'll write call space
followed by the procedure name which is
top underscore players
if I run this you can see
we have two players in our table who
have scored more than six goals so we
consider them as the top players in a
particular tournament
all right
now there are other methods that you can
use while creating a stored procedure
one of the methods is by using an in
parameter
so when you define an in parameter
inside a stored procedure the calling
program has to pass an argument to the
stored procedure
so I'll give a comment
stored procedure using in parameter
all right
so for this example I'll create a
procedure that will fetch or display the
top records of employees based on their
salaries
so if you have a table
in our SQL underscore IQ database which
is called employee details
I'm going to use this table you can see
we have the name of the employee the age
sex then we have the date of joint City
and salary
using this table I'll create a procedure
that will fetch or display the top
records of employees based on their
salaries
and we'll use the in parameter so let me
show you how to do it
I'll write
delimiter
this time I am going to use
forward slash
I'll write
create
procedure
followed by the procedure name let's say
SP for stored procedure
sort by
salary is the name of my procedure
and inside this procedure I'll give my
parameter
in
I'll create a variable VAR and assign a
data type integer
then I'll write begin
followed by my select statement where
I'll select the name
each
salary
from
my table name that is
EMP details or employee details
I am going to order this by
salary
descending
and
I want to display
limited number of
records so I'm using this
limit keyword and my variable VAR which
I
created here
I learned my select statement
I'll end my stored procedure with
forward slash
and I'll go back to my default delimiter
that is semicolon
all right
so let me
run this
should be a space here all right
so let's run this
okay you can see we have successfully
created our
second stored procedure which is sp
underscore sort by salary
now you can also check whether the
stored procedure was created or not here
you have an option to see the stored
procedures let me just refresh this
and you can see we have
three stored procedures that we have
created so far one is sp underscore sort
by salary
the other two were top underscore player
and top underscore players
okay
now let's call our stored procedure I'll
write call
space followed by the stored procedure
name which is sp underscore sort
by salary
and inside this I'll give my parameter
which was actually VAR and this VAR
we have used in limit
let's say I want to display only the top
three records of the employees who have
the top three highest salaries
okay so let me run it
there you go so Amy Sarah and Jimmy
where the top three employees who have
the highest salary
so you saw how you could use the in
parameter in a stored procedure
we created a variable and that variable
we used in our select statement and we
called our stored procedure and passed
in that
variable
okay
now
instead of a select statement inside
stored procedure you can also use other
statements let's say update
so I'll create a stored procedure to
update the salary of a particular
employee
so in this procedure instead of Select
statement we'll use the update command
in this example we'll use the in
operator twice
so let me show you how to do it
I'll write my delimiter first which is
going to be forward slash then I'll
write create
procedure
my name of the procedure is going to be
update salary
and inside the
update salary name
I'll write in
and then
temp
underscore name which will be a
temporary name variable and the type
I'll assign is worker 20
I'll again use my in parameter I'll
write in
next
my other variable would be new
underscore salary
and the data type would be float
I'll write begin
and write my update
command or update statement I'll write
update
table name that is employee details set
salary
equal to
new underscore salary
where
name is equal to
my temporary variable that is temp
underscore name
so this is my
update command and I'll
end the delimiter
all right
so let's run this
okay we have successfully created our
stored procedure if I refresh this
you can see I have my stored procedure
update underscore salary
okay
now let's see
first of all I'll
display
my
records that are present inside
employee underscore details table okay
so we have six rows of information let's
say you want to update the salary of
employee Jimmy or let's say
Mary
from seventy thousand to let's say
seventy two thousand
or let's say eighty thousand
so I'll
call my stored procedure that is update
underscore salary
and this time I'm going to pass in two
parameters the first parameter will be
the employee name and next with a comma
I'll give my new salary that I want to
so my employee name let's say is Mary
and the salary I want
to be updated is let's say eighty
thousand dollars
we'll give a semicolon
and I'll run it
you can see it says one row affected now
let's check our table once again
there you go if you see this record
for Mary we have successfully updated
the salary to eighty thousand dollars
now moving ahead
we learned to create a stored procedure
using the out parameter so I'll give a
comment
stored procedure using out parameter
okay
so suppose we want to get the count of
total female employees
will create total employees as an output
parameter and the data type would be an
integer
the count of the female employees is
assigned to the output variable which is
total underscore emps using the into
keyword let me show you how to write a
stored procedure using the out parameter
so first I'll declare my delimiter
to forward slash
I'll write
create
procedure
followed by the procedure name
it is going to be SP underscore
count
employees
and inside this I am going to give my
out parameter and the variable name that
is total underscore
emps which is total employees and the
data type will be integer
next I am going to write begin
followed by my select statement that is
Select I want the
count of total employees
and the output I am going to put into
my new variable that is total underscore
emps
from my table that is EMP underscore
details
where
sex is equal to
F which means female
I'll give a semicolon
next I'll end it
with the developmenter and I am going to
change the delimiter to a default
delimiter that is
colon
so let me tell you what I am doing here
I am creating a new stored procedure
that is sp underscore count employees
using this stored procedure I am going
to count the total number of female
employees that are present in our table
EMP underscore details so I've used my
out parameter and I'm creating a new
variable called total underscore emps
the data type is integer here in the
select statement I am counting the names
of the employees and the result I am
storing it in total underscore emps
I have used my wear condition where the
gender of the sex is female
so let's run this
okay so we have created our stored
procedure
let's refresh this
okay you can see we have a new stored
procedure SP underscore count employees
now
to call it I'll write call
the name of the procedure that is Count
underscore SP underscore count
employees
within brackets I'll pass in the
parameter as
at the rate
F underscore EMP
will give a semicolon then I'll write
select
at the rate F underscore
EMP as female employees
okay
so as is an alias name let's run this
one by one first I'll call my procedure
and then we'll display the total number
of female employees you can see in our
table we have three female employees
all right
now with this understanding
let's move on to our next Topic in this
tutorial on Advanced SQL now we are
going to learn about triggers in SQL
so I'll give a
comment here
triggers in SQL
so first let's understand what is a
trigger so a trigger is a special type
of stored procedure that runs
automatically when an event occurs in
the database server there are mainly
three types of triggers in SQL we have
the data manipulation trigger we have
the data definition trigger and login
triggers
in this example we'll learn how to use a
before insert trigger
so we will create a simple students
table that will have the students rule
number the age the name and the students
marks
so before inserting the records to our
table we'll check if the marks are less
than zero
so in case the marks are less than zero
a trigger will automatically set the
marks to a random value let's say 50.
so let's go ahead and create our
table that is
students
all right
so I'll write
create
table
student
now this table will have the student
rule number
the data type is integer
will have the age of the students
again the data type is integer we have
the names of the students so the third
column would be
name
the data type would be variable
or bearing character
size I am giving it as 30 finally we
have the marks as floating type
so let's create this table which is
student
so we have created our table
now
I'll write my
trigger command
so trigger command will start with
delimiter like how our usual stored
procedures have
next
this time I'll write create trigger
then you need to give the
name of the trigger that is Mark
underscore
let's say verify
I am going to use a before insert
trigger so I'll write before insert
on my table name that is student
next I'll write for each row
if
new DOT marks
is less than 0
then
will set
new DOT
marks equal to 50.
so this is my
condition first we'll check
before inserting if any student has
marks less than 0 we'll assign a value
50 to that student because usually the
marks are not less than 0 in any exam
I'll write end if
semicolon and I'll close the delimiter
so this is my
trigger command I'll run it
it says triggle already exists
so in this case we need to update the
trigger name let's say
I'll write marks underscore verify
underscore
student for SD
let's run it again
okay there is an error here because
in our table the column name is Mark and
not marks so here we need to change it
as Mark instead of marks
all right
let's run it
okay so we have created our trigger
now
let me insert
a few
records to the student table
so I'll write insert into student
I'll write
values
and give the values as
501 which is the student roll number the
age is let's say 10
the name is it's a Ruth
and the marks is let's say 75 point
zero
give a comma we'll insert our second
student record
student rule number is 502
age is 12
the name is let's say Mike
and this time I'm purposely giving a
value of minus 20.5
give another comma
we'll insert the Third record
for student rule number 503
age is 13
the name is Dave
and
let's say the marks obtained by div is
90
.
now we'll insert our final record for
student number
504
these is 10
name I'll enter as Jacobs
and this time again I'm purposely giving
the marks in negative
12 point let's say 5.
close the bracket and give a semicolon
and I'll run my insert statement okay so
we have inserted four rows of
information to our student table
now
let me run the select query I'll write
select star from student
if I run this you see the difference
there you go
so originally we had inserted
for 502 the marks was minus 20.5 and for
504 for Jacobs the marks was minus 12.5
our trigger automatically converted the
negative marks to 50 because when we
created our trigger we had set our marks
to 50 in case the marks were less than
zero
so this is how a trigger works
now you can also
drop a trigger or delete a trigger you
can just write drop trigger followed by
the trigger name in this case our
trigger name is
St
I'll just paste this here
and if you run this it will
automatically delete your trigger
you give this as a comment
okay
now moving on
now we are going to learn about another
crucial Concept in SQL which is very
widely used
this is known as views
so views are actually virtual tables
that do not store any data of their own
but display data stored in other tables
views are created by joining one or more
tables
I'll give a comment as views in SQL
okay
now
to learn views I am going to use my
table which is
present inside classic models database
now this database as I mentioned we have
downloaded
we had downloaded it from the internet
so first of all let me write
use classic models so I'll switch my
database first
all right now we are inside classic
models
so here
let me show you one of the tables which
is called customers so I'll write select
star from customers
okay
I missed s here
let's run it again so this is my
customer table which is present inside
classic models database it has the
contact last name the contact first name
the customer name customer number we
have the address State country and other
information
now I'll write a basic view command
using this customer table the way to
write is I'll write create
View
followed by The View name which is cast
underscore details
then you write as
select
I am going to select a few column names
from my original customer table which is
this one so I need the customer name
let's say I need the phone number
and the city so you have this
information here you have the phone
number and the City
all right
I'll write from my table that is
customers
if I run this
my view that is cast details will be
created
let's run it there's some error here
because the name of the table is
customers and not customer
I'll give an S and I'll run it again
all right so you can see we have created
our view
and to display the contents that are
present inside our view I can write
select star from followed by The View
name that is cost underscore details
let's run it
there you go so we have the customer
name the phone number and the City of
the different customers that you have in
our table
all right
now let's learn how you can create views
using joins so we'll join two different
tables and create a view
so for that I am going to use my
products table and the products lines
table I am talking about the products
table and the product lines table
present inside classic models database
so before I start let me display the
records that are present inside the
products table
let's run it so these are the different
products you can see here
now let's see what we have in product
lines table
so we have the product line the text
description and there's some HTML
description and image
so
I'll create a view by joining these two
tables and will fetch specific records
that are present in both the tables
so let me first start by writing create
View
followed by The View name that is
product underscore
description
as I'll write
select
product
name
comma
then I'll write
quantity
in stock
I also want the MSRP
now these three columns are present
inside the products table and next from
the
product lines table I want the text
description
of the products
so I'll write from
products table
I'll give an alias as p
followed by Inner join my other table
that is
product lines as let's say PL
on
the common column that is product line
so P Dot
product line
is equal to
I'll give a space
PL Dot product line
okay
so here we have used an inner join to
fetch specific columns from both the
tables and our view name is product
underscore description let us run it all
right so we have our view ready
now let me
view or display what is present inside
our product underscore description
View
I'll hit select start from
product underscore description
let's run it
there you go so we have the product name
the quantity in stock MSRP and textual
descriptions of the different products
in the table
okay
now there are a few other operations
that you can perform let's say you want
to rename a view instead of product
underscore description you want to give
some other name
so I'll just give a comment rename
description
so to rename a description you can use
the
rename statement I'll write rename table
product
underscore description Which is my
old name
I want to change this name to let's say
I'll give vehicle description
since
all our products are related to some of
the other vehicle so I'll write vehicle
description
okay
let us run it
all right so here you can see I have
renamed my
View
so here if I just refresh it
and I'll expand this you can see we have
the cash details view and we have the
vehicle underscore description View
okay
now either you can view all the views
from this panel
or you can use a command let's say
I'll write display views
just a comment
now to show all the views you can use so
full tables
where
table
underscore
type is equal to within single quote
I'll write View
so this is the command that will display
all the views that are present inside a
database
there is some
error here let's debug the error
this should be
okay so instead of table types it should
be table type equal to view
let's run it
you can see the two different views that
we have one is customer details another
is vehicle underscore description
okay
now you can also go ahead and delete a
view
for that you can use the drop command
so I'll write drop
view followed by The View name let's say
I want to delete
customer underscore details or cast
underscore details view
I'll write drop View cast underscore
details
let's run it
you can see
here we don't have the cast underscore
details view anymore
all right
now moving to our final section in this
demo
here we will learn
about Windows functions
now Windows functions were Incorporated
in MySQL in the 8.0 version
so Windows function in MySQL are useful
applications in solving analytical
problems so using the employees table
present inside my SQL underscore intro
database
so we'll find the total combined salary
of the employees for each department
so first let me switch my database to
SQL underscore
into database
I'll run it okay
I'll display my table
that is employee
so here we have 20 employees in our
table
using this table
we are going to find the combined salary
of the employees for each department so
we'll partition our table by department
and print the total salary and this we
are going to do using
some windows functions in MySQL
so I'll write
select
I want the employee name
the age of the employee
and the department of the employee
comma
next I'll write
the sum of salary
over
I want to partition it by
Department
so I'll write Partition by Department
which is Dept
and I'll give an alias as
total salary so that it will create a
new column with the name total salary
from my table that is employees
the output will be a little different
this time
let's execute it and see the result
there you go so here we have created
another column in our result that is
total salary and for each of the
employees and the respective departments
you have the highest salary so in
finance the highest salary of one of the
employees was
155 000 dollars
similarly if I come down we have the
highest salary from HR if I scroll
further we have the highest salary from
it marketing product sales and the tech
team
all right
now we'll explore
a function which is called row number
now the row number function gives a
sequential integer to every row within
its partition so so let me show you how
to
use the row number function I'll write
select
row underscore number function
over
my
column would be
salary so I'll write order by salary
I'll give the
Alias as ronum
we give a comma
and I want to display the employee name
and the salary of the employee
from my table that is employees
and I'll order by
salary
so let's see how our row number function
will create
sequential integers okay you can see
here we have a row num column and we
have successfully given row numbers to
each of the records you can see it
starts from 1 and goes up till 20.
okay
now this row number function can be used
to find duplicate values in a table
to show that first I'll create a table
I'll write create table
let's say I'll give a random name that
is demo
and let's see we have in this table the
student ID which is of type integer and
we have the student
name
which is of type worker
the size is 20
I'll create
the small table with a few records
let's create this table first
now we are going to insert a few records
to our demo table so I'll write insert
into
demo
values
I'll give 1 0 1
the name is
Shane
give a comma
I'll insert the second student name 102
the name is Bradley
give a comma
this time
for 1 0 3 we have
two records
let's say the name of the student is
hereat
give a comma I'll copy this
and we'll paste it again so we have
duplicated one zero three
next we have 104
the name of the student that says
Nathan
then again let's see for
the fifth student which is Kevin we have
two records
I'll copy this
and I'll paste it here
let me give a semicolon and we'll insert
these records to our table demo
all right
now
let me just
run this table for you I'll write select
star from demo
if you see this we have a few
information that are duplicated in our
table
that is for student id103 and student ID
105.
now I am going to use my
row number function to find the
duplicate
records present in my table I'll write
select student underscore ID comma
student underscore name
I'll give another comma and write
Rue underscore number
within brackets
I'll write partition
by
St underscore ID
comma
St underscore name
okay
then I'll write
order by St underscore ID
close the bracket I'll give an alias as
ronum
from my table that is demo
let's just run it
you can see here
okay
let me just
delete n from here and do it again
all right if you see here the richest
one student in the name Shane we have
one student in the name Bradley
but here if you see for here
the second record it says to which means
there are two records for hirath and if
I scroll down there is one record for
Nathan and there are two records for
Kevin which means Kevin is also repeated
okay
now we are going to see another Windows
function that is called rank function
in MySQL so the rank function assigns a
rank to a particular column
now there are gaps in the sequence of
rank values when two or more rows have
the same rank so first of all let me
create a table
and the name of the table would be a
random name we'll give it as let's say
demo one
and it will have only one
column let's say variable a of type
integer
we'll create this table first okay
now let's go ahead and insert a few
records to our
table which is demo one so I'll write
value
1 0 1
0 2
let's say 1 0 3 is repeated
I'm doing this purposely so that in the
output you can
clearly distinguish what the rank
function does
we have one zero four
one zero five
we have one zero six
and let's say 106 is also repeated
finally we have
one zero seven
okay
let me insert these values to my table
that is demo one okay this is done
now
if I write
select
VAR underscore a
and use my rank function I'll write rank
over
then I'll
order by my variable that is VR
underscore a
as
an alias name let's say test rank
from
my table that is demo one
let me execute this and show you how the
rank function works
now if I run this there you go
so here if you mark
so for variable a101
the test rank is one for one zero two
the test tank is 2 but
for this value which is 1 0 3 the test
rank is repeated because there was a
repetition of one zero three
so we have skipped the rank 4 here for
104 the rank is 5 now for one zero five
the rank is six now
one zero six again since the record was
repeated twice we have skipped the
eighth Rank and
our rank function assigned the same
value which is 7 for 106 and for the
last value 107 the rank is nine
all right
now moving ahead we'll see
our final Windows function which is
called first value
so first value is another important
function in MySQL so this function
Returns the value of the specified
expression with respect to the first row
in the window frame
all right
so what I am going to do is
I am going to select
the employee name
the age and salary
and I'll write
first underscore
value which is my function and pass in
my employee name
and then I'll write over
order by
my
column that is salary descending
I'll give an alias as highest underscore
salary
from my table that is employees
so let me run this and see how the
first
underscore value function works all
right so in our table
Joseph was the employee who had the
highest salary which was 115
000 so
the first value function populated the
same
employee name throughout the table you
can see it here
now you can also use the first
underscore value function
over the partition
so let's say you want to display the
employee name who has the highest salary
in each department so for that you can
use the partition
I'll write select EMP underscore name
comma
I want the department
and the salary
comma
I'll use my function that is first
underscore
value
followed by
the name of the employee inside my first
value parameter
I'll write
over
here I am going to use partition
I am going to partition it by
department since I want to know the
employee name who has the highest salary
in each department
and I am going to order by
salary
descending
and I'll give my Alias again as highest
salary
from
my table that is employees
so let's run this and see the difference
in the output okay
so as you can see here
we have
the employee who had the highest salary
from each department so for finance Jack
had the highest salary from HR it was
Marcus similarly in it it was William
if I scroll down for marketing it was
John for product it was Alice who had
the highest salary similarly in sales we
had Joseph
and in Tech we had Angela
so this is how you can use the first
underscore value function using
partition
all right
so that brings us to the end of this
demo session on our tutorial
so let me just scroll through and show
you what we did from the beginning first
we learned about sub queries in SQL so
we initially wrote a simple sub query
and then we used our classic models
database which was downloaded from the
internet and also shown you the link
from where you can download this
database here we used two different
tables and we performed a sub query
operation
we learned how to create stored
procedures
so we learned how you can use the in
operator or the in parameter as well as
the out parameter in stored procedure
after stored procedure we learned
another crucial Concept in SQL which is
called triggers now triggers are also
special kind of stored procedures so we
saw how to write a before insert trigger
you can see it here
next
we learned how to delete a trigger we
also saw how to work with views in SQL
so views are basically virtual tables
that you can create from existing tables
we also saw how you can use views using
two different tables and an inner join
and
we learned how to display views how to
rename
view names
how to delete a view and finally we
explored a few Windows function
so let's discuss what's in it for us
today
now we will first talk about why power
bi you know why it's a popular tool and
what problem it solves what is power bi
and what are the primary features of
power VI which you can use in your
day-to-day data analytics visualizations
creating fancy reports creating
meaningful intelligent reports
for your organization for your personal
use for crunching numbers for generating
reports real time Etc
now the most popular tool for power bi
is the power bi desktop uh I'll show you
certain
aspects of power bi desktop and then
I'll show you the steps how to install
power bi desktop on your machine
and then definitely power bi desktop is
a free tool provided by Microsoft but
then you can also subscribe for an
Enterprise version which is primarily
used uh by Enterprises for publishing
their data uh so we'll see the
difference and then overview of our
dashboards which can be created uh you
know what kind of dashboards can be
created in power pi
so this is the agenda for us today
now why power bi so generally uh you
know visualization tools reporting tools
are required in order to create and
prepare and analyze meaningful data it
could be a data for an organization it
could be a social media platform data it
could be a data from iot devices but
something which needs to be analyzed and
some intelligent inferences and data
mining has to be done on top of it now
imagine there is today we are in a world
where terabytes of data and information
is getting generated on an instantaneous
basis on minute-by-minute basis so it
becomes very essential to churn out
something meaningful something
intelligent out of it in the market
there are a lot of other tools which are
available like clicks uh all tricks
Tableau and power bi so power bi is a
Microsoft product which is one of the
most popular products and it comes as a
free to download product Microsoft power
bi desktop which is available and I'll
show you a couple of ways how you can
install it on your machine but why power
bi is uh popular is because it provides
a lot of out of the box features drag
and drop features which we will talk
about in our subsequent sessions and you
know classes but today's session is
primarily focused on giving you guys an
introduction on what is the purpose of
power bi and what all problems it solve
uh in the in the real world so power bi
allows you to view analyze and visualize
huge quantities of data and the data
could be in any format Excel CSV text or
it could be a direct connection to a
database like SQL MySQL Azure Oracle
anyone IBM db2 so it supports n number
of uh you know data types or data sets
and it's very powerful in terms of data
connectivity
so it uses powerful compression
algorithms to import and Cachet the data
within the dot pbix file so it's as
convenient as a simple software if
suppose you import a data and then you
prepare a report and then you can easily
share the reports with your peers or
someone who's co-developing with you
either through Power bi cloud services
or even you can share the pbix file in
an email
or through any other means and you can
share the data set with the concern and
they can then work on the report
independently so there are different
ways there is no uh kind of a limitation
for you know working on power bi there
are multiple ways and it is very fast it
is the most fast uh tool to work with
Excel because definitely Excel is also a
Microsoft Technology so it works very
fast on Excel based data and gives you
numbers and Reporting at a very high
speed
so now once you have imported the data
power bi allows you to model the data
allows you to work intelligently on the
data it allows you to model data in a
way that if you are importing data from
multiple Excel sheets importing data
from multiple tables you can easily
create a relationship between those
tables or data sets in power bi and then
create visually appealing reports
meaningful reports as I've been
emphasizing and make sense out of that
data no data in silos is of any use data
in Silo means a single worksheet or a
single data set will not churn out any
meaningful information until unless you
basically join it clubbit merge it Union
it append it with some other data sets
because a single data set will never be
able to hold that much amount of
information which is generally required
for a you know important report
so it has easy drag and drop
functionality with features that allow
you to copy all formatting across
similar visualizations so just like in
Microsoft Excel we use format painter to
copy the format of one cell to another
similar features very very similar to
excel products or Microsoft product they
have provided that if you have applied a
a particular thing on a report you can
easily replicate that on an any other
report the font uh the header size the
background color you don't need to do it
again and again so there's a lot of
reusable features which are also
available
okay now as I said Excel is a Microsoft
product power bi is a Microsoft product
so they have intercompatibility you can
publish data from Excel to power bi now
with the latest developments and
enhancements
as of today pixel has also plugged in a
new feature called Power pivot which
I'll uh show you later down the line but
that also allows you to do a quick
analysis no you can't create of course
complex reports or uh fancy reports like
power bi but Power pivot allows you to
create you know quick measures quick
functions quick calculations on your
data quickly only in Excel so it's an
Excel plugin but whereas you know you
can power bi is also compatible with
Excel so when you create a report in
power bi it gives you inbuilt feature to
export your power bi report into Excel
format directly you don't need to do any
programming for it also
you can easily publish when you publish
your power bi reports it allows you to
give some inbuilt intelligence of
analyzing your reports in Excel and it
gives you all those of all those
features of exporting your power bi
reports into Excel which is not
available in any other tool or otherwise
those tools have to create plugins
create add-ins and probably they might
charge for it but Power bi comes with
lot of out of the box features which are
very very helpful for analyzing data in
Excel and vice versa
Azure Cloud now Azure itself again is a
Microsoft cloud Tech stack so using
power bi with Azure allows you to
analyze and share large volumes of data
so Azure basically Azure database or
Azure Cloud servers are meant to hold
huge amount of data and power bi allows
you to have seamless connection you can
easily connect to Azure data Lake
you can reduce the time it takes to get
insights and increase collaboration
between business analysts data engineers
and data scientists so azure
data Lake becomes the central focal
point where all your analysts Engineers
can keep working on on the centralized
piece of data and churn out their
reports data scientists primarily job is
to keep the data in a structured way
optimized way optimize the input output
operations disk operations and memory
utilization so that the reports also get
churned out in a faster manner so every
uh you know every person has their own
role in order to give a quick
refreshable report a quick rendered
report any report which is taking huge
amount of time to get rendered will not
eventually be used by the business users
because then it does not solve the
purpose the report should be fast
reports should have uh you know
appropriate filters slices and dices you
should be able to you know create the
reports or dynamically or you should be
able to analyze visualize the data
dynamically so all those visualization
features are available in power bi and
it works seamlessly either it is small
data or huge data it allows that you to
work on those kind of data in a seamless
fashion
right so this is just a very uh quick uh
example of how our typical dashboard
looks like dashboard is nothing but you
know you have clubbed couple of multiple
reports on a single page and you know if
you change a filter uh uh a single
filter on the page all the reports will
honor that filter and the numbers will
change accordingly so if you see the in
this example there is a filter or a drop
down of product ID product name employee
name or supervisor or a date range so
whatever date range or filter you will
apply all the reports on this dashboard
will get changed based on the filter you
have selected so power bi allows you to
get insights from data and turn insights
into action to take data driven business
decision and that is the ultimate goal
of any visualization tool that is the
purpose for which visualization tools
are bought
and purchased by the organizations and
data is fed into them
Now power bi fetches data from Factory
sensors social media sources to get
access to real-time Analytics so that
you are always ready to make timely
business decisions so so basically there
is a a feature of live connection or cut
off data connection so either you can
work on data which is deciding on a
machine and you can just work on the
cutoff data like for example it's
there's a data which is available for
sales 2017 2018 and you're just working
on a historical data it's a cut off data
or it could be possible that you want to
be connected live uh to a real-time iot
based sensor based data or social media
data like Twitter Facebook feeds or you
know you're connected to live Google
worksheets that is also possible you
just need to publish your Google sheet
for a public domain embed that you are
into Power bi and then whoever updates
that Google sheet automatically the
power bi report will also start honoring
and consuming the new data which is
added in the uh Google sheet so all
those kind of real-time streaming
analytics is also possible and that is
one big feature and very important
feature of power bi which is widely used
and has a very huge uh you know Market
acceptance and Market utilization
now what is power bi
power bi is a business analytics service
provided by Microsoft that lets you
visualize your data and share insights
right so earlier
you know uh
Microsoft used to have a technology
called ssas now they have replaced
actually ssas and SSRS with power bi so
basically you can use power bi on the
data which is there in your Excel or any
other data source and the power bi
service or power bi desktop basically
creates a connection to those data sets
and import it cache it and give you a
handle to it in order to work with it so
you can create these fancy meaningful
visualizations like for example there's
a geographical map if you are importing
data for a country or a continent or a
region power bi will automatically
detect that it's a geographical
information and give you a map with
latitude longitude information and you
just need to plot
your uh your numbers on the map either
you can use bubbles or either you can
use triangles or whatever data structure
you want to use but all the mapping will
be available geographically then you can
create pie charts which is shown in this
visualization you can create tree maps
you can create cards where you know you
can highlight the most important numbers
like sales total sales of your company
across all the regions or the growth
chart or the month on month uh you know
sales of your organization or number of
total number of products or units sold
so whatever is important and to be
highlighted for the management to take
any meaningful decision or any insights
you want to share
power bi visualization tool the power bi
visualization uh
uh chart allows you to drag and drop and
create wonderful reports okay
so what are the features of power bi so
power bi desktop is something a
standalone tool which you need to
install on your machine it allows you to
build reports by accessing data easily
you do not need Advanced report
designing or query skills to build a
report though yes it is beneficial that
if you know some SQL programming
analytical programming or you are aware
of advanced features of any analytical
tool that might help you but that's not
a showstopper you can easily build
reports in quick turnaround time without
needing any technical background you
just need to have some analytical uh
mindset and you can create uh Savvy
visualization and you know analytical
reports
stream analytics as I mentioned you can
create a live connection uh with any
kind of data it could be iot it could be
media social media it could be Google
Docs it could be uh you know any other
kind of uh you know live connection it
could be a live database connection
itself so any insertions or updations or
deletions happening will automatically
reflect in your report
yes multiple data sources and that has
to be the primary criteria for any tool
to be popular if any visualization tool
is limited to certain data sets then you
know it will not be highly acceptable in
the market
and custom visualizations right so as I
showed you certain uh examples in the
past in the previous presentation uh
that feature is very important because
someone might want to look the kpis look
at the kpis from a different perspective
some management might want to look at
the kpis from a different perspective so
you need to you need to have that
capability to create different
visualization from the same data set now
let's take a look at how
to install power bi desktop on your
machine
so basically what you need to do is
you need to go to this URL
power bi dot microsoft.com en US desktop
okay
and you need to just
enter this
now you can download it for free so just
click over here and
it will open Microsoft store so
basically now what Microsoft have done
in the latest operating systems is that
when you are trying to download you can
actually directly go to the Microsoft
store
and search for Power bi
so let's wait for a couple of seconds
right here so power bi desktop in
Microsoft store for me it's already
installed so it's asking me to open it
I'll open it in a while but for you for
anyone who is not installed he will see
the button of install over here and it
will automatically install in your
machine and then you can easily go and
open power bi desktop now if I click
open over here
now this is the
uh UI of the power bi desktop I'm not
going to go right now in creating
reports right away we will talk about
that in a subsequent session with sample
data sets and we will cover the features
of power bi desktop one by one but this
is what it is this is the whole tool of
power bi which is having the
visualization pane all the different
visualizations are you know can be
created from this pane
then this is the pane which allows you
to select the data data fields then
there is a report view data View and
relationship view the data model view
where multiple relationships you can
create you can view the data in the grid
of the tables which you will create and
the reports so you can create multiple
reports on multiple Pages you can keep
adding pages either you can drag create
multiple reports on a single page and it
will become a dashboard or you can
create separate independent reports on
the single page
and these are the menu options which we
will talk about how you can change color
scheming you can do data modeling you
can create new reports and you can also
transform data which is the biggest
feature extract transform and load the
data apply different logic changing data
types massaging the information creating
new joins appending the data you know
adding new columns etc etc uh we that is
what you can do in transform data so
this itself is a whole different world
it's a dedicated topic so we will talk
about that in our subsequent sessions so
what's in it for us today we will be
learning how to connect to data
different data types data files like
Excel PDF then what are the different
data importing modes and then I will
also show you practically different sets
how to import them in power bi and use
it for your visualization purpose now
what are the steps to connect to data so
now we will go directly into Power bi
and try to import one by one few most
commonly and popularly used data sets
which are most commonly used in a
day-to-day activity rest of course there
are power bi supports n number of data
sources but we will do something
practical on the most popular ones so
let's let's open our power bi
now this is my power bi and first I want
to show you that how can I import data
directly from a web page and import the
data now it is asking for a URL in order
to import data
so what I have done is I have created a
Google Excel sheet with simple data with
rows and columns and what I have done is
I have shared this sheet as published to
web
okay so you just need to say publish to
the web the link as web page and
say done it's it's automatically
published and say link so copy the link
which you have published on the web copy
this link
and then go back to your tableau
paste that link over here and click ok
Now power bi will try to establish a
connection with this Google doc sheet
because it's published on the web
you need to wait for a while while it is
reading
okay now it has read one of the HTML
tables I'll select this one now you can
see it has it is showing me a preview of
the table which is there on my
Google sheet right it has 11 rows so it
has all showed all the 11 rows so now I
can go and transform this data because I
can see my headers are there starting
from the second row so there is an
opportunity for me to transform the data
so I'll go and transform it so that it
looks clean
okay so first is I need to remove the
first row which is the
null row remove the top rows
okay and then I need to use the first
row now as a header so you just click
this option use first row as headers
set so now if you see my row ID order ID
order date ship date all my data is now
ready so I can say close and apply
click apply changes
now this is an example of web data
import you can go and preview your data
right now uh the biggest advantage of
this data connection is that it's a live
data so for example I insert another row
let me change the order ID
some some I've sub change some basic
stuff and I
it's Auto saved
Ctrl s now I'll go to my tableau and
I'll refresh
now you can see as I refreshed my
power query editor I click refresh all
and I got my new row which is there in
the live data I got that fetched from my
okay I got that row the row number row
ID number 12 so I have to say close and
apply
now you can see the new row the row
number 12 is now available in my new
data set in the data set because it's a
live connection it's a live connection
with the web based Google sheet okay so
this is one
important way in which you can import
data
now let's try to import data from a text
file
now I have already prepared our text
file called
sub categories Dot txt
now let me just open it in a notepad now
it's a very plain simple file tab
separated file in which you have product
subcategory ID subcategory name and
product category key so basically to
which product category this particular
sub product belongs to right so what I'm
going to do is I'm gonna go back to my
get data option
and I am going to select text slash CSV
option
and I'm gonna select option mod product
subcategories Dot txt
okay so now power bi has identified that
it's a tab delimited file it has
recognized the headers
Etc right and I can now directly load
this file
okay
so now once the data is imported in
power bi it is like
irrelevant to me it's a composite data
in in Port I'm doing right so in my
presentation when I am talking about
importing data there are different
importing modes right import our data
import can happen through different ways
okay
one is direct query mode in which I
create a live connection to the database
which I'll also show you uh using MySQL
and Ms SQL server and also you can do a
composite mode in which you can have
data imported from Excel plus you can
have direct query modes so you can have
multiple uh modes to connect and create
a composite data model and that's what
we are doing right now in our practical
so what we are doing over here is one we
have imported data from the web second
we have imported data from a text table
now after doing text now our next task
is to import from CSV let's try another
one so now I have imported product
subcategory
now I'll import
a CSV file so again I'll choose the
option Text slash CSV and now in this
CSV file let me open this CSV file and
show you what it is it
so this is a list of all my products
product key products sub category Key
Products stock keeping unit Etc a simple
CSV file and I'm gonna import that
okay so now it is identified the
delimiter is comma rather than a tab and
it has already recognized the headers
correctly so I load it
okay so now my products are there
product subcategories are there for
product categories now what I have done
is I have created as Excel mode now so
now Excel I am using to import my
product category
so now I have to click on the option of
import data from Excel and I'll say
product categories
select the sheet load
and now so my products product
categories product sub categories do
with different uh data storage types but
still now the data is imported into
Power bi is a composite data model now
another very important data type which
you can import is the PDF also right so
what I have done is I have created a PDF
called customers my customers data is
lying in a PDF so what I've done is I've
created a PDF
which has data for some columns are
there like you know customer key prefix
first name last name birthdate marital
status gender email address annual
income total children etc etc so this is
the data set
which I have created in PDF so what I'm
going to do is
I'm going to select PDF now
and import customers.pdf
and see it has recognized my table on
page one which I am going to load
okay
you can rename this as PDF
table
okay so this basically these are the
different type of
data
types we have imported PDF Excel text
CSV and web page
now let's take a look at another
interesting data set which you want to
import is the my SQL Server data set
so what I have done is I've already
installed MySQL server on my local
instance and there's already a schema of
SQL live tutorial over there and I have
certain tables already
prepared over there like Department
employee Etc so my goal is now to import
this data or create a live connection
with this data set
now in order to import
my SQL database Connection in power bi
you need to First
download a
connector MySQL power bi connector so
you need to go to this link
and then click on download and install
the MySQL connector based on the
operating system you have you click on
download and install it
after you have done this go back to
Power bi
and then give
the IP address of the database in my
case it's there in this local machine
and the schema which I want to import is
SQL live tutorial so I'll give the name
click connect
okay now it's connected so now it is
asking me which particular tables you
want to create a connection with I am
choosing department and employee
and I'm just loading them
okay so now this is the exact data which
is there in the employee and Department
in MySQL okay so this is one example of
how to create connectivity between power
bi and MySQL
now I want to do the same thing using
SQL Server Microsoft SQL Server so I
have also installed Microsoft SQL server
on my machine
and I have used the SQL Express so this
is the name of my server so which I'll
copy the server name
and
go to get data
select SQL Server
and for now database is optional I can
say direct query click ok
now it is showing me what all tables I
can import so in my SQL Server tutorial
in my SQL Server I have
I have these three tables customers
employee attrition Olympic events so I
can use probably the customers one which
is
now you can see this is the data the
customer's data which is lying in my SQL
Server okay so I can preview it and load
it
so now you can you can preview the data
in uh Power bi that is this is the data
so I can rename his customers from
mssql
and this is from
MySQL
and
okay so now
this is not the only data
sets you can import now if you take a
look at the options which power bi gave
what different type and variations of
data it can it has compatibility to
import from
okay so we can just take a look at the
categorization on the left hand side
first there are five ways like Excel
text XML Json is also possible you can
evenly directly import an entire folder
and within the folder whatever uh data
types of files are there it will detect
it PDF power key or even SharePoint
folder which is itself Microsoft uh
technology then different kind of
databases SQL server and MySQL we just
saw but it's not only limited to this
you can connect to Microsoft Access
ssas Oracle database IBM db2 postgres
site base teradata and then sap
databases Amazon redshift Impala vertica
Snowflake and N number of databases
which are there in the market today
Amazon
Etc
then it also allows you to connect with
its own power platforms power bi
platforms data Marts power bi data flows
dataverse Etc
Azure there are different kind of
storage
mechanisms in Azure and Azure itself is
a Microsoft Technology so it has a
compatibility of a lot of azure uh based
data storages like Azure SQL database
blob storage uh Azure data breaks right
Azure HD insights path so if you have
those kind of services running on your
observed cloud services you can even
import them over here
now online services
like you know you have erps running uh
or some data which is shared on the
internet if you want to import it uh
that is also possible through certain
products uh Dynamics 365 Microsoft
Exchange online Salesforce Google
analytics Adobe analytics GitHub
LinkedIn sales if you want to do some
analysis of some social networking uh
you know feeds that also you can import
then other miscellaneous are also their
web-based hive R script python script if
there's something to import get data
from uh Google Sheets like we store one
example in our video right now so there
are multiple options available
now once you have imported the data
which is relevant to you
um in our subsequent sessions we will
see how to create relationships but just
giving you a glimpse that whatever data
you are importing power bi Auto detect
certain relationships and it will create
for you but then you can go and manually
also change so this is the composite
data model which is getting created in
the back end while you are importing the
data you can easily go and manage these
relationships either keep them as is you
can delete and create new ones manually
so there is no limitation in that
so this is what we have witnessed we
have imported data from different files
types data types and then you know we
have tried once it is imported into uh
Power bi then there is no limitation of
how you use it you can create
visualization across different data sets
and then create your
standard reports
so this is the example of importing data
from web importing data from a database
from a PDF
and then once you have data you can
shape and combine data you can basically
do whatever whatever transformation you
want to do you want to uh make joins
merge the data so for example if we go
back to our power bi and if I go back to
my transform data section
now as I have now different data sets
available with me I have I can do any
kind of you know operation
transformation on the data right uh
so like I showed you I uh upgraded the
header row because one of the imported
data was not showing the header
correctly uh or this columns like this
exact one column is extra I can remove
the column
right all those Transformations whatever
I do in the back end gets captured in
the applied steps section right
this is the customer data you can create
uh you can merge it you can append it uh
you know with other data sets right
let's for example I want to create a
merge data set of my categories and
subcategories so I can say mer selectors
two data sets and say merge queries as
new
and
and I can select product categories and
product search categories select
product category key on both the sides
and then they do a left Auto Zone so
whatever product categories are there
I'll get the subcategories associated
with it and I'll create a new table
which will have
now I have the table which has the
category and the subcategory and sub
category in one table itself so I can
rename it now to as
category
sub category
table it's a it's a merge basically it's
a join between category and subcategory
and now I have a common table right and
I can close and apply
so imagine I have created a new table
which is imported created from one data
set is which is Excel page another data
set which is text based
see this category subcategory table so
now I can use it
the way I want in my visualization
reports so that's what the presentation
says right that once you have uh the
imported data you can shape you can
combine you can adjust you can do
whatever transformation you want to do
and create your visualization okay so
what topics we are going to cover today
we are going to talk about different
types of data modeling and the most
important part
and aspect of data modeling is the
cardinality the cardinality which you
basically decide after reviewing the
nature of data and after you've imported
it what kind of cardinality you have to
basically highlight right and there are
different type of cardinalities which
you might have heard earlier also if you
are from PL SQL background like one is
to one one is too many Etc we will we
will talk about that
now what are the different types of data
modeling now dimensional data modeling
is one of the most popular and most uh
you know widely used uh modeling in
dimensional data modeling you have
Master data uh like for example customer
data date store data product data so
these are like you know uh less
frequently changing data sets so there
is an organization right and you have
set of customers their email ID phone
numbers
Etc that will change less frequently as
compared to the sales transactions
because transactions are happening every
day every minute so sales is a more fast
changing data set in dimensional
modeling which is in the terminology of
data uh is also called as a fat and
customer store product which are like
more of static data and less changeable
data is sometimes called a diamond
ancient so this is a typical dimensional
data model which is typically used uh
sometimes right and then there is
another model which is relational model
this is a typical model which we have
been using in database design like you
know primary key foreign key
relationships so for example you have a
customer who has purchased a product so
probably he might have the customer
might have the details of the product
which is processed and you will make a
join between customer and product table
and even you can make a join between
product or product type or customer or
product types customer table will also
have a key to the product type so this
is less conducive for reporting but it
is more of a transactional relational
model but of course this is also
feasible but from the power bi
perspective when we talk about reporting
and visualization this is the most
extensively used dimensional data model
and this is what we are going to see in
our example now so what I'm going to do
is I'm gonna show you certain data sets
first we will prepare and create certain
offer data sets and then we will Import
in our sample power bi file and then
slowly slowly we will create the
relationships
now one important thing which you need
to understand that in power bi if you go
to Power bi there is an option that that
power bi Auto detect new relationships
after data is loaded and import
relations from the data source on first
load so for example if you are importing
the data from a database where you have
already defined the primary keys and the
foreign key relationships so uh that is
the first option which power bi will
Auto detect and secondly if suppose you
are importing two different kind of data
sets one is Excel one is csb and if
power bi detects a common column key
columns it will auto detect a
relationship which you can go and later
change modify manage in your
relationship
menu manage relationship menu in power
bi which I'm gonna show you okay so if I
open a power bi and this is where the
option lies go to file
go to options and setting options
data load
and these are the two options which are
by default check you can uncheck it and
auto and manually prepare relationships
there's no limitation to that but if you
uh keep it checked then power bi will do
its job to detect the relationships okay
now coming to the next important factor
cardinality now before I start playing
around with my data and start showing
you certain relationships it's very
important to understand these four types
of cardinalities one is many to one
right so basically
many to one means that many orders
contain data of One customer so per
order one customer is there so from
customer to order or product or delivery
address it's a one-to-man relationship
and from the other side from order to
customer perspective it's a many-to-one
relationship
okay
second other cardinality is one is to
one one is to one relationship is only
applicable when you are saying it's an
extension of the current table so for
example in one table you have employee
details and you are extending the
details of the employee in another table
like employee address employee ID so
that is like one is to one there is no
multiple records of a single employee in
the address table only one employee ID
exists right
now one is too many as I said is the
reverse side of many is to one so in
customer table only one customer record
exists per customer and one customer can
place many orders for multiple products
and can also have multiple delivery
addresses so that way this is a typical
one is to many relationship we will be
seeing this example also in our sample
data set
and last is the many-to-many
relationship now many to many is a very
typical example so which I'm going to
show you practice practically and in our
case we will see that like for example
you have placed an order for a
particular product uh you know but there
are multiple fulfillments which has
happened so suppose you made order for
10 products but at the back end when the
company is fulfilling it is first
fulfilling the first two products then
the rest three so basically you the
Fulfillment is happening in batches so
one order ID might have a multiple
fulfillments for the same order ID so
there will be a multi many to many
relationship which I'll show you
practically so now with this background
let's
start importing our data now the first
important thing which we need to import
is the Master data so first I'll import
all my master Dimensions which is uh
which I'm gonna you know use in my
example so first is the customers table
customers data
so this is the customer details the
customer key prefix first name last name
birth date marital status and gender
some redundant columns are also present
but we'll remove it
so my customer data is loaded now
today's session is all about this
section of modeling so we will keep our
Focus over here
okay now some columns probably some
blank columns are there I can select
them and say delete from model
yes
okay so now this is my customers data
with the relevant columns and the key
per customer customer key
now there's no relationship in this
model right now right because only
single table is there and the associate
data is only imported now let me also
import my another important master table
is the products
select the products data product key
product sub category product SKU product
name model name product description
color size so just see all the relevant
information only specific to the product
is available so at imported
okay now see there's no relationship
between product and customers directly
because until unless a customer makes an
order places an order for a particular
product there is no join right so now
between these two tables the most
important now another table which will
now make sense is the sales order table
sales table
now I I'm assuming that power bi have
Auto detected the relationship now you
can see that because I've already uh
ticked that check box now let's see what
power bi what relations power bi has
Auto detected let's first say check the
relation between customer and sales I'll
double click this
join now what it has done is it has
created a join of many to one
between sales and customer so what does
that mean is that one customer has can
place many orders right and that is that
it is detected by the quality of the
data and the data sampling which power
bi has done you can also reverse this
relationship here I can select customers
and I can select sales now it has become
one too many so that you can also do
manually so that is what I said whatever
power bi is detected it is up to the
description of power bi internal uh
configuration and algorithm but you can
go and change it so this is now you can
this is by default active so we want to
keep it active One customer many sales
orders cross filter Direction means that
only from customers to sales is the
filter applicable not reverse I'll come
to this with my another example but
first let's
change the relationship so one is too
many means from One customer and many
sales orders
similarly let's see what has happened at
the product side
of the relationship
similarly power bi many sales orders for
one product you can for simplicity's
sake you can say products
sales
product key is the join now just focus
one more thing please also see the the
column on which the join is is the grade
column grade out column product key is
also here product key is also there and
it is what we wanted so one is too many
relationship from product to sales table
and act
now looks fine this is something which
is looking logical and probably now we
can
proceed further to create a report
now let me explain the cross filtering
with an example
now for example I want to check in a
report
that what is the count of products which
uh which a particular customer has
ordered
okay so what I'll do is I'll select the
product count of product name
now if you see
and for each customer in front of each
customer name the count is coming as 293
293 it is getting repetitive because
because there is a one-way filter
Direction filter between customers and
sales and sales and products right so
this join
is single sided it means that from
customer to product you can't find a
relationship because it's a single side
cross filter right what does this if I
change it to both it means that it is
equal to a join between product and
sales and every product detail now is
appended to the sales table so if I want
to make you visualize this you need to
go here
I'll first open my sales table
we can also open it here let's make
click it says okay now if I click OK you
can see the single arrow is changed to
Double Arrow it means it's a it's a both
site filter
So when you say a both site filter it
means that implicitly within power bi
you can imagine that all the product
columns now will get appended because of
both ways filter you have applied and if
you go to your report now see the change
of the numbers now 40 20 so the total
count of products across all my
customers come out to be 293 now the
report looks uh correct if I change the
relationship from back to single between
product and sales then you can't make a
join between customers and products
basically you can't derive the product
count from the product table see this
if you have to live with it then you
would have to go to the sales table get
the product key and get the value of
count of product key but that is not
correct okay
so if you want a report in which you
want the count of product name
and even if you want a count of distinct
product name so this will not come
correctly you would have to go and
change the
direction of the filter which is from
single to both so this is a typical
example they where you want to use a
two directional filter
now let's proceed further and import
other data set in order to give show you
another example
now I want to show you an example of
one is to
1.
so I have another table which is called
customer details so the key in this
table is again customer key but only
email address annual income total
children education level Etc other
details of the customer is there
so I'm loading the customer details now
you see it has Auto detected a one is to
one relationship
what is the meaning of one is to one
means One customer key only has one
entry in customer details there is no
multiple entry so if you click this
button
it's a one is to one and the cross
filter can be both or single doesn't
matter because one customer will have
only one value you can make this as
active okay and if you go to the
customer report table you can now easily
associate a
email address with the first name you
will get one is to one
record
so now you can see that with one is to
one relationship
with the first name I have Associated
the email ID and for each email ID
there is a Associated first name method
so this is an example of
one is to one relationship so in this
example what we have explained is that
for each customer there is an Associated
customer detail right uh so you have the
first name email address education level
homeowner occupation and total children
count
so in this report what we have done is
uh if you click over here so the first
name and the email address okay so
there's a one is to one relationship
and then
and if you drag
the customer key
report takes time to render and even if
you can
so this is the reporting output you have
the customer key first name associated
email address and the count of product
names uh which the customer has ordered
now this is an example of 1 is to 1.
now I want to show you an example of
many too many now for that I'll import
my fulfillment data set
huh
okay now in my fulfillment data set
there is a column for
order number so basically what I'll do
is I'll drag order number from here to
here
okay so now what has uh
power bi detected
I will do one thing I'll select sales
over here
fulfillment over here and order number
to odd number
okay so it's a many-to-many relationship
so it means that per order I have
created multiple batches to fulfill that
particular order now
many-to-many relationship is a
definitely a candidate for both ways
cross filter detection uh a Direction
but you can you can check that but
definitely uh Power bi shows a warning
that this relationship has cardinality
to many to many and this should only be
used if it is expected that neither
column contains unique values okay so we
know that fact that's why we are
accepting this relationship as many to
many because we know there are multiple
order numbers over here in the sales
table which are mapped to the multiple
order numbers in the Fulfillment table
we'll click ok
now you want to keep uh the uh
direction as both ways or One Direction
that is up to you the way you want to
map the report so I can double click
over here
and you can even click so now you can
select from which way single filter you
want from fulfillment to sales or sales
to fulfillment I'll prefer sales to
fulfillment and click ok
okay now we have our all our different
kind of relationships over here uh which
we have tried to shortlist one to many
many to one one to one which is uh this
example and uh many too many
now if I show you further relationships
which you can keep on adding like for
example I have uh the example of
territories
now in which particular territory the
sales was done
I put over here
okay so now it's a typical one is too
many relationship because territory is
my master table uh where I have a static
list of continent country region and it
is mapped to the uh territories which
are for in which my orders have been
placed so it's a typical one is too many
so that way you know you can keep on
adding data then you have
uh details of returns
now this is another transactional table
which is about the orders which have
been returned rather than being you know
returned by the customers so you have a
product key
and so automatically power bi has
detected a relationship between the
product key and the product uh table
right and even if you can join the
territory key in which territory the
return has happened
right so mostly the most common
relationship which you will observe is
the one is too many because
as I told earlier the most common
relational model is the dimensional
model uh the static data the slow
changing Dimensions the scds are the
master tables and the most frequent
changing are the fact tables so if I
talk about a typical dimensional model
the Fulfillment table sales table and
the territory stable sorry the
Fulfillment table sales table and my
returns table are the fact tables of my
data model now so far what we have done
as per our last session is that we did
data modeling on the different data sets
which we had imported in power bi like
products sales data returns fulfillment
customer details and customer Master
data calendar details Etc so in the last
session we prepared a data model and
established the relationships between
these different data sets like one is to
one one is too many many to one one is
to one Etc and we saw the examples now
once our relational model is prepared
our data model is prepared now our next
activity is to create certain additional
columns which we want to derive basis
the data which we have imported
so for example I'll start with my
product data set now in my product data
set I want to introduce a column which
basically
categorizes that if any product which
has a color uh you know red black or
gray I am going to tag it as a colored
product rest I'm gonna say not a colored
product right so all these are like
example of byte type product skus so for
that now in order to introduce a new
column you just need to do what you need
to select the table in the data grid go
to the table tools and say new column
okay so column will get appended to the
rightmost part and you will start seeing
a uh formula section typical to like you
get in your Excel now I'm gonna say that
the name of my column is going to be
byte type color okay and I'm just
creating a if condition if
product
color
is equal to
black
okay
or
or if it is equal to red
or if it is equal to
Gray
then
say yes it's a colored product I'll say
no
okay so now you can see this is the
product color red and black they are
saying by type color Yes blue is no
multi is no etc etc so this is a classic
example of an if and else condition
based conditional column
okay so you can create such columns now
second column custom column which I want
to create is I'm going to call as
discount
now this is the pricing of my products I
want to associate certain discounts
which I am ready to give to my customers
this is the product category like what
is the pricing of the category again I'm
going to use make use of if else but in
a nested way so if I am saying if my
product
price is less than 100
then I will give
zero percent of
uh zero percentage of discount so 0 into
product price just to keep it consistent
now I'm seeing
else
if less than 100 and 0 else I'll check
again that
if
the price is
less than
500 then I'm ready ready to give one
percent discount
on the product price
else
I'll move further so like this
I have created a formula
so what I'm saying is if product price
is less than 100 give zero percent if it
is less than 500 then give one percent
less than 2 000 then 1.5 percent less
than three thousand then two percent and
otherwise else less than three thousand
if a two percent else three percent
right now after this column is created
now you can check right so this C the
product price for this particular
product it is less than 100 so that's
why there is no discount it is uh
between 100 to 200 then this has been
given a one percent discount so like
this all the discount column is now
calculated now this column is available
just like a regular column in my product
table
now after this I'll go to my sales table
now in sales table I want to
identify and uh
create a column called as cost
there is no product cost column over
here so that will be derived
so let's create a column
called as cost
and it is derived by order quantity
into now the cost of the product
is in the product table and I know I
have already created a relationship
between product and sales table
so I just need to select the product
cost column now only keyword which I
have to use in power bi is the related
keyword so this will pick up the
relation
and now for this particular sale order
the cost has already been derived so
this order number this is the cost for
which uh the product has is the costing
of the product for this particular order
you do
okay
now I'm gonna create another conditional
column over here called as
order status
I'm saying if
any order whose order quantity is
greater than 2
then for my organization it's an urgent
order
else it is a
normal order
oh sorry
lost it
so this is my
order status column and I have my order
quantity
urgent or normal
so any order which has order quantity
one is normal any order which is having
order quantity as greater than
2 is
urgent you can see this
so there's a this whole power bi
uh tabs and sheets allow you to also
review the data what you're doing so
it's very convenient
now
I have my sales data now what I want to
bring within the sales is my discount
column so here also I want to bring the
discount which I have created
so I'll say discount
[Music]
will be order quantity
into
related
product discount right so the discount
calculated column which I had created
under products I'll bring over here
now I am creating the order level
discount so if you see for this
particular order these are 25 uh
uh you know for 25 rupee discount at the
cost is hundred thousand rupees okay
and what is the order price now so I
have taken the order cost the discount
now I have to create a column call as
price order price so that will be
again order quantity
into related
price which is per product
price enter
okay so now I have the cost the discount
and the price right available with me
now I want to
calculate the total
uh
total revenue total profit and loss
right
per order how much
so first I'll calculate per order how
much revenue I am generating so now I
have to generate a column called as
Revenue
revenue is price
minus discount
so 1700 minus 25
1700 minus 25 2071 minus 42 and if I
want to calculate the profit per order
then it is
Revenue
Minus cost
okay so now you can see you know typical
custom columns calculated columns which
we have created are all playing around
with the number numeric values numeric
data primarily and trying to give
inferences into per order cost discount
per order price revenue and profit so
typical calculation columns which I have
prepared in front of you
now let's take a look at other different
variations of custom columns
I'll create certain columns for text
based custom columns calculated columns
using Text data so I'm now moving
towards my customer table in which I
have customer key prefix first name last
name birth date marital status and
gender
now I want to create a new column in
which I want to derive the age of each
customer as of today right so I'll use
another function a date function called
as
date div
now date div so I want the difference
between the birth date of the customer
and as of today
in years
okay so this customer as of today 68
year old one is 74 68 57 Etc so this is
one derivation of a calculated column of
age
let's take another example now this is a
text based column where I want to
derive the full name of the customer
now here I'll say first
lowercase in lower case I'll concatenate
the prefix
then ampersand
space
ampersand
first name
Ampersand space
ampersand
last name
and closing brackets
Etc
full name
okay so this is an example of full name
in low cases
now another
calculated column conditional column at
the customer level
I want to identify a flag which says who
is my Target customer base is the
demographics shared over here Target
customer
so I'll say
if
the marital status is equal to
m
and
total children
hurry
and total children annual income
so okay so let me change the logic a bit
so marital status is M and age
is
less than
50
these customers are my Target customers
okay so I would say
yes
else no
see this
he is a marital status is married Logan
Diaz and age is less than 50 else
everyone so if I try to filter
so these are the my Target customers
69 out of 1178 so this is just a
conditional column but a logical
condition an example which I am trying
to highlight over here
okay now
let's look at certain calendar
date oriented columns calculated columns
very typical like now I have a simple
date column now I'll keep adding certain
columns which are you know which help
you which will help you understand how
we can uh
you know do some calculations on the
dates so like for example I want a date
which is 12 days after the current date
the date in the column so just simple 12
Days After
select the date and add 12.
now if you see the date format you can
go and change the format at the top
and if whatever you feel like like this
now see 12 days after first Jan 2015 is
13 Jan 2005. you can go and change the
format and other details
let me also show you if I go to my cost
and other columns I can go and change
the format this is like a currency cost
is currency so I can go and
select the
change the currency type and you can
even show the dollar value or whatever
currency type it is
so for numbers you can do currency or
text or dates you can select the format
so this is available at the column tools
level
now in customers
like we had our
column of full name so now what all
things are available format as text okay
data type text so very minimal options
are there with date you have options of
the date format
now next
I want a column which defines the expiry
date okay so eight months prior
to the
expiry date within which is coming up in
eight months so I'll create a column
called as eight months expiry
and then there is a e date function I'll
use that I'll use my
date in the data set
comma I'll say eight so now this date
column will append eight months to my
actual date and again I can go and
change the format
correct
now another important column like I want
to know the date name
so I'll use a function called as
format
and I'll select my calendar date column
and I'll say give me the DDD
format of it so it will give me the day
name the day the day name of on that
particular date
next
years in between
so I want the years in between the
today's date and the date of my calendar
so equal to
D Def
the calendar date
comma today
comma year
end
seven years 2015 to 2022
then last date of the month
so if I want what is the last date of
this particular calendar month
I will use a function EO month which is
there available in the
power bi so I'll say
last date of the month
equal to
e o month
then
just select the calendar CSV date
comma
0 in months and enter
change the format
then similarly start of the month
so I'll use a function called start of
month
so for for all January dates end of the
month is 31st Jan and start of the month
will remain 1st of Jan
change the format
foreign
next I want to know what is the weak
number of that particular date so now
there is an inbuilt function called
week number week num and just pass the
date and you will get
the weak number first week of the year
second week of the year Etc
now another very
good example is whether the weak
day is a weekday or a weekend right so
what is it's a weak type okay
so I'll check I'll put a if condition
and there is a function called weekday
and I'll pass the calendar
if it is less than 6
it means it's a weekday as it's a
weekend
so all Saturday
and Sunday D names will come as weekends
or else everything else will come as
weekly
so these are very different variations
of different column types calculated
columns which is a very important
utility and uh and any Bravo bi project
you will definitely be ending up
creating n number of calculated columns
to derive your numbers to prepare your
reports but it's important to understand
what all things we can do that yes there
are n number of functions available in
power bi but uh what I have tried to
Showcase over here is some important
functions but basis your utility basis
your problem statement you can look up
for a relevant function in the power bi
dictionary
now with this
introduction to calculated column this
is the base for us to now get into our
next session where we'll be talk we will
be talking about creating dacs measures
and Dax functions we will be using power
bi Dax functions which is much more
powerful than simple uh calculated
columns where you can do more uh complex
calculations uh you can calculate totals
and then use them in the reports so for
that we will look up into our next
session
feeling inspired already not what but we
have multiple success stories to share
if you are inspired consider checking
the simply lens postgraduate program in
data analytics offered by Purdue
University for more details use the link
in the description box below the link
should redirect you to the official
course landing page that will give you a
complete overview of the course being
offered also if you are a complete
beginner and an aspiring data analyst
looking for online training and
certifications in collaboration with
leading experts then search no more
simple lens data analysis Masters
program should be a right choice for
more details use the link in the
description box below
in this session we will start with
certain exercises which we will perform
in Tableau in order to understand some
basic concepts
now in order to learn Tableau the basic
first step is to import a sample data so
in our case what we have done is we have
imported a sample Superstore which is in
Excel format a sample superstore.xl
which has three worksheets in it orders
people and returns so by importing this
data into Tableau first of all we will
create relationships between these
sheets in order to identify who all have
placed orders and how many people have
returned the orders we will do some
analysis on the orders placed by certain
set of people and Order returned by
certain set of people
now as we have imported uh the sheet we
will make certain joins so the first
step is to drag the orders
table the order sheet on the
relationship canvas here okay and you
can see the data sample data the first
100 rows over here
okay then now we need to create an inner
join with people's table between order
and people okay so if you see
it has automatically detected the field
names on which the inner join has to be
created so on the order side you have
region and on the right hand side which
is the people data you have also a
region okay so both these columns are
common and that's how we have made a
join between orders and people data
so if I close this box and go and check
the people's data
open
all right
so see the region and the person these
two columns from the people table have
now been
joined with the orders table right so it
means that these are the orders in a
particular region which has been placed
by
in this region
okay
let me show you the sample Superstore
Excel file now this is the structure of
the file you have a sample list of
transactions basically the orders which
are placed by customers
across multiple regions
south west of USA South Region west
region then you have a list of order IDs
which have been returned so basically
the order ID in the returns sheet
matches with those orders in the orders
table
and then you have the people
sheet in which you have region
and a person associated with that region
the sales person associated with that
region okay so basically when we are
combining joining orders with people we
are joining that
which orders
belongs to which region and who is the
sales person associated with it so what
we have done over here is we have made a
inner join means all the orders should
belong to particular region and that
region is in the people's sheet
and then in the second step
now we will make a
left join between returns and orders
not inner join we'll make a left join
between returns and orders and we will
make a join using the
order ID
okay so just edit this
click on left
and
select order ID as the join column now
what does left join means left join mean
is that consider all the orders from the
orders table and only consider the
orders from the returns table which have
data means which are returned otherwise
show null for the order IDs which are
not returned so if you see this is the
these are the two columns from the
return statement and these are null
because this is relevant to the order
IDs which are not returned okay which
has been accepted by the customer but
these are the orders for which you see
data in the returned and Order ID column
it means that these have been written
now with these joins in place please
save your book and now we have our
relations created in the
um
in the Tableau now we are ready to
create certain reports and extract
certain kpis using this relationship
model
now we'll move to sheet 1
okay
and first we will place
state
and person on the rows
sheet okay
then
I'll go to my
numbers and
put the profit or D so per state per
person how much profit I am making as a
company okay this is my goal to check
now sort by highest to lowest
so California is giving me the maximum
profit of 76 381 then New York then
Washington so this is the sorted order
in which I have
listed my profit in descending order
now I can also check what are the number
of orders
placed
and check the distinct count
so out of 120 out of the total orders of
127 okay so this is the number of total
number of orders which have been
returned for California is 127.
it's 16 29 so the sorted order is as per
the revenue as per the profit and this
is the details of the orders which have
been returned per state
so if you see for connected for a Kansas
there are zero returns
so you can also extract data
foreign
ERS and identify new rows using order
date so as and when new data is being
added you can
refresh it now say extract
and now you can save this information
profit
by state
and click save so this is the extraction
of this particular report which is
possible in tableau
so this is the first exercise which we
have completed for
reviewing and analyzing the profit per
state highest to lowest and within that
per state what are the number of
orders which have been returned by all
the customers the distinct count of
order IDs which have been returned
now let's start our second exercise on
creating calculated fields in tableau
now in this exercise we will be doing
certain
activities like we will be creating a
set to show the states which have more
than 100 customers then we will be
creating a calculated field to show an
average sales per customer okay then we
will create a calculated field to show
the sales goals and then show emerging
and developing stage so these are the
four kpis which we have to derive
now the first thing we have our sample
Superstore data already imported and the
relationships created in a join with
people and left joined with returns
now we have our sheet 2 in which we will
create the states a list of states which
has more than 100 customers
so what we have to do is we have to
click right click on the customer name
and click create set
okay
now we have to give the name as states
with 100 plus customers
and then go to the condition tab
select by field
and then apply condition as
count of customer name
greater than equal to
100
and click
ok
now we have this set created states with
100 plus customers
now to determine average sales by
customer we have to now create a
calculated field
so go to the analysis and click on
create calculate field
okay
now name it as
average
sales per customer
and now we will say average
we will use a
foreign
that per customer we are using a level
of definition function include which
means that per customer what is my
average sales right we've already used a
function aggregated function called
average so we are saying per customer
give me the total and then give me the
average per customer so we're going to
click ok
now create another calculated field you
can also create from here
and name is as name it as sales goal
now in this we are going to type the
formula if
minimum
States
with 100 plus customers equal to true
then
sum of
sales
into 1.3
else
average sales per customer into
100 so me we are saying that
if the customer belongs to the set of
states with 100 plus customers then the
sales Target should be
1.3 times the actual sales as of today
else it should be 100 of the average
sales per customer
now let's create another calculated
field which we call as
emerging
or developing state
if distinct count
of customer name
is greater than equal to 100
then
the state is tagged as developing state
yeah
else it is called as
emerging state
okay so we have now
three calculated Fields average sales
per customer emerging or developing
State and sales goals
now we will use this in our reporting
so we will drag sales goal under the
columns
and then I'll drop my state
so now this is the statewise sales goal
depending whether the state has 100 plus
customers or not
then add your customer name
make the measure as count distinct
and make it as discrete
okay so if you see this
we have the count of customers per state
and the
the sales goal
for that particular state
and now
I'll put my sum of sales the total sales
which I want
which is there per state
now go to show me and select
this particular chart
bullet graph
now to bring sales goals to column right
click on the sales access and select
swap reference line fields
now from your left hand panel drag and
drop emerging or developing straight on
the color panel
okay so a merging state is the orange
one and the developing state is the blue
one
and save the sheet as
developing and the emerging States
so if you see this it's an emerging
State because its count is less than the
customer count is less than 100
its sales goal is
57384 but the actual sales is 19511 okay
so now this is a developing State its
count is greater than equal to 100 and
its sales goal and its sales is exactly
the same it matches so that's why you
are saying the bar and the blue bar is
ending exactly where the vertical bar is
so what we are trying to depict is that
whether the state is going Beyond its
Target sales goal or it's behind it
and you can see that using this
particular vertical bar like for example
Michigan its sales goal is 71 952 but
its actual sales is seven six seven two
seven zero average sales so that's why
it is be above its Target and it's a
developing state
because it has more than 100 customers
so you can even sort
by the count of the uh customers higher
to lower so all your developing state
will group from at the top and the
emerging States Will Group at the bottom
or you can sort by
the sales goal
so the orange bar is the sales goal or
the blue bar so depending what sales
goal
has been
derived for each state
we are going to take example of the
Netflix database which we have and we
will prepare certain reports in order to
identify what kind of reports we can
generate from such a data set
So currently on my screen what you can
see is the Tableau the Netflix data
sheets the data sources where you have
the Netflix shows movies their
Associated duration what kind of shows
or movies are there the release here are
the associated rating description and
key which is the show ID now this is the
unique identifier for each show in this
Netflix title sheet and with this show
ID all other sheets are related like you
know who are the directors of the show
in which country the show was released
what is the cost of each show all that
information is in this sheet and to
which particular category basically the
listed in category is being listed in
this particular sheets so what we're
going to do is first we are going to
import this sheet into tableau
okay and then create relationship
between them using the Tableau
relationship canvas
so first our the primary transaction
table the sheet in which all the
information related to movies is there
or shows is there is in Netflix titles
and then we will drag
sheet like Netflix cast titles cast now
W has automatically identified the
relationship between the show ID of
titles and show ID of titles cast and it
has made a join
so if you double click this
you can see this relationship
cardinality and the related fields
similarly I'll drag
titles category
countries and directors
Now by virtue of this all the sheets
have now been joined with Netflix titles
and with this relationship ready we can
start preparing our reports
now let's create a basic report where we
can just glance the data like you know
whatever we were seeing in the Excel how
it looks in w
so you have all the types of movies then
for example I drag the release Here
now first I do not want to consider it
as a
Dimension so I'll just
release year or category per type there
is a release Here and then I'll drop the
listed in
so now these are the categories of per
year the the details of the categories
right and then you can
drag the title and the associated rating
so this is just a view of your data
we can name it as shows listing report
now let's try to create some report for
some
measures some numbers
Etc
so now let's check in which country how
many movies or titles were released you
know what is the count
so first let's drag the
country
so as soon as we dragged the country
uh
uh field it is identified that it has
the geographical names and identified
the latitude and longitude details so
Tableau internally does that
automatically and it has identified the
spots across the globe of the relevant
country
now let's drag the listed in on the
color section
now what it is doing is it is showing in
which country what different kind of
uh category wise movies are or shows are
being released like in Sri Lanka
documentaries have been released in
India action and adventure United States
action and adventure like this
now let's
put
account of
the titles right so if you see 247
action adventure
movies or shows have been released in
United States
okay so this is one inference by this
particular report you can
identify
so let's save this report as
listed
in
by country
okay now let's create another report
we will call it as the per year
statistical report in this first I'll
put the release years in the column
now
count of Netflix titles so this is the
count of Netflix titles per year 2017
2016 14. and then count of Netflix
titles in the countries
this is the second bar chart okay now
what I'll do is I'll combine it into one
so one report
we are
moving in the bar creating the bar and
one in the line now I just have to
so we will click on the count of Netflix
titles by country right click Market
dual access
so now as soon as you click click this
both the charts have been combined and
right click over here and say
synchronize access
okay
okay so now if you can see see right in
2017 you had uh 2 303 Netflix releases
across all categories and 1159
titles right one zero six three titles
in 2017. so this is a descending
representation of the count of titles
release per year across category and
across titles
so let's call this as
per year
stats
now let's create another report
number of shows
but title okay
so or or sorry per rating so we will
drag the rating column
and
we will
count of titles
and
unique count of titles and unique count
of show IDs
okay
one is bar and one is line
okay
so this is a report which shows rating
wise titles and the show IDs
so in the tooltip you can see the
listing count of Titus and show ID per
rating
okay so let's call it
shows
per rating
now let's create another sheet
call it as
shows
by caste
so in this
what we're going to do is first drag the
cast column on the rows section you have
name all of all the cast and then we
drag the
show ID on the column section and put a
count d
and sort it okay
you can remove the null cost and this is
your
sorted order and on the labels section
you can say show Mark labels and you
will see the count that don't open care
has done the maximum
so this is the details on this sorted
order that who has done how many shows
okay
then next is
shows by director similar to shows by
cast
dragged
director into rows
or differently if you want to prepare
into columns and then count off
show ID
okay sort it
and you can actually filter out the null
director value
and this is the account
put the label
so you can see Jan's Twitter has the
maximum shows
okay
then create another report
shows by category
now similarly drag the listed in
in the rows and show ID count
remove the null category
and sort
labels show Mark labels so International
movies are the highest category dramas
the next comedy International TV shows
this way
you have your category
now let's create a dashboard in which we
want to bring combine all these reports
and
take a common view so first let's drag
listed in by country
then
shows by director
also please let's set the size as
automatic
then let's drag shows by category
and shows by cast
now these four reports are on a single
dashboard we will link them to each
other so go to worksheet actions
add action
filter
select dashboard one
only select shows by category here
and in Target dashboard one
except shows by category keep everything
else
and in the source sheet just select
click select
click ok
okay now whatever category you will
select over here
that related category data will
automatically be shown in other reports
like see International movies across the
globe across countries directors of only
International movies who has done the
maximum
Johnny Tow and uh shows by cast right
that who has done the maximum
International movies or dramas
or comedies
travel has a maximum number of comedies
and then if you see the comedy movies uh
you know these are the count of comedy
movies released across the countries and
the who is the director
another a very interesting report which
you can prepare is that for example you
want to check in which country maximum
duration of
uh your
maximum duration of
movies have been released so
first let's create a measure
remove this
okay
so if you see
maximum duration of the movies or the
entire Netflix content is maximum United
States then in India these many minutes
next is United Kingdom and you can also
change the colors
whatever you feel is as per your
standards or as per the convention you
can change the color combination
so there are multiple ways you can
generate reports and uh hope you have
understood how you can leverage such a
data to create your reports we have
reached the end of this session on the
data analytics crash course should you
need any assistance PPT project code and
other resources used in this session
please let us know in the comment
section below and our team of experts
will be happy to help you as soon as
possible until next time thank you and
keep learning staying ahead in your
career requires continuous learning and
upskilling whether you're a student
aiming to learn today's top skills or a
working professional looking to advance
your career we've got you covered
explore our impressive catalog of
certification programs in Cutting Edge
domains including data science cloud
computing cyber security AI machine
learning or digital marketing designed
in collaboration with leading
universities and top corporations and
delivered by industry experts choose any
of our programs and set yourself on the
path to Career Success click the link in
the description to know more
hi there if you like this video
subscribe to the simply learned YouTube
channel and click here to watch similar
videos turn it up and get certified
click here