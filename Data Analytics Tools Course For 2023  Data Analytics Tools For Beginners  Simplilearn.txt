welcome to the world of data analytics
where data holds the key to unlocking
success in the corporate realm in this
comprehensive video course we will take
you on a transformative Journey
empowering you with the Knowledge and
Skills to harness the immense power of
data analytics tools whether you are a
data professional seeking to make data
driven decisions or an aspiring analyst
eager to dive into the world of data
this course is a gateway to becoming a
master of data analytics tools together
we will navigate through a vast
landscape of Cutting Edge tools
exploring their capabilities and
functionalities we will delve into
popular platforms like Excel numpy
pandas tab blue Power bi and SQL and
Wheeling their hidden gems and advanced
features to our side of this video we
would also be covering the popular data
analytics boot camps and frequently
asking interview questions to keep you
on the safer side of your upcoming
interviews but that's not all you will
go beyond the basics immersing ourselves
in data visualization statistical
analysis predictive modeling and data
storytelling we will uncover the secrets
to extracting actionable insights from
complex data sets transforming row
numbers into strategic advantages are
you ready to unleash the power of data
and evolutionize your business
strategies join us on this exhilarating
Journey as we demystify data analytics
tools equip you with the Real World
skills and Empower you to make data
driven decisions that drive success
let's embark on this transformative
adventure together that's it if you are
an aspiring data analyst looking for
online training and certifications from
prestigious universities and in
collaboration with leading experts then
search no more simply lens postgraduate
program in data analytics from Purdue
University in collaboration with IBM
should be a right choice for more
details use the link mentioned in the
description box below with that in mind
or to our training experts I will run
you through the top 6 data analytics job
roles so before I dive deep into the
various job rules let's quickly
understand how important a career in
data critics is and what the future
holds for Professionals in this domain
let's take a look at the growth of data
so back in the early 2000s there is
relatively less data generated but with
a rapid rise in Technologies and with
the increase in the number of various
social media platforms and multinational
companies across the globe the
generation of data has increased by
Leaps and Bounds did you know that
according to the IDC the total volume of
data is expected to reach 175 zettabytes
in 2025
now that's a lot of data let's take a
look at how organizations leverage all
of this data
as you know there are zillions of
companies across the world these
companies generate loads of data on a
daily basis when I say data here it
simply refers to business information
customer Data customer feedback product
Innovations sales reports and profit
loss reports to name a few
companies utilize all of this data in a
wise way they use all of this
information to make crucial decisions
that can either hamper or boost their
businesses you might have heard of the
term data is the new oil well it
definitely is but only if organizations
analyze all the available data very well
then this oil is definitely valuable
and for that we have data analytics
organizations take the help of data
analytics to convert the available raw
data into meaningful insights
so what is data analytics technically
you can say it is a process wherein data
is collected from various sources then
cleaned which involves removing
irrelevant information and then finally
transformed into some meaningful
information that can be interpreted by
humans
various Technologies tools and
Frameworks are used in the analysis
process
as you might have heard of the term data
never sleeps well it surely doesn't
every millisecond some of the other data
is generated and this is a constant
process this process is only going to
increase in the near future with the
Advent of newer Technologies the data
analytics domain holds Paramount
importance in every sector
companies want to leverage on all the
generated big data and boost their
businesses
they need professionals who can play
with data and convert them into crucial
insights organizations are constantly on
the lookout for such candidates and this
opportunity will only increase as data
is only going to grow every second
so if you want to start your career in
this field or if you want to switch your
job role into a role in the data
analytics domain then we have a set of
job profiles that you can look at
weave a look into six job roles in the
data analytics field and learn what each
job role is all about the
responsibilities of a professional
working in that particular role the
skills required to get that particular
job the average annual salary of a
professional working in that Troll and
finally the company is hiring for that
role so let's start off
first we had the job role of a data
analyst
a data analyst is a person who collects
processes and performs statistical
analysis of large data sets
every business generates and collects
data be it marketing research sales
figures Logistics or Transportation
costs a data analyst will take this data
and figure out a variety of measures
such as how to price new materials how
to reduce Transportation costs or how to
deal with issues that cost the company
money they deal with data handling data
modeling and Reporting
now talking about their responsibilities
data analysts recognize and understand
the organization's goal they collaborate
with different team members such as
programmers business analysts engineers
and data scientists to identify
opportunities for solving business
problems
data analysts write complex SQL queries
scripts and store procedures to gather
and extract information from multiple
databases
they filter and clean data using
different modern tools and techniques
and make it ready for analysis they also
perform data mining from primary and
secondary data sources
data analysts identify analyze and
interpret Trends in complex data sets
this is done using statistical tools
such as R and SAS
another key responsibility of a data
analyst is to create summary reports and
build various data visualizations for
decision making and presenting it to the
stakeholders
next let us discuss the important skills
that you need to know to become a data
analyst
firstly you should have a bachelor's
degree in computer science or
information technology a master's degree
in computer applications or statistics
is also preferable
you must have a good understanding of
programming languages like R python
JavaScript and also understand SQL
in addition to that it is beneficial if
you have hands-on experience with
statistical and data analytics tools
such as SAS Miner Microsoft Excel and
ssas
basic understanding of machine learning
and its algorithms would be an advantage
acquaint yourself with descriptive
predictive prescriptive and inferential
statistics
most importantly you need to have a good
working knowledge of various data
visualization software along with
presentation skills this will help you
pitch in your ideas and viewpoints to
the clients and stakeholders better
now talking about their salaries a data
analyst earns nearly 5 lakhs 23 000
rupees per annum in India while in the
United States they earn around 62 000
453 dollars per annum
let's now look at a few of the companies
hiring data analysts so as you can see
we have the American e-commerce giant
Amazon then we have Microsoft the
American online payments company PayPal
then we have Walmart Bloomberg and
Capital One so that was all about data
analyst
the next job role is of a business
analyst
business analysts help guide businesses
in improving products services and
software through data-driven solutions
they are responsible for Bridging the
Gap between it and business using data
analytics to evaluate processes
determine requirements and deliver
data-driven recommendations and reports
to Executives and stakeholders
business analysts are responsible for
creating new models that support
business decisions and come up with
initiatives and strategies to optimize
costs
now let us look at the various
responsibilities of a business analyst
business analysts have a good
understanding of the requirements for
business their vital role is to work in
accordance with relevant project
stakeholders to understand their
requirements and translate them into
details which the developers can
understand
they frequently interact with developers
and come up with a plan to design the
layout of a software application
they also run meetings with stakeholders
and other authorities they engage with
Business Leaders and users to understand
how data-driven changes to products
Services software and Hardware can
improve efficiencies and add value
they ensured that the project is running
smoothly as per the requirements and the
design planned through user acceptance
and validation testing
they make sure all the features are
being incorporated into the application
Bas rely on different software to write
documentation and design visualization
to explain all the findings it is
extremely critical for any ba to
effectively document the findings where
each requirement of the client is
mentioned in detail
now let us look at the skills required
for a ba
a bachelor's degree in the field of
science engineering or statistics or any
related domain will suffice
knowledge of programming languages such
as Python and Java is beneficial you
should be really good at writing complex
SQL queries and you should also have
knowledge of various business process
models
along with knowledge of programming
languages ideas about statistical
analysis and predictive modeling is
necessary
decision making strong analytical and
problem solving skills are necessary to
solve software and business issues you
also need to have excellent presentation
and communication skills both oral and
written
moving on to their salary a business
analyst is expected to earn around 7
lakh rupees per annum in India in the US
they earn nearly 68 346 dollars per
annum
IQR Dell Phillips Honeywell the famous
American messaging platform WhatsApp the
UK based company Ernest and Young a few
of the companies hiring for business
analysts
up next we have the job role of a
database administrator
a database administrator is a
specialized computer systems
administrator who maintains a successful
database environment by directing or
performing all related activities to
keep the organization's data secure
they are responsible for storing
organizing and retrieving data from
several databases and data warehouses
their top responsibility is to maintain
data Integrity this means that database
administrator will ensure that the data
is secure from unauthorized taxes
moving on to their responsibilities
a database administrator develops
designs and maintains a database to
ensure that the data in it is properly
stored organized and managed well
they maintain data Integrity by avoiding
unauthorized access and they keep
databases up to date
they run tests and modify the existing
databases to ensure that they operate
reliably they also inform end users of
changes in databases and train them to
utilize systems
they need to cooperate with programmers
data analysts and the IT staffs to
ensure smooth running and maintenance of
databases
database administrators are responsible
for taking system backups in case of
power outages and other disasters so
they should have an efficient Disaster
Recovery plan
now let's have a look at their skills
to become a database administrator you
should have a bachelor's degree in
computer science or information
technology
knowledge of programming languages such
as python Java and Scala is important
you need to carry at least three to five
years of experience in data management
you need to have an understanding of
different databases such as Oracle DB
mongodb MySQL server and postgresql also
they should have an idea about database
design and writing SQL queries
finally you need to have a good
understanding of operating systems such
as Windows Mac OS and Linux along with
storage Technologies
talking about their salary a database
administrator in India can earn up to 4
lakh 97 000 rupees per annum in the US
they earn around 78 000 per annum
let's have a look at the companies
hiring for database administrators
so as you see here we have bookmyshow
Oracle the American MNC Intel Amazon
Robert Half and the New York Times to
name a few
fourth in the list of job rules we have
data engineer a data engineer is someone
who's involved in preparing data for
analytical and operational uses a data
engineer transforms data into useful
format for analysis they build and test
scalable Big Data ecosystems for
businesses a data engineer is an
intermediary between a data analyst and
a data scientist
now let's jump into their
responsibilities
data Engineers develop test and maintain
architectures they are responsible for
managing optimizing and monitoring data
retrievals storage and distribution
throughout the organization
they discover opportunities for data
acquisition fine Trends in data sets and
develop algorithms to help make raw data
more useful to the Enterprise
data engineers build large data
warehouses using ETL for storing and
retrieving data
they also recommend ways to improve data
quality and efficiency along with
building algorithms to help give easier
access to Raw data
data Engineers often work with big data
and submit their reports to data
scientists for analysis purpose they
need to recommend and sometimes
Implement ways to improve data
reliability efficiency and quality
moving on to the skills of a data
engineer
a data engineer should hold a bachelor's
degree in computer science or
information technology
they should have good hands-on
experience with python R and Java
also data Engineers should be well
versed with big data Technologies such
as Hadoop Apache spark Scala Cassandra
and mongodb
data warehousing and detail experience
are essential to this position along
with in-depth knowledge of SQL and other
database Solutions
basic knowledge of statistical analysis
will be an advantage along with idea
about operating systems
here is what a data engineer can earn so
in India a data engineer can earn up to
8 lakhs 85 000 rupees per annum while
they can earn around 103 000 dollars a
year in the USA
we have capgemini shot a stock the
American provider of stock photography
Spotify Accenture genpact and Facebook
hiring data engineers
the next exciting job role is of a data
scientist
a data scientist is a professional who
uses statistical methods data analysis
techniques machine learning and related
Concepts in order to understand and
analyze data to draw business
conclusions they make sense to messy and
unstructured data and bring value out of
it they employ techniques and theories
drawn from many fields within the
context of mathematics statistics
computer science and information science
a data scientist understands the
challenges in business and comes up with
the best Solutions using modern tools
and techniques to analyze visualize and
build prediction models to make business
decisions
let us now look at their
responsibilities in the industries
data scientists clean process and
manipulate data using several data
analytics tools they perform ad hoc data
mining collect large sets of structure
and unstructured data from disparate
sources
they design and evaluate Advanced
statistical models to work on Big Data
they also create automated anomaly
detection systems and keep constant
track of their performance
data scientists interpret the analysis
of big data to discover Solutions and
opportunities
a data scientist takes input from data
analysts and Engineers to formulate the
results
they use visualization packages and
tools to create reports and dashboards
for Relevant stakeholders they also
adopt new business models and approaches
apart from this they regularly built
predictive models and machine learning
algorithms
now moving on to the skills of a data
scientist
a bachelor's degree in computer science
or information technology will be fine
but a master's degree in the field of
data science will hold a major advantage
you also need to have a good experience
in the analytics domain
you should be proficient in programming
languages such as python Java and C plus
knowledge of Perl will also be an
advantage
familiarity with Apache Hive big and
Apache spark is necessary along with the
knowledge of Hadoop
in addition to knowing programming
languages you also need to know SQL
machine learning and deep learning
data visualization and bi skills are
necessary for creating reports and
dashboards you should also be able to
communicate and present information and
ideas properly
now talking about their salary a data
scientist in India can expect an annual
salary of 10 lakhs 47 000 rupees per
year
meanwhile in the US they can earn up to
113 000 per annum that's a lot of money
from the many companies hiring for data
scientists here we have a few companies
named they are yet again Amazon Citibank
Apple Google the Japanese electronic
Commerce and online retailing company
Rakuten and Facebook
and finally we have machine learning
engineer machine learning Engineers are
professionals who develop intelligent
machines that can learn from vast
amounts of data and apply knowledge
without human intervention
they use different algorithms and
statistical modeling to make sense of
data they design and develop machine
learning and deep learning algorithms
their main goal is to create
self-running software
let's have a look at the
responsibilities of a machine learning
engineer
machine learning Engineers research
design and develop machine Learning
Systems they use exceptional
mathematical skills in order to perform
faster computations and work with
algorithms to create sophisticated
models
they perform a b testing and use data
modeling to fine-tune the results
they use data modeling and evaluation
strategy to find hidden patterns and
predict unseen instances
machine learning Engineers work closely
with data Engineers to build data
pipelines and interact with stakeholders
to get a Clarity on the requirements
most importantly they analyze complex
data sets to verify data quality but for
model tests and experiments choose to
implement the right machine learning
algorithm and select the right training
data sets
moving on to their skills
a machine learning engineer should have
a degree in computer science and
information technology they should have
an advanced degree in computer science
or maths
in addition to this they should also
have experience in the same domain
they should be proficient in programming
languages such as python RC plus and
Java
knowledge of Statistics probability and
linear algebra is necessary as all the
machine learning algorithms have been
derived from mathematics also having an
idea of signal processing would be
beneficial
machine learning Engineers need to have
a good understanding of data
manipulation and machine learning
libraries such as numpy Panda
scikit-learn Etc
they should have good oral and written
communication skills
let us now have a look at their salary
structure a machine learning engineer
earns 8 lakh rupees per annum in India
while in the US they can earn around 114
000 a year now that's a whopping amount
isn't it
let's have a look at the company's
hiring machine learning engineers
so as you see we have Amazon Microsoft
Oracle Salesforce Rapido and Accenture
to name a few
that was all about the job role of a
machine learning engineer a study from
new Vantage Partners suggests 97.2
percent of companies are now investing
in data and its analysis nowadays every
company needs a data expert do you also
want to become a part of this Market if
yes how to become a part of it what are
the essential skills one should have
this video will answer all these
questions but before watching this video
please subscribe to Simply learns
YouTube channel and press the Bell icon
to never miss any updates first of all
we are going to discuss who is a data
analyst working of a data analyst skills
required to become a data analyst two is
required and companies hiring and
finally we are going to discuss about
salary of a data analyst let me tell you
how simply learn can help you in your
journey to become a data analyst check
out the codes on data analytics in
collaboration with IBM with real time
project and business case studies you
will learn tools like SCI pipe pandas
and programming languages like python or
R2 enroll Now link is in the description
box below question for you which one of
the following is not a python library
for visualization
pandas Jupiter notebook please leave the
answer in the comment section below
moving on who is a data analyst a data
analyst collects analyzes and interprets
data a data analyst will convert raw
data into useful information data
analysts are in high demand because
every industry uses data analysis work
of a data analyst as a data analyst you
will work closely with the raw data and
generate valuable insights to help
companies decide their future goal if
you like thinking out of the box you are
the perfect fit for this domain data
analysts help maximize output when it
comes to generating Revenue working
closely with both business and data
nevertheless this field boasts handsome
salaries for all levels of expertise can
become a data analyst without prior
experience
yes anyone can become a data analyst if
they enjoy solving real world problems
have a strong background in statistics
and have a creative mind if you feel you
don't have it you can definitely develop
it so let us know the skills in detail
what are the basic skill sets required
for a data analyst data analyst must
know
basic mathematics and statistics
programming skills machine learning and
also data visualizations tools so let us
know what are the basics that you need
to learn as a data analyst
mathematics it is always better to know
basic mathematics like linear algebra
and probability fundamentals linear
algebra is used in data preprocessing
and transformation which is the critical
process of every data analyst
statistics a branch of mathematics that
deals with collection analysis
presentation and implementation
probability we know that probability is
the study of How likely something will
happen which is essential for concluding
both probability and statistics are the
backbones of data analysis it is
feasible to become a data analyst with
only a basic understanding of these
three areas of mathematics but in order
to remain relevant and grow as a data
analyst once mathematical knowledge
should not be restricted compulsorily
use some of the tools as a data
analystic what are that
first is Microsoft Excel it is the most
well-known spreadsheet software in the
world it also has computation and
graphic features that are excellent for
data analysts no matter your area of
expertise or additional software you
might want Excel is a standard in the
industry it's useful built-in features
include form design tools and pivot
table it also generate a wide range of
additional features that help simplify
data manipulation
as a programming language every data
analyst should know python it is easy to
learn and has a simple syntax python is
quite adaptable and includes a vast
variety of resource libraries that are
appropriate for a wide range of diverse
data analytics activities these
libraries help in numerical and data
computation the pandas and numpy
libraries for instance are excellent for
supporting standard data processing and
stabilizing highly computational
operations you can also choose between
Python or RR is a well-known open source
programming language much like python
data visualization tool as we previously
mentioned data visualization tool is
also necessary to become a data analyst
power bi is a user-friendly interface
makes building interactive visual
reports and dashboard simple its most
vital selling point is its superb data
integration it works flawlessly with
Cloud sources like Google and Facebook
analytics as well as text files SQL
servers and Excel
Pablo is one of the best commercial data
analysis tool available it handles huge
amounts of data better than many other
bi tools and as is effortless it has a
visual drag and drop interface however
because it has no scripting layer there
is a limit to what Tableau can do for
example it could be better for
pre-processing data or building more
complex calculations
you might have heard about MySQL a lot
of time it is a standard language for
interacting with databases and it is
very helpful when working with
structured data SQL creates
user-friendly dashboards that may
present in various data ways and since
it is so simple to send complex commands
to databases and change data in seconds
it has commands like add edit delete
data in addition SQL is an excellent
tool for creating data warehouses
because of its Simplicity Clarity and
interactivity
overall I would suggest that to become a
data analyst you should work on
programming languages like python or R
plus MySQL to work on databases adding
to that Excel plus visualization tools
like Tableau or power bi you now know
what are the skills are and how it is
used what are you up to in an
organization as a data analyst
to create and evaluate the report using
automated tools like Tableau or power bi
to troubleshoot the reporting database
environment and reports data analyst you
will use statistical method to analyze
data sets and spot any valuable trends
that may develop over time
evaluate companies functional and
non-functional requirements data analyst
assist data warehousing in inspecting
and Reporting needs these are all the
responsibility of a data analyst in an
organization coming to companies hiring
a data analyst IBM Accenture Capital
mini TCS Facebook Amazon Flipkart meta
these are the top companies hiring a
data analyst but data suggests that
every small and medium-sized company
needs a data analyst therefore demand of
a data analyst is in every company so
there is no network job and salary of a
data analyst this is the final part the
salary of a data analyst is high all
over the world when it comes to the USA
the average salary for a data analyst as
a beginner is going as high as 70 000
plus dollars per annum for experienced
professional it is going as high as 120
000 per annum in India for a fresher it
is going as high as 8 lakh per annum and
for experienced professionals it is 20
lakh plus per annum welcome to this
tutorial on Microsoft Excel so we will
learn about functions and formulas we
will learn about conditional formatting
data validation pivot chart and pivot
table
now let's look at the scenario here so
one day in a startup
One Professional speaks that their
business is growing and they would need
an efficient way to work with the data
they would have to find a way to work
faster with storing and analyzing data
now to that another colleague response
well we can make use of Microsoft Excel
to do this job
the question is will excel be able to
cater to their business needs
now
the colleague response well we can make
use of excel in several ways and it also
is a cost efficient option
now in that case the colleague who posed
the question says let's go ahead with
Excel and let's train our employees in
Excel
and the suggestion is welcomed which
would make the job easier for them and
they would basically decide on using
Excel so they decide on taking a
training right away and basically
starting to learn Excel
now
before we move to excel one of the
question is why should we use Excel
so let's look at some of the points here
so Excel proves to be a great platform
to perform various mathematical
calculation on large data sets which is
one of the biggest requirements of
various organizations these days various
features in Excel like searching sorting
filtering makes it easier for you to
play with the data and Excel also allows
you to beautify your data and present it
in the form of charts tables and data
bars
now when it comes to reporting reporting
accounting and Analysis can be performed
with the help of excel it can help you
with your task lists your calendars and
goal planning worksheets
Excel also provides good security for
your data Excel files have the feature
of password protection this way your
information can be safe
now when we talk about what is Excel and
how it can be used so Excel or you might
have heard a spreadsheet can be
basically used for a lot of different
tasks than just storing the information
in so-called tabular format
now Microsoft Excel is an application
that is used for recording analyzing and
visualizing data it is in the form of a
spreadsheet
let's have a look at few of the
functions and formulas used in Excel and
before we do that we can also quickly
take a small tour to understand how to
work with Excel now to do that what we
can do is we can type in in our search
say for example Excel and just select
your Excel app which is installed and
here you see you have lot of options
which says take a tour drop down list
get started with formulas make your
pivot table going forward with pie
charts and much more so we can click on
this one which says take a tour
and that basically pops up a window
which says welcome to Excel and if you
have always wanted to be better at Excel
you have this which can help you so
let's click on Create and that takes us
to the store window now that says
instructions for screen readers which
basically talks about 10 different steps
in which we can learn Excel and using
the spreadsheet app so there are more
than 11 sheets which we see here at the
bottom end and each one gives us a
simple example which we can work on so
for example if I click on ADD now that
takes me to this page which says how do
we add numbers now you might be provided
data which we can upload by loading a
file from our machine or getting data
from a web Source or even connecting to
a database so there are various options
which we will see in some time so here
we have an option which is called Data
you can click on this one and this
basically has
options where you can use existing
connections if you have created some you
can always click on from other sources
and you can get your data from SQL
Server from analysis services from odata
data feed you can get in from XML from
data connection Wizard or also from
Microsoft query you can be running in
different queries here which shows up in
the option which says new query there
are connections which you can use and
that basically will display all the
connections for this particular workbook
which we do not have as of now but we
can create them but let's look at simple
examples now you can follow these
instructions here which says basically
adding up the numbers and that could be
easily done by just placing your cursor
here and what you could do is either you
can type in the formula that is from
which row to which row you would want to
add the data so for example I could just
do a sum here and that shows up all the
different functions which are available
then we can open up a parenthesis and we
can say I would be interested in
totaling the amount
from
column D and I would select for example
D4 so I could be doing this and then I
could say D4
onwards till d 7 so that's the data
which I'm interested in you can close
your parenthesis and hit enter and that
gives you the total
there is also a shortcut for this which
you can always do is we can first delete
this and you can just place your cursor
here and just use your alt and equals
that automatically selects the
numericals which we can anytime expand
or basically collapse so I will
basically select this which says this
function needs two numbers which is
number one and number two and then you
can hit on enter and that gives you the
total
so similarly we can be getting in the
data here by selecting all the fields so
here it also says that you can use a
shortcut now what we can also do is we
can add numbers over 50 by selecting the
yellow cell here and then giving a
condition
such as so I can basically use something
like sum if and then open a parenthesis
I can select I would be interested in
this row and then I can even drag and
drop
till here so that tells me the 11 to the
15 you can then put in a comma here and
you can give your condition say for
example we would say I would be
interested in numbers only above 50 and
we can select this
close your codes and then just close
your parenthesis and that's your formula
so you can do this and that basically
gives me the total is hundred now
similarly we could do that for the
amount here I could select this now
there is also an option I can click on
home and I can go for something like
Auto sum so that's one more way of doing
it which anyway says sum is alt plus
equals so it automatically adds up your
values and I can try doing a auto sum
that automatically selects my rows and
then I can get my total now as for this
activity here it says try adding another
sum F Formula here but add amounts that
are less than 100 and the result should
be 160. so what we can do is we can
basically select all the numbers which
are lesser than 100 so the way we did
earlier here there can be always a
shortcut so you can always for example
if you would want to avoid typing in the
formula you can always copy it from here
and then just hit on enter so you are
back into this cell and then I can
basically go here and paste the number
and then as per the requirement we are
required to select anything which is
lesser than 100 so what I could do is I
could select here I could say let's say
G and then I can change this value to
g15 and that's one more way now we see
our selected rows have been changed so I
can hit on enter and I can check what is
the result so we would be interested in
looking for numbers which are lesser
than 100 so I will have to also change
this one to a lesser sign and that
basically gives me the total which is
160. so that's how you can simply add
numbers you can use autosum you can type
in the formula you can select the fields
or you can just place your cursor where
you would be looking for a sum and then
you can just do a alt equals and that
basically populates the sum
now let's look at some easy options of
filling your cells or automatically
populating the values in your cells
within your Excel sheet now here we have
an option which says 100 now we can
click on this and that basically says it
is making a sum of column C4 to D4 so if
I click on this one I can check that
this is row number four which shows up
here and I also know this is column C I
also have D so this equals is basically
giving me a sum of C4 to D4 now what we
can do is we can always place our cursor
here at the right corner and then we can
just drag and drop and this basically
gives me a total of all the numbers for
all different rows so this is one
shortcut which we can do to get the
total Excel will automatically give the
totals which we call as filling down now
what we can do is in the same way if we
would want to get the totals here we can
first check what is this 200 and this
tells me this C11 to c14 total so it is
totaling the rows from C11 so column C
and 11th row till 14th row and that's
the sum now what I can also do is I can
similarly like above we can do a filling
right which basically means bringing
your cursor here and then just dragging
and dropping it all the way where you
would need the totals and this basically
gives me the total there is one more
quick way to check if this is right so
the easiest option would be to select
this cell now what I can also do is I
can just select all of these fields by
just highlighting and selecting all the
fields once it is selected press on Ctrl
R and that gives you the total now if we
would be doing this stop down then I
could select all these rows for this
particular column and then I could do a
control D so that's your filling down
and this one was filling right so this
is an easier option of doing a fill when
you would want to have the formula
applied to every row as it occurs in the
first row or the last row we could test
this by for example selecting these
fields I could delete them and I have
here which says 130 I could just place
my cursor here and I could drag it all
the way up and that should also do the
same magic which we were seeing from top
down so this is a simple way wherein you
can fill up your cells and you can also
automatically really
propagate or move your computation to
all the cells
let's look at the split option which
basically helps us in splitting the data
when we have some kind of pattern or
when we have some kind of delimiters in
our data in say one particular column
and we would want to derive the values
out of it so we can always use the
splitting option now the easiest option
would be so for example we have our
email column which has the email IDs and
which we can clearly see has a first
name dot last name now I see that there
is a last name Smith filled up here
first name is empty so what I can also
do is I can just type in say Nancy here
now that's the first name I can again
start typing the second name and as soon
as you do that you would see a faded
list of numbers and that's your clue to
hit enter and once you do that you would
see all the first names have been filled
in here if you would want to maintain
the case sensitiveness you can just go
ahead and delete these and let's type in
as it occurs so let's say Nancy as the
first name go down to the next cell and
just type in Andy and there is your
grade list so just hit on enter and that
basically fills up your first name what
we can also do is
we can just select this particular field
and either we can type in control e
which basically fills up all the options
now I can just do a undo by typing in or
clicking Ctrl Z and that's basically
gone what I can also do is I can select
a particular field and then I can go
into home option and under home you have
an option here which says fill so you
can select this and then you can do a
Flash Fill which is what we are doing
here so click on Flash Fill and that
automatically fills up the values so in
this way you can work within your
spreadsheet and you can be filling up
the values where a delimiter by default
is understood and we can split the data
now however sometimes you might have
some data which has a different kind of
delimiter and there is again a smarter
way of splitting your data so you can
always scroll down here and that says
splitting a column based on delimiters
so we have some values in the data
column and these values in each row are
separated by comma so
select this your data is already
selected text to columns delimited comma
selected and now click on next so it
basically says what is the destination
let's select this one
and I can choose what would you want to
have so that shows me this would be my
data preview now I can basically select
this one I can say finished and say okay
and now if you see our data has been
placed in in the columns appropriately
so this is how you can split your data
based on a delimiter and then organize
your data in a better way now there are
some Advanced options which we can learn
later but this basically tells about
using a formula so this is something if
say if we have some name in one cell and
if you would want to split it into first
name your helper column your middle name
last name so that can also be done using
formulas and this basically tells how
would you extract characters from your
left cell and how would you place them
in your right cell so you can try this
activity which is a little more of
advanced option the benefit is that you
can always use this
wherein if you do some kind of
transformation using your formulas if
your original data gets updated then the
split data will also get updated and
that's the benefit of using formulas
where you can place values from one cell
into multiple cells based on execution
of your details in the formulas
how about using the transpose option now
you might have heard of situations where
you would want to
switch or turn your rows into columns
and your columns into rows and that's
where transposing comes into picture it
might be useful when you have your data
in your X and Y axis or as I would say
in rows and columns and you would want
to switch your rows to become the
columns and columns to become your rows
so what we can do is the simplest way is
you can select all your
values so here we basically have six
columns and I would say two rows now I
can select all of these and then I can
select an empty field for example the
one which is highlighted here well you
can always do a control alt V that's a
shortcut what you can also do is once
you have selected all your Fields you
can just copy them so just do a Ctrl C
and then click on an empty cell and then
what you can do is you can do a special
paste or paste special so under your
home you have the paste option and here
you can go for paste special and once
you do that you need to select the
transpose option over here and click on
OK and now you will see that the columns
and the rows have been transposed so
your row name was item and that has
become the column heading you had row
name as a mount and that has become the
column heading and all your values have
been transposed in this particular
format now there is another way of doing
that and again that's using your
formulas so what you can do is you can
transpose with a formula also and that
basically works when you have similar
kind of data so this has six columns and
basically two rows so you can basically
do this so you can select this and
earlier we were doing a copy but now
what we would want to do is we would
want to just look at the row numbers
which tells me it is c33 c34 and it
starts with c and ends in with your H
column so what we can do is we know that
we have six columns and two rows so
transposing that would actually give me
two columns and six rows so what we can
do is we can select two columns and six
rows in our Excel sheet I can then
basically start typing in the message or
I can just go to the address bar and
here I can say
transpose
let's go for c33 h34 it basically
selects my data and now I can just do a
control shift and enter and now if you
see all the values have been populated
now you can just place your cursor in
one of the cells but if you see the
address bar the formula Remains the Same
this is because this is an array formula
so we can read more about an array
formula here it's basically something
which performs calculations and on more
than one cell in an array and in the
example here the array is the original
data that is c33 to h34 so your
transpose is just changing the
horizontal orientation to the vertical
orientation so this is a very simple way
in which you can basically use the
excel's capability to transpose your
data and convert your rows into columns
and columns into rows apart from working
on
additions subtractions filling up your
data sorting the data or basically
splitting your data transposing your
data one of the other requirements is
sorting and filtering your data so that
can be very handy when you're working on
huge data and you would want to sort it
in a particular order say ascending or
descending or might be based on a
particular field or if that field was or
if the cell was highlighted with a
particular color sorting the data so
let's look at how Excel can be used for
sorting and filtering examples are
pretty simple here so let's check that
so if we're going to sort and filter and
say this is the data I have say for
example I would want to sort the values
in the department column alphabetically
so what I can do is I can select
Department column and I'm already in the
Home tab I can straight away go here
which says sort and filter I can then
say sort A to Z and that's basically
alphabetically sorting your department
column and once once I do this you would
see the data has been sorted but it's
not just this data we can just do a
control Z and check what are the values
we have so here we have meet which is
beef and ninety thousand hundred ten
thousand the values then you have Bakery
which should ideally be the first row if
we sort it in an alphabetical order
which goes with Bakery as desserts you
have the values so we can check this
again so select department and then just
do a sort and filter and let's say sort
A to Z and if you see the data has
changed but it's not just in changing
your First Column but then it has taken
care of all the data however the data
has been sorted based on the department
column so you have Bakery which aligns
with deserts which has the values and
now now we have all the data which has
been filtered now what we can also do is
we can sort December's amounts from
largest to smallest so what we can do is
we can basically click any cell in the
December column let's say 20 000 and
then what I can do is I can go into sort
filter and then I can say sort largest
to smallest so if you see Bakery breads
is the row which has the smallest data
or maybe you have Delhi sandwiches so
that one looks also smaller so let's do
a larger to smallest and if I do this
you would see the values have been
shifted now so it is no more based on
the department column
because now the data is being sorted
based on the values in the December
column and you see Bakery which was
alphabetically the first one has become
second last
so either you can sort the data based on
a department column which goes based on
the values these are all string values
or words so it sorts alphabetically if
you have numbers might be you can give
some values and you can sort the data
you could anytime do a custom sort and
you could basically select if you would
want to select the data so I could do a
custom sort and then I could choose
which is the column which we would want
to use for sorting what is the Sorting
needs to be done is it cell values is it
cell color font color conditional
formatting and then you can also choose
the order so that's one more way to do
that now if you scroll down that also
shows how you can sort by date or a
color so for example if you would want
to sort based on the expense date so
there are different options so what I
can do is I can select this date field I
can just do a right click I can go into
sort and then I can choose I would want
to sort oldest to newest so since I
selected the date field it basically has
sorted all the data Theta and it has
taken the expense State into
consideration now there are these
filters which you see on the row
headings we could have also used those
so I could have selected this and that
basically says or mentions which are the
dates I would be interested in looking
at I also have sort by color here I can
do a sort oldest or newest or newest to
oldest so I could also use these filters
which have been applied here now we have
the data which is in color so if I would
want to basically select the color
columns or color cells I could select
this I can basically do a right click
here and when I go into sort I could
choose put selected color or cell color
on the top and that basically will make
sure that my data is sorted and it has
also sorted that in a descending order
so in this way you can sort or basically
filter your data what we can also do is
we can add filters so sometimes we can
go for formulas which we would want to
use what we can also do is we can
basically select the filter which has
been applied here now how does the
filter come in there so if I would
select a particular row I could select a
particular row and then I could decide
if I would want to just add a filter to
this one and that's how the filter has
come in so we have the filter what we
can do is we can basically click on this
drop down and then you have something
like number filters so we can always go
here we can basically choose one of
these so we can basically choose above
average so I could select this and then
basically it shows me the values we
could also delete the filter by clicking
on this one and we could say well I'm
not interested in this filter anymore so
I could clear the filter and that shows
me all the values or I could say
that let's click on some other field for
example food I can go in here I can go
into number filters and then I could say
well I'm interested in values which are
below average above average might be
greater than and then I can choose what
is the value so for example if we say I
am interested in food which is greater
than 25 dollars I could give a value
here I could say okay and now I have
applied the filter similarly you can
select this and then you can just clear
your filter and your data is back so
remember no data is lost it is just
hidden or basically based on the filter
not shown so that's good enough for us
and in this way you can sort and filter
the data so for more details obviously
in all the sheets you have the links
which point to more information on the
web and you can always refer to these so
this is simple way in which you can sort
and filter any amount of data which has
been stored within your Excel within a
particular sheet now that we have
learned about add fill split transpose
sorting and filtering it will also be
good to learn how to work with tables or
basically converting your data into a
tabular format and then doing some easy
computations so click on this tables
option here now here we see there is
some data which is in five columns and N
number of rows so I can basically select
this data and then what I can do is I
can insert choose the table option and
then it says my table as headers and
we'll be okay with that I'll say okay
and now if you see this is the table
created it basically has different
filters which we have learned earlier
how to use and this is basically my
table which is a collection of cells
which has some special features so we
can easily add rows to this table we can
add columns to this table and we can
even do some calculations so for example
here I can click on this one I can
basically enter some field and then I
can hit on enter and we see that this
row has been inserted wherein we can
easily fill in values for example I
would say chocolates
I could give some value here size 25
000 might be 35
000 and then basically I can given some
values here now what you can also do is
you can continue adding rows in this way
and say for example you would want more
columns so you can select this
option here in the top bottom right
corner you can just drag it towards the
right and that basically has
automatically created columns for my
next months wherein I can feed in the
data so this is a simpler way wherein
you can keep adding more rows and
columns to your data if that has been
converted in a tabular format now let me
just do a control Z that basically
deletes the columns again Ctrl Z deletes
the last row which we added and I can
stop here or I can even remove my values
by doing multiple control Z and removing
my rows so this is how I converted my
data into a table and then I can easily
work on this what I can also do is I can
do some calculations so what we can do
we have a table here we have a total
field and what we can do is we can just
select one cell here now as we have
learned earlier we can do a alt and then
equals and that basically says what is
this doing so it says it is calculating
the sum of the last three months and if
that's what you would want to do just
hit on enter and it has automatically
calculated the totals for all your rows
for these three columns so the sum
formula is getting filled up now I can
select any particular cell and I can
look in my address bar so it has already
given me the formula where it has
started calculating the sum from the
October column till the December column
and has given me the calculated values
of the columns what we can also do is we
can get total rows in the table now
that's a simpler option so what we can
do is we can select any l in this
particular table
and then we see that there is a table
tools design option showing up here now
I can select this and then it says well
let's get a total row so let's select
this and it automatically populates the
total here and if you would want the
average then we could select this and
from the drop down I can select what I'm
interested in so for example I would
want the average values and not the
total I could just select this and that
gives me the average of these values so
we can always do simpler computations
here by converting our data into table
format let's learn about one more
efficient way
of working with the data and that's
using your drop downs so let's see how
drop downs work here now say for example
you have this data which has the values
in the food column and department is
empty and say for example you would want
to enter the values in Department
however you would want to select the
department should either have produce or
meet and bakery and these are the only
three options which should be available
for any user to fill in the values how
do we do that so we can basically create
a table by pressing Ctrl D so what I can
do is under my department
here I can select one of the cells and
then I can do a control T that basically
converts this into a table I can say
okay and my table is created now what I
can do is once this part is done
we can select all the blank Fields here
where we would want this drop down to be
applicable now under your data tab you
can go in and select data validation and
this has an option called Data
validation click on this which basically
says allow any value so here I will
select I would want to give a list of
values and then I can type in my values
here which I can say produce
say for example meet and then say Bakery
now these are the values so we can click
on okay
and once we have done that we basically
have a drop down here next to Apples
which will only show us the values which
we can feed in under the department
column so I can go into every cell and
then I can basically choose what is the
department which handles this and then
basically I can select one of these from
the drop down so this is an easier
option of creating your drop down and
then feeding in the values from the set
of values which you have defined here on
the right so this is a simple example of
using your drop downs working with your
tables working with your sort and filter
transpose split filling up your data
adding in some data here and similarly
you can use Excel for more than one use
case using its inbuilt features to
easily work with your data let's see how
we can import data or bring in data into
our Excel from your local machine or
from an external web source so what we
can do is we can open up a blank Excel
sheet and say for example you have been
provided a text file or a CSV file and
you would want to import that data into
your Excel sheet that can be easily done
so right now I've opened an
Excel sheet now I can click on data and
here I have an option which says
existing connections from other data
sources so or you can click on
connections if you have already created
some so we can click on from other
sources so this is one option where you
can connect to your different data
sources and you can get the data from
one of these what we can also do is I
can click on connections now it says
there is none I can click on ADD it says
well show the connections where
connection files or Network
connection files on this computer so I
can say let's get some files from this
computer now if that does not show up
something so say browse for more and
that basically shows you different
options so let's basically select a
folder where I have some data sets I'll
click in here and this is basically a
folder where I have some data sets now
let me select this particular file and I
know it is a CSV file so let's click on
open now if you would want to verify
this you could have gone and looked into
the properties of the file and it says
it is a DOT CSV file which is what we
are interested in so I'll take this file
I'll say open now this basically shows
me the text import wizard option which
says is the file delimited I'll say yes
click on next so I will select comma as
my delimiter I can say text qualifier is
none now this is my data so my data
preview is already showing me the data
is what is the data in the CSV file you
can click on next and then you have an
option which says data format is General
you can go for date format you can go
for advanced options so I'll just say
finish
and basically now this has been created
here so we basically have this and now I
can click on
close now once you have done that you
can click on existing connections it
shows me the data which we have here the
connection which we have created say
open and then it says do you want to
import this data or bring this data into
existing worksheet
you can also say add this to a data
model if you are doing some data
modeling so click on OK and now this
data is automatically inserted in my
Excel file I can basically save it
into
this particular sheet now what we can
also do is we can also start a new sheet
and that does not have a data and we can
get some other data from web so what I
can do is I can go into my GitHub and
let's say I would be interested in this
CSV file so I can select this and this
is my GitHub path a path on web so I can
click on draw and that basically gives
me the raw path where this particular
file is now you can select this copy
this particular path and here you can
come back to your Excel sheet we would
be interested in getting the data from
web might be from a text file where we
will have to specify the delimiters or
let's go to web and here I can given the
web path from where I would be
interested in getting the file let's
give the GitHub path which is publicly
available and then click on import now
once you click on import it tells me
that two Fields data and value
these are
within double quotes separated by comma
so first let's click on import
now once we do this it will basically
get the data from web and put in here it
says existing worksheet so we had
already created a new worksheet so let's
click on OK and now you have the data
coming in but then this basically shows
me in one particular field so what we
can also do is we can just do a control
a that selects all my columns here and
that's my data so we can then basically
filter this out so we can say text to
columns it's a delimited file click on
next we can select comma and let the
text qualifier be codes
it shows me data preview click on next
so you have the general format it shows
the destination that's the column click
on finish and now your data has been
split and you have the data which you
have imported from web so this is the
data which is coming in from web this is
the data which came in from my local
machine and similarly we can even create
connection with an existing database so
I can basically click on connections if
I would want to do that so I have an
option called connection here and it
says where the selected connections are
used I can basically click on ADD I can
basically choose if I would want to get
the files from Network or from computer
like we did earlier I can click on
browse for more which should show me
different other options to create
connections say you would want to create
a new SQL Server Connection you can
connect to a new data source coming in
from different place you could basically
choose what kind of connection would you
want so these are all the different
options which we can go for and we can
basically connect to a database for
example if I have some database and say
for example access database
I can see if there are some files with
that particular database and I can
import it so similarly we can also uh
click in here which says new query and
that also gives you an option of getting
the data from your files from all these
folders from databases so you can
basically click here and then you can
import data from a mySQL database
provided that is set up on your local
machine or on a particular server you
can go from cloud you can get it from
online services you can get it from
other sources which says from web from
your Hadoop file system from active
directory from a blank query and you can
even combine queries wherein you can run
a power query editor you can get the
data from different sources and then you
can bring it into your Excel so in this
way you can get your data from different
sources into your Excel into your
spreadsheet and then you can continue
working on those data sets
we have uh already learned some basic
operations which you can do in Excel and
let's Implement our knowledge by working
on this particular data which is coming
in from housing data set now here if we
see some fields we have agent date
listed area list price and this is
basically the data which has been sorted
in newest to oldest order of date listed
so how do we
arrive at this so what I can do is I can
just click on data listed and then I can
either go in here I can select sort I
can get into custom sort and then I can
choose the column based on which I would
want to sort the data so I would look
for the newest data to the oldest data
that means that would mean a descending
order of dates or you could say the
oldest state or the earliest month will
be towards the lower side of your sheet
so here we can select date listed now I
can say let it sort based on Cell values
and the order what we have here so we
have newest to oldest so let's select
this I can say OK and now if you see the
date has been sorted so we have your
10 18 2007 on the top so that seems to
be the latest date and as we go down we
will see an earlier month hour and
earlier month than that in the state
listed so we have sorted our data into
newest to oldest order and that's based
on your date column so the result shows
up here now what we can also do is we
can have different questions which we
would want to answer so for example I
would want to sort the data in ascending
order of area and descending order of
agent name how do we do that so let's
look into this so this is here I already
have the result here and how did I get
this so I'm looking for ascending order
of area and descending order of agent
name so we can start with any particular
column that does not matter so for
example if I look into this Excel sheet
I have my agent name select this which
we want in a descending order so we
could either do a sort and then go for
descending sort Z to A we could also use
the filter option here on the top right
and we could do it or I could just say
sort Z to A and then it has arranged the
data based on the agent column being in
descending order now I can go into area
and then I can again do a sort and I
wanted my area column to be used for
sorting the data and ascending to
descending and that basically not only
changes the order of this particular
column but for my complete data so let's
do that and now if you see we have the
data which has been sorted so we can see
how many values we have here and the
area values which we see and this is how
you get your result so I'll just do a
control Z and again and I'm back to my
original data and this is the sorted
result which we are seeing at similarly
we can answer other questions for
example sort the data according to the
following order of area that is we are
saying counties
Central and then your county so we can
basically choose in which particular way
we would want to do it so it is County
Central and then again County so if I
look into my sheet 3 so here I basically
have my data which is having some South
County then you have your Central and
then you have your North County so we
would want to sort the data to solar
problem which is according to the
following order so first we go for area
then we go for South County Central and
North County so what we can do is we can
basically have area field selected and I
would want to sort this particular data
so I have South County Central and North
County so I can basically go for custom
sort
and then I can choose which is the value
or column which I'm interested in let's
go for area
we will go for something like cell
values well you can also try to explore
conditional formatting icon if this is
what you would want to use or we can
basically go for just cell values and
here we can say if I would be interested
in first getting my values for South
County so for example I can say custom
list and then I can basically given the
new list here so I can say s
Dot County
and then I would want Central and then I
would want North County
so let's select this
as it exists we can basically say add
and that's basically the order which we
want to say okay and then say okay here
and now what we would want is we would
want our data so we can compare that
with the values which we see here it
starts with Kelly you have in the 12th
row something like Lang and that's what
we are doing so we can basically arrange
the data in a particular order by
choosing a custom list and then sorting
your data so that's one more simpler
task what we have done where we have
sorted the data in the order where
under our area column we first wanted
South County then we wanted Central data
and then we wanted North County so this
is how you can do it now let's look into
one more problem so it says find all the
houses in the central area and we would
want to basically apply a regular filter
let's let's see how do we do that so we
can click on this and here we have the
data so the problem statement is we
would want to find all the houses in
Central Area now how do we do that we
can do a sorting but we would want to
use the filter which you see here is
implemented so how do you do it so you
can select this area and say for example
I would want to apply filter I can just
go in here and I can say let's get a
filter on my first row and now I have
filters applied so we are interested in
looking into the Central Area houses
let's go in here it says all these
fields are selected that means it shows
everything wherein your area has all
these values let's unselect this and
then I will only be interested in the
central so let's say okay and then say
okay so now you see that the area filter
has been applied and we are looking at
the central column so what we have done
is we have applied a simple filter and
we are looking at our data at any point
of time if you do not want the filter
then what I can do is I can select this
and I can say well I'm interested in all
the data so I could do this or you can
clear the filters from area and you get
your data back so that's in one way you
can filter out your data so let's look
at an example of sort and filter where
we might have to filter the data based
on two columns or multiple columns with
different kind of values where it could
be and and or condition now say for
example this is the data I have and this
is the question which we need to answer
such as find the list of all houses in
the central region with pool and South
County without pool now if it was a
simple filter based on one cell I could
have just selected my header row I could
have then applied the filter
and once I have the filter I can look in
area where I have three regions so I'm
only interested in Central and South
County so I can get rid of North County
and that's fine but then we have two
different conditions here so we need the
data in central region to have the value
for pool being true
and for South County the value has to be
without pool now how do we do that so
what we can do is we can first create a
copy of these headers here so let me do
that now the area has to be South County
so basically I can either just select
this and I can choose this value
and then I can select this and then I
can choose Central so that's the
criteria which I have and the pool value
has to be so central region should be
with pool so then this one
basically has to be true
and this one has to be basically false
so south county is without pool so let's
select one of the values here and this
is my criteria now to get my result uh
we can always place your cursor here and
you can check this is M column and
eighth row okay so we would want the
result here so let's go ahead and now
click on data and then in filter you
have an option called Advanced and here
what I can do is I can say I would want
to filter the list in the place but
that's not what I would want to do so
I'll say copy to another location and
here if you see the list range will tell
me that this is the data so A1 to J 126
so a to J column selected and all the
rows criteria range is basically based
on what I have given here so that is m
from 1
to V which is 3
so I am selecting these columns and then
I am saying all the way whatever
criteria I have given and copy 2 I am
saying M8
2 V8 so that basically will give me my
filtered result so you could basically
just say okay and now I have my data
which has been filtered and I have my
area which is South County that is
without Pool Central with pool again
South County without pool and then if
you look at your central value that's
pool so this is an advanced filter which
we have applied where simply we have
filtered the data based on two columns
and then we have our result so in this
way you can have your customized filter
applied on two different columns and get
your data which can be either replacing
the existing content or in the same
sheet in different set of columns and
rows you can have your result let's look
at one more example of filtering where
you are trying to filter the data based
on a and condition
condition being met in two different
columns and then you would want to
filter out the data for only specific
columns so the situation is the agents
with a house in North County that should
be County area having two and a single
type family so we are talking about two
bedrooms and we would basically have a
single type family and here the criteria
is that if we would want to only
populate these columns which is Agent
area bedroom and type now what you can
do is as I explained earlier that you
can get your result in the same sheet in
a different location so here I have
created these headers which says agent
area bedrooms and type now this is
basically a copy of all the columns what
we have here agent data listed area list
price bedrooms bath square feet feet and
so on so you can basically create a copy
of the headers here and this is where we
will give our Advanced criteria to
filter the data so the conditions which
need to be met is we need to look at
North County so for example here in area
I can basically go ahead and select one
of the values North County now the
criteria is having two bedrooms only so
let's say bedrooms and let's say the
value should be 2
and then basically I am saying a single
type family so when you would want the
single type family so here under type I
can give the criteria single type so
this is my and condition so we are
saying North County area having two
bedrooms and the type is single family
now this is the criteria which basically
means if I select this this one tells me
that this is m one row onwards till V
2 so this is what we have and we would
want to filter based on this so let's go
ahead and then go for data filter
advanced and here in advanced it says
filter the list in place now that's not
what we would want to do so I'll say
copy to another location this basically
selects the list range so which is
telling me A1
to J 126 so that's the
columns and rows selected criteria range
is based on M1 V2 which we have given
here and copy to I would say for example
from M7
2
P 7 now this is the area where I would
this is the place where I want the
result let's say okay and now I get my
data which is based on the question
which has been asked that you would want
the agents with a house in North County
area having two bedrooms and single type
family so in this way you can basically
do Advanced filtering get your data and
get it stored in the sheet anywhere at a
different location well I could have
also done filtering in place and that
would have replaced the data
which we have but that's not what we
want we would want the filtered result
in a different place so this is how you
can do some Advanced filtering we can
also use Excel to filter out the data in
one particular column which might be
conditional or say using some numerical
filters now here say for example the
problem statement is that you would want
to display all the houses whose list
price is between
45
000 to 600 000 or say for example we
would want to filter out the data to
something else say for example let's say
I have I would want to filter out the
data between 300
000 and 400 000 so we can basically
update this
say for example I am saying I'm
interested in 300
thousand
two
to four hundred thousand and that's the
criteria to filter out the data now
there are two different ways or there
are two easier ways to do it one is I
would want to
look at the list price so I can select
this I can go ahead and do a filter here
and in the list price now this is where
we would want to do the filtering so
it's pretty easy you can click on this
one and then you can go into number
filters and you can choose between now
that's one easier way of doing it so I
could basically select this I could say
I'm looking for Value which is greater
than or equal to three hundred thousand
and then is less than or equal to 400
000 so if I just do this I have applied
my filter and I have my data which is
filtered based on my criteria right so
that's one easier way of doing it or let
me do a Ctrl Z
now let the filter be there which you
can anyways use but what we can also do
is as we have seen earlier methods so
get a
set or get your column headers here
and then you are giving two columns here
now the only difference between
my
this set of columns which I have one two
three four and then you have seven and
ten columns and if you see here we have
4 5 6 7 8 9 10 11 right so whenever you
want a and condition you will basically
add the columns where I can give add
condition if it is the same column if it
was a different column then it would be
same number of columns but and
conditions will lie in the same line and
or condition would lie in a different
line now here I can give this value so I
am looking for listed price being
between three hundred thousand so I am
saying it should be greater than or
equal to three hundred thousand and then
I can say less than or equal to 400
000 now that's my criteria and then I
need my result here which is in M 7 so
what I can do is once I have given my
criteria which I'll be using to filter I
can get into Data I can get into
advanced and then I can say copy to
another location so it is selecting my
A1 to J 126 criteria range is based on
M1 to
W2 and then I would want my result from
this particular column so let's say okay
and now you have your data filtered out
in a different location in the sheet
which has been filtered based on your
and condition so you can filter out the
data in this way or you could just apply
a filter on a column and give the
conditions
now let's solve one more interesting
problem and here we would want to use
Excel where we would have an and and an
or condition so say for example this is
the data given to you and the question
is that you would want to find all the
houses in North County again that's a
spelling mistake but then they are North
County area with a list price greater
than 300 000 and having three or four
bedrooms so the bedroom has conditional
so it has R 3 and 4 and then basically
you have list price which is greater
than three hundred thousand now I could
have obviously selected The Columns and
then basically gone for a filter so I
can just do a filtering here and then
I'm looking for list price being greater
than 300 000 so which we can always give
a number filter and I can say great
greater than and then I can say greater
than or equal so I can say greater than
and then I can give 3030 300 000 and
that's basically the filter which we
would want and here I would want to
select the bedrooms which should be just
either three or four so if for example
here I go in here and I unselect this
and then I say 3 and 4 right so I am
getting my data which is greater than
300 000 and it should have the bettering
values which will be either 3 or 4
selected now that's one way of doing it
let's do a control Z and get it back
2 as we were or you can even just say
clear filter so you get your data back
as it was so what we can do is we can
hear
give the criteria
so for example I have my list price now
this is what I would want as a condition
so let's say greater than
three hundred thousand
300 000 and bedrooms should be three
and then I can say greater than three
hundred thousand
and then I can say four so this one
basically gives me a situation where
your list price has to be greater than
three hundred thousand and bedroom
should be either three or four so we
have given our filtering criteria now to
get the result what we can do is we can
go into Data we can go into advanced and
we can say copy to another location so
our list range is selected which is
columns a to J row number 1 to 126 your
criteria range is given in M1 to V3
where we have specified and we are
saying the result would be in M 7 to V7
so if I do this now I have got the same
data which we were seeing earlier and
here the bedroom values are three or
four and basically the list price is
greater than three hundred thousand so
this is a simpler way in which you can
create your filters and all this
Advanced filtering what we are seeing it
will be saved with your sheet you can
always go back and change this value or
you could do filtering where one person
has to look into the filter to see what
values have been selected
now that we have looked into some
operations which we can perform in Excel
using filter or sorting the data
creating your tables let's also quickly
look at functions and formulas which can
be used for doing some easy calculations
or computations now Excel can be used in
different kind of data analysis so for
example you have different inbuilt
functions which can be used and we can
always check for a particular function
so for example if I had if I wanted to
look at a particular function I could
just type in here something for example
is and then it shows me all the possible
functions and you can always have a look
at the detail of the function for
example you have is even which will
return true if the number is even if we
would say is logical so I could search
for is logical and that tells me whether
a value is logical value true or false
and returns your value true and false
now we can obviously
say subtotal so you can search for any
of these useful functions and that tells
me what this function can be used for so
returns a subtotal in a list or a
database
you have many other such functions such
as integer sum average you may be
interested in working on truncating
some data getting the absolute value
getting the square root basically
getting a count or getting a max value
you can look for any particular
functions within your Excel sheet now
you also have other functions such as
now or time for example let's look at
Now function so I can search for
now and here it is so this is Returns
the current date and time formatted as a
date and time so this is the function
which we would want to use and if I just
give the function it tells me what is
the current time let's first look at the
description of time here so say for
example I would want time it says
converts hours minutes and seconds given
as numbers to an Excel serial number
formatted with a time format so for
example if I would say two hours and
then 30 minutes and 30 seconds and if I
do this it has basically converted this
into your time format so you can always
use different inbuilt functions for your
work now we will also look at some
Advanced functions like sumf or some ifs
you have countif and countifs
and you can be working on various
functionalities of excel to easily help
you in doing some calculations
computations working with your data
working with your different cell values
so let's look at some example of using
functions like sum or sum if so for that
let's go to this sheet and here we have
some data now I have already applied a
filter which can allow me to filter out
the data so it says find the total units
that were sold in the east region now we
know that in region we have east
and
I have multiple regions I could
basically be saying unselect all and
select only East
and say OK and that basically gives me
the units which were sold and if I
placed my cursor here and then if I did
a auto sum so it would basically give me
the function which is being used so
something like subtotal and it is
basically working on your rows which is
E2 to e44
and here we can just do this so that
gives me the total but this is this is
fine you could do that but
it would be good if we know how do we
use a function like sumif to do that so
here I am seeing this is the subtotal
where I am looking at the values and
basically what I have done is I have
filtered out the region and then
basically I am getting a count but this
does not give me clearly how a sum was
calculated from all the values which
were listed what we can also do is let's
do a control Z and let's get it back so
now we have our data and we would want
to get the total units that were sold in
the east region so what I can do is I
can start typing in my formula and for
that I'll use an inbuilt function so for
example I would be interested in going
for sumif now it says sum if adds the
cells specified by a given condition or
criteria when you talk about some ifs
this is when you could give set of
conditions or multiple criterias so
let's look at some if let's do this now
obviously this gives me an error because
the formula
is not right so we have to basically
come in here and let's start with sum if
now when I say sum if it shows me there
is a function with sum if which we would
want to use and here once I open up the
bracket it tells me okay what is the
range of data which you are interested
in so I am interested in all the units
that were sold in the east region so we
are interested in the region
which is here so I can basically be
selecting this and this tells me
you are interested in the data here so
let's not take the header value so let's
say B2 and then we can go all the way to
the end so we can basically select this
way
that's the data we have select this and
hit enter so now here it has selected B2
to B4 but we need to basically now give
the criteria so the criteria is either a
value or you can point it to a cell
which has that particular value so as
per our problem statement we are looking
for the units which are sold in east
region so I can select the value East
here and then my sumif needs the range
on which you want to
calculate a sum so
let's select this and now we are
interested in finding out the sum of
units so that's basically this column e
column so I can basically type in
instead of selecting so I can say e and
I'm interested in e 2 2 e 44 so that
basically selects the area or all the
values and now let's do this so that
basically gives me the sum is 691 right
now this is the criteria where I have
pointed it to a cell and whatever value
that cell has well I could have done
something like this so I could have
selected East giving the value and then
doing it it still does the same thing
and in this way you have more clarity
that you are using some if you are
filtering the data so you have given the
rows
you are given the criteria and then you
have given the range on which you would
want to sum up the values now similarly
if the question was what was the total
revenue generated from binder
now we would want to find out what is
the total revenue generated from binders
that means my filtering criteria will be
binder
and then I want to find out the total
revenue generated so we have the revenue
generated field also here and we have we
don't have any region to be filtered we
are just looking for binder so let's
again start doing the same thing so we
can go for some if we can open the
bracket now it needs the range so we are
interested in revenue generated now
that's the summation we want and we
would want to
get the range of data so here we can
basically select
uh d
2
D 44
so that's the data selected now I would
want to give the filtering criteria so
let's say binder and then we need to
give the range on which the sum needs to
be calculated so that's my Revenue
column so that's G so I can say G to
2G 44 and that basically selects the
column and then you get your sum so it
tells me what is the total revenue
generated from binder
now I could be doing this for other
things also so say for example if you
would want to filter out something else
you could basically just drag and drop
here and then I could come here and
change this to say instead of binder I
would be interested in say
pencil
if that's the criteria you are
interested in remember to change this so
that you take all the values
and here we will change
it to select the relevant rows and then
this is the data I'm getting so I know
that this is the revenue generated
from pencil this is the revenue
generated from binder now this is a
simple use case where we are using some
if what if we would want to use some IFS
so sum ifs let's have a look at how we
get to some ifs so sumif says where you
would want to work on
doing some calculation but then you
would want
multiple criterias to be met so let's
see how we get this so here what I can
do is let's work on this problem
statement which says what is the total
revenue generated from central region
where the item is a pencil so that's
something which I would want to check
now when we are answering this question
we can also look at the order in which
things have been asked in the question
so it says what is the total revenue
generated from central region so we need
the total revenue generated we know
there is a revenue column we are
interested in getting the total revenue
generated
we are saying the filtering criteria is
central region and we say in that we
would be interested only in the item if
it is pencil how do I do it so I can use
sumifs where you can pass in multiple
criteria so let's start with some IFS
and when I start with some ifs let's
open up the bracket so it says sum range
it says criteria range then it gives one
criteria and you can given any number of
criterias so for example we are
interested in total revenue generated
now that's my G column so let's follow
in the same order so let's say G2
so that's my first value and then I know
there are 44 rows here so I can say G 44
and you can obviously check if that has
selected all the rows now that's my
total revenue generated so I would want
the total revenue generated so I'm
saying setting this sum range
then I need to give the criteria range
so it says from central region so
central region comes into column two
that's B so let's say b 2 to B44 so
that's my criteria range then you have
to give your criteria but we need to
filter out the region being Central so
let's select this now either I could
point to a value in the cell or I can
just give the exact value here
we can also give a
wild card or matching pattern so that
also works now this one is fine we are
now also interested in finding the total
revenue generated when the region is
Central and the item is pencil how do we
do that so for
item we know the columns the column is
D2 so let's select D two to D 44 so that
basically selects all the rows in the D
column and we need to give the
filtering criteria so let's do a comma
and then just given our value so let's
say pencil and then let's close your
bracket and that basically gives you the
result
so we need to just follow the order of
our question which says
what is the total revenue generated so
we are looking at the revenue column we
are selecting all the rows
then it says from the central region so
we need to select the region column and
give the filtering criteria Central or
point to a cell which contains that
value and then it says we would be
interested only in item being pencil so
then you select the column which has all
the items and provide your filtering
criteria that is pencil so that's your
easy calculation of using some if which
we compare with sum if here so sum if
here was just having
your criteria so basically you are
selecting your rows giving your
filtering criteria and then your sum
range in some ifs we are giving multiple
condition now same thing can be done
here it says how many units were sold by
sales representative Johns or Jones
where the cost of each item was greater
than 4. so how many units were sold by
sales representative
so when we talk about how many units
that's your e column
so let's start with that so let's say
sumifs I would be interested in E column
then let's give the range so it says sum
range so those are the number of units
on which we would want to find the sum
then it says you need to give the
criteria range so we say sales
representative where the name is
Jones so sales representative is in
sales rep column C so let's say C2 to
c44
now
then we need to give our filtering
criteria so let's say Jones
is the sales representative where we are
interested about whom we are interested
in and then we the question says where
the cost of each item
so cost of each item is what we are
interested in you have unit cost
so that's what we are interested in so
that would be F and then say F2 to f44
and then you need to give your cost so
it says where each item is greater than
4 so let's select this
and let's
do this so this tells me 3 0 1. now
similarly let's answer our third
question which is how many units did
Jones sell excluding
pencil item so we would want to find out
what was the total number of units units
that were sold
and that units or that should not
include the pencil item how do we start
doing this so let's start with some IFS
now we know that you start with some ifs
you need to give the sum range so we are
interested in the number of units so
let's basically go in and select our
number of units which were sold so
that's your column e so I can say E2 to
e44 that's where I would want to perform
the sum now I'm saying
how many units that were sold where
we are talking about sales rep being
Jones so let's see let's select the
columns C and then give
the range
after that we need to give our giving
filtering criteria which is zones and
then we are interested in the items but
excluding pencil so items is in column D
so let's say d to d44 and then we have
to give
our criteria so we can say well that
should exclude pencil
so I can basically say
pencil
and let's close this
and let's check so that's my formula
which says that these are the number of
units which the sales representative
whose name is Jones had sold and that
does not include pencil as an item let's
also look at an example of using countif
or countifs now both of these can be
very useful when you would want to
calculate certain values so for example
if I would want to work on count if
let's try solving this problem now
remember you can answer these questions
using filters and that can be an easier
way but then sometimes you may want to
get the formulas so that you can make
your spreadsheet and your calculation
more
dynamic in nature and that will
basically depend on the values in the
columns or rows so for example if I have
find the total number of times Gill has
made a sale now if I look at my data
here it tells me that for every sales
representative there is some value in
the sale and it says sales has greater
than 3 so for example Jones you have
sales greater than three or you have
Jardine which is sales greater than 3
and so on so what we are interested in
is doing a quick count and finding out
the total number of times Gill has made
a sale how do we do that so we can use
this count if function and if I go into
countif it says counts the number of
cells within a range that meet the given
condition now what's our condition our
condition is Gill and we would want to
find out how many times the name say
Gill appears or kill has made a sale now
I could just say count if and then open
up a bracket I need to give a range so
let's say we are interested in looking
at the range so let's say we will choose
sales rep so I can say C and then I can
say C2 to c44 now that's my range
let's not give that in quotes
so you have to give a range so let's do
a count if that selects the data and
then we need to give the condition so
for example let's here give the name
which is Gill and then close this so
that basically tells me it is five times
kill appears here we can check this so I
can go in here I can add a filter and
then might be I would be interested in
looking at only Gill
and that basically gives me 5 right so
we can always do that and we can be
using formulas like this now what about
this question so which basically says
with sales representative made a sale
more than three times now we it might be
looking little confusing when I say for
example let me clear out this filter
now we have sales greater than 3 and we
would want to find out which sales
representative made a sale more than
three times now I could basically check
for every sales representative here if
they have made a sale more than three
times and what I can do is I can just
say equals I can start with count if
then I need my filtering criteria so
that's your range so first thing is we
will choose for example is choose C2 to
C 44 and then we need to
give and criteria what is the criteria
we need basically a sales representative
so I can choose the value here in C2
and then I can close this and then I can
say the sale has to be greater than 3
and let's check so it tells me the
Boolean value that yes this guy has made
sales more than three times and what we
can do is we can just drag and drop
which basically gives me the value for
other sales rep you can always check the
value is automatically changing to this
value in cell and for example let's go
in here so this is obviously 2 so it
saves me false right and you can
basically get the values for all your
values so that basically tells me which
sales representative has made a sale
more than three times
now like sumifs we also have countifs
where you can give multiple criterias so
for example the question is how many
orders were placed from the east region
after this particular date so we have
a date criteria we also have the region
criteria and we need to basically get
the count of number of orders which were
placed now I can in this case use count
ifs
and this basically says that you can
start with an criteria so it says how
many orders were placed from east region
after particular date so date is in my
First Column so for example I could say
a
start with 2 and say for example let's
go a44 that should have selected all the
rows
and then I need to
once I have given the criteria range I
need to give the criteria so we are
saying the date has to be greater than
10th Feb so let's give it
2
10
2019
and then you need to say
how many orders were placed so you need
to give the criteria second criteria
range
so we are looking at the number of
orders which were placed
from the east region so when I would
want to look at the region that's your
column B so I can basically say B2 to B
44
and here
I would basically give my criteria so
the criteria is East
let's give that
and once you have done this you would
want to find out the total number of
orders so let's select this and if I do
this it tells me 13 now is that right so
we are looking for your date
your region being East and then getting
the total number of orders so here I can
just do a count if I'm saying A2
to a44
wherein I have given the date criteria
that it should be greater than
10th Feb because I do not want to count
10 Feb it says after 10 February and
then you are saying the region has to be
East so we would want to find out the
total number of orders so my region is
east and that gives me the result
now similarly you can also find out how
many times Gill
sold pencils so here we will have to
give the range so
let's start with count
ifs
now here I would want that item is
pencils so we can as well select column
D2
d44
then you have to give your criteria so
that's your
pencil
and then we are looking for sales rep
which is Gill so
that is my column C so let's say c 2 2 C
44
and the value should be
just kill
so it tells me
it's twice where Gill has sold pencils
so we can obviously check this by going
in here
choosing my filter and then let's search
for rep being just Gill
okay and now we are interested only in
the item being pencil so I can say well
let's get to pencil only and that tells
me twice so you can obviously re-verify
using filters but using functions or
using formulas it is always good to
calculate and that can be making your
computation and calculation more dynamic
let's look at one more interesting
feature of Excel and that's your
conditional formatting now as you see on
the screen conditional formatting has
different rules which can be applied on
your data and that allows you to
basically differentiate or easily
identify data values which are
based on certain criterias or rules so
when you talk about conditional
formatting you have different options
such as you can highlight cell rules you
can get top and bottom values you can
apply different rules apply different
color scales and you you can easily
manage these rules so conditional
formatting is very useful for people who
would want to work on huge amount of
data and easily perform some data
analysis
it's easy to use as it is shown here and
with your conditional formatting
you can format cells based on a preset
condition you can perform conditional
formatting to identify cells you can
highlight a few significant cells and
you can easily perform conditional
formatting
as shown on the left side
now how do we work with conditional
formatting let's have a quick look so
say for example we have our Excel sheet
and if you see here I am highlighting
the sales person who have generated
Revenue greater than 10 000. so we can
be looking at the values where the
revenue generated by a particular sales
person is greater than 10 000 it has a
particular
color and how do we get here so for
example let's select this data
and what I could do is
I could go into conditional formatting
now I could basically highlight cell
rules and we could just say greater than
that's an easier way I could also go
ahead and create a new rule but then I
can use one of this option I can say
greater than and let's give some value
might be we would be interested in
looking at any value greater than 12 000
so let's choose 12.
1000
and here it says what color would you
want to select so for example I would
say something like
yellow filled with dark yellow text
and let's say okay so right now what I'm
doing is I have all the values where the
revenue generated was greater than 10
000 but then I have also selected all
the sales people who have made or who
have generated Revenue greater than 12
000. so I can just do a control Z to see
the previous result now here I had the
values which were greater than 10 000
and the one which we did just now
basically
highlighted the values which are greater
than twelve thousand so this is one
simple example now we can look at some
other examples say for example you want
to format cells using three color scale
so if you look at the values here I have
a three color scale mainly in green
yellow and red and how do you do this so
for example I can go in here and I can
go to conditional formatting so I would
want to go for color scales and here you
can create different rules so we can set
up a two color scale so we can say
format only values that are above and
below average I can format only cells
that contain something I can get the top
and bottom value so these are different
ways in which I can have a three color
based scale now what I will do is I will
select this and let me show you the rule
which which I have so for example I can
go into manage rules and if you see here
there are certain rules which have been
specified now what does that mean so you
would want to specify a three grade
scale so for example if I would want to
look at my first rule it tells me that I
am choosing three color scale I can
choose lowest value percentile and
highest value and that basically will
select the cells based on their values
so what we could have done is I can
basically
use one of these values I can delete
these rules which I have created so for
example I have all these rules but you
should always carefully remember that
the rules will be applied in the order
shown so for example if I just delete
these rules
and then say apply and say okay my data
is back now it does not have any
highlighting now I can go in here I can
say conditional sorry conditional
formatting I could go for color scale so
I could basically go into
new rule so I would want
the
cells to be using three color scale so
let's
choose three color scale now when you
say three color scale it says what will
be the color of lowest value
and we could choose might be any one of
this let's choose red I can say midpoint
is percentile 50 and then the highest
value is green and if that looks good
let's say okay and now if you see the
lowest values have been highlighted as
read you have mid values and then you
have the positive value so this is the
three color scale and that easily helps
me in identifying the data based on the
cell values
now in conditional formatting what you
can also do is you can basically color
the cells based on their value so what
we are seeing here is if the revenue
generated is greater than average then
that shows in green and if the revenue
generated is lesser than average that's
shows in Orange now how do we do that so
we can basically again manage some rules
so I can basically create a new rule now
here I can select one of the options
which says format only values that are
above or below average and that's the
option I would want to select now I can
select this and it says format values
that are above average so in our case we
had it in green so for example I'll say
above average and then here I can go for
a particular color
so you can go for a particular size so
let's go and look into
the formatting so for example let's
choose yellow
say okay now I am saying wherever the
cell values are above average it would
be yellow instead of green
and let's go in here let's go and look
into manage rules so this is basically
the rule which we are applying now we
can also add a new rule
and I need to select the values so for
example I will say
here so we had gone for above now we'll
go for below we'll go for format we will
choose red we'll say okay we'll say
now these are basically
the rules which we have created and here
it says applies to your data so right
now it has not been applied so for
example if I select this and then I
could basically choose my area just hit
on enter
and similarly you can go in here and
then select your area hit on enter and
say apply say okay and now if you see I
have really chosen bright colors but
then I have said wherever my revenue
generated is above average it should be
in yellow and
below average should be in Red so we
wanted above
average to be in green and below average
to be in Orange so
that's what we have here right so you
can always
color code your cell values based on
some rules which you are setting up now
similarly you can also find the top 10
and bottom 10 values and that's pretty
easy so you can just select this and
then you can go into conditional
formatting you can go for top and bottom
values top 10 items bottom 10 items or
you can go in for more rules so you can
say format only top or bottom ranked
values so you have top 10 now you can
choose the color and for example I'll go
for blue
and
I'll say okay so now if you see my top
10 values are blue now similarly I can
add one more rule so I can say new rule
and I can say let's go for top or bottom
let's go for bottom let's go for format
let's say orange
say okay say okay and that's it so now
you have your values which are top or
bottom 10 values so you are using
conditional formatting where you are
basically highlighting your cell values
based on different colors and here easy
conditional formatting based on
different rules helps us to do that now
similarly you can also have the values
which is basically
showing you how the values are
increasing so what we can do is we can
select our columns either you could
apply this to all the columns now here I
have applied this only to Jan and April
now I could apply this for June so let's
say June so you can go for gradient fill
you can go for solid fill you can
obviously just select the color and that
takes care of the things you can say for
example select this and now this is
selected what I would want to might be
format this so I can go in here I can go
into manage rules now that will tell me
what rule has been applied
in the order so I can just do a edit
Rule and that basically says this is a
solid fill which is color you have no
border this is basically color is black
now I can go for something like gradient
fill
and I can say okay and now if I say
apply and okay so this basically is Like
Your First Column so you can use
conditional formatting for various use
cases and you can highlight the values
so anyone who would look at the value
would automatically notice which are the
higher values which are lower values
might be here the revenue is getting
generated or was getting generated but
did not grow Beyond a particular value
and so on now similarly you can also go
in for different options say for example
here we would want to
see if the revenue was dropping
or if the revenue was
if the revenue decreased or say for
example if the revenue was going up for
this particular sales person so here we
are looking at Carol so in Jan the
revenue Generation by sales was very
high then in Feb it was falling down
in March it was kind of stable then in
April it went way below so we can
obviously work on this wherein we can
grade our cell values so what we can do
is we can go in for
highlighting the cell values now you can
go for color scales you can go for Icon
sets and this is where you can choose
your different shapes
so you could choose one of these shapes
so for example I would be interested in
looking at the indicators like
directional I could go
using this three arrows I can go in for
this color I can choose directional and
then my values are
automatically using directional now what
we can also do is we can then go into
manage rules and that basically tells me
what rules have been applied so for
example the latest one is the icon set
which I have chosen it shows the
selected columns I can obviously do a
edit Rule and then I can choose so I'm
saying the format style is icon sets I'm
not using a data bar I'm not using color
scale now here
I have chosen the style of icons
and then here you can basically give
some values so you have icon which is
green when the value is greater than or
equal to 67 percentage
when I say
hyphen or minus it is less than 67. it's
way below 33 percentage then you give
this value so you can obviously edit and
easily highlight your cell values based
on this icon set so I can apply this and
that's how I use conditional formatting
so conditional formatting can be very
useful if you would want to use icon set
if you want to use your data bars if you
would want to highlight particular
values if you would want to color code
based on some calculation if you would
want to
use a three color or a two color scale
or if you would want to just find out
values based on some simple calculation
so conditional formatting is used
extensively by data analysts or people
who are working in business intelligence
teams or people who would want to use
Excel to easily identify the data
easily identify the cells which contain
particular value or finding out less
significant or more significant cells to
then pull out values and carry out your
computations calculations or analysis if
you're an aspiring data analyst looking
for online training and certifications
from prestigious universities and in
collaboration with leading experts then
search no more simply lens postgraduate
programming data analytics from Purdue
University in collaboration with IBM
should be a right choice for more
details use the link mentioned in the
description box below let's continue
learning on using Excel for various
things now we have learned on
conditional formatting and seen how that
can be very helpful let's learn one more
feature of Excel and that's basically
your data validation now this can be
very useful when you would want to work
on validating the data which is being
fed in the cells so you could limit it
to basically a number between a
particular value you could also add some
messages to it if you would want or you
could even
Circle invalid data or clear validation
circles so data validation really helps
us in validating the data which is being
fed in to particular fields
now it's a feature in Excel which is
mainly used to control what a user can
fill in a Cell you can decide what type
of values must be entered you can also
restrict user to enter only valid data
and if any invalid data is entered an
error message will be displayed now
that's where you can use your data
validations so let's see how that can be
done so for data validation let's see
some exercises here so for example you
have a name column and you would want to
restrict that the name should accept
only 15 characters now how do you do
that so you can basically select the
cells or you can just select a
particular cell and then we can later
drag the property to other fields now
here once the cell is selected so for
example let's try this out and let's see
if that works so for example example I
will say Peter Johnson
okay and that is basically five and nine
and 12 characters so let's say
Junior
and if I do this it says input length is
greater than 15 do you want to continue
if I say yes right so basically
it is allowing me to add the value here
but then it has basically violated the
rule now this is giving a message to the
user that the username should be entered
less than 15 characters now how do we do
that so for this we can basically select
the column and then we can search for
data Tab and get into Data validation so
this is where you can create or select
different kind of rules so for example I
can go into Data validation I can go
into settings and I can say the text
length and that should be less than 15
now this is the maximum I'm giving and
it says apply these changes to all other
cells within the same settings so I can
do this or I can just drag and drop so I
can basically
apply this formula and now you can in
fact randomly check in any particular
cell is the rule applied so it says text
length less than 15. so we can basically
Control Data validation in this
particular column and that will allow
only 15 characters it will pop up a
message if the user really wants to go
beyond the particular limit now you also
have similarly date of birth so the
Restriction is date of birth should be
between 10 Jan 1990 to 30 December 1998
so this is what we want to restrict how
do we do that so we can select the field
we can click on data validation and if
you see here I have selected date and
then date is between and then obviously
you can give a range that is 10 Jan date
1990 12 30 1998 so that's the start and
the end filter which has been applied
and once this is done you can also check
your input messages which says
when cell is selected show this input
message enter a valid date
so if you see here on the left there is
a pop-up which is coming up which says
enter a valid date now I can also say
when user enters invalid data show this
error alert so I can say stop I can say
invalid entered
and this is how I have set a rule so for
example if I just do something like this
and that says invalidate entered I can
do a retry it will take me back here but
unless and until I do not give the right
format the date will not be accepted and
again the same thing applies to all the
cells similarly email so we are saying
the email should have at the rate
present in the value provided now for
this we can use a formula and we can
select well I would want to apply this
rule to all these rows starting from C2
to c14 so let's get into Data validation
let's look in settings and here we are
choosing custom now within custom I am
choosing what is the formula so I'm
saying is number
and then I'm saying find
at the rate for
the rows C2 to c14 so the only thing we
are concerned about here is the value
should have an email
icon
you can input a particular message you
can say what has to be done for error
alert so for example we can basically go
in here and we can say
invalid email
that's the title I'm giving and we can
say email should contain
at the rate so if I do this and if I say
ok now you can test it so you can say A
B C D and that says email should contain
at the rate and basically that will not
allow me to add the values so now you
have the field called salary it says
salary should be greater than 50 000 now
we can limit the values by choosing a
whole number so for example for salary I
can go into Data validation I can go
into settings so here I can say
something like decimal or I can go for
whole number so both of the things are
fine it depends on what kind of values
get into this particular field so if I
say whole number and if I say it has to
be greater than 50 000
so I'm saying the minimum is 50 000 or I
could have given a decimal and then I
can say greater than less than equal or
anything or even between so I can select
greater than and then I can just say
okay
now for rank the rule is rank should be
between 100 and 200 so again we can use
a whole number so ranks will generally
not be decimal so this would be whole
number salary is can be a whole number
or it could be decimals so we have
chosen decimal here and in rank if you
click on data validation I have chosen
whole number
I have set data between 100 and 200
input message nothing error alert
nothing but that depends I can give this
so this is how you can just do a simple
data validation and control the values
which land in the cell okay so now let's
also understand how we can
restrict the values in a particular cell
which might be based on a list of items
now for example here if you see I have
two columns so one column basically has
the values of city names and then you
have places within that particular City
so if I would want to implement a data
validation based on this so for example
if you see here City and that basically
shows me only the four values which can
be entered and if I go to place then it
tells me for Maharashtra I can only
enter Pune Mumbai nashik now how do I do
this so say for example you take an
empty field and you want to restrict the
values of city names so I could select
data validation I could basically select
list and then it tells me you need to
enter the list values that is the source
so you click here and then I can just
select these fields now if I do this and
if I say okay it has implemented a data
validate but if you look into this it
will show me the same thing but then it
shows me some empty cells which did not
have any value so this is fine but it
would be better if we do it in a
different way so I can select this and I
have already given my city names here so
I can just do a data validation and here
in the source let me get rid of this now
I can just have my cursor here I can
select these values and then if I say ok
so now if you see my city names have
been restricted to these values and
that's how you can Implement your data
validation so I have this data
validation here but I will get rid of
this one by just doing a control Z now
I'll come here and say for example I
would want to implement the same data
validation now the easiest way would be
e in doing this for all my four cities
now if you see here I have data
validation I could choose Bangalore and
if you come and check here there is no
data validation but we have implemented
data validation here now how is that
done so I could select this or for
example I can go in here I can select
data validation I can select list and
then here in the source I will say for
Bangalore the value should be these and
then if I basically say okay
now if we see these are the values which
are fed into Bangalore so we could do
this or like what we have done here so
if you can check the data validation
rule I have used list and then I have
said indirect F2 so basically I'm giving
in a formula which relates to the value
which is in for the city Maharashtra so
we could do this or in a simpler way we
could do this and then just drag and
drop here so we could check for
Maharashtra what are the values let's
choose a different city so for example
Kolkata and here I will choose now since
we did a drag and drop it has basically
taken the values of Bangalore so that's
not right so we select this we go into
Data validation and here I can either
feed in the values that is such as
Bangalore I could basically say
something like this Kolkata and I could
say okay so now if you see it shows me
the places in Kolkata now here we have
let's choose a different city so for
example let's go for Delhi and here I
can go to data validation and I can just
say Delhi so this is an easier way of
doing it or if you remember the formula
then what you can do is you can just
give in
indirect and then basically
give the
value of the cell for which you would
want to
keep in the values so this is how you
can do list validation so you can
provide a list of values and then you
can restrict the values in a Cell which
should be belonging to a particular list
so this is how you do a simple data
validation by restricting the data in
the form of a list
now let's learn about devote charts and
tables which is one more very useful
feature of Excel and which allows you to
work with your data or perform data
analysis now pivot table is a summary of
your data
it is used in cases where there are
numerous rows and columns in your data
set and it allows you to group your data
in several ways so that you can derive
meaningful information from it now the
visual representation of a pivot table
is termed as a pivot chart now how do we
do that so let's see an example now here
is some data here you see we have some
row labels which basically gives me some
category of items here it also tells me
the sum of sales and basically it gives
me per item what is the total sum of
sales which were made now how do I get
this here so for example if I would want
to delete this and I would be interested
in getting the
total sales under each category of items
now we know that we have
different data here and it's huge for
example on the row end if I just do a
control and right arrow it tells me
what's my right last column and if I
just do a control and down arrow it
tells me there are
9994 rows now I can use this and what I
can do is I can basically work on
insert and go to pivot table now this
basically tells you need to choose the
range now since I have chosen my first
row and First Column it basically has
selected the data and that's fine now do
you want the result in a new worksheet
I'll say existing worksheet and I can
choose a location now that basically
needs me to select a field might be we
can just select this field and that
should be good enough so for example if
I close this or if I say ok so
this is basically an indication that my
pivot table will be created now what are
the fields we are interested in so as
per the problem we need to find out what
the total sales for each category so
let's go in here and let's select the
field category now as soon as you do
that it shows that the rows
which are being selected are for this
column category and now we are
interested in getting the sales so we
would want the sales per category so
let's select this so you see some of
sales is selected now close this and
that's it that's that's your data so it
shows you row labels it tells you what
are the different categories
and it also gives you some of sales
which is per category now this is
one easy example where we have solved
the problem where we have tried to find
what were the total sales under each
category of items so for example let's
have another data set so again you can
just check how many rows we have and it
is basically the same 9994
and if I look in columns it basically
shows me profit is the last column
and here we would want to find out which
category
so for example let me get rid this with
subcategory of items sold the maximum
under each category so we have some
categories here which says furniture and
it shows some sub categories and then it
shows me office supplies and then some
sub categories and same thing with
technology now we know how we got this
data but this is different than what we
were seeing here so here we were just
getting the categories what what we did
not have any breakdown of sub categories
within this particular category and here
you see there is a breakdown and then
basically you can also apply a filter
which basically says what is the data
you want and if you are interested in
finding out a particular value now how
do we do this so for example let me get
rid of this now we know how we can find
out the category of items but we would
want to find out which sub category of
item so the maximum under each category
so here we are not looking at sales but
we are looking at the quantity okay so
what we can do is we can go to the first
row and First Column click on insert
click on pivot table data is already
selected let's choose existing worksheet
let's choose a location in our worksheet
where we would want to have this so
maybe I can select this particular field
and then just close this so it says this
is the existing worksheet say okay and
now you need to select your columns so
for example
if I would want the data for categories
so I can select this now I know that
within category these are the options
which we have and then there is a
subcategory so let's select that and if
you see here now we have the data which
will be filtered So based on your
category and subcategory and then we
will choose quantity so it automatically
understands that this is something on
which summation can be done so let's
select this and close on this now if you
see here we have got our items where we
can see
the sub categories within a particular
category now I can basically close this
and that just shows me high level
categories here so here I can again
select a particular
row and column I can go for
either a new pivot table so we could
basically select this the row is already
selected existing worksheet is what I
want so now I will select
this particular place
say okay now we do the same thing like
what we did earlier so we will select
category sub category and quantity so
the data has already come in just select
this and now you already have all your
data but this is not what we want we
want to basically apply a filter
to this now how do we do that so we can
go for
slicer so I can go for insert slicer and
then it tells what are the sub
categories which you are interested in
so for example if I go for something
like subcategory and say Okay so this
tells me what are the categories you are
interested in so for example we know
that furniture has Furnishings with the
highest value so I can select say
furnishings and then I was interested in
office supplies So within office supply
I can basically
search for
here
binder so I can just do a control and
select binder
and then I can also know for technology
I can select phones so I'll say control
and select phones and now if you see the
filter has been applied and we have
these subcategories which are selected
so we have our data here now we don't
need really this so I can just delete
this and I have my data which shows me
Furniture being the main category and
that has only Furnishings office supply
having binders and Technology having
phones and that basically is a filter
applied on the result of your pivot so
this is how we are seeing which
subcategory of items were sold
maximum for each category
so this is how you can easily use pivot
tables and you can do some analysis
let's look at some more examples
now
let's see if you have to answer this
question which says which were the top
three states for each region that made
the highest average profit now how do we
calculate that so for example this is
the data we have and as I've instructed
earlier you can select the first one
first column you can click on insert go
into pivot table and that basically
selects all your data we will choose the
result should be in this existing
worksheet so select this click here and
then basically let's select
this cell and I will say okay so now my
pivot table will be here so we are
interested in finding out top three
states within each region which have
made the highest
profit or which have made the highest
average profit so for that first we will
select region so when we select region
it shows here region and within region
you will then select state So within
every region you have multiple States so
that's what we are selecting and then we
are interested in looking at the profit
so let's select profit and that
automatically shows up here so we can
now say close this so basically we have
all the data but we are looking at the
sum of profit but that's not what we
want we are looking for
top three states
from each region that made the highest
average profit now how do we change that
so here we have sum of profit so I can
do a right click and basically I can say
summarize values by average so now I'm
getting the average here and that
basically tells per region I have the
average profit but first is let's sort
this data so let's go into sort more
options and here I have average of
profit or for example as I said you can
select region say okay and now it is
basically having the
regions and then you have your state
value so again we can do a sorting here
and I can say
let's go for more sort options I'll say
descending the state values should be
based on average profit so let's say
okay and now if you see
in particular region we have the data
which has been
sorted wherein you have the highest
average profit on the top now what we
can also do is we can basically
then go for filtering we can say top 10
but I am not interested in top 10 so I
could reduce this to top three
and this is the items average of profit
say okay and now you see per region you
have the data which is
showing me top three states what are the
average and then you are also looking at
the subtotal so which basically says
average profit for your West now if you
would want to arrange this
your west and south and east and Central
in a particular alphabetical order if
you would want to sort it you can always
do a sorting and you can choose sort Z
to A if that's what you would want to do
or you can go for sorting more sort
options and you want to
sort the region which is as of now
based on descending z2a let's make it
ascending say okay and now you see the
data has been filtered so it says per
region now you can always select this
and you can say what is this so this is
basically your average of profit now we
are looking at each region and the
states the top three states as we wanted
within the region and what is the
average now we have one more question
what is the percentage contribution of
each subcategory of products under each
category to the total sales so we know
there are different products there are
different categories and all the
categories contribute to the total sales
so we would want to find out what is the
percentage contribution of each
subcategory
of products under each category so we
not only want the category percentage
but we would also want what is the
contribution of each subcategory
to
each category to the total sales how do
we do that so for that we need to again
just place
our cursor here or select the first row
in First Column click on your insert
click on your pivot table and now the
data is already selected existing
worksheet place your cursor here and
then let's select this cell say okay
now your pivot table fields are here so
we are interested in category
so let's select category and then within
a category we will have sub categories
and we are interested in the sales data
wherein it is already going to give us
the sum of sales but we would want this
in the form of percentage rather than
just the sump now we can click here
value field settings and it says if you
would want to summarize this it says
show value as and what are the values
you would want so you can straight away
go ahead here and say percentage of
grand total so we could do that because
we know
we will get a sum of sales in grand
total now I could basically say
percentage of grand total say okay and
then just close this so once you have
closed this you see already the data is
in
percentage so now we have our data with
subcategories but we also want the data
to be sorted might be in a descending
order which tells which subcategory is
contributing more than others we can
select how many subcategories we are
interested in so we can basically select
one of the subcategory cells right click
now you have option filter and you have
sorting so we can say more sort options
now here I will say descending and you
want the descending to be sum of sales
which is already showing as percentage
click on OK and now you see for each
category
it shows the percentage contribution
towards the sales it shows the sub
categories contribution
to a particular category and also to
total sales so technically speaking if
you look at all these values which are
sub categories and if you would total
them that would be your total grand
total so this is how we can solve a
simple problem like this what is the
percentage contribution of each
subcategory of products under each
category to the total sales
the next question is which customer made
the lowest profit in the home office
segment in each state now here we know
that we are looking for home office
segment we are looking for customer
which made the lowest profit we are also
looking for the state as the main
criteria so in each state we would look
for home office segment and within that
we would look for customer which has
made the lowest profit that means
the lowest value
of the profit so how do we do this so
let's say let's get into selecting our
row and column we will go into insert
I'll say pivot table I'll say existing
worksheet and let me get my result here
so let's say okay now that gives me the
pivot table so the first thing is we are
looking at per state
and
I would be interested in
home office segment or I could first
start with segment now here we have
segment and in segment I can basically
select home office so I can just do a
uncheck and select home office only
and now I can select
state so that will be my
subcategory within segment and then
within State we would want to find out
the customer so let's get the customer
name
and we are interested in finding out the
lowest profit so let's select profit and
here we have sum of profits so the
fields are selected close this and now
you have your data
which basically shows me the names of
customers which made the profit but it's
it's not sorted so we can sort this and
we have state entries also so that's
fine so what I can do is here I can
basically say sorting go to more sort
options I can say I want to do it
descending or I want to do an ascending
and ascending based on sum of profit so
let's do that now you see the topmost
value is the lowest value per state
within home office segment now what we
also want is we just want one value per
state so how do we do that so we can
just go for filtering go for top 10
values I am interested in bottom value
and in that also I am looking for only
the
lowest value so let's select one
say okay and now you see we have data
for home office segment
per state
customer who has made the lowest profit
so we have easily answered this question
using our pivot table
now say for example we have a question
which says find the sales made in each
quarter of 2016 for all the regions
so the data has to be divided quarterly
and use order here as a slicer we can do
that by selecting what data we would
want to slice and then we would want to
create a pivot chart also so for example
how do we do that so for example I will
get rid of this
I will get rid of
this my Pivot chart which we can
recreate so find the sales made in each
quarter of 2016 for all the regions so
this is what we want now how do we do
this so for example let's select this we
will do a insert pivot table we will
basically say existing worksheet and
then I can select this particular cell
I'll say okay and now I am interested in
data quarterly so first let's select
our field here so we should basically
have
if all our fields are selected say for
example if I say order date
now
you see we have quarters and years which
are selected now we could be selecting
these fields which says
quarters years and if I would want data
to be filtered based on years I could do
that or I could get rid of here so I
have quarters I have ordered date
so
that's being already selected now what
else we need we need to find out
for every region so let's select the
region and we can also add region as a
column here so that will basically give
me all the regions as different columns
and then finally we want the sales so
let's select this
and now let's look what we have so if
you see here
we have our data which is
for each quarter
it gives me the total data but what we
would be interested in is not looking at
the total data but we are only
interested in quarter of
2016. now how do we do that so what we
do here is we have row labels so let's
click on this so we have date filters
and then in date filters we can go for
between and then we will say
2016 and the value has to be 1
and then let's select this and let's
change this to 2016
and this is 12th month
and then we can say 31
so we are seeing the date has to be
2016.
and it basically says not a valid date
so let's select
let's select a particular date and see
so the month has to be here
so let's see in this and let's make it
date and say okay and now we have our
data which is
foreign
2016. so for example I could basically
select this and here I could be looking
at
what are the filters we have so it says
clear filter from order data so we have
applied the filter on order date
and
these are your date filters which is
basically
date 16 or this is wrong so this one has
to be changed to 2016. so select this
and now we have our data for 2016.
so we have found the sales made in each
quarter of 2016 for all the regions the
grand total
for a particular quarter if we are
looking at the value or for individual
months in a particular quarter and we
have sliced the data now we could have
also introduced a slicer by
selecting
which field we would want to implement
so for example if I would select a
particular field and then I could click
on slicer I could choose I would want to
slice the date based on order date and
then could have done it or we have just
given the
date for 2016. now we just need to plot
a graph for this and that's very easy so
you just need to select the complete
pivot data and here you have the chart
options so let's go for line chart and
that basically shows me the line chart
so we can select this we can just drag
and drop it here and then we can
basically check if that is showing us
the data so if you see here this is line
chart where it has divided the regions
in different colors so we have all the
regions we could filter out in pivot
chart a particular region we have the
quarterly
time here in order data the filter is
applied it says it is 2016 in quarters
it tells me it is 16. so we have our
data we have created a pivot chart and
basically we have sliced the data for
2016.
let's answer one more question and
that's finding the profit made in each
year for all the categories of products
in east and west regions only and then
we would want to create a histogram for
the same pivot table so histogram
usually gives us the frequencies so
let's look at how do we calculate the
profit made in each year for all the
categories so what I can do is I can
basically
select my row ID here and now I'll do a
pivot table so the data is already
selected I'll choose existing worksheet
let's select this particular cell say
okay now what are we interested in now
if you look at the fields we don't see
any years or quarters and so on so for
example here I can just choose order
date
and then basically
I can choose say for example years or
quarters the data which is coming out
from my order date so here I will just
select years
now
then I have my order date so
we are interested in the Years orders
and
we are interested in
let's look at our column or the question
what we had here
so we have years
find the profit made in each year so
let's select profit so that basically
says sum of profit but then I'm on also
interested in
for all the categories of products so
what I can do is here I have my field
which is category and that I'll add to
the columns so that shows me what are
the different categories
and this looks fine now I'm also
interested in east and west regions so
that is basically in the region so
either we could add a slicer or we could
do a filtering here by adding the
filters so first is I'll click on region
and here it says select all I'm only
interested in east and west so let's
select this
take this put it here
let's say okay and now we have the data
which has been filtered based on the
region so here we have region so you can
always look at the filter it is east and
west and we have our year data per year
we have different categories you can
always look at what are these column
labels so this is my different
categories and this is the profit per
category
and then you have your grand total so we
have already our data now let's say
close this so we have our data for all
these years different categories the
profits made per year and if I would
want I could go into an ear and I could
look into different months so that also
is showing up and now we would want to
basically plot a histogram with this
data so I can just place my cursor here
I can select this and then I can go into
insert and here I have different options
so we can go for bar chart we can go for
insert hierarchy chart
we can go into waterfall funnel stock
surface or radar chart so there are
different options what you have here and
we will go for a simple histogram which
is two dimensional let's select this and
here you see you can obviously select
different regions
you have your ears which shows up you
have your order date
and then you have your categories which
can be chosen for your histogram or for
your bar chart and that basically is how
you use your pivot table you use some
calculations and then you can plot your
needed graph to visualize the data and
understand it in a better way so let's
start with what is number numpy is the
core library for scientific and
numerical Computing in Python it
provides high performance
multi-dimensional array object and tools
for working with arrays and I'll go a
step further and say there are so many
other modules in Python built on numpy
so the fundamentals of numpy are so
important to latch onto for the python
so you can understand the other modules
and what they're doing numpy's main
object is a multi-dimensional array it's
a table of elements usually numbers all
of the same type indexed by a tuple a
position integers in numpy dimensions
are called axis
take a one-dimensional array or we have
remember dimensions are also called axes
you can say this is the first axis 0 1 2
3 4 5. and you can see down here it has
a shape of six why because there's six
different elements in it in the one
dimension array and they usually denote
that as six comma with an empty node on
there and then we have a two dimensional
array we can see zero one two three four
five six seven and in here we have two
axes or two dimensions and the shape is
two four so if you were looking at this
as a matrix or another mathematical
functions you can see there's all kinds
of importance on shape we're not going
to cover shape today but we will cover
that in part two did you know that
numpy's array class is called ND array
for numpy data array now we're going to
take a detour here because we're working
in Python and two of my favorite Tools
in Python is the Jupiter notebook and
then I like to use that sitting on top
of anaconda and if you flip over to
jupiter.org that's jump e y t e r dot
org you can go in here you can install
it off of here if you don't want to use
the Anaconda notebook but this is the
Jupiter setup the documentation on the
Jupiter Jupiter opens up in your web
browser that's what makes it so nice is
this portable the files are saved on
your computer they do run an IPython or
iron Python and you can create all kinds
of different environments in there which
I'll show you in just a minute I myself
like to use Anaconda that's
www.anaconda.com if you install Anaconda
it will install the jupyter notebook
with the Anaconda separate and you can
install Jupiter notebook and it'll run
completely separate from anaconda's
Jupiter notebook and you can see here
I've now opened up my anaconda Navigator
what I like about the Navigator and this
is a fresh install on a new computer
which is always nice I can launch my
Jupiter notebook from in here I can
bring other tools so the Anaconda does a
lot more and under environments I only
have the one environment and I can open
up the terminal specific to this
environment this one happens to have
python 37 in it the most current version
as of this tutorial and then you open a
terminal if you're going to do your pip
installs and stuff like that for
different modules you can also create
different environments in here so maybe
you need a python36 python35 you can see
we're having a nice framework like
Anaconda really helps so you don't have
to chat track that on your own in the
Jupiter notebook in your different
Jupiter notebook setups we'll go ahead
and launch this Jupiter notebook and
then I've set my browser window for a
deep fault of chrome so it's going to
open up in Chrome and you can see here
this opens up a folder on my computer we
have a couple different options on here
remember I set the environment up as
python 3.7 you would install any
additional modules that aren't already
installed in your python on this and it
keeps them separate so you do have to
for each environment install the
separate modules so they match the
environment on there and in here we have
a couple things we can look up what's
running do you have your different
clusters again this is I just installed
this on a new machine so so I just have
the one a couple things in here that
were run on here recently and when we go
on here is we then have on the upper
right new and from the pull down menu
you'll see python3 and this will open up
a new window
and now we're in Jupiter python so this
is a python window and we'll just do a
print
and this of course is this little hello
world
and we'll run that and it prints out
hello world in the command line there's
a couple special things you have to know
we're not going to do today which is on
Graphics if you've never seen this
one of the things you can do is you can
also do a equals hello world and if you
just put the a in there now if you do a
bunch of these we have a equals hello
world b equals goodbye world and you put
a b a then return B it'll only run the
last one but you can see here if you put
the variable down here it will show you
what's in that variable
and that has to do with the Jupiter
notebook inline coding so that's not
basic python that's just jupyter
notebook shorthand which you'll see in a
little bit so back to our number numpy
array versus python list python list
being the basic list in your python why
should we use numpy array when we have
python list well first it's fast the
numpy array has been optimized over
years and years by multiple programmers
and it's usually very quick compared to
the basic python list setup it's
convenient so it has a lot of
functionality in there that's not in the
basic python list and it also uses less
memory so it's optimized both for Speed
and memory use and let's go ahead and
jump into our Jupiter notebook since
we're coding best way to learn coding is
to code just like the best way to learn
how to write is write and the best way
to learn how to cook is cook so let's do
some coding here today and just like any
modules we have to import numpy we
almost always import it as NP that is
such a standard so you'll see that very
commonly we can just run that and now we
have access to our numpy module Insider
Python and then the most common thing of
course is to go and create a number
array
and in here we can send it a regular
list
and so we'll go ahead and send this a
regular array let's go one two three to
make it simple and then I'm just going
to type in a and we'll run this
and so you can see down here the output
is an array of one two three and we
could also do
print just a reminder that this is an
inline command so that wouldn't work if
you're using a different editor you can
see that it's an array one two three but
we'll go and leave it as a
kind of a nice feature so you can see
what you're doing really quick in the
jupyter notebook and just like all your
other standard arrays I can go a of 0
which is going to be a value of one of
course we do a of one you go all the way
through this
I have one has a value of 2 in it so
whether using that numpy array or the
basic python list that's going to be the
same that should all look pretty
familiar and be pretty straightforward
remember the first value is always zero
and when we set on there so let's take a
look why we're using numpy because we
went over the slide a little bit but
let's just take a look and see what that
actually looks like and what we want to
look at is the fact that it's fast
convenient and uses less memory so let's
take a glance at that in code and see
what that actually looks like when we're
writing it in Python and what the
differences are
and to do this I'm going to go ahead and
import a couple other modules we're
going to import the time module so we
can time it and we're going to import
the system module so that we can take a
look at how much memory it uses and
we'll go and just run those so those are
imported and so we'll do b equals a
range of one yeah 1000 is fine
and so that's going to create a list of
100 0 to 999 remember it starts at zero
and it stops right at the 1000 without
actually going to the 1000. and let's go
ahead and print
and we want system dot get size of
and we'll pick any integer because we
have you know zero to a thousand we'll
just throw one in there five it doesn't
matter because it's gonna whatever
integer we put in there is going to
generate the same value it's looking the
size of how how much memory it stores an
integer in
and then we want to have the link of the
B that's how many integers are in there
and if we go ahead and execute this and
run this in a line we'll see Oops I did
that wrong comma if we multiply them
together
we'll see it generates twenty eight
thousand so that's the size we're
looking at is twenty eight thousand I
believe that's bytes that sounds about
right
so let's go ahead and create this in
numpy and we'll go with C equals NP and
this is a range
so that's the numpy command to do the
same thing that we were just doing in a
list
and we'll also use the same value on
there the 1000
. once we've created the C value of C
for NP dot a range let's go ahead and
print and we can do that by doing C dot
size
times C dot item size
well that's very similar we did before
we did get the size of so the C size is
the size of the array and each item size
just reversed so it's the size of an
integer five item size is going to be
the integers and C size now let's just
take a look and see what that generates
and wow okay we got four thousand versus
28 000. that's a significant difference
in memory how much memory we're using
with the array and then let's go and
take a look at speed let's do oh let's
do size we trade this with lower values
and it would happen so fast that the
npra kept coming up with zero
because I just rounded it off so size
and let's create an L1
Bulls range of size
and we'll do an L2
I'll just set up to the same thing it's
also range
of size on there there we go
and then we can do on A1
equals NP Dot
a range size
and then let's do an A 2 equals NP dot a
range we'll keep it the same size
and what we're going to do is we're
going to take these two different arrays
and we're going to perform some basic
functions on them
but let's go ahead actually let's just
load these up now we'll go ahead and run
this so those are all set in memory
except for the typo here
quickly fix that
there we go so these are now all loaded
in here and let's do a start equals
time dot time
so it's just going to look at my clock
time and see what time it is and it will
do result equals and let's do oh let's
say we got an array and we're going to
say
let's do some addition here X Plus y
for X comma y
in and we'll zip it up here
two different arrays so here's our two
different arrays we're going to multiply
each of the individual things on here L1
L2
there we go so that should add up each
value so L1 plus L2 each value in each
array
and then we want to go ahead and print
and let's say python list took
and then we'll do
time
dot time
we'll just subtract the start out of
there so time whoops I messed up on some
of the quotation marks on there
okay there we go
time minus the start
and we'll convert that to seconds so
we'll go to this in milliseconds or
times one thousand
and let's hit the run on there it's kind
of fun because you also get a view while
we're doing this
of some ways to manipulate the script
and as you can see also my bad typing
there we go okay so we'll go ahead and
run this
and we can see here that the python list
took 34
actually I have to go back and look at
the conversion on there but you can see
it takes roughly 0.34 of a second and we
can go ahead and print the result in
here too
let's do that
and we'll run that just so you can see
what the what kind of data we're looking
at
and we have the zero two four six eight
so it's just adding them together it
looks pretty straightforward on there
and if we scroll down to the bottom of
the answer again we see python list took
46 a little different time on there
depending on what um core because I have
this is on an eight core computer so it
just depends on what course running on
what else is pulling on the computer at
the time and let's go back up here and
do our start time paste that into here
and this time we're going to do a result
equals and this is really cool notice
how elegant this is It's So
straightforward this is a lot of reason
people started using numpy is because it
can add the two arrays together by
simply going A1 Plus A2 makes a lot of
sense both looking at it and it's just
very
convenient remember this slide we're
looking at fast convenient and less
memory so look how convenient that is
really easy to read real easy to see and
I don't know if we don't need to print
the result again so let's just go ahead
and print the time on here and we'll
borrow this from the top part
because I really am a lazy typer
this isn't the python list this is the
numpy list or numpy array
and let's go ahead and see how that
comes out and we get 2.99 so let's take
a look at these two numbers 46 versus
2.99 so we'll just round this up to
three that's a huge difference that's
that's like more than 10 times faster
that's like 15 times roughly at a quick
glance I'd have to go do the math to
look at it and it's going to vary a
little bit depending on what's running
in the background the computer obviously
so we've looked at this and if we go
back here we found out it's much faster
yes there's different going to be
different speeds depending on what
you're doing with the array very
convenient easy to read and it uses less
memory so that's the core of the numpy
that's why a lot of people base so many
other modules on numpy and why it's so
widely used
so we did glance at a couple operations
when we were looking at speed and size
let's dive into a little bit more into
the basic operations
and these are always nice to see I mean
certainly you want to go get a cheat
sheet if you're using it for the first
time you know look things up Google is
your friend we did this where the most
basic numpy dot array or NP dot array
and we'll go ahead and create an array
let's do pairs one comma two
and then let's do a three comma four and
if we do that let's do five comma six
let's go and if we go ahead and take
this and run this and go ahead and do
our a down here so it's in line and I'll
print that out
you can see it makes a nice array for us
so we have a and if you look at that we
have three different objects each with
two values in them and hopefully you're
starting to think well how many
dimensions or indexes is that and you'll
see three by two so let's go ahead and
take a look and let's go how about a dot
in Dimensions speaking of which we'll
run that and we have two dimensions for
each object
and then we can do the item size so a
DOT we saw this earlier we looked up how
many items it was up here where we
wanted to multiply item size times the
actual size of the object so the memory
is being used versus the item size
and we should see four there
memory is compressed down that's always
a good thing
and then the shape the shape is so
important when you're working with data
science and you're moving it from one
format to another
so we have our shape we just talked
about that we have three by two three
rows by two objects in each one
generally I don't look too much at the
size but the dimensions I'm always
looking up this is nice you can automate
it so you might be converting something
you might need to know how many
dimensions are going into the next
machine learning package so that you can
automatically just have it send that
information over
so we looked at a shape let's go and
create a slightly different array NP dot
array let's go ahead and just do as our
original
set up here
and one of the features we can do which
is really important is we can do D type
equals in this case let's do NP
float 64. and so what we've done is
converting all of these into a float and
we type in a
and now instead of having one two three
four five six you see they're all float
values 1.0 there's no actual zero in
there just shows the one dot or the one
period two three period four period five
period six period
and this again data science I don't know
how many times I've had to convert
something from an integer to a float so
it's going to work correctly in the
model I'm using so very common features
to be aware of and to be able to get
around and use
now we'll also do let's just curiosity
item size
we'll go ahead and run that
and we see that it doubled in size so
it's not a huge increase well doubling
is always a big increase in computers
but it's not a huge increase compared to
what it would be if you're running this
in the python list format
and then we did the shape earlier
without having it set to the float 64.
let's go ahead and do a shape with it
set to 64. and it should be the same
three comma two so it all matches so
we've gone through and remember if you
really if this is all brand new to you
according to the Cambridge study at the
Cambridge University if you're learning
a brand new word in a foreign language
the average person has to repeat it 163
times before it's memorized
so a lot of this you build off of it so
hopefully you don't have to repeat it
163 times but we did manage to repeat at
least twice here if not a little bit
more and let's go ahead and take this
we're going to look at one more setup on
here and let me just take this last
statement here on the converting our
properties of our data and instead of
float 64
let's do complex let's just see what
that looks like and let's go ahead and
print that out and run it
and so we now have a complex data set up
and you'll see it's denoted by the one
dot plus 0 dot j
and if we flip over here and do a basic
search for numpy data types better to go
to the original web page but pull up a
bunch of these you can see there's a
whole list of different numpy data types
shorthand complex we have complex
complex 64 complex 128 complex number
represented by 264-bit floats real and
imaginary components
one option on there float 16 float32
float shorthand for float 64 most
commonly used and of course all the
different ones that you can possibly put
into your numpy array so we covered a
basic Edition up there we're comparing
how fast it runs but it's a very basic
components how to set up a numpy array
how many dimensions it has item size
data type item again we went to item
size and there's also the
shape probably one of the more used I
used a shape all the time very commonly
used
and then down here you can see where we
actually created a numpy complex data
type
so let's look at some other features in
numpy one of them is you could do numpy
Dot
zeros
and we're going to do three comma four
there we go and we'll go ahead and run
this and you can see if I do NP dot
zeros I create an empty array of zeros
this is really important I was building
my own neural network and I needed to
create an array where I initialized the
weights and I want them all to be the
same weight in this case I want them to
start off as zero for the particular
project I was working on and there's
other options that you can do on p1s
and we'll do the same thing three comma
four we'll run that and you can see I've
created a an array of numpy ones in this
case it comes out as a float array
and this is an interesting to note
because we have let's go back to our
Python and do L Range Five
and we'll print the L so there's our
list and if I run that
it doesn't create the range and tell
after the fact until you actually
execute it that's an upgrade in python
python 2 7 actually created the array
zero one two three four this one
actually creates the script and then
once it's used it then actually
generates the array and if we do that in
numpy a Range remember that from before
and if we do a numpy a range 5
and let's do a
l or we can just leave it as numpy
that's right there we go just run that
you can see there we actually get an
array 0 1 2 3 4 for the value of the
numpy range a range five generates the
actual array
and for part one we're going to do just
one more section on basic setup
and we're going to concatenation
concatenation example
there we go we're gonna do strings let's
take a look at strings and what's going
on with there and let's do
oh let's see print
Let's do an NP character something new
here
and we're going to add and then here's
our brackets for what we're going to add
oh and let's say
um let's do
hello
comma High
and in the brackets on there let's
create another one
and this one's going to be
ABC and we'll do
x y z so we're just creating some
randomly making sum up on here and then
we'll go ahead and just print this
if we run that and come down here and of
course make sure all your brackets are
open and closed correctly and then you
can see in here when we concatenate the
example in numpy it takes the two
different arrays that we set up in there
and it combines the hello with the ABC
and the high with x y z
and if we can also do something like
print oh let's do NP character dot
multiply
so there's a lot of different functions
in here again you can look these up it's
probably good to look them all up and
see what they are but it's good to also
just see them in action let's do hello
space comma three
and we'll run this one
and run that without the error you'll
see it does hello hello hello so we
multiplied it by three and we can also
let's just take this whole thing here
instead of retyping it
and we can do character Center so
instead of multiply this to Center
and over here keep our hello going
the space out of there and let's do
Center at 20.
and fill character
equals we'll fill it with dashes
so if we run this
you can see it prints out the hello with
dashes on each side and we keep going um
with that we can also in addition to
doing the fill function we can play with
capitalize we can title we can do
lowercase we can do uppercase we can
split split line strip join these are
all the most common ones and let's go
ahead and just look at those and see
what those look like each one of them
so we're going to do the hello world
all-time favorite of mine I would like
to say Hello Universe and you can see
here we do Capital H with the world but
so we want to capitalize so capitalize
is the first one in the array so we get
Hello World on there and we can also
take this and instead of capitalizing
another feature in here is title and
let's just change this to how are we
doing
how are you doing
you and let's run that
and you can see here because we created
it as a title that capitalizes the first
letter in each word
and in this one we're going to do
character lower
two different examples here we have an
array we have Hello World all
capitalized and we have just hello and
you can see that one is an array and one
is just a string if we run that you get
a an array with Hello World lowercase
and hello lowercase and if we're going
to do it that way we can also do it the
opposite way there's also upper
and let's paste those in there and you
can see here we have character Dot Upper
opposite there
python.data and we'll do python is easy
hopefully you're starting to get the
picture that most of the Python and the
scripting is very simple is when you put
the bigger picture together and starts
building these puzzles and somebody asks
you hey I need the first letter
capitalized unless it's the title and
then we have you start realizing that
this can get really complicated so numpy
just makes it simple and we like that
and so in this case we did python data
it's all uppercase python is easy like
shouting in your messenger python is
easy and then if you're ever processing
text and tokenizing it a lot of times
the first thing you do is we just split
the text and we're just going to run
this in P dot character.split are you
coming to the party if we do that it
returns an array of each of the
individual words are you coming to the
party splitting it by the spaces
and then if you're going to split it by
spaces we also need to know how to split
it by lines
and just like we have the basic split
command we also have split lines hello
and you'll see here the scoop in for our
new line
and when we run that if you're following
the split part with the words you should
see hello how are you doing the two
different lines are now split apart
and let's just review three more before
we wrap this up commonly used string
variable manipulations we have strip and
in this case we have Nina admin Anita
and we're going to strip a off of there
let's see what that looks like and then
you end up with nin dominate it
basically takes up all leading and
trailing letters in this case we're
looking for a more common would be a
space in there but it might also be
punctuation or anything like that that
you need to remove from your letters and
words and if we're going to strip and
clean data we also need to be able to
reformat it or join it together so you
see here we have a character joined
we'll go ahead and run this
and it has on the first one it splits
each of the letters up by the colon and
the second one by the dash and you can
see how this is really useful if you're
processing in this case a date we have
day month year year month date very
common things do we have to always
switch around and manipulate depending
on what they're going into what you're
working with
and finally let's look at one last
character string we're going to do
replace if you're doing misinformation
this is good pulling news articles
replacing is and what in this case we're
just doing he is a good dancer and we're
going to replace is with was
and you can see here he was a good
dancer hopefully that's not because he
had a bad fall he just was from like you
know 1920s and it's gotten old
so there we go we've covered a lot of
the basics in numpy as far as creating
an array very important stuff here when
you're feeding it in how do we know the
shape of it the size of it what happens
we convert it from a regular integer
into a float value as far as how much
space it takes we saw that that doubled
it item size you have your in dimensions
and probably the most used is shape I
will cover more on shape in part two so
make sure you join us on part two
because there's a lot of important
things on shaping in there and setting
them up we also saw that you can create
a zeros based array you can create one
with ones if we do a range you can see
how it is a lot easier to use to create
its own range or a range as it is in
numpy you saw how easy it was to add two
arrays we saw that earlier just plus
sign then we got into doing strings and
working with strings and how to
concatenate so if you have two different
arrays of strings you can bring them
together we also saw how you can fill so
you can add a nice headline dash dash
dash we saw about capitalize the first
letter we saw about turning it into a
title so all the first letters are
capitalized doing lowercase on all the
letters upper for all the letters just
lower and upper nice abbreviation we
also covered how to split the character
set how to strip it so if you want to
strip all the A's out from leading A's
and ending A's or spaces you can do that
very easily also how to join the data
sets so here's a character join option
for your strings and finally we did the
character replace now let's go ahead and
dive in there since we're going right
into part two which is getting some
coding going under our belt and here in
our Jupiter notebook we can go under new
and create a new folder python3 I think
I forgot to do this last time but we
could just do the control plus plus
which in any browser enlarges a page
makes it a lot easier to see always a
nice feature another beautiful benefit
of using jupyter notebook and let me go
ahead and show you a neat thing we can
do in Jupiter this is nice if you're
working with people and you're doing
this as a demo on a large screen I'm
going to do the hashtag or pound symbol
array manipulation kind of a title that
we're working on and then I'm going to
call this cell cell type markdown as
opposed to code and you'll see it
highlights it here and then if I run it
it just turns it into array manipulation
and then we're specifically going to be
working on array manipulation changing
shape to start with and we'll go ahead
and Mark this cell also a markdown so as
a nice little look there and then it
comes up and you can see it just like I
said it just highlights it it makes it
very bold print just making it easier to
read not a python thing but a Jupiter
thing that's good to know about
especially if you're working with the
shareholders since they're investing
money in you because the first thing you
want to do is import we're going to
import numpy
as in p and that should be standard by
now by now you you start a Python
program you're doing some data science
numpy is just something you bring in
there and let's go ahead and create our
array and we're going to do that as the
NP dot a range remember that's uh zero
well we're going to do 0 to 9.
and uh we'll print
a little title on the original array
we'll just print that array a remember
from the first lesson so we have our
array which is 0 1 2 3 4 5 6 7 8 and
let's add a print space in between
let's create a second array B but we
want this to reshape array a and what
does that mean
and the command is simply reshape and
then we have nine items in here and this
is so important right now so be very
aware if I did some weird numbers in
here it's not going to work
and we want multiples of nine we know
that three times three is nine so we're
going to reshape our a array by 3 by 3
and then we're going to print well let's
give it a title oops added too many
brackets in there modified array and
then let's go ahead and print
RB and let's see what that looks like
and as we come down here you can see
we've taken this and it's gone from 0 1
2 3 4 5 6 7 8 to an array of arrays and
we have 0 1 2 3 4 5 6 7 8. and so we
split this into three by three and you
can guess that if I tried to reshape
this let's just do a five by three which
is 15. that's going to give me an error
so it's not going to work you're not
going to reshape something unless the
shape all the the data in there matches
correctly
so we can take this nine this flat 9 and
we call it a flex it's just a single
array and we can reshape it into a three
by three array and first you may think
matrixes which this is used for that
definitely I use it a lot in graphing
because they'll come in that I have an
array that's X Y comma X Y 1 white 1
comma X2 Y2 and so the shape of it might
be two by the length of the number of
points and I need to separate that into
X flat array and a y flat array and you
can see this can be very easy to reshape
the array doing that and we can of
course go back we can do B
print
and we'll do B dot Latin remember I said
it's called a flatten array and if we
run that you'll see this goes back to
the original one it takes this zero one
two three four five six seven eight and
flattens it back to a single array
and then one other feature to be aware
of is if we flatten it one of the
commands we can put in there is order
let me just go ahead and do that order
equals
F strangely enough F stands for Fortran
they hold fourtran days I remember
actually studying Fortran programming
language in this case you'll see that it
uses the first like zero three six is
the order so instead of flattening it
like we had before zero one two three
four five six seven eight it now does
zero three six one four seven two five
eight and if you go to the numpy array
page you can see here that they have the
flatten and you just open up the numpy
and D array flatten setup to look it up
and they have three different options
they have c f and a and it's whether to
flatten in C which was based on how the
C code works for flattening originally
worked which is row major
Fortran which is column major or
preserve the column Fortran ordering
from a so whatever it was in the default
is the C version so the default that you
saw you could put orders equals c and
you'd have the same effect as we saw
there before you could even do order
equals a that would also have the same
effect because that's the default so
really the only other thing you need to
change on here is to change it to C if
you need it and you can see right here
or F I mean not C the only thing you
really want to change it to is to your f
for the Fortran order which then does it
by column versus by row and let's look
at here we go reshape so let's create a
range of 12
and let's reshape it
I will do 4 comma 3 for this one and
remember this is numpy I forgot the NP
there
NP dot arrange
and we can type in just a for print or
you can do full print a and of course
Jupiter notebook even have a little
extra print at the beginning we run this
we'll see we create a nice array of 0 1
2 it's reshaped it so we have four rows
and three columns or you could call that
three columns and four rows zero one two
three four five six seven eight nine ten
eleven
but this one is so important we'll do NP
transpose
a let's go ahead and run that
and it helps if I get all the s's in
there and don't leave an S out and
you'll see here we've taken our array if
you remember correctly we had 0 1 2 3 4
5 6 7 8 9 10 11 and we've swapped it so
we've gone from a three by four or a
four by three to a three by four
and this really helps if you're looking
at like a huge number of rows and the
data all comes in like let's say this is
your features in row one your features
in row two and this is x y z well when
you go to plot it you send it all of X
in one array all of one another one
array and all Z in another array
so it's really important that we can
transpose this rather quickly
this is kind of a fun thing I can
highlight it and do brackets around it
if you remember correctly
because we're in Jupiter it doesn't
matter where we do the print or not
it'll automatically print it for us and
you see if I hit the Run button it comes
up at the same exact thing and let's
play with the reshaping you know let's
end this up a little bit here
make that even bigger so you can really
see what's going on and let's play with
the reshape just a little bit more we'll
do b equals
NP dot a range let's do eight
reshape I'll do two comma four
let's go ahead and print B
and then run that
and you'll see we have now the two rows
this is a bit more like so we have four
maybe two rows of four things so this
might be all of our X components and our
y components so we can switch it back
and forth real easy important to note
here whether we do two comma four or in
the case of four comma three this has 12
elements and so however you split it up
it's got to equal 12. so 4 times 3
equals 12 that's pretty straightforward
same thing down here 2 times 4 equals
eight if I change this and let's say I
do two comma three let's just run that
in and you'll find we get an error
because you can't split 8 up into two
rows by three
we have to pick something that it can
split up and arrange it in so let's go
ahead and run that and just for fun
let's go um
reshape our B again if I can type
reshape our B again and what else goes
into eight well we could do two by two
by two
so we can take this out to three
different dimensions
and then of course if we um because this
is going to come out you as a variable
we can just go ahead and run it
and it'll print it we can also do a
print statement on there just like we
did before and you'll see we have two
different groups of two variables of two
different dimensions so two by two by
two and let's go ahead and assign this
to a variable C equals B reshape and
let's do something a little different
let's roll the axes roll
axes
and we'll take our C do two comma one
and if we go ahead and run this it's
going to print that out whoops
hit a wrong button there let's do that
one again and you roll the axis and you
can see that we now have a set of zero
one two three four five six seven we now
have the zero two one three four six
five seven
so what's going on here we're taking and
we're rolling the numbers around and
let's just simplify this we'll just do
it with C comma 1 and run that and so if
we roll a single axis you get 0 1
and then it rolled the four five up and
then we have two three six seven and if
we do two let me see what happens there
and this is one of those things you
really have to play with and start
feeling what it's doing
we've now taken 0 2 4 6 1 3 5 7. so you
can see we've now rolled by two digits
instead of rolling the one set up we now
rolled two digits up there and so if we
go back and we do the one
so we've rolled it up zero one four five
and then we're going to take the 2 in
there and we've rolled the 0 1 2 3 4 5
and 6 7. so we start rolling these
things around on here there's a lot of
different things you can do on this
what's another way to manipulate the
numbers on your uh numpy
and finally let's go ahead and
swap
axes we'll do c and let's just go ahead
and run that it's going to get an error
on there
that's because it requires a multiple
arguments left out the arguments so now
we can swap them we get the zero two one
three four six five seven so you can see
everything's been swapped around
so next thing we want to go over is we
want to go over numpy arithmetic
operations
how can we take these and use these let
me just go ahead and put this cell as a
markdown there we go we'll run that so
it has a nice thing all right nice title
on there that's always helpful
and let's start by creating two arrays
we'll do a as an EP NP
range a range nine and let's reshape
this
three by three so by now you should be
saying this reshape stuff and it should
all look pretty familiar we have our
zero one two three four five six seven
eight on there and let's create a second
one b and this time instead of doing a
range let's do NP array we'll just
create a straight up array
we'll do an array of three objects
so it's going to be three by one and if
we go ahead and print B out let me run
that this is actually pretty common to
have something like this where you have
a three by whatever it is in a three by
by three array when you're doing your
math you kind of have that kind of setup
on there
and what we can do is we can go
P dot add
a b don't forget we can always put a
print statement on there so if we add it
you'll see that it just comes in there
and it goes okay we're adding 10 to
everything and we could actually do
something more oh make it more
interesting 11 10 11 12. so it's change
B's now 10 11 12 and let's run that
and you can see that we have 10 and then
you had 1 plus 11 is 12. 2 plus 12 is 14
13 so 10 plus 3 is 13 11 plus 4 is 15
and 12 plus 5 is 17 and so on
we'll put this back since that's how the
original setup was let's do 10 by 10 by
10 and run that and run that and get the
original answer and if you're going to
add them together we need to go ahead
and subtract
a b
and we run that
we get minus 10 minus 9 minus 8 just
like you would expect so we have our
subtraction 0 minus 10 is minus 10 and
so on and if you're going to add and
subtract you can guess what the next one
is we're going to multiply
and we'll multiply
a b
and this should be pretty
straightforward you should expect this
if we multiply 10 times 0 we got 0 10
times 10 is 10 and so on
and finally if you're going to multiply
let's
divide
what happens when we do divide a by B
and we run this
we're going to get 0 and this is 0
divided by 10 is 0 1 divided by 10 is
0.1 2 divided by 10 is 0.2 and so on and
so on so that math is pretty
straightforward it just makes it very
easy to do the whole setup and again if
we went this and let's say let's change
this up up here instead of 10 we do a
hundred
and make this a thousand there we go if
we run that and then we do the add you
can see we got 10 plus 100 plus a
thousand same thing with the subtract
same thing with the multiply
then you can also see the same thing
here with the Divide so a lot of control
there with your array and your math
again let's set this back to 10 oops
it's right up here wrong section
there we go 10 and we'll just go ahead
and run these and get back to where we
were
and this brings us to our next section
which is slicing and let's put in our
just make this a
[Music]
of course it gives us a nice looking
slicing there and slicing means we're
just going to take sections of the array
so let's create an array NP a range
let's just do 20.
and if remember if we do a we have a 0
to 19.
and then we can do a and remember we can
always print these this can always be
put in a print but because I'm in
Jupiter if you're doing a demo in
Jupiter that is it's just so great that
you have all these controls on here so
we could slice four on and this should
look familiar because this is the same
as the python and a lot of other
different scripting languages if we do
four we'll go 0 1 2 3 as the first four
in the thing and the skip summon starts
with this one the first four Skip and
then from there on you can also do the
opposite
and go till the fourth one if we run
that we get 0 1 2 3 quite the opposite
on there we can do a single item so we
can pick object number five on the list
run that and five happens to be five
because that's the order they're in and
then this one's interesting because I
can do s equals slice
and let's create a slice here and let's
do two comma 9 comma
yeah let's leave a 2 on there so we'll
create an S Slice on here and then if we
take our array and we do array of s
we're taking our slice in there and
let's go ahead and run that and let's
take a look and see what it generated
here first off we started with two so we
have two at the beginning we're going to
end at 9 which happens to be eight so it
stops before the nine remember when
we're doing arrays in Python and then we
step two so two four six eight we could
do this as three let me run that and you
can see how that changes two five eight
and we could do this as let's leave this
at three and if we change this to 10
oops
12. there we go
and we run that we have 2 5 8 11. so
that's pretty straightforward it's a
very nice feature to have on here where
you can slice it and take different
parts of the series right out of the
middle so now that we've accessed the
different pieces of our array and let's
get into iterating iteration and this is
interesting because my sister who runs a
college data science division
first question she asks is how do you go
through data and she's asking can you do
you know how to iterate through data do
you know how to do a basic for Loop do
you know how to go through each piece of
the data and in numpy they have some
cool controls for that this has a
markdown there we go and run it
it's called the nditter
sure what the ND stands for but ND it or
for iterator
so before we do that though let's create
an array or something we can actually
iterate through we'll call it a equals
NP a range let's do something a little
funny here or funky
and we'll do 0 45 5. I'm not sure why
the guys in the back pick this
particular one was kind of a fun one and
if I run that we do this you can see um
we get 0 5 10 15 20 25 30 35 40. that's
what this array looks like
and this is from our slice you could
this is just a slice that's all that is
is we created a slice of 0 45 0 to 45
step five and so we can do with this we
can also do a equals reshape let's go
ahead and take and reshape this and
since there's nine variables in there
we'll do a reshape at three by three so
if we run that oops miss something there
that is the a that really helps so if we
do the a reshape and we'll go ahead and
print that out we get 0 5 10 15 20 25 30
35 40. and then we simply do four x in
our numpy ND enter of a
colon and we'll just go ahead and print
X and let's see what happens here when
we run through this and we print each
one of those
it goes all the way through the whole
array so it's the same thing we just saw
before we got 0 5 10 15 20 25 30 35 40.
so it prints out each object in the
array so you can go through and view
each one of these
and certainly if you remember you could
also flatten the array and just do for a
and that also and get the same result
there's a lot of ways to do this but
this is the proper way with the ND
iterator because it'll minimize the
amount of resources needed to go through
each of the different objects in the
numpy array
and hopefully you asked this question
when I just did that
and the question is how can I change
this instead of doing each object so
first of all let's go ahead and take my
cell type and Mark that down run it and
so we're going to work on iteration
order C Style
C because it came from the C programming
and that's because it came from the old
Fortran programming so let's give us a
reminder I will do a print a and we'll
do four x and NP iterate a but we also
want to do this in a specific order and
you know what I'm a really lazy typer so
let's go back up here
this is the ND iterator I know I'm
missing the ND part of a let's do order
equals
C we'll print X on there and let's do
that again and this time order
equals
f
let me go order equals F and let's go
ahead and run this
and see what happens here and the first
thing you're going to notice our
original array 0 5 10 15 20 25 30 35 40.
when we do order C that's the default 0
5 10 15 20 and so on and then when you
come down here
you'll see F order f is 0 15 30. so it
takes the first digit of each of the sub
arrays or the second dimension and then
it goes into the second one 520 35 10 25
40. so slightly different order for
iterating through it if you need to do
that so we've covered reshaping we
covered math we've covered iteration
we've covered a number of things the
next section we want to go ahead and go
over
is going to be joining arrays so we need
to bring them together let me go ahead
and take the cell and make it a markdown
cell type markdown there we go and run
that so let's work on joining arrays so
we can bring them together and what
different options we have
and let's do we'll do an NP array one
two comma three four
we'll go ahead and print
oops
first
these Rays aren't that big so let's just
go ahead and keep it all on one line a
so if we run this first array one two
three four whoops I forgot it
automatically wraps it when you do it
this way so we'll go ahead and keep it
separate
print a there we go and let's go ahead
and do a b
and we'll do five six seven eight and
notice I'm keeping the same shape on
these two arrays depending on what
you're doing those shapes have to match
let's go ahead and print
second array
print
B go and run that up
I've missed something up there let me
fix that real quick
and I was reformatting it to go on
separate lines I messed that up there we
go run all right so we have first array
one two three four secondary five six
seven eight
and we'll put a carried return on there
and the keyword we use is concatenate
and if you're familiar with Linux it
usually means you're adding it to the
end on there and we're going to do what
they call a long axis zero so we have
concatenate a b along axis zero let's go
ahead and run that and see what that
looks like
so we have one two three four five six
seven eight so now we have an array that
is four by two has a nice shape of four
by two one here
and if we're going to do it along the
axis 0
you should guess what the next one is
we're going to do it along the one axes
and let's see how those differ from each
other let's just go ahead and run that
and again all we're doing is adding in
the axes equals one so we have our
concatenate we have a b and then axis
one remember a couple things one these
are the same shape so we have a two by
two same dimensions going in there
you're going to get an error if you're
concatenating and they're not if you
have something that instead of one two
is one two three four five six with a
five six seven eight they'll give you an
error on there in fact let's take a look
and see what happens when we do that let
me just take this
one two three three four five and let's
run that and if we come down here up we
got there it says it says all the input
array Dimensions except for the
concatenation axes M must match exactly
so it will let you know if you mess up
that's always a good thing let's go
ahead and take this back here and let's
go ahead and run that
and so we have our zero axes which is
one two three four five six seven eight
let me bring them together and you'll
see a very different setup here when we
do it along the axis one we end up with
instead of uh four by two we end up with
a two by four one two five six three
four seven eight and this is changing
which axes we're going to go ahead and
concatenate on what I find is when
you're talking about the concatenate or
the joining arrays you really got to
play with these for a while to make sure
you understand what you mean by the axes
it looks very intuitive when you're
looking at it actually 0 1 2 3 4 5 6 7 8
axes one is then splitting in a
different way one two five six three
four seven eight
when you're actually using real data you
start to really get a feel for what this
means and what this does
so if we're going to do that let's go
ahead and look at splitting the array
and do that in a markdown and run it
there we go so you have a nice little
title there
and we'll go ahead and create an array
of nine
let's do NP split
we'll do a and we're going to split it
by three
let's just see what that looks like so
if we split it we get an array 0 1 2 3 4
5 we get three separate arrays on here
now remember we're looking at let me
just print a up here
so we're looking at zero one two three
four five six seven eight and then we
can split it into three separate arrays
and let's take this we're going to do
this right down here just move the a
split down here instead of the three
let's do four comma five put that in
Brackets
and so we do it this way we have zero
one two three four five six seven eight
and that's kind of interesting I wasn't
sure what to expect on that but we get
when you split an a by four comma five
you get a totally different setup on
here as far as the way it split the
array
and to understand how this works I'm
going to change the 5 to a 7. and this
will visually make this a little bit
more clear
so we had four and five I went zero one
two three four five six seven eight and
you see the markers four and five when
we do four and seven I get zero one two
three four five six seven eight and so
what you're looking at here is the first
markers this is going to go to four
so there's our first split at the four
the marker of four and then the second
split is going to be at position seven
and this is the same thing here a four
position five that's why we're splitting
it in those two sections we could also
do it seven let's just see what that
looks like run and you can see I now
have zero one two three four five six
seven eight
so we could split it in all kinds of
different ways and create a different
set of multiple arrays on here and split
it all kinds of different ways and
before we get into the graphs and other
miscellaneous stuff
let's go ahead and look at resizing the
array I'm going to take the cell and set
and set cells a markdown and run it
give us a nice title there and we'll do
an array an in Peru of one two three and
four five six here I'm just going to
just print
let's go print a DOT shape then we'll go
ahead and run that oops hit a wrong
button there
hit the comma instead of the dot so we
have a shape of two comma three here
and this is important to note because we
start resizing it it's going to mess
with different aspects of the shape
and so we'll go ahead and do a print
scoop in for a blank line there we go
let's do b equals
NP dot resize
we're going to resize a
and let's resize it with three by two
and then we'll just go ahead and
print
B
and print the period shape not a comma
I'll run that
oops forgot the quotation marks around
the end we'll go ahead and run that and
let's just see what that looks like so
we have one two three four five six
original array with the shape of two
three
and then we want to go ahead and resize
it by three two and we end up with one
two three four five six and we end up
with the shape of three two that
shouldn't be too much of a surprise you
know we got six elements in there we can
resize it by two three was the original
one and then we're actually just
reshaping is how that kind of comes out
as when you resize it like that
but what happens if we do something a
little different
and let's go ahead and just take this
whole thing and copy it down here so we
can see what that looks like
and instead of doing three two remember
last time I did the um to reshape it I
messed with the numbers and it gave me
an error but when you resize it you
don't have to match the numbers they
don't have to be the same dimensions so
we can instead of going from a 2 3 to a
3 2 we can resize it to a three three so
let's take a look and see how it handles
that and we come down here to 3 3 we end
up with one two three four five six and
it repeats one two three
so it actually takes the data and just
adds a whole other Block in there based
on the
and repeating it
all right now at this point you know
we've been looking at tons of numbers
and moving stuff around we want to go
ahead and do is get a little visual here
because it um
certainly you can picture all the
different numbers on there but let's
look at histogram let's put this into a
histogram let me go ahead and run that
and to do that we're going to use the
Met plot Library so from matplot library
we're going to import pipelot as PLT
that's usually the notation you see for
pi plot so if you ever see PLT in a code
it's probably Pi plot in the matplot
library
and then the guys in the back did a nice
job and gals too guys and gals back
there our team over at simply learn put
together a nice array for me 2087 4 40
53 with a bunch of numbers that way we
had something to play with and what we
want to do is we want to do plot the
histogram now remember a histogram says
how many times different numbers come in
and then we're going to put them in bins
and we have been 0 to 20 to 40 to 60 to
80 to 100.
you might in here with the matplot
library they call them bins you might
hear the term buckets or they put them
in buckets as a really common term then
we want to give it a title so the way it
works is you do your plt.hist for
histogram your PLT title and your PLT
show and we're doing just a single array
in here in the numpy array of a and
let's go ahead and run this piece of
code
taking a moment to come out there's his
finger size so it's generating the graph
and you can see we have and let's just
take a look at this and go down a size
there we go okay so now we can see we're
taking a look at here so between 0 and
20 we have three values so we have a 20
here we have a four and a 11 and a 15.
zero one two three it's actually Four
values but they start at zeros remember
we always count from zero up
and from 20 to 40 we got 20 this is 142.
3 4
5 6.
and so you can see in the histogram it
shows that the most common numbers
coming up is going to be between the 40
and 60 range least common between the 80
and 100 this looks like an age
demographics is what this looks like to
me and you can see where they would have
put it in the buckets of different age
groups which would be a nice way of
looking at this histograms are so
important and so powerful when you're
doing demos and explaining your data so
being able to quickly put a histogram up
that shows what's common and how it's
trending is really important and using
that with a numpy is really easy and you
know what let's take the same data and I
want to show you why we do bins or why
we have buckets of data I'm used to
calling it buckets why we have bins
let's do it instead of by 20 let's do it
by tens and see what happens
and what happens when you do it by tens
is you miss out on the you can see a
nice curve here on the first one and on
the second one it looks like a ladder
going up and a plummet a letter going up
and a plummet and a ladder going down
so the first would be more indicative of
an age group and the second one would be
what you would get if you divide it
incorrectly you wouldn't see the natural
trend
I don't know what this would be maybe
how much food they eat hopefully not
because I'm in 50 so I'm right in the
middle there that which means I eat a
ton of food compared to everybody else
but it's some kind of democrat maybe
it's mental maybe it's knowledge because
we we hit a certain point and we start
losing our marbles start leaking out or
something so you start off knowing
something and then as you get older you
grow more but you can see here we lose
that you lose that continuity in the
thing if you split the histogram into
too many bins or too many buckets
and if you actually plotted this by the
individual numbers it would just be a
bunch of dots on
it wouldn't mean a whole lot
and reflected graphs there turns out
there are a ton of useful functions in
numpy
I'm sure there's even new ones that are
aren't going to be in here but let's
just cover some important ones you
really need to know about if you're
using the numpy framework
one of them is Lane space function this
is generating data so you have a line
space we have one three ten and when we
do that we end up with 10 numbers so if
you count them there's 10 numbers
they're between 1 and 3 and they're
evenly spaced we get 1 1.222 but these
are all there's a total of 10 here and
it's right between the one and three
range
that could be there's a lot of uses for
that but they're probably more obscure
than a lot of the other common numpy
arrays set up
a real common one is to do summation so
we'll do summation where you do in this
case we create a numpy array of one of
two different arrays One Two Three or
two different dimensions one two three
three four five and we're going to sum
them up under axes zero which is your
columns and if you remember correctly
columns is the one plus three two plus
four three plus five so we have three
columns and if we change this we'll just
flip this to one
we get two numbers so we get one two
three all added together which equals
six and three plus four plus five which
equals twelve
that's a zero
there we go since it says we're looking
at zero
and these probably could have been some
of these could be used to start math
section square root and standard
deviation two very important tools we
use throughout the machine learning
process and data science and simply we
take the NP array we have again the one
two three four five six three four five
I don't know I need to keep recreating
it I probably could have just kept it
but we can take the square root of a so
it goes through and it takes a square
root of all the different terms in a and
we can also take the standard deviation
how much they deviate in value on there
and there's a ravel function we can run
that
and NP array is X we're going to do x
equals hey we changed it from a to x x
equals Ravel and this sets it up as
columns so we have one two three four
five this is all columns on here very
similar to the flattened function
so they kind of look almost identical
but we also have the option of doing a
ravel by column and then another one is
log so you can do mathematical log on
your array in this case we have one two
three and we'll find the log base 10 for
each of those three numbers there's a
couple of them they don't you can't just
do any number here after log but there
is also log base 2. log base 10 is
pretty commonly used on here I'm going
to run that there we go
before we go let's have a little fun
let's do a little practice session here
on some more challenging questions so
you start to think how this stuff fits
together right now we just looked at all
the basics and all the basic tools you
have so let's do some numpy practice
examples and let's start by figuring out
how do you plot say a sine wave in numpy
what would that look like and so in this
project we wouldn't have to do this
because I've already run these but we'd
want to go ahead and import our numpy as
NP and import our matplot library
pipelot as PLT so we get our tools going
here and then we'll break it into two
sections because we need our x Y
coordinates in here so first off let's
create our x coordinates and our x
coordinates we're going to set to an a
range
and we want this error a range since
we're doing sine and cosine it's going
to be between 0 and 0.1
and then we use our NP and we actually
can look up numpy stores Pi so you have
the option of just pulling Pi in there
directly from numpy it has a few other
variables that it stores in there that
you can pull from there but we have
numpy pi and we generate a nice range
here and let's go ahead and run this and
just out of curiosity let's see what x
looks like I always like to do that so
we have
0.1.2.3.4 so we're going 0 to in this
case 9.4 3 times numpy pi remember that
Pi is like three point something
something something that makes sense it
should be about nine and we're doing
intervals of 0.1 so we create a nice
range of data and then we need to create
our y variable and so Y is going to
Simply equal NP or numpy dot sine of X
and then once we have our X and Y and if
we print let's go and just print y you
can see all that we'll do this let's do
this so it looks print
X print y
so we basically have two arrays of data
so we have like our X axes and our y
axes going on there
and this is simply a
plt.plot because we're going to plot the
points and we'll do X comma Y and then
we want to actually see the graph so
we'll do plot dot show and we'll go
ahead and run that and you see we get a
nice sine wave and here's our number 0
through 9 and here's our sine value
which oscillates between -1 and 1 like
we'd expect it to then for the next
challenge let's create a six by six two
dimensional array and let one and zero
be placed alternatively across the
diagonals
oh that's a little confusing so let's
think about that we're going to create a
six by six two dimensional so the shape
is six by six two dimensional array and
let one and zero be placed alternatively
across the diagonals
now if you remember from lesson one we
can fill a whole numpy array with zeros
or ones or whatever so we're going to do
NP we'll create a numpy zeros and we're
going to do a six by six and we'll go
ahead and make sure it knows it's an
integer even though it's usually the
default and just real quick let's take a
look and see what that looks like so if
I run this you can see I get six by six
grid so six by six zero zero zero zero
zero
now if I understand this correctly when
they say ones and zero placed
alternatively across the diagonals they
want the center diagonal maybe that's
going to stay zero all the way down
and then the next diagonal will be ones
all the way across diagonally and then
the next one zeros the next one ones and
the next one zeros and so on hopefully
you can see my mouse lit up there and
highlighting it so let's take a little
piece of code here
and we'll do Z One colon colon two comma
colon colon two equals one and wow
that's a mouthful right there so let's
go ahead and run this and see what
that's doing and so what we're doing is
we're saying hey let's look at in this
case Row one there's one and then we're
going to go every other row two so we're
going to skip a row so skip here skip
here skip here so we're going down
this way and we're going every other row
going this way it's hard to highlight
columns so you can see right here where
the that we're not touching each row is
like this row right here is not being
touched okay so we're going to start
with Row one and then we're going to
skip a row and another one and so we're
going every two rows and then in every
two rows we're looking at every two
starting with the beginning that's what
this thing blank means so we're going to
start with the beginning and we're going
to look at all of them but we're going
to skip every two so starting with Row
one
we look at all the rows but we do we do
it by two steps so we go one Skip One
you know one Skip One One skip one one
if you lift this out and do every one
this would just be ones in fact let's
see what this looks like if I go like
this
and run it you can see that I guess get
ones
so this notation allows us to go down
each row row by row and we're going to
do every other row set up on there and
so if we're going to start with Row one
we also
control Z
try that there we go we'll start with
row zero again we're going to go each
row step two so we'll start with row
zero and we'll go every other row and
this time we'll start with one column
one and again we go every other one
going down
step that's what that step two is
skipping every other one we're going to
set that equal to one so let's see what
that looks like and you can see here we
get our answer we get zero one one zero
zero but it has the ones going in
diagonals on every other diagonal and
zero on every other one
a little bit of a brain teaser that one
trying to get that one to work out so
you can see how you can arrange your
rows and here's your step in your
different axis on there
and then the next one is find the total
number and locations of missing values
in the array the first challenge is to
create some missing numbers so let's
create our array Z we're going to do uh
numpy dot random dot Rand 10 comma ten
and before we do the second part let me
just take the second part out
and let's just see what that looks like
so let's run that and there we go so we
have a 10 by 10 random array it randomly
is picking out numbers
and next we want to go ahead and take
our random integer size equals 5. and
then we're going to do a random random
10 size equals 5. so in the Z we're
going to select a number of random
spaces here and set them equal to null
value
now let's go ahead and run that so you
can see what that looks like and if we
look at the array
we've created one two
three four this should be a fifth one in
here my eyes may be filling me so we've
created a series of oh because zero zero
to five zero one two three four so we
got five there are different null values
on here and
this is kind of a neat notation to
notice that we can generate
random integers size equals five so this
generates five by five miniature grid
inside of this to tell it where to put
the nands at so that's kind of a cool
little thing you can do
and we want to look up and see how many
null values are in there
and this is simply just NP is Nan of Z
simple so if it is nand then we want to
sum it up so we're going to sum up all
of the different null values on there
now let's do one one more feature in
here which is really cool
let's go ahead and print the indexes so
NP argue where NP is
Nan of Z so we're going to create our
own another NP array and let's run this
and we'll see here there comes up with
the four indexes so we didn't count four
of them up there
it tells you where they are one nine two
zero four six five four
and then let's go ahead and run this
again run run there we go this time I
got five let's get for random numbers
another fun one that I always like to do
it's very similar is we have NP is nand
z dot sum so we're summing the number of
nands and we can get the indexes and you
can reshape the indexes but you can also
just do we'll do an inds where NP is Nan
of Z
and let's just print let's print that
print inds let's see what that looks
like
and it's very similar we have we have
zero one three zero six three eight six
nine three if I have split it into two
different arrays
so we have our X and our y kind of
coordinates going there and what I can
now do is I can now do Z inds
equals and at this point you can also
instead of getting the sum you can get
the means or the well the numbers and
that kind of thing you have or the
average as it is so be one thing you
could do and you can pick up the average
that's very common in data science to
get the average and just use that for a
value
but we're going to set it to zero and
then let's go ahead and print our Z and
run that and you can see we come down
here we have wherever there was a null
value it is now zero
and you could set this whatever you want
this is another way to replace data or
help clean data depending on what it is
you're doing
so wow we covered a lot of stuff so a
quick rehash going over everything we
went into there we looked at array
manipulation changing the shape
how to switch that around we even had
the flatten down there which remember we
have another command lower that's
similar we could change the order by F
remember F stands for Fortran very
strange connotation but there's C and F
C is the standard and F switches it to a
different order
to be honest I usually have to look it
up because I almost never use f but when
you need it you're like oh my gosh it
was the other order just do a quick
Google so we talked about reshape making
sure that the dimensions are the same
you don't want to have like something
that has 12 objects in it and reshape it
to C 11 and 5 because it doesn't work it
doesn't divide into 12. we can transpose
so we can switch them so we can go from
a four by three to a three by four Oops
I did that the other way around
three by four to four by three
we covered reshaping the array we did
the roll the axes you can do some weird
things with swapping and rolling axes
and transposing the numbers
we dug a little bit into the arithmetic
so we talked about adding we talked
about subtracting multiplying dividing
and you know at this point it's so
important we just look up the numpy
mathematics and you can see here they
have just about everything your
trigonometry
uh your hyperbolic functions rounding
sums products differences there are so
many all these different miscellaneous
mathematical connotations so you know
Google it go to the main numpy page and
look at the different setups you can do
on there so we covered that and we did
slicing I just break it apart we did
iterating over the array we covered
joining arrays and how to concatenate
remember concatenate just means add-on
to it so in this case how are you adding
B onto a is how you'd read that from
Linux you should catch the concatenate
because that's used regularly there
splitting the array we talked about how
to split the array in different ways so
you can split it in Array of arrays all
kinds of different ways to split the
array up how to resize it and remember
resize does not have to have the same
shape but if you resize it it will take
the data and begin at the beginning and
add new rows on if the size is bigger if
it's smaller it truncates it it just
cuts the end off
we looked at how to do a histogram and
how to plot that
we mentioned buying buckets or bins as
they call them in pi plot and then we
covered a lot of other useful functions
in numpy we talked about the line space
setup for doing
um numbers in a series how to sum the
axes up again that's part of the
mathematical formulas there that we
looked at there's a sum there's also
means and median all of those you can
compute in numpy and you can also do the
square root and standard deviation
the Ravel function very similar to the
flat
to be honest I almost always just use
the flat but you know the Revel has its
own kind of functionality that it does
and then we went into some numpy
practice examples we challenge you to
create a sine wave in numpy and how to
do that we're kind of looking for that a
range remember how we do the a range and
you can
have your beginning value your n value
which they did is three times pi number
pi and we're going to do intervals of
0.1 and then y just equals the numpy
sine of x there's our math from the math
page we were just looking at remember
that's right at the top
and finally we went down here we had
this kind of a little brain teaser how
to do diagonal zeros and Ones playing
with the different connotations of Z of
the numpy array
and then we did a random size and we
played a little bit with how to with the
null values playing with null values
if you're doing any data science you
know null values are like a headache
what do you do with them big sets of
data you get rid of them small sets of
data you have to factor something in
there like figure out the average or the
median there and then replace it with
that
pandas really is a core python module
you need for doing data science and data
processing there's so many other modules
that come off of it there's actually
sits kind of on numpy so if you've
already had our numpy array hopefully
you've already gone through the numpy
tutorial one and two So today we're
going to cover what is pandas we'll
discuss series we'll discuss basic
operations on series and then we'll get
into a data frame itself basic
operations on the data frame file
related operations on a data frame
visualization and then some practice
examples roll up our sleeves and get
some coding underneath there and let's
start with just some real general what
is pandas pandas is a tool for data
processing which helps in data analysis
it provides functions and methods to
efficiently manipulate large data sets
now this is a step down from say using
spark or Hadoop in Big Data so we're not
talking about Big Data here but we are
talking about pandas when there is some
connections there's like an interface
going on with that so there is
availability but you really should know
your pandas because if you're working in
Big Data you'll know there's data frames
well pandas is a data frame primarily it
has a couple different pieces we'll look
at here and if you've never worked with
data frames before a data frame is
basically like an Excel spreadsheet you
have rows and columns you can access
your data either by the row or the
column when you have an index and
different that kind of setup and we'll
dig more into that as we get deeper into
pandas but think of it as like a giant
Excel spreadsheet that's optimized to
run on larger data on your computer and
then I said it that it's a data frame so
the data structures in pandas are series
one-dimensional arrays and then we have
data frame two-dimensional array and it
really centers around the data frame the
series just happens to be part of that
data frame and here's a closer look at a
pandas series series is a
one-dimensional array with labels it can
contain any data type including integer
strings floats python objects and more
so it's very diverse if you remember
from numpy we studied they had to be all
uniform not in pandas and pandas we can
do a lot more and pandas actually kind
of sits on numpy so you really need to
know both of those if you haven't done
the numpy tutorials and you can see here
we have our index one two three four
five and then our data a b c d and e
very straightforward it's just two
columns and we have a nice index label
and a column label for the data and then
a data frame is a two-dimensional data
structure with labels we can use labels
to locate data and you can see here we
had if we go back one we had our index
one two three four five so in each one
of these series they would share the
same index over there the row index so
you have your row index DF dot index and
then you have a column index df.columbs
and this is like I said this would be
really familiar if you've done any work
with spreadsheets Excel so it kind of
resembles that this does make it a lot
easier to manipulate data and add
columns delete columns move them around
same thing with the rows so you have a
lot of control over all of this now
we're of course going to do this in our
Jupiter notebook you can use any of your
python editors but I highly suggest if
you haven't installed Jupiter and
haven't worked with it it is probably
one of the best ways for easily
displaying a project you're working on I
skip between a lot of different user
interfaces or Ides for editing my Python
and it's just simply jupiter.org
j-u-p-y-t-e-r dot org and then I always
let mine sit on anaconda anaconda.com
and just real quick we'll open that up
for you oops offline mode don't show me
that again but you can see here that I
have different tools that I can actually
install in my anaconda including the
Jupiter notebook which comes by default
and then I have access to the
environments and again that's
anaconda.com named after the very large
one of the largest world's largest
snakes and then Jupiter notebook in this
case jupiter.org and when we're in our
I'm going to go in here to our jupyter
notebook and we're going to go ahead and
just do new and a Python 3 and this will
open up a Python 3 Untitled folder so
diving right in let's go ahead and give
this a title pandas tutorial and we'll
go up to cell and we'll change the cell
type to mark down so it doesn't execute
it as actual code one of those wonderful
tools when you have jupyter notebooks
you can do demos with this and let's go
ahead and import pandas and usually
people just call it PD that's become
such a standard in the industry so we'll
go ahead and run that now we have our
pandas has been imported into our
jupyter notebook
and then oh we can go ahead and let me
do the Control Plus since it's Internet
Explorer I can enlarge it very easily so
you have a nice pretty view oops too big
there we go and whenever you're working
with the new modules good to check your
version of the module in pandas you just
use the in this case PD dot underscore
underscore version underscore underscore
that's actually pretty common in most of
our python modules there's different
ways to look up the version but that's
one of the more common ones and we'll go
ahead and run that we get
0.23.4 and if we go to the pandas site
we see
0.23.4 is the latest release and of
course a reminder that if you're going
to an environment you need to install it
so you'll need to do pip install pandas
if you're using the PIP installer we'll
go and close out of that
and the first thing we want to do is
we're going to work with series a lot of
the stuff you do in series you can then
do on the whole data set we need to do
what create one we need to manipulate it
take pieces of it so query it query it
delete so you can delete different parts
of it so we want to do all those things
with the series and we'll start with the
series and then almost all the code in
fact all the code does transfer right
into
the actual data table so we go from a
series of a single list of one column
and then we'll take that and we'll
transfer that over to the whole table
and we'll start by creating let's put up
there we go creating a series from
list
and let's just call this ARR equals and
we'll do 0 1 2 3 4. if you remember from
our last one we could easily do R equals
range of five which would be zero to
four but we'll do R equals zero to four
and we'll call this S1 and we'll go PD
and series is capitalized this one
always throws me is which letters do you
capitalize on these modules they're
getting more and more uniform but you
got to watch that with python and we're
just going to go ahead and do ARR so
we're just going to take this python
list and we're going to turn it into a
series and then because we're in Jupiter
we don't have to put the print statement
we can just put S1 and it'll print out
this series for us and let's go ahead
and run that and take a look
and you'll see we have two rows of
numbers so the first one is the index
now it automatically creates the index
starting with zero unless you tell it to
do differently so we get 0 index row 0
is 0 1 1 2 2 3 3 4 4. and because it's a
series it doesn't need a title for the
column there's only one column so why
title it
and this also lets you know that it's a
data type of integer 64. so we print
this out this is our series our basic
series we've just created now let's do a
second series
PD and we'll use the same
data list and let's go ahead and do
order we'll give it an order equals oh
let's do it this way
let's go index equals order
and it helps if we actually give it an
order so we'll do order equals and let's
do one two three four five so instead of
starting with zero we're going to give
it an order starting with one we're
going to run that and we'll go ahead and
print it out down here S2
and we'll see that we now have an index
of one two three four five and that
represents zero one two three four in
the series and we're still data type
integer 64. and very common is you're
missing with numpy arrays is we can
import our numpy as NP remember that
from our numpy tutorials we can go ahead
and create a numpy at a random with the
random numbers of five and let's just
see what that end looks like so we can
see what our number looks like so we
have some nice random float values here
2.33 so on and this from our last
tutorial the numpy tutorial one and two
and instead of calling it order let's
call it index and we're going to set our
index equal to a b c d and e I want to
show you that the index doesn't have to
be an integer so it can be something
very different here and then let's go
ahead and create our we'll just use S2
again and here's our NP for numpy
series capital s
and N is our NP for numpy PD for pandas
there we go switching my anachronisms so
we have pd.series of N and we go and do
our index equals our index we just
created
and then let's go ahead and see what
that looks like S2 is a primit and let's
run that and we can see here we have a
nice Series going on a b c d and e for
our indexes so instead of it being 0 1 2
3 or 4 we can make this index whatever
we want and you can see the numbers here
going down that we randomly generated
from the numpy array so we use numpy to
create our Panda Series right here
and so continuing on with creating our
Series this one I use so often we create
a series from a dictionary so we have
our dictionary in this case we went
ahead and did a of one B is 2 C of three
D4 EF5 so each one of those is a key and
then a value and then we're going to use
oh let's use S3 equals PD for pandas
series and then we want to go ahead and
just do D in here
print out S3 here and let's go ahead and
run this and you can see we got a is one
B is 2 C is three D is four e is 5. and
it's still of integer 64 Because the
actual data is one two three four five
and it's all integers 64 type 64. and
the last thing we want to do in the
creating section of our series is to go
ahead and modify the index because we're
going to start modifying all this data
so let's start with modifying the index
of the series and if you remember let's
do a print this time S1
I'll go ahead and run this and the
reason I did print is because it only
prints out the last variable so if I put
S1 up here and we're going to do another
variable back down lower it won't print
the first one just the last one and
we're going to go ahead and take S1
the index and we're just going to set it
equal to a new index and obviously the
number of objects in our index has to
equal the number of objects in our data
and then because it's the last variable
we can go ahead and just do an S1 and
let's run that and you can see how we
went from 0 to 0 0 1 2 3 4 as our index
we've now altered it to a b c d and e so
this would be much more readable or
might be representational of a larger
database you're working with
So Cool Tools we've covered creating
database based on my basic array python
array we've showed you how to reset the
index
that we showed you how to use a numpy
array so you can put a numpy array in
there it's all the same you know
pd.series numpy array and then we can
set the index on there and the same
thing with the dictionary so it's very
versatile how it pulls in data and you
can pull in data from different sources
and different setups and create a new
series very easily in the pandas and
then we looked on changing your index so
now we have a new index on here
and then we want to go ahead and do some
selection let's do some basic
slicing most common thing you'll
probably do on here and we'll just do S1
this notation should start to look
really familiar again this is going to
put an output so I'd usually it doesn't
change S1 this just selects it so we
might do a equals S1 and then print a
and you'll see that it just looks at the
first three zero one two and we can do
the same thing by not having the a in
there I'll go ahead and take that out
but it's just a reminder that it's not
actually changing S1 it's just viewing
S1 so simple slicing on here and we can
likewise do an append oops before we do
a pin let's just do a quick kind of fun
one we'll do two minus one and you'll
see it covers everything but the E of
course you can do minus two on this side
so one another way to select it is to go
how far from the end and likewise we can
do a 2 here c d e to the end so it
starts at the second one and another way
we can do this is we can do a minus two
over here and that looks at just the
last two in the slice so you can see how
easy it is to slice the data and of
course there's no reason to do this but
you could select all of them if you
wanted to view all of them on there oops
32 there's not 32 so it's just going to
show the first three there we go and
then we can also append so I can take
and oh let's create another series and
append one to it and if you remember we
had S3 there's our S3 and we have our S1
I'm going to do S1
and let's go ahead and do let's call it
S4
equals S1
a pin S3
so we're just going to combine those two
into S4
and if we go ahead and print S4 on here
you'll now see that we have a b c d e a
b c d e zero one two three four one two
three four five because we started the
data at one so very easy to compend one
series to the next and if we're going to
append one series to the next we need to
go ahead and drop or delete one and drop
is a keyword for that and let's just do
e our index e and so if I run this
you'll see that it'll print it out and
ABCD there's no e and remember all these
changes if I type in S4 again you'll see
that S4 still has e in it so this change
does not affect the series unless you
tell it to so I'd have to do like x S4
equals S4 dot drop e and there's another
way to do that which we'll show you
later on let me just cut this one out
there we go all right so we've covered
all kinds of Cool Tools here we have
appending we have slicing we did all the
creating stuff earlier as you can see
here on the setup how easy it is to
manipulate the series
so next what we want to get into is we
want to get into
operations that happen on the series so
let me go ahead and change this cell to
mark down there we go and run so series
operations what can we do with the
series and let's start by creating a
couple arrays we'll call it array one
and we'll do 0 through 7 and array two
six through six seven eight nine five I
don't know let me through the five on
the end let's go ahead and run those so
those load up into Jupiter and we'll do
this a little backwards we're going to
do S5 equals a panda series of array two
so I'm doing this in reverse and then
when we do S5 you'll see that we have
zero to four it automatically assign the
index
67895 for our series and let's go ahead
and do the same and we'll call this S6
and we'll set this equal to PD series
for our first array and if we do an S6
down here to print it out
we'll see something similar I got zero
through six zero one two three four five
seven for the data so those are two
series we just created series six five
and six
and one of the first things we can do is
we can add one series to the next so I
can do S5 dot add S6 and let's see what
that generates and just a quick thing if
you've never used pandas what do you
think is going to happen with the fact
that this only has five different values
in it and this one has seven values
so let's see what that does and we end
up with 6 8 10 12 9 and it goes oh I
can't add this there's nothing there so
it gives us a null return very different
than the numpy that would have given you
an error this instead tells you there's
no value here because we couldn't
generate one so we can easily add S5 dot
add S6 and likewise we can do S5 Dot
sub for subtract S6 and we'll run that
and on the add the subtract and you
guessed it we're going to do multiply
and divide next again you can see
there's the null values where it can't
subtract the two because there's no
values there to subtract we can also do
S5 multiply mul they're all three
letters on these that's one of the ways
to remember how they figured out the
code for this so remember these are all
three letters mole we'll go ahead and
run this and you can again you can see
how they're multiplied together and then
we can also do the S5 div three letters
again S6 and run that
and you'll see here this goes to
Infinity because we have 0 in the wrong
position so it actually gives you a
whole different answer here that's
important to notice and then in the null
values because there's no data and it
can't actually produce an answer off of
null off of missing data and since we're
in data science let's do S6
median so let's look at the median data
which is simply median sorry for those
who are following the three letters
because median is not three letters and
you can see an S6 is 3.0 and let's do a
print here and we'll do median
or average S6
and let's print Max
S6 and just like median there's max
value and if we're going to have a max
value we should also have a minimum
value so let's pop in minimum
we'll go ahead and run this and you're
starting to see something that would be
generated like say an R where you're
starting to get your different
statistics we have a median value of
three max value of 7 and a minimum value
of zero and what it does when it hits
these null values if there is no values
in there because we could still do that
we could actually you know what let's go
up here and do
let's pick this one where we multiplied
let's go s seven equals
I'll go to print the S7 just so I keep
it nice and uniform so I still have my
S7 down there and run it and then I want
to take the S7
because S7 now has null values and an
Infinity value and let's see what
happens
this is going to be interesting because
I want to see what it is with infinity
and we end up with a median of six
maximum of 27 and minimum of zero which
is correct it drops those values so when
it gets to there and it doesn't know
what to do with them it just drops those
values and then it computes it on the
remaining data on there so that's
important to know when you're making
these computations you're looking at Min
and Max and median you're not going to
know that there's no values unless you
double check your data for the null
values that's a very important thing to
note on there so just a real quick
review on there we've done our created
our PD series and we've gone ahead and
done addition subtraction multiplication
division all those are three letters so
sub Min div add and then we looked at
median maximum and minimum so we're
going to go ahead and jump into the next
big topic which is to create a data
frame so now we're going to go from
series and we're going to create a
number of series and bundle them
together to make a data frame
there we go cell type markdown and
so we have a nice title on there it's
always good to have a good title all
right so our first data frame we'll jump
in with some stuff that looks a little
complicated we'll break it down first
I'm going to create some dates and you
know what let's just go ahead and do
this I want you to see what that looks
like what I'm creating here I've created
a series of dates PD date range and
we're going to use these for the index
okay so when you look at this you'll see
that it's just basically it comes out
kind of like a basic python list or
numpy array however you want to look at
it with our different dates going down
and we've generated six of them and it's
going to have whatever time it is right
now on your on the thing for the date
for the time that's that time stamp
right there and then you'll see we have
11 19 2008 11 20 11 19 and looking into
the future there so that's all this is
is generating a series of dates that
we're going to use as our index and this
is a pandas command so we have a date
range which is nice that's one of the
tools hidden in there in the handles
that you can use and next we're going to
use numpy to go ahead and generate some
random numbers in this case we'll do the
np.random.random and six comma four you
can look at this as rows and columns as
we move it into the pandas and of course
you could reshape this if you had those
backwards on your data but we want the
six to match the rows and we have six
periods so our indexes should match
along with the rows on there and then
you know before we do the next one let's
go ahead and just print out our numpy
arrays and see what that looks like here
we have it one two three four by one two
three four five six four by six so it's
a nice little setup on there and since
working with data frames can be very
visual let's give our columns we have
four columns and we're going to give
them names A B C and D so now we have
columns on there also and then let's put
this all together in a data frame and we
can actually you know what let's do this
since I did it with everything else
let's go ahead and do columns and you
can see there's our columns on there
and we'll go ahead and do df1 equals
pandas dot data frame and note that the
D and the f are capitalized series it
was just the S and I always highlight
this because you don't know how many
times these things get retyped when you
forget what's capitalized on there it's
a minor thing you'll pick it up right
away if you do a lot of it and the first
thing we want to do is we want to go
ahead and take our numpy array because
we're going to create our data frame off
of it's a numpy array and then we want
our index equal to our dates so there's
our index in there and then we also have
columns equals columns and then finally
let's see what that looks like now
remember we had all the different data
that just looked like a jumble of data
we have our column names and everything
else our numpy array kind of just a
jumble array over there four by six you
can sort of read it but look how nice
this looks I mean this is you come into
a board meeting you're working with your
shareholders
this is pretty readable this is you know
this is our date this is our a b c d
whatever it is maybe it's one of these
dates has your leads
closures lost leads total dollar made
you know whatever it is if it's in a
business maybe it's measurements on some
scientific equipment whether searching
material you know where this is like
high of the temperature low of the day
humidity of the day whatever it is so
you can see that we can really create a
nice clear chart and it looks just like
a spreadsheet you know we have our rows
and we have our columns and we have our
data in there now this one I use all the
time if we're going to create we can
create it like you saw here with our
numpy array very easy to do that and
reshape it you can also create it with a
dictionary array so here we have some
data and let me just go down a notch so
you can see all the data on there we
have an animal in this case cat cat
snake dog dog cat snake cat dog we have
the age so we have an array of Ages we
have the number of visits and the
priority was it a high priority yes no
and then we're going to take that we're
going to create some labels we have a b
c d e f g h i and what I want you to
notice on this is we have a title animal
and then we have basically a python list
and these lists they don't necessarily
have to be equal because we can have
non-data you know np.net numpy array
null value but we want to go ahead and
create labels that are equal to the
number in the list so a the first cat B
the second cat C the snake D the dog and
so on so we'll go ahead and create our
labels which we're going to use as an
index and we'll call this DF let's do it
this way we'll call this df2
equals PD for pandas data frame and then
we have our data just like we did before
and then we have our index equals
labels
and if we're going to go from there
let's go ahead and print it out so we
can see what that looks like df2 so
let's go ahead and run that and another
again you have a nice very clean chart
to look at we've gone from this mess of
data here to what looks like a very
organized spreadsheet very Visual and
easy to read animal age visits priority
and then a through J cats and all the
different animals so on and so on and
then when you do programming a lot of
times it's important to know what the
data types are so we can simply do df2
D types
and if we run that we can see that our
animal
is an object because it's just a string
but it comes in as an object age is a
float64 integer 64 and then priority
again is just an object
and exploring this this one's very
popular let's go df2 head and if we
print that out the df2 head Returns the
first five and we can change this you
don't have to do five you might want to
just look at the top two maybe you want
to look at let's see let's do six so
maybe we'll look at just the top six in
the database in your data frame and you
can actually this creates another data
frame so I could have a df3 equal to df2
and this now takes the df2 and just the
first six values so if we do df3
run get the same answer
and if we do it the head of the data we
can also do the tell it's the same thing
DFT you can look at the last we'll just
do the tell which by default does five
the last five and of course you can just
look at the last three of those real
quick just to see what's at the end of
the data and this is the tell I love
doing the tell of one because I'll have
like the index or something like that
and it will just show me the last
whatever the last entry was looking at
stock values and I might want to look at
just the last five days of the stock
values I can do that with the data frame
tail
and some other key things to look up are
the index so we can do df2 dot index
and I want you to notice that this isn't
a call function so if I put the brackets
on the end it'll give me an error
because index is not callable it's just
an object in there so we do df2 dot
index there's also columns
so we can go ahead and let's do uh let's
print this remember the first one is not
going to show unless I print it and then
df2 columns so now we can see we have
our indexes and we have our columns
listed here df2. columns animal age
visits priority that tells you what kind
of object it is or what kind of data
type it is and they're both object
and then finally df2 dot values and
again there's no brackets on the end of
df2.values because this is an actual
object it's not a callable function so
we'll go ahead and run that and it
creates this displays a nice array a
very easy way to convert this back to a
numpy array basically so before I go
into the next section let's just take a
quick look at what we covered so far
with the data frame we came up here we
created our data frame we did it from a
numpy array first setting the columns
and the index the index is setting it up
is the same as when we set up the series
so that should look very familiar so is
the whole format the numpy array the
index dates and the columns columns and
remember in our numpy array we're
looking at row comma column so six rows
four columns is how that reads in the
data frame
and we went ahead and also did that from
a dictionary in this case animal was the
column name with all the date data
underneath that column and then age with
that data visits that data priority that
data and then of course we added our
labels in there for our index so there's
no difference in there but it
automatically pulled the column names
important to know when you're dealing
with the data frame and importing a data
frame this way
and then we did looking up D type we
looked at head and tail looking at your
data really quick we also did index and
columns and values and note these don't
have the brackets on the end
so the next thing we want to do is go
ahead since we're dealing with data
science is we want to go ahead and
describe the data so we have def2 dot
describe to do that and we're going to
manipulate it in just a minute but let's
just see what this generates
and you can see right here we have age
and visits so looking at our data from
up above let me just go all the way up
here animal age business priority
and it does a nice job generating your
age versus visits which has all the data
you have your account your means your
standard deviation your minimum value 25
or in this group 50 75 and your maximum
value so this should look familiar as a
data science setup with your describe
for a quick look at your data Frame data
so let's start manipulating this data
frame and moving stuff around and we'll
start with transposing and it is simply
capital T for transpose and when we run
that it flips The Columns and the
indexes so now the indexes are all
column names and the columns are all
indexes animal age visits priority so if
we had come in here with our data shaped
wrong up above where we had a four by
six we can quickly just swap it if we
had it backwards not a big deal and we
can also sort our data so something that
you can't deal which is more difficult
to do with a lot of other packages and
the data frame is really easy to do take
our data frame df2 and we're going to
sort underscore values by equals age and
so when we run this you'll see the
default is ascending so we have 0.5 to
2.53 and everything else is organized so
if you look at your indexes they've been
moved around because each index it moves
a whole row not just the one piece of
data is not being sorted so a very quick
way to sort by age are different data in
the data frame and in addition to
sorting it we can also slice the data
frame so I could do df2 and this should
look familiar from earlier we'll just do
one to three so we're going to pull out
oops it does help if I use the DF
instead of just D and we're going to
pull up just between one and three so we
have not zero which is a we have B which
is 2 or B which is one and C which is
two so one two and then it does not
include 3 which is the standard in
Python and we can even do something like
this we can combine them which is always
fun because remember this returns a data
frame so if I take df2 dot sort foreign
values and we'll do by equals age this
is just kind of fun and then I'm going
to slice it there we go double check my
typing and run it and now you should see
fa because F A are now one and two on
there
I'm seeing very quickly create a whole
string on here which narrows it you know
that you can sort it then slice it and
do all kinds of fun things with your
data frame we'll just go back to the
original one run there we go and if we
can slice it by row we can also query
the data frame so we can do df2 and this
is a little different because I'm going
to create an array within an array and
in this case we're going to look at oh
let's do age comma
visits so look at the different format
in here we have one to three so we've
done this by slicing by an integer value
and then on here I've done df2 age comma
visits in an array and when I run this
you can see that we get just these two
columns on here we get age and visits so
it's a quick way to select just two
columns or select number of columns
you're working with
and if you stop there we did the slicing
almost identical to slice is I location
which uses the integer location one
comma three there's a push in pandas to
move to this particular setup instead of
doing just a regular slice and that's
because this can be confusing when we
slice one to three and then we select
agent visits so there is a push to go
ahead and move to an eye location which
does the same thing you can see here BC
it's the same as up above there's also a
copy command so we can do df3 equals df2
copy we're just going to create a
straight copy of it
next we do df3
that'll be the same as the df2 on there
so df3 equals df2 dot copy and then
let's do df3 dot is null so we're
looking for null values
and this will return a nice map and
you'll see that everything is false
except when you go up here under the cat
or H they had a null there and so if we
go to have a couple up here also
underneath of let's see the dog okay
there's a bunch of nulls in here there's
D up here so let's look at D down here
and you'll see false true there it is
there's our null value so we can create
a quick chart of null values you can use
this to do other things we can leverage
that null value to maybe take an average
or something and fill those null spaces
with data and we can also modify the
location so here's our df3 location
and notice this is location not I
location I location has I for integer
location uses the in this case the
variables on the left and what we can do
on here and we're going to set this
equal to one five and some I'll pick a
spot let's go back up here where we had
let's do F A just let's see what were
they looking at oh here we go let's do F
and age and up here f is set to age of
2.0 and we find out that that's
incorrect data so we go ahead and switch
to df3 equal and then we're going to
print out our df3
and if we go to F and H it is now 1.5 so
we're just changing the value in the D
of three and this is changing the actual
data frame remember a lot of our stuff
we do a slice and like it returns
another data frame this changes the
actual data frame and that value in the
data frame
so we've covered uh location and I
location is null making a copy here's
our I location which is equivalent of a
slice and also selecting columns so now
we want to dive just to take a little
detour here and let's look at df3 means
and this is kind of nice because you can
do this you can either do this by as you
can select a single column here by the
way you can just add the column
selection right here like we did before
so we could have age
look up the mean that just creates a
series if I run that there's our age
but if I take that out instead of
selecting it we can do the whole setup
and it has age and visits so why doesn't
it have priority or animal well those
are not integers so it's really hard
they're non-numerical values so what is
the average I guess you could do a
histogram which probably will look at
that later on but the only two things we
could really look at is age and visits
and we have the average or the mean on
the age is 3.375 and the mean on visits
is 1.9 and let's do df3
visits we'll go ahead and steal the
visits again
and remember all those different
functions we looked at for a series well
we can do those here we can do the sum
so if we run that we'll see that these
sum up to 19. we could also look up
minimum if you remember that from before
the minimum is 1 Max so all that
functionality is here so we'll just go
back to summing it up and adding it all
together so real quick we've shown you
how to take the series operations and
put them into the data frame and then we
can actually this is interesting one we
can just do df3 sum run and you'll see
the different summations on there it
just combines them I like the way it
just combines the strings on there for
priority and animal we've looked at is
null we've also looked at copying along
with the different slices which we
talked about earlier so let's talk about
strings let's dive into the string setup
on there and let's go ahead and create a
string series string equals PD series
and we just put it right in there we
have a c d a a b a c a popped in a null
value cow and Al I don't know why they
picked Cal and Al in the background
someone must like those animals and of
course we can just do string if we run
that you'll see leave the r out we'll
get an error but if we put it in there
you'll see that we have a simple series
0 a 1C 2D and it automatically indexes
it zero to eight and then we can go
string dot lower so when we're talking
about our data frame in this case or our
data series string in this case we use
the string function Str and we're going
to make it lower and we go ahead and put
the brackets on there and you'll see
that we've gone from capital a Capital C
so on to ABC and Baka CBA cow Al they
were all lowercase already and of course
if you want to go lower you can also do
upper and we'll go ahead and run that
and you can see we now have ACD AAA
everything's capitalized except for the
null value which is still null all right
so we looked at a few basic string you
can see that string functions upper and
lower we're going to jump into a very
important topic I'm even going to give
it its own header on here because it's
such an important topic what do you do
with missing values Panda has some great
tools for that so we'll dive into those
and we'll call we'll work with df4 and
if you remember the DF copy from above
we're just going to make a copy of df3
and let's just take a quick look at the
data we're working with oops df3 forgot
the three on there there we go so here
we have our cat snakes and dogs
hopefully not all in the same container
because that would be just probably mean
to all of them so we made a copy we're
going to be working with df4 and the
reason we made a copy is we want to go
ahead and fill the data and we just
simply do fill in a and then we're going
to give it the value we want to put in
there we'll go at the value 4. so I can
run in here and you'll see now that df4
now has where the N A was is filled with
the value of four same thing down here
a lot of times we'll compute the mean
first so I might do a mean page equals
df4 and then we want to go ahead and do
age
dot mean
and then I'll do something like this df4
I only want to select the age and I want
to fill that
with the mean h i run in there and
you'll see that our df4h now has the
means in there just a quick way of
showing you how you can combine these
and let me go back to our original one
there we go and run that and keeping
with good practices df5 equals df3 dot
copy
a little printer df5 which should be the
original one
and then on the df5 we can now drop our
missing data
so now simply drop in a and we're going
to use how equals any so I'm going to
drop any row that has missing data in it
and you'll see we had D here with
missing data and H and then let's go
ahead and see what df5 looks like when
we do that
there we go and there it is D is gone
and so is H so we create a new data
frame off of this missing those values
now if you have a lot of data dropping
values is a good way to take care of it
because you don't miss some data if you
have not a whole lot of data you're
working with like the iris data set or
something like that or something small
you want to start trying to find a way
to fill that data in so you don't lose
your computational power of the data you
got so just a quick look at processing
null values
or missing values you can fill them
usually with the means some people use
medium or the mode there's different
ways you can fill it one way is means
and we can also just drop those rows
those are the two main things we do with
missing data
here we go uh we're going to cover next
this is I so love data frames for this
file operations it saved me so much time
because they have so many different
tools for bringing data in and saving
data so we're looking at the data frame
file operations it's really streamlined
I don't know how many times I'll go on
to different data downloads and they'll
have Panda download standard on there
just because it's so widely used so
let's start with the most common file is
a CSV so we have df3 to CSV or animal
and let me just show you the folders
going into right now I have some
Untitled and a few things in here but
nothing labeled animal so we go ahead
and run this and this is now save the
animal to my hard drive and you can now
see the animal folder up here and if I
let's do edit with a notepad oh let's
open up with just a regular notepad
there we go or wordpad if I open that up
you can see it's comma separate did our
titles they don't have an index on the
categories on the top in the index comma
then all the different data is separated
by commas
standard CSV file on there and if we're
going to send it to CSV and notice the
format is dot 2 underscore CSV and it's
just the name of the file we're sending
it to you can also put the complete path
by default it's going to go whatever the
active directory this program is running
on that's why those other folders are in
there so we have our df3 to CSV and then
if we're going to put it in there we
want to also get it back out and we'll
call this one DF underscore animal
equals PD read underscore CSV I always
have to remember is two underscore CSV
and read underscore CSV I always want to
do like a capital in there and not the
underscore we're going in here again
it's the active directory so if I now do
print out my DF animal
and let's just do the head we only want
to look at the first three lines so if I
go ahead and run this we'll see the
first three lines and they should match
up here what we saved to our CSV so very
easy to save and import from our CSV
files on here
and it turns out DF 3 also has a two
Excel they actually have a lot of
different formats but you know old
school Excel was real popular for so
long still is we can go ahead and save
it as animal dot xlsx we're going to
call the sheet named sheet1 and then I
can also do DF we'll call it animal 2.
two and this one's going to come from
and the same format on here there we go
so we still have our animal xlsx
the sheet 1 that's where it's coming
from index columns equals none so we're
not going to we're going to suppress the
indexing on the columns n a values and
it'll just assign that zero one up on
your indexes so if it says index columns
equals none that's what it does and then
we've added null values because null
values in here and we want to just make
sure that they're marked as n a and
we'll go ahead and just print out the
animal animal to there we go and let's
run that let's make this let's just do
the whole thing so we'll go ahead and
run that and it probably doesn't help
that I completely forgot the read so
animal 2 equals PD dot read
Excel there we go Excel so now we go
ahead and run it and what we expect is
happening here we have the same data
frame on here and if I flick back to my
folder you can now see that we have the
animal one of these is in Excel and one
of these is a CSV on here and so there's
our two file Types on there and they
have other formats these are just the
two most common ones used and I don't
know how many times I've had stuff from
Excel I need to pull out if you've ever
played with Excel it's a nightmare on
the back end because of the way they do
the indexing
so this just makes it quick and easy to
pull in an Excel spreadsheet so we
looked at two different ways to bring
data in and save it to files we've
looked at all kinds of different ways of
manipulating our data set and slicing it
and creating it for our data frame let's
get in there put your visualization
always a big thing at the end because
one it lets you check to see what you
did make sure it looks right and then
also if you're going to show somebody
else it makes it very clear what's going
on if they see something visual so this
is where a really important part of data
science is so let's go ahead and bring
in our tools we're going to do import
numpy as NP we want to make sure we have
our Amber sign matplot library in line
this just lets Jupiter know that we're
going to print it on this page if you're
using a different IDE you don't really
necessarily need that but this does help
it displays quickly in Jupiter notebook
and if you remember for earlier we could
create a we're going to call it TS we're
going to create a pandas which are cute
cuddly creatures versus a pandem short
for pandemonium no so we have TS equals
PD series and we're just going to create
a random setup of 50. we'll do an index
we'll set it equal to the pandas date
range today periods equals 50. so the
50s should match and I want you to
notice something here I did not import
the matplot library why because it's
already in there pandas already has its
built-in connection and interface with
matplot Library so you don't have to
import it and we'll go ahead and do TS
equals TS dot cumulative sum we're going
to do the cumulative sum
it's a little reformatting there and
we'll go ahead and plot it and let's
take a look at what that looks like so
we have a nice graph here we have the
dates on the bottom we set this up so we
have a nice range between in this case
minus four to looks like about two maybe
or one minus four and one so what we've
done here we've plotted a basic series
just a single row of data and we've set
indexes on there but we can also do the
whole data frame on there and let's see
what that looks like so first let's go
ahead and create the data frame we have
here random number so we're going to do
50 by 4 and then we'll go ahead and
create columns a b X and Y just because
we can index is a ts.index on there so
we're going to use the same index as
before just to keep it nice and uniform
we've already generated the dates to go
with it and then we can do just like we
did with the series we can also do with
the data frame
DF equals DF cumulative sum so we're
going to sum the whole data frame and
then we'll do simply DF plot and this
puts that in and let's go ahead and run
this and look how easy and quick that
was to generate a nice graph with all
the different data on there so we have
our shared index we have the shared
columns and then we have the different
data from each one that we can easily
look at and compare so very quick way of
displaying data you can imagine if you
were working in oh I think I mentioned
stock earlier because I've been doing
some analysis of stock lately so you'd
have your date down here and then you
would have stock a Stock B stock X Y
whatever it is and you can put them all
in one chart and see how they what they
look like next to each other and this
isn't too far off from what some of
those graphs looks like and this is just
randomly generated so stock has a lot of
Randomness in it which is one of the
reasons I actually play with it for
doing some of my models on for testing
them out now there are a lot of features
in pandas so we're going to show you one
more thing on here there's some of the
things like I didn't go too deep we
looked at the top two for importing data
from a CSV and from an Excel spreadsheet
showed you how to quickly plot the data
there's more settings in there you can
do we're going to do one more thing down
here and this is kind of a fun one
changes to a mark down and run that so
how would you remove repeated data using
pandas
and this is where you have a data set
that comes in and maybe it's feeding
from one location and in instead of
noting that it's repeated the date like
oh let's go back to stocks that's a good
visual we have the stocks from the 23rd
and it adds another row and it's the
same row it's importing the 23rd again
and again so now you have that data
repeated three times and you need to go
back and figure out how to get rid of it
how do you track that down so let's
start by creating a quick database our
data frame not a database I keep saying
databases the data frame and we'll just
make this data frame has using our
dictionary going in this data frame only
has one data Series in it which is fine
so if we do DF to print it out you'll
see a one two two two two four five six
seven and so on and so how would you
remove that well there is a neat feature
in data frames called shift
along with another feature that lets us
select just certain information and
we'll go with the location function put
that in Brackets remember that from
above location and then in the location
let me just spread this out a little bit
so it's really easy to read in fact I'm
going to go upscale on that since we're
doing some a little bit more complicated
here
what you can see on this on the location
is I have DFA dot shift so this is going
to shift up one by default you can
actually change this to two or three you
could even do a minus one and it shifts
the other way but it's going to shift up
by one by default that's going to say if
that does not equal DF of a then we want
that if you look down here we had one
two two two two when we run this Logic
on here and we do the shift it now gets
rid of all the duplicates so we went
from one two two two two two four four
five whatever it was here it is one two
two two four four four five five five
six six six two one two four five six
seven eight and you'll see on the index
it just deletes them out of there so the
index stays the same obviously you don't
want the dates to change if you're
working with an index dated setup so it
just deletes those duplicates out of
there this is just a quick way to
introduce you to one the fact that you
can add logic gates into here and two
the I location allows you to use shift
so there's the shift function and then
the I location selects that based on
true or false
wow so we've actually covered a lot
today in pandas we've really covered
into the basics of selecting your
different series out of your column out
of your data frame how to index rows how
to slice how to plot hopefully you'll
take this beyond that and start
combining these different things and you
can create long strings and really
explore your data generate some nice
graphs if you're in Jupiter notebook
it's a great demo to show others and I
didn't know this about Jupiter notebook
you can do this in Jupiter notebook and
then you can download and I always I
never really look too closely at all the
downloads but you download as an HTML
and post it to your blog so it's got a
neat feature in there but any of this is
really powerful tool all of this is
really powerful tools for doing your
if you're an inspiring data analyst
looking for online training and
certifications from prestigious
universities and in collaboration with
leading experts then search no more
simply lens post graduate program in
data analytics from Purdue University in
collaboration with IBM should be a right
choice for more details use the link
mentioned in the description box below
So currently I am on my MySQL workbench
let me connect to the local instance
so I'll give my password
and click on OK
all right so this is my my SQL workbench
query editor so first we are going to
learn sub queries let me give a comment
and write sub queries
all right
so first of all let's understand what a
sub query is so a sub query is a query
within another SQL query that is
embedded within the where Clause from
clause or having clause
so we'll explore a few scenarios where
we can use sub queries so for that I'll
be using my
database that is SQL underscore intro so
I'll write my command use SQL underscore
intro now this database has a lot of
tables I'll be using the employee stable
that is present inside SQL underscore
intro Let me just expand this and you
can see here we have an employee stable
so let me first show you
the contents within this table I'll
write select star from employees
let me execute it
okay you can see here we have the
employee ID employee name each gender
there's date of joint Department City
and salary and we have information for
20 employees if I scroll down you can
see there are 20 employees present in
our table
so let's say you want to find the
employees whose salary is greater than
the average salary
in such a scenario you can use a sub
query so let me show you how to write a
sub query
I'll write the select statement
in the select statement I'll pass
by column names that I want to display
so the column names I want are the
employee name
that I want the department of the
employee and the salary of the employee
from
my table name that is employees
next I'll use a where condition where
my salary should be greater than the
average salary of all the employees so
I'll write salary greater than
after this I am going to write my sub
query
so I'll give select
average of salary
from
my table name that is employees
and I'll close the bracket and give a
semicolon
so what it does is
first it is going to find the average
salary of all the employees that are
present in our table
once we get the average salary number
we'll use this where condition where
salary is greater than the average
salary number
so
the inside sub query let me run it first
if I run this
this gives you the average salary of all
the employees which is 75 350 dollars
now I want to display all the employees
who have salary greater than 75
350 dollars so let's run our sub query
there you go so there are eight
employees in our table who have a salary
greater than the average salary of all
the employees
all right
next
let's see another example
suppose this time you want to find the
employees whose salary is greater than
John's salary
so we have one employee whose name is
John
let me
run the table once again
okay if I scroll down
you see we have an employee
as John
you see this our employee ID 116 has
John and his salary is sixty seven
thousand dollars I want to display all
the employees whose salary is greater
than John's salary so basically all the
employees who are earning more than 65
000 I want to print them
so let's see how to do it I'll write
select
I want the employee name comma the
gender of the employee
I also want the department and salary
from my table name that is employees
I'll write where
salary is greater than
I'll start my
opening bracket inside the bracket I'm
going to give my inner query that is
Select
salary
from employees
where
the employee name is John
So within single quotations I'll give
John as my employee
and end with a semicolon
so
let me first run my inner query
so this will give us the salary that
John has which is sixty seven thousand
dollars now I want the employees who are
earning more than sixty seven thousand
dollars so let's run our
sub query
okay so you can see
12 rows returned which means there are
12 employees in our table who are
earning more than sixty seven thousand
dollars you see here all these employees
have a salary greater than sixty seven
thousand dollars
okay
now
you can also use sub queries
with two different tables so suppose you
want to display some information that
are present in two different tables you
can use sub queries to do that
so
for this example we'll use
a database that is called classic models
you can see the first database
so let me use this database called
classic Model so I'll write use classic
models
now this database was actually
downloaded from the internet there's a
very nice website I'll just show you the
website so this is the website that is
MySQL tutorial.org
you can see here they have very nice
articles blogs from where you can learn
MySQL in detail so we have
downloaded the database that is classic
models from this website you see here
they have a MySQL sample database if you
click on this
it will take you to the link where you
can download the database so they have
this download link which says download
MySQL sample database
and the name of the database is classic
models all right
so we are going to use this classic
models database throughout our demo
session
if I expand the tables
section you can see there are a lot of
tables that are present inside this
classic models database we have qriket
customers as employees
office there's orders order lines and
many more
so for our sub query we'll be using two
tables that is order details and
products table first let me show you the
content that is present inside
the products table first
if I run this
you see here it says 110 rows return
which means there are 110
different products that are present in
our table which has the product code the
product name
product line we have the product vendor
description quantity in stock Buy price
MSRP
the other table we are going to use is
order details which has the details of
all the orders
let me show you
the records
order details tables has okay so there
are thousand records present in this
table you have the order number the
product code quantity ordered price of
each item you have the order line number
as well
okay
now
we want to know the product code the
product name and the MSRP of the
products whose price of each product is
less than hundred dollars for this
scenario we are going to use two
different tables and we are going to
write a sub query
okay
Okay so
if you see here in the order details
table we have a column called price each
I want to display the product code the
product name and the MSRP of the
products which have a price of each
product less than hundred dollars
so the way I'm going to do is
I'll write select
product code comma
product name now one thing to remember
that this product name is actually
present inside our products table
and product code is present in both the
tables that is production order details
here you can see this is the product
code column
comma MSRP which is present inside the
product stable again
from my table that is
products
where
I'll write
product
code
I'm going to use the in operator
next I'll write my inner query that is
Select
product code
from my table
order details
where
my price of each product
is less than 100 dollars
let me run this
okay so you can see there are total 83
products in our table which have
a price less than hundred dollars you
can see the
price here
okay
now we learn another Advanced Concept in
SQL which is known as stored procedures
I'll just give a comment saying
stored procedure
okay
so first let's understand what is a
stored procedure
a stored procedure is an SQL code that
you can save so that the code can be
reused over and over again
so if you want to write a query over and
over again save it as a stored procedure
and then call it to execute it
so in this example I want to create a
stored procedure that will return the
list of players who have scored more
than six goals in a tournament
so I have a database called SQL
underscore IQ
these are a few databases that I've
already created so this database has a
table called players if I expand the
tables
option you see we have a table called
players and you can see the columns
player ID the name of the player the
country to which the player belongs to
and the number of goals each player has
scored in a particular tournament
so I'll write a stored procedure that
will return the list of top players who
have scored more than 6 goals in a
tournament so first of all let me Begin
by
using MySQL underscore IQ database
we'll run it
so now we are inside the SQL underscore
IQ database
let me
select
star from players to show the
values that we have in the players table
you can see there are six players in our
table
we have the player ID
the names of the players the country to
which these players belong to and the
goals they have scored
so I'll write a stored procedure
so the stored procedure syntax is
something like this it should start with
a delimiter
okay
in the delimiter I'll write
ambition ampersand
next I'll write
create
procedure
followed by
the procedure name let's say amount to
name my procedure as top underscore
players
okay
next statement is begin
after begin I'll write my select
statement
I want to select the name of the player
the country
and the goals
each player has scored
from my table that is
players
where
I'll write goals is greater than
6.
will give us semicolon
then
I'll end my
procedure with a delimiter that was
double ambison
next
I'll write
delimiter
and give
a semicolon
now the semicolon suggests
this is a default delimiter
there should be a space okay
now let's run our
stored procedure
there you go so you have successfully
created a store procedure now the way to
run a stored procedure is
you need to use the
call method and give the procedure name
that is top underscore place in our case
with brackets and a semicolon
let's execute it
okay there is some problem here
so we made a mistake while creating a
procedure
the name of the column is goals and not
goal
let me create that procedure again
okay it says the procedure top
underscore player already exists let's
just
edit the procedure name instead of top
player we'll write it as top players and
similarly we'll edit here as well
now let's create it again
okay
now to
call my procedure I'll write call space
followed by the procedure name which is
top underscore players if I run this you
can see
we have two players in our table who
have scored more than six goals so we
consider them as the top players in a
particular tournament
all right
now there are other methods that you can
use while creating a stored procedure
one of the methods is by using an in
parameter
so when you define an in parameter
inside a stored procedure the calling
program has to pass an argument to the
stored procedure
so I'll give a comment
stored procedure using in parameter
all right
so for this example I'll create a
procedure that will fetch or display the
top records of employees based on their
salaries
so if you have a table
in our SQL underscore IQ database which
is called employee details
I'm going to use this table you can see
we have the name of the employee the age
sex then we have the date of joint City
and salary
using this table I'll create a procedure
that will fetch or display the top
records of employees based on their
salaries
and we'll use the in parameter so let me
show you how to do it
I'll write
delimiter
this time I am going to use
forward slash
I'll write
create
procedure
followed by the procedure name let's say
SD for stored procedure
sort by
salary is the name of my procedure
and inside this procedure I'll give my
parameter
in
I'll create a variable VAR and assign a
data type integer
then I'll write begin
followed by my select statement where
I'll select the name
each
salary
from
my table name that is
EMP details or employee details
I am going to order this by
salary
descending
and
I want to display
limited number of
records so I'm using this
limit keyword and my variable VAR which
I
created here
I learned my select statement
I'll end my stored procedure with
forward slash
and I'll go back to my default delimiter
that is semicolon
all right
so let me
run this
there should be a space here all right
so let's run this
okay you can see we have successfully
created our
second stored procedure which is sp
underscore sort by salary
now you can also check whether the
stored procedure was created or not here
you have an option to see the stored
procedures let me just refresh this
and you can see we have
three stored procedures that we have
created so far one is sp underscore sort
by salary
the other two were top underscore player
and top underscore players
okay
now let's call our stored procedure I'll
write call
space followed by the stored procedure
name which is sp underscore sort
by salary
and inside this I'll give my parameter
which was actually VAR and this VAR
we have used in limit
let's say I want to display only the top
three records of the employees who have
the top three highest salaries
okay so let me run it
there you go so Amy Sarah and Jimmy
where the top three employees who have
the highest salary
so you saw how you could use the in
parameter in a stored procedure
we created a variable and that variable
we used in our select statement and we
called our stored procedure and passed
in that
variable
okay
now
instead of a select statement inside a
stored procedure you can also use other
statements let's say update
so I'll create a stored procedure to
update the salary of a particular
employee
so in this procedure instead of Select
statement we'll use the update command
in this example we'll use the in
operator twice
so let me show you how to do it
I'll write my delimiter first which is
going to be forward slash then I'll
write create
procedure
my name of the procedure is going to be
update salary
and inside the
update salary name
I'll write in
and then
temp
underscore name which will be a
temporary name variable and the type
I'll assign is worker 20
I'll again use my in parameter I'll
write in
next
my other variable would be new
underscore salary
and the data type would be float
I'll write begin
and write my update
command or update statement I'll write
update
table name that is employee details set
salary
equal to
new underscore salary
where
name is equal to
my temporary variable that is temp
underscore name
so this is my
update command and I'll
end the delimiter
all right
so let's run this
okay we have successfully created our
stored procedure if I refresh this
you can see I have my stored procedure
update underscore salary
okay
now let's see
first of all I'll
display
my
records that are present inside
employee underscore details table okay
so we have six rows of information let's
say you want to update the salary of
employee Jimmy or let's say
Mary
from seventy thousand to let's say
seventy two thousand
or let's say eighty thousand
so I'll
call my stored procedure that is update
underscore salary
and this time I'm going to pass in two
parameters the first parameter will be
the
employee name and next with a comma I'll
give my new salary that I want to
so my employee name let's say is Mary
and the salary I want
to be updated is let's say eighty
thousand dollars
we'll give a semicolon
and I'll run it
you can see it says one row affected now
let's check our table once again
there you go if you see this record
for Mary we have successfully updated
the salary to eighty thousand dollars
now moving ahead
we learned to create a stored procedure
using the out parameter so I'll give a
comment
stored procedure using out parameter
okay
so suppose we want to get the count of
total female employees
will create total employees as an output
parameter and the data type would be an
integer
the count of the female employees is
assigned to the output variable which is
total underscore emps using the into
keyword let me show you how to write a
stored procedure using the out parameter
so first I'll declare my delimiter
to forward slash
I'll write
create
procedure
followed by the procedure name
it is going to be SP underscore
count
employees
and inside this I am going to give my
out parameter and the variable name that
is total underscore
emps which is total employees and the
data type will be integer
next I am going to write begin
followed by my select statement that is
Select I want the
count of total employees
and the output I am going to put into
my new variable that is total underscore
emps
from my table that is EMP underscore
details
where
sex is equal to
F which means female
I'll give a semicolon
next I'll end it
with the developmenter and I am going to
change the delimiter to a default
delimiter that is colon
so let me tell you what I am doing here
I am creating a new stored procedure
that is sp underscore count employees
using this stored procedure I am going
to count the total number of female
employees that are present in our table
EMP underscore details so I've used my
out parameter and I'm creating a new
variable called total underscore emps
the data type is integer here in the
select statement I am counting the names
of the employees and the result I am
storing it in total underscore emps
I have used my wear condition where the
gender of the sex is female
so let's run this
okay so we have created our stored
procedure
let's refresh this
okay you can see we have a new stored
procedure SP underscore count employees
now
to call it I'll write call
the name of the procedure that is Count
underscore SP underscore count
employees
within brackets I'll pass in the
parameter as
at the rate
F underscore EMP
will give a semicolon then I'll write
select
at the rate F underscore
EMP as female employees
okay
so as is an alias name let's run this
one by one first I'll call my procedure
and then we'll display the total number
of female employees you can see in our
table we have three female employees
all right
now with this understanding
let's move on to our next Topic in this
tutorial on Advanced SQL now we are
going to learn about triggers in SQL
so I'll give a
comment here
triggers in SQL
so first let's understand what is a
trigger so a trigger is a special type
of stored procedure that runs
automatically when an event occurs in
the database server there are mainly
three types of triggers in SQL we have
the data manipulation trigger we have
the data definition trigger and login
triggers
in this example we'll learn how to use a
before insert trigger
so we will create a simple students
table that will have the student's rule
number the age the name and the students
marks
so before inserting the records to our
table we'll check if the marks are less
than zero
so in case the marks are less than zero
a trigger will automatically set the
marks to a random value let's say 50.
so let's go ahead and create our
table that is
students
all right
so I'll write
create
table
student
now this table will have the student
rule number
the data type is integer
it will have the age of the students
again the data type is integer we have
the names of the students so the third
column would be
name
the data type would be variable
or varying character
size I am giving it as 30 finally we
have the marks as floating type
so let's create this table which is
student
so we have created our table
now
I'll write my
trigger command
so trigger command will start with
delimiter like how our usual stored
procedures have
next
time I'll write create trigger
then you need to give the
name of the trigger that is Mark
underscore
let's say verify
I am going to use a before insert
trigger so I'll write before insert
on my table name that is student
next I'll write for each row
if
new DOT marks
is less than 0
then
we'll set
new DOT
marks equal to 50.
so this is my
condition first we'll check
before inserting if any student has
marks less than 0 we'll assign a value
50 to that student because usually the
marks are not less than 0 in any exam
I'll write end if
semicolon and I'll close the delimiter
so this is my
trigger command I'll run it
it says triggle already exists
so in this case we need to update the
trigger name let's say
I'll write marks underscore verify
underscore
student for St
let's run it again
okay there is an error here because
in our table the column name is Mark and
not marks so here we need to change it
as Mark instead of marks
all right
let's run it
okay so we have created our trigger
now
let me insert
a few
records to the student table
so I'll write insert into student
I'll write
values
and give the values as
501 which is the student roll number the
age is let's say 10
the name is it's a Ruth
and the marks is let's say 75 point
zero
if a comma we'll insert our second
student record
student rule number is 502
age is 12
the name is let's say Mike
and this time I'm purposely giving a
value of minus 20.5
give another comma
we'll insert the Third
record
for student rule number 503
age is 13
the name is Dave
and
let's say the marks obtained by Dave is
90
now we'll insert our final record for
student number
504
these is 10
name I'll enter as Jacobs
and this time again I'm purposely giving
the marks in negative
12 point let's say 5.
close the bracket and give a semicolon
and I'll run my insert statement okay so
we have inserted four rows of
information to our student table
now
let me run the select query I'll write
select star from student
if I run this you see the difference
there you go
so originally we had inserted
for 502 the marks was minus 20.5 and for
504 for Jacobs the marks was minus 12.5
our trigger automatically converted the
negative marks to 50 because when we
created our trigger we had set our marks
to 50 in case the marks were less than
zero
so this is how a trigger works
now you can also
drop a trigger or delete a trigger you
can just write drop trigger followed by
the trigger name in this case our
trigger name is
St
I'll just paste this here
and if you run this it will
automatically delete your trigger
give this as a comment
okay
now moving on
now we are going to learn about another
crucial Concept in SQL which is very
widely used
this is known as views so views are
actually virtual tables that do not
store any data of their own but display
data stored in other tables
views are created by joining one or more
tables
I'll give a comment as views in SQL
okay
now
to learn views I am going to use my
table which is
present inside classic models database
now this database as I mentioned we have
downloaded
we had downloaded it from the internet
so first of all let me write
use classic models so I'll switch my
database first
all right now we are inside classic
models so here
let me show you one of the tables which
is called customers so I'll write select
star from customers
okay
I missed s here
let's run it again so this is my
customer table which is present inside
classic models database it has the
contact last name the contact first name
the customer name customer number we
have the address State country and other
information
now I'll write a basic view command
using this custom table the way to write
is I'll write create
View
followed by The View name which is cast
underscore details
then you write as
select
I am going to select a few column names
from my original customer table which is
this one so I need the customer name
let's say I need the phone number
and the city so you have this
information here you have the phone
number and the City
all right
I'll write from my table that is
customers
if I run this
my view that is cast details will be
created
let's run it there's some error here
because the name of the table is
customers and not customer
I'll give an S and I'll run it again
all right so you can see we have created
our view
and to display the contents that are
present inside our view I can write
select star from followed by The View
name that is cast underscore details
let's run it
there you go so we have the customer
name the phone number and the City of
the different customers that we have in
our table
all right
now let's learn how you can create views
using joins so we'll join two different
tables and create a view
so for that I am going to use my
products table and the products lines
table I am talking about the product
stable and the product lines table
present inside classic models database
so before I start let me display the
records that are present inside the
products table
let's run it so these are the different
products you can see here
now let's see what we have in product
lines table
so we have the product line the text
description and there's some HTML
description and image
so
I'll create a view by joining these two
tables and will fetch specific records
that are present in both the tables
so let me first start by writing create
View
followed by The View name that is
product underscore
description
as I'll write
select
product
name
comma
then I'll write
quantity
in stock
I also want the MSRP
now these three columns are present
inside the products table and next from
the
product lines table I want the text
description
of the products
so I'll write from
products table
I'll give an alias as p
followed by Inner join my other table
that is
product lines as let's say PL
on
the common column that is product line
so P Dot
product line
is equal to
I'll give a space
PL Dot
product line
okay
so here we have used an inner join to
fetch specific columns from both the
tables
and our view name is product underscore
description let us run it all right so
we have our view ready
now let me
view or display what is present inside
our product underscore description
View
I'll hit select start from
product underscore description
let's run it
there you go so we have the product name
the quantity in stock msrpn textual
descriptions of the different products
in the table
okay
now there are a few other operations
that you can perform let's say you want
to rename a view instead of product
underscore description you want to give
some other name
so I'll just give a comment rename
description
so to rename a description you can use
the
rename statement I'll write rename table
product
underscore description Which is my
old name
I want to change this name to let's say
I'll give vehicle description
since
all our products are related to some of
the other vehicle so I'll write vehicle
description
okay
let us run it
all right so here you can see I have
renewed my
View
so here if I just refresh it
and I'll expand this you can see we have
the cash details view and we have the
vehicle underscore description View
okay
now either you can view all the views
from this panel
or you can use a command let's say
I'll write display views just a comment
now to show all the views you can use so
full tables
where
table
underscore
type is equal to within single quote
I'll write View
so this is the command that will display
all the views that are present inside a
database
there is some
error here let's debug the error
this should be
okay so instead of table types it should
be table type equal to view
let's run it
you can see the two different views that
we have one is customer details another
is vehicle underscore description
okay
now you can also go ahead and delete a
view
for that you can use the drop command
so I'll write drop
view followed by The View name let's say
I want to delete
customer underscore details or cast
underscore details view
I'll write draw View cast underscore
details
let's run it
you can see
here we don't have the cast underscore
details view anymore
all right
now moving to our final section in this
demo
here we will learn about Windows
functions
now Windows functions were Incorporated
in MySQL in the 8.0 version
so Windows function in MySQL are useful
applications in solving analytical
problems so using the employees table
present inside my S12 underscore intro
database
so we'll find the total combined salary
of the employees for each department
so first let me switch my database to
SQL underscore
into database
I'll run it okay
I'll display my table
that is employee
so here we have 20 employees in our
table
using this table
we are going to find the combined salary
of the employees for each department so
we'll partition our table by department
and print the total salary and this we
are going to do using
some windows functions in MySQL
so I'll write
select
I want the employee name
the age of the employee
and the department of the employee
comma
next I'll write
the sum of salary
over
I want to partition it by
Department
so I'll write Partition by Department
which is Dept
and I'll give an alias as
total salary so that it will create a
new column with the name total salary
from my table that is employees
the output will be a little different
this time
let's execute it and see the result
there you go so here we have created
another column in our result that is
total salary and for each of the
employees and the respective departments
you have the highest salary so in
finance the highest salary of one of the
employees was
155 000 dollars
similarly if I come down we have the
highest salary from HR if I scroll
further we have the highest salary from
it marketing product sales and the tech
team
all right
now we'll explore
a function which is called row number
now the row number function gives a
sequential integer to every row within
its partition
so let me show you how to
use the row number function I'll write
select
row underscore number function
over
my
column would be
salary so I'll write order by salary
I'll give the
Alias as ronum
we give a comma
and I want to display the employee name
and the salary of the employee
from my table that is employees
and I'll order by
salary
so let's see how our row number function
will create
sequential integers okay you can see
here we have a row num column and we
have successfully given row numbers to
each of the records you can see it
starts from 1 and goes up till 20.
okay
now this row number function can be used
to find duplicate values in a table
to show that first I'll create a table
I'll write create table
let's say I'll give a random name that
is demo
and let's see we have in this table the
student ID which is of type integer and
we have the student
name
which is of type worker
the size is 20
I'll create
the small table with a few records
let's create this table first
now we are going to insert a few records
to our demo table so I'll write insert
into
demo
values
I'll give 101
the name is
Shane
give a comma
I'll insert the second student name 102
the name is Bradley
we'll give a comma
this time
for 1 0 3 we have
two records
let's say the name of the student is
hereat
give a comma I'll copy this
and we'll paste it again so we have
duplicated one zero three
next we have one zero four
the name of the student let's say is
Nathan
then again let's see for
the fifth student which is Kevin we have
two records
I'll copy this
and I'll paste it here
let me give a semicolon and we'll insert
these records to our table demo
all right
now
let me just
run this table for you I'll write select
star from demo
if you see this we have a few
information that are duplicated in our
table
that is for student id103 and student ID
105.
now I am going to use my
row number function to find the
duplicate
records present in my table I'll write
select student underscore ID comma
student underscore name
I'll give another comma and write
Rue underscore number
within brackets
I'll write partition
by
St underscore ID
comma
St underscore name
okay
then I'll write
order by St underscore ID
close the bracket I'll give an alias as
ruinum
from my table that is demo
let's just run it
you can see here
okay
let me just
delete n from here and do it again
all right if you see here the richest
one student in the name Shane we have
one student in the name Bradley but here
if you see for here
the second record it says 2 which means
there are two records for hirath and if
I scroll down there is one record for
Nathan and there are two records for
Kevin which means Kevin is also repeated
okay
now we are going to see another Windows
function that is called rank function
in MySQL so the rank function assigns a
rank to a particular column
now there are gaps in the sequence of
rank values when two or more rows have
the same rank so first of all let me
create a table
and the name of the table would be a
random name we'll give it as let's say
demo one
and it will have only one
column let's say variable a of type
integer
we'll create this table first okay
now let's go ahead and insert a few
records to our
table which is demo one so I'll write
value
101
102
let's say 1 0 3 is repeated
I'm doing this purposely so that in the
output you can
clearly distinguish what the rank
function does
we have one zero four
one zero five
we have one zero six
and let's say 106 is also repeated
finally we have
one zero seven
okay
let me insert these values to my table
that is demo one okay this is done
now
if I write
select
VAR underscore a
and use my rank function I'll write rank
over
then I'll
order by my variable that is VAR
underscore a
as
an alias name let's say test rank
from
my table that is demo one
let me execute this and show you how the
rank function works
now if I run this there you go
so here if you mark
so for variable a101
the test rank is one for one zero two
the test tank is 2 but
for this value which is 1 0 3 the test
rank is repeated because there was a
repetition of one zero three
so we have skipped the rank 4 here for
104 the rank is 5 now for one zero five
the rank is six now
one zero six again since the record was
repeated twice we have skipped the
eighth Rank and
our rank function assigned the same
value which is 7 for 106 and for the
last value 107 the rank is nine
all right
now moving ahead we'll see
our final Windows function which is
called first value
so first value is another important
function in MySQL so this function
Returns the value of the specified
expression with respect to the first row
in the window frame
all right
so what I am going to do is
I am going to select
the employee name
the age and salary
and I'll write
first underscore
value which is my function and pass in
my employee name
and then I'll write over
order by
my
column that is salary descending
I'll give an alias as highest underscore
salary
from my table that is employees
so let me run this and see how the
first
underscore value function works all
right so in our table
Joseph was the employee who had the
highest salary which was hundred and
fifteen thousand dollars so
the first value function populated the
same
employee name throughout the table you
can see it here
now you can also use the first
underscore value function
over the partition
so let's say you want to display the
employee name who has the highest salary
in each department so for that you can
use the partition
I'll write select EMP underscore name
comma
I want the department
and the salary
comma
I'll use my function that is first
underscore
value
followed by
the name of the employee inside my first
value parameter
I'll write
over
here I am going to use partition
I am going to partition it by
department since I want to know the
employee name who has the highest salary
in each department
and I am going to order by
salary
descending
and I'll give my Alias again as highest
salary
from
my table that is employees
so let's run this and see the difference
in the output okay
so as you can see here
we have
the employee who had the highest salary
from each department so for finance Jack
had the highest salary from HR it was
Marcus similarly in it it was William
if I scroll down for marketing it was
John per product it was Alice who had
the highest salary similarly in sales we
had Joseph
and in Tech we had Angela
so this is how you can use the first
underscore value function using
partition
all right
so that brings us to the end of this
demo session on our tutorial
so let me just scroll through and show
you what we did from the beginning first
we learned about sub queries in SQL so
we initially wrote a simple sub query
and then we used our classic models
database which was downloaded from the
internet and also shown you the link
from where you can download this
database here we used two different
tables and we performed a sub query
operation
we learned how to create stored
procedures
so we learned how you can use the in
operator or the in parameter as well as
the out parameter in stored procedure
after stored procedure we learned
another crucial Concept in SQL which is
called triggers now triggers are also
special kind of stored procedures so we
saw how to write a before insert trigger
you can see it here
next
we learned how to delete a trigger we
also saw how to work with views in SQL
so views are basically virtual tables
that you can create from existing tables
we also saw how you can use views using
two different tables and an inner join
and
we learned how to display views how to
rename
view names
how to delete a view and finally we
explored a few Windows function so let's
discuss what's in it for us today
now we will first talk about why power
bi you know why it's a popular tool and
what problem it solves what is power bi
and what are the primary features of
power VI which you can use in your
day-to-day data analytics visualizations
creating fancy reports creating
meaningful intelligent reports for your
organization for your personal use for
crunching numbers for generating reports
real time Etc
now the most popular tool for power bi
is the power bi desktop I'll show you
certain
aspects of power bi desktop and then
I'll show you the steps how to install
power bi desktop on your machine
and then definitely power bi desktop is
a free tool provided by Microsoft but
then you can also subscribe uh for an
Enterprise version which is primarily
used uh by Enterprises for publishing
their data uh so we'll see the
difference and then overview of our
dashboards which can be created uh you
know what kind of dashboards can be
created in power pi
so this is the agenda for us today
now why power bi so generally uh you
know visualization tools reporting tools
are required in order to create and
prepare and analyze meaningful data it
could be a data for an organization it
could be a social media platform data it
could be a data from iot devices but
something which needs to be analyzed and
some intelligent inferences and data
mining has to be done on top of it now
imagine there is today we are in a world
where terabytes of data and information
is getting generated on an instantaneous
basis on minute-by-minute basis so it
becomes very essential to churn out
something meaningful something
intelligent out of it in the market
there are a lot of other tools which are
available like clicks uh all tricks
Tableau and power bi so power bi is a
Microsoft product which is one of the
most popular products and it comes as a
free to download product Microsoft power
bi desktop which is available and I'll
show you a couple of ways how you can
install it on your machine but why power
bi is uh popular is because it provides
a lot of out of the box features drag
and drop features which we will talk
about in our subsequent sessions and you
know classes but today's session is
primarily focused on giving you guys an
introduction on what is the purpose of
power bi and what all problems it solve
uh in the in the real world so power bi
allows you to view analyze and visualize
huge quantities of data and the data
could be in any format Excel CSV text or
it could be a direct connection to a
database like SQL MySQL Azure Oracle
anyone IBM db2 so it supports n number
of uh you know data types or data sets
and it's very powerful in terms of data
connectivity
so it uses powerful compression
algorithms to import and Cachet the data
within the dot pbix file so it's as
convenient as a simple software if
suppose you import a data and then you
prepare a report and then you can easily
share the reports with your peers or
someone who's co-developing with you
either through Power bi cloud services
or even you can share the pbix file in
an email
or through any other means and you can
share the data set with the concern and
they can then work on the report
independently so there are different
ways there is no uh kind of a limitation
for you know working on power bi there
are multiple ways and it is very fast it
is the most fast uh tool to work with
Excel because definitely Excel is also a
Microsoft Technology so it works very
fast on Excel based data and gives you
numbers and Reporting at a very high
speed
so now once you have imported the data
power bi allows you to model the data
allows you to work intelligently on the
data it allows you to model data in a
way that if you are importing data from
multiple Excel sheets importing data
from multiple tables you can easily
create a relationship between those
tables or data sets in power bi and then
create visually appealing reports
meaningful reports as I've been
emphasizing and make sense out of that
data no data in silos is of any use data
in Silo means a single worksheet or a
single data set will not churn out any
meaningful information until unless you
basically join it clubbit merge it Union
it append it with some other data sets
because a single data set will never be
able to hold that much amount of
information which is generally required
for a you know important report
so it has easy drag and drop
functionality with features that allow
you to copy all formatting across
similar visualizations so just like in
Microsoft Excel we use format painter to
copy the format of one cell to another
similar features very very similar to
excel products or Microsoft product they
have provided that if you have applied a
a particular thing on a report you can
easily replicate that on any other
report the font uh the header size the
background color you don't need to do it
again and again so there's a lot of
reusable features which are also
available
okay now
as I said Excel is a Microsoft product
power bi is a Microsoft product so they
have intercompatibility you can publish
data from Excel to power bi now with the
latest developments and enhancements
as of today pixel has also plugged in a
new feature called Power pivot which
I'll uh show you later down the line but
that also allows you to do a quick
analysis no you can't create of course
complex reports or uh fancy reports like
power bi but Power pivot allows you to
create you know quick measures quick
functions quick calculations on your
data quickly only in Excel so it's an
Excel plugin but whereas you know you
can power bi is also compatible with
Excel so when you create a report in
power bi it gives you inbuilt feature to
export your power bi report into Excel
format directly you don't need to do any
programming for it also
you can easily publish when you publish
your power bi reports it allows you to
give some inbuilt intelligence of
analyzing your reports in Excel and it
gives you all those of all those
features of exporting your power bi
reports into Excel which is not
available in any other tool or otherwise
those tools have to create plugins
create add-ins and probably they might
charge for it but Power bi comes with
lot of out of the box features which are
very very helpful for analyzing data in
Excel and vice versa
Azure Cloud now Azure itself again is a
Microsoft cloud Tech stack so using
power bi with Azure allows you to
analyze and share large volumes of data
so Azure basically Azure database or
Azure Cloud servers are meant to hold
huge amount of data and power bi allows
you to have seamless connection you can
easily connect to Azure data Lake
you can reduce the time it takes to get
insights and increase collaboration
between business analysts data engineers
and data scientists so azure
data Lake becomes the central focal
point where all your analysts Engineers
can keep working on on the centralized
piece of data and churn out their
reports data scientists primarily job is
to keep the data in a structured way
optimized way optimize the input output
operations disk operations and memory
utilization so that the reports also get
churned out in a faster manner so every
uh you know every person has their own
role in order to give a quick
refreshable report a quick rendered
report any report which is taking huge
amount of time to get rendered will not
eventually be used by the business users
because then it does not solve the
purpose the report should be fast
reports should have uh you know
appropriate filters slices and dices you
should be able to you know create the
reports or dynamically or you should be
able to analyze visualize the data
dynamically so all those visualization
features are available in power bi and
it works seamlessly either it is small
data or huge data it allows that you to
work on those kind of data in a seamless
fashion
right so this is just a very uh quick uh
example of how our typical dashboard
looks like dashboard is nothing but you
know you have clubbed couple of multiple
reports on a single page and you know if
you change a filter uh uh a single
filter on the page all the reports will
honor that filter and the numbers will
change accordingly so if you see the in
this example there is a filter or a drop
down or product ID product name employee
name or supervisor or a date range so
whatever date range or filter you will
apply all the reports on this dashboard
will get changed based on the filter you
have selected so power bi allows you to
get insights from data and turn insights
into action to take data driven business
decision and that is the ultimate goal
of any visualization tool that is the
purpose for which visualization tools
are bought
and purchased by the organizations and
data is fed into them
Now power bi fetches data from Factory
sensors social media sources to get
access to real-time Analytics so that
you are always ready to make timely
business decisions so so basically there
is a a feature of live connection or cut
off data connection so either you can
work on data which is deciding on a
machine and you can just work on the
cutoff data like for example it's
there's a data which is available for
sales 2017 2018 and you're just working
on a historical data it's a cut off data
or it could be possible that you want to
be connected live uh to a real-time iot
based sensor based data or social media
data like Twitter Facebook feeds or you
know you're connected to live Google
worksheets that is also possible you
just need to publish your Google sheet
for a public domain embed that you are
into Power bi and then whoever updates
that Google sheet automatically the
power bi report will also start honoring
and consuming the new data which is
added in the Google sheet so all those
kind of real-time streaming analytics is
also possible and that is one big
feature and very important feature of
power bi which is widely used and has a
very huge uh you know Market acceptance
and Market utilization
now what is power bi
power bi is a business analytics service
provided by Microsoft that lets you
visualize your data and share insights
right so earlier
you know uh
Microsoft used to have a technology
called ssas now they have replaced
actually ssas and SSRS with power bi so
basically you can use power bi on the
data which is there in your Excel or any
other data source and the power bi
service or power bi desktop basically
creates a connection to those data sets
and import it cache it and give you a
handle to it in order to work with it so
you can create these fancy meaningful
visualizations like for example there's
a geographical map if you are importing
data for a country or a continent or a
region power bi will automatically
detect that it's a geographical
information and give you a map with
latitude longitude information and you
just need to plot
your uh your numbers on the map either
you can use bubbles or either you can
use triangles or whatever data structure
you want to use but all the mapping will
be available geographically then you can
create pie charts which is shown in this
visualization you can create tree maps
you can create cards where you know you
can highlight the most important numbers
like sales total sales of your company
across all the regions or the growth
chart or the month on month uh you know
sales of your organization or number of
total number of products or units sold
so whatever is important and to be
highlighted for the management to take
any meaningful decision or any insights
you want to share
power bi visualization tool the power bi
visualization uh
uh chart allows you to drag and drop and
create wonderful reports okay
so what are the features of power bi so
power bi desktop is something a
standalone tool which you need to
install on your machine it allows you to
build reports by accessing data easily
you do not need Advanced report
designing or query skills to build a
report though yes it is beneficial that
if you know some SQL programming
analytical programming or you are aware
of advanced features of any analytical
tool that might help you but that's not
a showstopper you can easily build
reports in quick turnaround time without
needing any technical background you
just need to have some analytical uh
mindset and you can create uh Savvy
visualization and you know analytical
reports
stream analytics as I mentioned you can
create a live connection uh with any
kind of data it could be iot it could be
media social media it could be Google
Docs it could be uh you know any other
kind of uh you know live connection it
could be a live database connection
itself so any insertions or updations or
deletions happening will automatically
reflect in your report
yes multiple data sources and that has
to be the primary criteria for any tool
to be popular if any visualization tool
is limited to certain data sets then you
know it will not be highly acceptable in
the market
and custom visualizations right so as I
showed you certain uh examples in the
past in the previous presentation uh
that feature is very important because
someone might want to look the kpis look
at the kpis from a different perspective
some management might want to look at
the kpis from a different perspective so
you need to you need to have that
capability to create different
visualization from the same data set now
let's take a look at how
to install power bi desktop on your
machine
so basically what you need to do is
you need to go to this URL
power bi dot microsoft.com en US desktop
okay
and you need to just
enter this
now you can download it for free so just
click over here
and
it will open Microsoft store so
basically now what Microsoft have done
in the latest operating systems is that
when you are trying to download you can
actually directly go to the Microsoft
store
and search for Power bi
so let's wait for a couple of seconds
right here so power bi desktop in
Microsoft store for me it's already
installed so it's asking me to open it
I'll open it in a while but for you for
anyone who is not installed he will see
the button of install over here and it
will automatically install in your
machine and then you can easily go and
open power bi desktop now if I click
open over here
now this is the
uh UI of the power bi desktop
I'm not going to go right now in
creating reports right away we will talk
about that in a subsequent session with
sample data sets and we will cover the
features of power bi desktop one by one
but this is what it is this is the whole
tool of power bi which is having the
visualization pane all the different
visualizations are you know can be
created from this pane
then this is the pane which allows you
to select the data data fields then
there is a report view data View and
relationship view the data model view
where multiple relationships you can
create you can view the data in the grid
of the tables which you will create and
the reports so you can create multiple
reports on multiple Pages you can keep
adding pages either you can drag create
multiple reports on a single page and it
will become a dashboard or you can
create separate independent reports on
the single page
and these are the menu options which we
will talk about how you can change color
scheming you can do data modeling you
can create new reports and you can also
transform data which is the biggest
feature extract transform and load the
data apply different logic changing data
types massaging the information creating
new joins appending the data you know
adding new columns etc etc uh we that is
what you can do in transform data so
this itself is a whole different world
it's a dedicated topic so we will talk
about that in our subsequent sessions so
what's in it for us today we will be
learning how to connect to data
different data types data files like
Excel PDF then what are the different
data importing modes and then I will
also show you practically different sets
how to import them in power bi and use
it for your visualization purpose now
what are the steps to connect to data so
now we will go directly into Power bi
and try to import one by one few most
commonly and popularly used data sets
which are most commonly used in a
day-to-day activity rest of course there
are power bi supports n number of data
sources but we will do something
practical on the most popular ones so
let's let's open our power bi
now this is my power bi and first I want
to show you that how can I import data
directly from a web page and import the
data now it is asking for a URL in order
to import data so what I have done is I
have created a Google Excel sheet with
simple data with rows and columns and
what I have done is I have shared this
sheet as published to web
okay so you just need to say publish to
the web the link as web page and
say done it's it's automatically
published and say link so copy the link
which you have published on the web copy
this link
and then go back to your tableau
paste that link over here and click ok
Now power bi will try to establish a
connection with this Google doc sheet
because it's published on the web
you need to wait for a while while it is
reading
okay now it has read one of the HTML
tables I'll select this one now you can
see it has it is showing me a preview of
the table which is there on my
Google sheet right it has 11 rows so it
has all showed all the 11 rows so now I
can go and transform this data because I
can see my headers are there starting
from the second row so there's an
opportunity for me to transform the data
so I'll go and transform it so that it
looks clean
okay so first is I need to remove the
first row which is the
null row remove the top rows
okay and then I need to use the first
row now as a header so you just click
this option use first row as headers
that's it so now if you see my row ID
order ID order date shift date all my
data is now ready so I can say close and
apply
click apply changes
now this is an example of web data
import you can go and preview your data
right now uh the biggest advantage of
this data connection is that it's a live
data so for example I insert another row
let me change the order ID
some some I've sub change some basic
stuff and I
it's Auto saved
Ctrl s now I'll go to my tableau and
I'll refresh
now you can see as I refreshed my
power query editor I clicked refresh all
and I got my new row which is there in
the live data I got that fetched from my
okay I got that row the row number ID
number 12 so I have to say close and
apply
now you can see the new row the row
number 12 is now available in my new
data set in the data set because it's a
live connection it's a live connection
with the web based Google sheet okay so
this is one important way in which you
can import data
now let's try to import data from a text
file
now I've already prepared our text file
called
sub categories Dot txt
now let me just open it in a notepad now
it's a very plain simple file tab
separated file in which you have product
subcategory ID subcategory name and
product category key so basically to
which product category this particular
sub product belongs to right so what I'm
going to do is I'm gonna go back to my
get data option
and I'm gonna select text slash CSV
option
and I'm gonna select option mod product
subcategories Dot txt
okay so now power bi has identified that
it's a tab delimited file it has
recognized the headers
Etc right and I can now directly load
this file
okay
so now once the data is imported in
power bi it is like
irrelevant to me it's a composite data
in import I am doing right so in my
presentation when I am talking about
importing data there are different
importing modes right import our data
import can happen through different ways
okay
one is direct query mode in which I
create a live connection to the database
which I'll also show you uh using MySQL
and Ms SQL server and also you can do a
composite mode in which you can have
data imported from Excel plus you can
have direct query modes so you can have
multiple uh modes to connect and create
a composite data model and that's what
we are doing right now in our practical
so what we are doing over here is one we
have imported data from the web second
we have imported data from a text table
now after doing text now our next task
is to import from CSV let's try another
one so now I have imported product
subcategory
now I'll import
a CSP file so again I'll choose the
option Text slash CSV and now in this
CSV file let me open this CSV file and
show you what it is it
so this is a list of all my products
product key products
stock keeping unit Etc a simple CSV file
and I'm gonna import that
okay so now it is identified the
delimiter is comma rather than a tab and
it has already recognized the headers
correctly so I load it
okay so now my products are there
product subcategories are there for
product categories now what I have done
is I have created as Excel mode now so
now Excel I am using to import my
product category
so now I have to click on the option of
import data from Excel and I'll say
product categories
select the sheet load
and now so my products product
categories product sub categories do
with different uh data storage types but
still now the data is imported into
Power bi is a composite data model now
another very important data type which
you can import is the PDF also right so
what I have done is I have created a PDF
called customers my customers data is
lying in a PDF so what I've done is I've
created a PDF
which has data for some columns are
there like you know customer key prefix
first name last name birth date marital
status gender email address annual
income total children etc etc so this is
the data set
which I have created in PDF so what I'm
going to do is
I'm going to select PDF now
and import customers.pdf
and see it has recognized my table on
page one which I am going to load
okay
you can rename this as PDF
table
okay so this basically these are the
different type of
data
types we have imported PDF Excel text
CSV and web page
now let's take a look at another
interesting data set which you want to
import is the my SQL Server data set
so what I have done is I've already
installed MySQL server on my local
instance and there's already a schema of
SQL live tutorial over there and I have
certain tables already
prepared over there like Department
employee Etc so my goal is now to import
this data or create a live connection
with this data set
now in order to import
my SQL database Connection in power bi
you need to First
download a
connector MySQL power bi connector so
you need to go to this link
and then click on download and install
the MySQL connector based on the
operating system you have you click on
download and install it
after you have done this go back to
Power bi
and then give
the IP address of the database in my
case it's there in this local machine
and the schema which I want to import is
SQL live tutorial so I'll give the name
click connect
okay now it's connected so now it is
asking me which particular tables you
want to create a connection with I am
choosing department and employee
and I'm just loading them
okay so now this is the exact data which
is there in the employee and Department
in MySQL okay so this is one example of
how to create connectivity between power
bi and MySQL
now I want to do the same thing using
SQL Server Microsoft SQL Server so I
have also installed Microsoft SQL server
on my machine
and I have used the SQL Express so this
is the name of my server so which I'll
copy the server name and
go to get data
select SQL Server
and for now database is optional I can
say direct query click ok
now it is showing me what all tables I
can import so in my SQL Server tutorial
in my SQL Server I have
I have these three tables customers
employee attrition Olympic events so I
can use probably the customers one which
is
now you can see this is the data the
customer's data which is lying in my SQL
Server okay so I can preview it and load
it
so now you can you can preview the data
in uh Power bi that is this is the data
so I can rename his customers from
mssql
and this is from
MySQL
and
okay so now
this is not the only data
sets you can import now if you take a
look at the options which power bi gave
what different type and variations of
data it can it has compatibility to
import from
okay so we can just take a look at the
categorization on the left hand side
first there are five ways like Excel
text XML Json is also possible you can
evenly directly import an entire folder
and within the folder whatever uh data
types of files are there it will detect
it PDF power key or even SharePoint
folder which is itself for Microsoft uh
technology then different kind of
databases SQL server and MySQL we just
saw but it's not only limited to this
you can connect to Microsoft Access
ssas Oracle database IBM db2 postgres
cybase teradata and then sap
databases Amazon redshift Impala vertica
Snowflake and N number of databases
which are there in the market today
Amazon
Etc
then it also allows you to connect with
its own power platforms power bi
platforms data mods power bi data flows
dataverse Etc
Azure there are different kind of
storage
mechanisms in Azure and Azure itself is
a Microsoft Technology uh so it has a
compatibility of a lot of azure uh based
data storages like Azure SQL database
blob storage uh Azure data breaks right
Azure HD insights path so if you have
those kind of services running on your
observed cloud services you can even
import them over here
now online services like you know you
have erps running uh or some data which
is shared on the internet if you want to
import it uh that is also possible
through certain products uh Dynamics 365
Microsoft Exchange online Salesforce
Google analytics Adobe analytics GitHub
LinkedIn sales if you want to do some
analysis of some social networking uh
you know feeds that also you can import
and then other miscellaneous are also
their web-based hive R script python
script if there's something to import
get data from uh Google Sheets like we
saw one example in our video right now
so there are multiple options available
now once you have imported the data
which is relevant to you
um in our subsequent sessions we will
see how to create relationships but just
giving you a glimpse that whatever data
you are importing power bi Auto detect
certain relationships and it will create
for you but then you can go and manually
also change so this is the composite
data model which is getting created in
the back end while you are importing the
data you can easily go and manage these
relationships either keep them as is you
can delete and create new ones manually
so there is no limitation in that
so this is what we have witnessed we
have imported data from different files
types data types and then you know we
have tried once it is imported into uh
Power bi then there is no limitation of
how you use it you can create
visualization across different data sets
and then create your
standard reports
so this is the example of importing data
from web importing data from a database
from a PDF
and then once you have data you can
shape and combine data you can basically
do what whatever transformation you want
to do you want to uh make joins merge
the data so for example if we go back to
our power bi and if I go back to my
transform data section
now as I have now different data sets
available with me I have I can do any
kind of you know operation
transformation on the data right uh
so like I showed you I uh upgraded the
header row because one of the imported
data was not showing the header
correctly uh or this columns like this
exact one column is extra I can remove
the column
right all those Transformations whatever
I do in the back end gets captured in
the applied steps section right
this is the customer data you can create
uh you can merge it you can append it uh
you know with other data sets right
let's for example I want to create a
merge data set of my categories and
subcategories so I can say mer selectors
two data sets and say merge queries as
new
and
and I can select product categories and
products are categories select
product category key on both the sides
and then they do a left Auto Zone so
whatever product categories are there
I'll get the subcategories associated
with it and I'll create a new table
which will have
now I have the table which has the
category and the subcategory and
subcategory in one table itself so I can
rename it now to as
category
sub category
table it's a it's a merge basically it's
a join between category and subcategory
now I have a common table right and I
can close and apply
so imagine I have created a
new table which is imported created from
one data set is which is Excel page
another data set which is text based
see this category subcategory table so
now I can use it
the way I want in my visualization
reports so that's what the presentation
says right that once you have uh the
imported data you can shape you can
combine you can adjust you can do
whatever transformation you want to do
and create your visualization okay so
what topics we are going to cover today
we are going to talk about different
types of data modeling and the most
important part
and aspect of data modeling is the
cardinality the cardinality which you
basically decide after reviewing the
nature of data and after we've imported
it what kind of cardinality you have to
basically highlight right and there are
different type of cardinalities which
you might have heard earlier also if you
are from PL SQL background like one is
to one one is too many Etc we will we
will talk about that
now what are the different types of data
modeling now dimensional data modeling
is one of the most popular and most uh
you know widely used uh modeling in
dimensional data modeling you have
Master data uh like for example customer
data date store data product data so
these are like you know uh less
frequently changing data sets so there
is an organization right and you have
set of customers their email ID phone
numbers
Etc that will change less frequently as
compared to the sales transactions
because transactions are happening every
day every minute so sales is a more fast
changing data set in dimensional
modeling which is in the terminology of
data uh is also called as a fact and
customer store product which are like
more of static data and less changeable
data is sometimes called a diamond
ancient so this is a typical dimensional
data model which is typically used uh
sometimes right and then there is
another model which is relational model
this is a typical model which we have
been using in database design like you
know primary key foreign key
relationships so for example you have a
customer who has purchased a product so
probably he might have the customer
might have the details of the product
which is processed and you will make a
join between customer and product table
and even you can make a join between
product or product type or customer or
product types customer table will also
have a key to the product type so this
is less conducive for reporting but it
is more of a transactional relational
model but of course this is also
feasible but from the power bi
perspective when we talk about reporting
and visualization this is the most
extensively used dimensional data model
and this is what we are going to see in
our example now so what I'm going to do
is I'm gonna show you certain data sets
first we will prepare and create certain
offer data sets and then we will Import
in our sample power bi file and then
slowly slowly we will create the
relationships
now one important thing which you need
to understand that in power bi if you go
to Power bi there is an option that that
power bi Auto detect new relationships
after data is loaded and import
relations from the data source on first
load so for example if you are importing
the data from a database where you have
already defined the primary keys and the
foreign key relationships so uh that is
the first option which power bi will
Auto detect and secondly if suppose you
are importing two different kind of data
sets one is Excel one is csb and if
power bi detects a common column key
columns it will auto detect a
relationship which you can go and later
change modify manage in your
relationship
menu manage relationship menu in power
bi which I'm gonna show you okay so if I
I open a power bi and this is where the
option lies go to file
go to options and setting options
data load
and these are the two options which are
by default check you can uncheck it and
auto and manually prepare relationships
there's no limitation to that but if you
keep it checked then power bi will do
its job to detect the relationships okay
now coming to the next important factor
cardinality
now before I start playing around with
my data and start showing you certain
relationships it's very important to
understand these four types of
cardinalities one is many to one right
so basically
many to one means that many orders
contain data of One customer so per
order one customer is there so from
customer to order or product or delivery
address it's a one-to-many relationship
and from the other side from order to
customer perspective it's a many-to-one
relationship
okay
second other cardinality is one is to
one one is to one relationship is only
applicable when you are saying it's an
extension of the current table so for
example in one table you have employee
details and you are extending the
details of the employee in another table
like employee address employee ID so
that is like one is to one there is no
multiple records of a single employee in
the address table only one employee ID
exists right
now one is too many as I said is the
reverse side of many is to one so in
customer table only one customer record
exists per customer and one customer can
place many orders for multiple products
and can also have multiple delivery
addresses so that way this is a typical
one is to many relationship we will be
seeing this example also in our sample
data set
and last is the many-to-many
relationship now many to many is a very
typical example so which I'm going to
show you practice practically and in our
case we will see that like for example
you have placed an order for a
particular product uh you know but there
are multiple fulfillments which has
happened so suppose you made order for
10 products but at the back end when the
company is fulfilling it is first
fulfilling the first two products then
the rest three so basically you the
Fulfillment is happening in batches so
one order ID might have a multiple
fulfillments for the same order ID so
there will be a multi many to many
relationship which I'll show you
practically so now with this background
let's
start importing our data now the first
important thing which we need to import
is the Master data so first I'll import
all my master Dimensions which is uh
which I'm going to you know use in my
example so first is the customers table
customers data
so this is the customer details the
customer key prefix first name last name
birth date marital status and gender
some redundant columns are also present
but we'll remove it
so my customer data is loaded now
today's session is all about this
section of modeling so we will keep our
Focus over here
okay now some columns probably some
blank columns are there I can select
them and say delete from model
yes
okay so now this is my customers data
with the relevant columns and the key
per customer customer key
now there's no relationship in this
model right now right because only
single table is there and the associate
data is only imported now let me also
import my another important master table
is the products
select the products data product key
product sub category product SKU product
name model name product description
color size so just see all the relevant
information only specific to the product
is available so I'll import it
okay now see there's no relationship
between product and customers directly
because until unless a customer makes an
order places an order for a particular
product there is no join right so now
between these two tables the most
important now another table which will
now make sense is the sales order table
sales table
now I I'm assuming that power bi have
Auto detected the relationship now you
can see that because I've already uh
take that check box now let's see what
power bi what relations power bi has
Auto detected let's first say check the
relation between customer and sales I'll
double click this
join now what it has done is it has
created a join of many to one
between sales and customer so what does
that mean is that one customer has can
place many orders right and that is that
it is detected by the quality of the
data and the data sampling which power
bi has done you can also reverse this
relationship here I can select customers
and I can select sales now it has become
one too many so that you can also do
manually so that is what I said whatever
power bi is detected it is up to the
description of power bi internal uh
configuration and algorithm but you can
go and change it so this is now you can
this is by default active so we want to
keep it active One customer many sales
orders cross filter Direction means that
only from customers to sales is the
filter applicable not reverse I'll come
to this with my another example but
first let's
change the relationship so one is too
many means from One customer and many
sales orders
similarly let's see what has happened at
the product side
of the relationship
similarly power bi many sales orders for
one product you can for simplicity's
sake you can say products
sales
product key is the join now just focus
one more thing please also see the the
column on which the join is is the grade
column grade out column product key is
also here and product key is also there
and it is what we wanted so one is too
many relationship from product to sales
table and act
now looks fine this is something which
is looking logical and probably now we
can
proceed further to create a report
now let me explain the cross filtering
with an example
now for example I want to check in a
report
that what is the count of products which
uh which a particular customer has
ordered
okay so what I'll do is I'll select the
product count of product name
now if you see
and for each customer in front of each
customer name the count is coming as 293
293 it is getting repetitive because
because there is a one-way filter
Direction filter between customers and
sales and sales and products right so
this join
is single sided it means that from
customer to product you can't find a
relationship because it's a single side
cross filter right what does this if I
change it to both it means that it is
equal to a join between product and
sales and every product detail now is
appended to the sales table so if I want
to make you visualize this you need to
go here
I'll first open my sales table
we can also open it here let's make
click it says okay now if I click OK you
can see the single arrow is changed to
Double Arrow it means it's a it's a both
site filter
So when you say a both side filter it
means that implicitly within power bi
you can imagine that all the product
columns now will get appended because of
both ways filter you have applied and if
you go to your report now see the change
of the numbers now 40 20 so the total
count of products across all my
customers come out to be 293 now the
report looks uh correct if I change the
relationship from back to single between
product and sales then you can't make a
join between customers and products
basically you can't derive the product
count from the product table see this
if you have to live with it then you
would have to go to the sales table get
the product key and get the value of
count of product key but that is not
correct okay
so if you want a report in which you
want the count of product name
and even if you want a count of distinct
product name so this will not come
correctly you would have to go and
change the
direction of the filter which is from
single to both so this is a typical
example they where you want to use a
two directional filter
now let's proceed further and import
other data set in order to show you
another example
now I want to show you an example of
one is to
1.
so I have another table which is called
customer details so the key in this
table is again customer key but only
email address annual income total
children education level Etc other
details of the customer is there
so I'm loading the customer details now
you see it has Auto detected a one is to
one relationship
but what is the meaning of one is to one
means One customer key only has one
entry in customer details there is no
multiple entry so if you click this
button
it's a one is to one and the cross
filter can be both or single doesn't
matter because one customer will have
only one value you can make this as
active okay and if you go to the
customer report table you can now easily
associate a
email address with the first name you
will get one is to one
record
so now you can see that with one is to
one relationship
with the first name I have Associated
the email ID and for each email ID
there is a Associated first name method
so this is an example of
one is to one relationship so in this
example what we have explained is that
for each customer there is an Associated
customer detail right uh so you have the
first name email address education level
homeowner occupation and total children
count
so in this report what we have done is
uh if you click over here so the first
name and the email address okay so
there's a one is to one relationship
and then
and if you drag
the customer key
report takes time to render and even if
you can
so this is the reporting output you have
the customer key first name associated
email address and the count of product
names uh which the customer has ordered
now this is an example of 1 is to 1.
now I want to show you an example of
many too many now for that I'll import
my fulfillment data set
huh
okay now in my fulfillment data set
there is a column for
order number so basically what I'll do
is I'll drag order number from here to
here
okay so now what has uh
power bi detected
I'll do one thing I'll select sales over
here
fulfillment over here and order number
to odd number
okay so it's a many-to-many relationship
so it means that per order I have
created multiple batches to fulfill that
particular order now
many to many relationship is a
definitely a candidate for
both ways cross filter detection uh a
Direction but you can you can check that
but definitely uh Power bi shows a
warning that this relationship has
cardinality to many to many and this
should only be used if it is expected
that neither column contains unique
values okay so we know that fact that's
why we are accepting this relationship
as many to many because we know there
are multiple order numbers over here in
the sales table which are mapped to the
multiple order numbers in the
Fulfillment table we'll click ok
now you want to keep the uh
direction as both ways or One Direction
that is up to you the way you want to
map the report so I can double click
over here
and you can even click so now you can
select from which way single filter you
want from fulfillment to sales or sales
to fulfillment I'll prefer sales to
fulfillment and click ok
okay now we have our all our different
kind of relationships over here which we
have tried to shortlist one to many many
to one one to one which is uh this
example and many too many
now if I show you further relationships
which you can keep on adding like for
example I have a uh the example of
territories
now in which particular territory the
sales was done
map it over here
okay so now it's a typical one is too
many relationship because territory is
my master table uh where I have a static
list of continent country region and it
is mapped to the uh territories which
are for in which my orders have been
placed so it's a typical one is too many
so that way you know you can keep on
adding data then you have
uh details of returns
now this is another transactional table
which is about the orders which have
been returned rather than being you know
returned by the customers so you have a
product key
uh so automatically power bi has
detected a relationship between the
product key and the product uh table
right and even if you can join the
territory key in which territory the
return has happened
right so mostly the most common
relationship which you will observe is
the one is too many because
as I told earlier the most common
relational model is the dimensional
model uh the static data the slow
changing Dimensions the scds are the
master tables and the most frequent
changing are the fact tables so if I
talk about a typical dimensional model
the Fulfillment table sales table and
the territory stable sorry the
Fulfillment table sales table and my
returns table are the fact tables of my
data model now so far what we have done
as per our last session is that we did
data modeling on the different data sets
which we had imported in power bi like
products sales data returns fulfillment
customer details uh and customer Master
data calendar details Etc so in the last
session we prepared a data model and
established the relationships between
these different data sets like one is to
one one is too many many to one one is
to one Etc and we saw the examples now
once our relational model is prepared
our data model is prepared now our next
activity is to create certain additional
columns which we want to derive basis
the data which we have imported
so for example I'll start with my
product data set now in my product data
set I want to introduce a column which
basically
categorizes that if any product which
has a color uh you know red black or
gray I am going to tag it as a colored
product rest I'm gonna say not a colored
product right so all these are like
example of byte type product skus so for
that now in order to introduce a new
column you just need to do what you need
to select the table in the data grid go
to the table tools and say new column
okay so column will get appended to the
rightmost part and you will start seeing
a uh formula section typical to like you
get in your Excel now I'm gonna say that
the name of my column is going to be
byte type color okay and I'm just
creating a if condition if
product
color
is equal to
black
okay
or
or if it is equal to red
or if it is equal to
Gray
then
say yes it's a colored product I'll say
no
okay so now you can see this is the
product color red and black they are
saying bike type color Yes blue is no
multi is no etc etc so this is a classic
example of an if and else condition
based conditional column
okay so you can create such columns now
second column custom column which I want
to create is I'm going to call as
discount
now this is the pricing of my products I
want to associate certain discounts
which I am ready to give to my customers
this is the product category like what
is the pricing of the category again I'm
going to use make use of if else but in
a nested way so if I am saying if my
product
price is less than 100
then I will give
zero percent of
uh zero percentage of discount so 0 into
product price just to keep it consistent
now I'm seeing
else
if less than 100 and 0 else I'll check
again that
if
the price is
less than
500 then I am ready ready to give one
percent discount
on the
product price
else
I'll move further so like this I have
created a formula
so what I'm saying is if product price
is less than 100 give zero percent if it
is less than 500 then give one percent
less than 2 000 then 1.5 percent less
than three thousand then two percent and
otherwise else less than three thousand
if you're two percent else three percent
right now after this column is created
now you can check right so this C the
product price for this particular
product it is less than 100 so that's
why there is no discount it is
uh between 100 to 200 then this has been
given a one percent discount so like
this all the discount column is now
calculated now this column is available
just like a regular column in my product
table
now after this I'll go to my sales table
now in sales table I want to
identify and uh
create a column called as cost
there is no
product cost column over here so that
will be derived
so let's create a column
called as cost
and it is derived by order quantity
into now the cost of the product
is in the product table and I know I
have already created a relationship
between product and sales table
so I just need to select the product
cost column now only keyword which I
have to use in power bi is the related
keyword so this will pick up the
relation
and now for this particular sale order
the cost has already been derived so
this order number this is the cost for
which uh the product has is the costing
of the product for this particular order
thank you
okay
now I'm gonna create another conditional
column over here called as
order status
I'm saying if
any order whose order quantity is
greater than 2
then for my organization it's an urgent
order
else it is a
normal order
oh sorry
lost it
so this is my
order status column and I have my order
quantity
urgent or normal
so any order which has order quantity
one is normal any order which is having
order quantity as greater than
2 is
urgent you can see this
so there's a this whole power bi
uh tabs and sheets allow you to also
review the data what you're doing so
it's very convenient
now
I have my sales data now what I want to
bring within the sales is my discount
column so here also I want to bring the
discount which I have created
so I'll say discount
[Music]
will be order quantity
into
related
product discount right so the discount
calculated column which I had created
under products I'll bring over here
now I am creating the order level
discount so if you see for this
particular order these are 25 uh
uh you know for 25 rupee discount at the
cost is 100 000 rupees okay
and what is the order price now so I
have taken the order cost the discount
now I have to create a column call as
price order price so that will be
again order quantity
into related
price which is per product
price and
okay so now I have the cost the discount
and the price right available with me
now I want to
calculate the total
uh
total revenue total profit and loss
right
per order how much
so first I'll calculate per order how
much revenue I am generating so now I
have to generate a column called as
Revenue
revenue is price
minus discount
so 1700 minus 25
1700 minus 25 2071 minus 42 and if I
want to calculate the profit per order
then it is
Revenue
Minus cost
okay so now you can see you know typical
custom columns calculated columns which
we have created are all playing around
with the number numeric values numeric
data primarily and trying to give
inferences into per order cost discount
per order price revenue and profit so
typical calculation columns which I have
prepared in front of you
now let's take a look at other different
variations of custom columns I'll create
certain columns for text based custom
columns calculated columns using Text
data
so I am now moving towards my customer
table in which I have customer key
prefix first name last name birth date
marital status and gender
now I want to create a new column in
which I want to derive the age of each
customer as of today right so I'll use
another function a date function called
as
date div
now date div so I want the difference
between the birth date of the customer
and as of today
in years
okay so this customer as of today 68
year old one is 74 68 57 Etc so this is
one derivation of a calculated column of
age
let's take another example now this is a
text based column where I want to
derive the full name of the customer
now here I'll say first
lowercase in lower case I'll concatenate
the prefix
then ampersand
space
ampersand
first name
Ampersand space
ampersand
last name
and closing brackets
Etc
full name
okay so this is an example of full name
in low cases
now another
calculated column conditional column at
the customer level
I want to identify a flag which says who
is my Target customer base is the
demographics shared over here Target
customer
so I'll say
if
the marital status is equal to
m
and
total children
hurry
and total children annual income
so okay so let me change the logic a bit
so marital status is M and
age
is
less than
50
these customers are my Target customers
okay so I would say
yes
else no
see this
he's a marital status is married Logan
Diaz and age is less than 50 else
everyone so if I try to filter
so these are the my Target customers
69 out of 1178 so this is just a
conditional column but a logical
condition an example which I am trying
to highlight over here
okay now
let's look at certain calendar
date oriented columns calculated columns
very typical like now I have a simple
date column now I'll keep adding certain
columns which are you know which help
you which will help you understand how
we can uh
you know do some calculations on the
dates so like for example I want a date
which is 12 days after the current date
the date in the column so just simple 12
Days After
select the date and add 12.
now if you see the date format you can
go and change the format at the top
and if whatever you feel like like this
now see 12 days after first Jan 2015 is
13 Jan 2005. you can go and change the
format and other details
let me also show you if I go to my cost
and other columns I can go and change
the format this is like a currency cost
is currency so I can go and
select the
change the currency type and you can
even show the dollar value or whatever
currency type it is
so for numbers you can do currency or
text or dates you can select the format
so this is available at the column tools
level
now in customers
like we had our
column of full name so now what all
things are available format as text okay
data type text so very minimal options
are there with date you have options of
the date format
now next
I want a column which defines the expiry
date okay so eight months prior
to the expiry date within which is
coming up in eight months so I'll create
a column called as eight months expiry
and then there is a e date function I'll
use that I'll use my
date in the data set
comma I'll say eight so now this date
column will append eight months to my
actual date and again I can go and
change the format
correct
now another important column like I want
to know the date name
so I'll use a function called as
format
and I'll select my calendar date column
and I'll say give me the DDD
format of it so it will give me the day
name the day the day name of on that
particular date
next
years in between
so I want the years in between the
today's date and the date of my calendar
so equal to
D Def
the calendar date
comma today
comma year
end
seven years 2015 to 2022
then last date of the month
so if I want what is the last date of
this particular calendar month
I will use a function EO month which is
there available in the
power bi so I'll say
last date of the month
equal to
e o month
then
just select the calendar CSV date
comma
0 in months and enter
change the format
then similarly start of the month
so I'll use a function called start of
month
so for for all January dates end of the
month is 31st Jan and start of the month
will remain 1st of January
change the format
foreign
next I want to know what is the weak
number of that particular date so now
there is an inbuilt function called
week number week num and just pass the
date and you will get
the weak number first week of the year
second week of the year Etc
now another very
good example is whether the weak
day is a weekday or a weekend right so
what is it's a weak type okay
so I'll check I'll put a if condition
and there is a function called weekday
and I'll pass the calendar
if it is less than 6
it means it's a weekday as it's a
weekend
all Saturday
and Sunday D names will come as weekends
or else everything else will come as
weekly
so these are very different variations
of different column types calculated
columns which is a very important
utility and uh and any proper bi project
you will definitely be ending up
creating n number of calculated columns
to derive your numbers to prepare your
reports but it's important to understand
what all things we can do yes there are
n number of functions available in power
bi but uh what I've tried to Showcase
over here is some important functions
but Basin is your utility basis your
problem statement you can look up for a
relevance function in the power bi
dictionary
now with this
introduction to calculated column this
is the base for us to now get into our
next session where we'll be talk we will
be talking about creating Dax measures
and Dax functions we will be using power
bi Dax functions which is much more
powerful than simple uh calculated
columns where you can do more uh complex
calculations uh you can calculate totals
and then use them in the reports if
you're an aspiring data analyst looking
for online training and certifications
from prestigious universities and in
collaboration with leading experts then
search no more simply lens postgraduate
program in data analytics from Purdue
University in collaboration with IBM
should be a right choice for more
details use the link mentioned in the
description box below in this session we
will start with certain exercises which
we will perform in Tableau in order to
understand some basic concepts
now in order to learn Tableau the basic
first step is to import a sample data so
in our case what we have done is we have
imported a sample Superstore which is in
Excel format a sample superstore.xl
which has three worksheets in it orders
people and returns so by importing this
data into Tableau first of all we will
create relationships between these
sheets in order to identify who all have
placed orders and how many people have
returned the orders we will do some
analysis on the orders placed by certain
set of people and Order returned by a
certain set of people
now as we have imported uh the sheet we
will make certain joins so the first
step is to drag the orders
table the order sheet on the
relationship canvas here okay and you
can see the data sample data the first
100 rows over here
okay then now we need to create an inner
join with people's table between order
and people okay so if you see
it has automatically detected the field
names on which the inner join has to be
created so on the order side you have
region and on the right hand side which
is the people data you have also a
region okay so both these columns are
common and that's how we have made a
join between orders and people data
so if I close this box and go and check
the people's data
yeah
open
so see the region and the person these
two columns from the people table have
now been
joined with the orders table right so it
means that these are the orders in a
particular region which has been placed
by
in this region
let me show you the sample Superstore
Excel file now this is the structure of
the file you have a sample list of
transactions basically the orders which
are placed by customers
across multiple regions
south west of USA South Region west
region then you have a list of order IDs
which have been returned so basically
the order ID in the returns sheet
matches with those orders in the order
stable
and then you have the people
sheet in which you have region
and a person associated with that region
the sales person associated with that
region okay so basically when we are
combining joining orders with people we
are joining that
which orders
belongs to which region and who's the
sales person associated with it so what
we have done over here is we have made a
inner join means all the orders should
belong to particular region and that
region is in the people's sheet
and then in the second step
now we will make a
left join between returns and orders
not inner join we'll make a left join
between returns and orders and we will
make a join using the
order ID
okay so just edit this
click on left
and
select order ID as the join column now
what does left join means left join mean
is that consider all the orders from the
orders table and only consider the
orders from the returns table which have
data means which are returned otherwise
show null for the order IDs which are
not returned so if you see this is the
these are the two columns from the
returns table and these are null because
this is relevant to the order IDs which
are not returned okay which has been
accepted by the customer but these are
the orders for which you see data in the
returned and Order ID column it means
that these have been returned
now with these joins in place please
save your book and now we have our
relations created in the
um
in the Tableau now we are ready to
create certain reports and extract
certain kpis using this relationship
model
now we'll move to sheet1
okay
and first we will place
state
and person on the rose
sheet okay
then
I'll go to my
numbers and
put the profit or D so per state per
person how much profit I am making as a
company okay this is my goal to check
now
sort by highest to lowest
so California is giving me the maximum
profit of seventy six thousand six three
hundred eighty one then New York then
Washington so this is the sorted order
in which I have
listed my profit in descending order
now I can also check what are the number
of orders
placed
and check the distinct count
what happens
so out of 120 out of the total orders of
127 okay so this is the number of total
number of orders which have been
returned for California is 127.
it's 16 29 so the sorted order is as per
the revenue as per the profit and this
is the details of the orders which have
been returned per state
so if you see for connected for a
cancers there are zero returns
so you can also extract data
table to refresh his orders and identify
new rows using order date so as and when
new data is being added you can
refresh it now say extract
and now you can save this information
profit
by state
and click C so this is the extraction of
this particular report which is possible
in tableau
so this is the first exercise which we
have completed for
reviewing and analyzing the profit per
state highest to lowest and within that
per state what are the number of orders
which have been returned by all the
customers the distinct count of order
IDs which have been returned
now let's start our second exercise on
creating calculated fields in tableau
now in this exercise we will be doing
certain
activities like we will be creating a
set to show the states which have more
than 100 customers then we will be
creating a calculated field to show an
average sales per customer okay then we
will create a calculated field to show
the sales goals and then show emerging
and developing stage so these are the
four kpis which we have to derive
now the first thing we have our sample
Superstore data already imported and the
relationships created in a join with
people and left joined with returns
now we have our sheet 2 in which we will
create the states a list of states which
has more than 100 customers
so what we have to do is we have to
click right click on the customer name
and click create set
okay
now we have to give the name as states
with 100 plus customers
and then go to the condition tab
select by field
and then apply condition as
count of customer name
greater than equal to
100
and click
ok
now we have this set created states with
100 plus customers
now to determine average sales by
customer we have to now create a
calculated field
so go to the analysis and click on
create calculate field
okay
now name it as
average
sales per customer
and now we will say average
we will use a
foreign
that per customer we are using a level
of definition function include which
means that per customer what is my
average sales right we've already used a
function aggregated function called
average so we are saying per customer
give me the total and then give me the
average per customer so we're going to
click ok
now create another calculated field you
can also create from here
and name is as name it as sales goal
now in this we are going to type the
formula if
minimum
States
with 100 plus customers equal to true
then
sum of
sales
into 1.3
else
average sales per customer into
100 so me we are saying that
if the customer belongs to the set of
states with 100 plus customers then the
sales Target should be
1.3 times the actual sales as of today
else it should be 100 of the average
sales per customer
now let's create another calculated
field which we call as
emerging
or developing state
if distinct count
of customer name
is greater than equal to 100
then
the state is tagged as developing state
yeah
else it is called as
emerging state
okay so we have now
three calculated Fields average sales
per customer emerging or developing
State and sales goals
now we will use this in our reporting
so we will drag sales goal under the
columns
and then I'll drop my state
so now this is the statewise sales goal
depending whether the state has 100 plus
customers or not
then add your customer name
make the measure as count distinct
and make it as discrete
okay so if you see this
we have the count of customers per state
and the
the sales goal
for that particular state
and now
I'll put my sum of sales the total sales
which I want
which is there per state
now go to show me and select
this particular chart
bullet graph
now to bring sales goals to column right
click on the sales access and select
swap reference line fields
now from your left hand panel drag and
drop emerging or developing straight on
the color panel
okay so a merging state is the orange
one and the developing state is the blue
one
and save the sheet as
developing and the emerging States
so if you see this it's an emerging
State because its count is less than the
customer count is less than 100
its sales goal is
57384 but the actual sales is
19511 okay
so now this is a developing State its
count is greater than equal to 100 and
its sales goal and its sales is exactly
the same it matches so that's why you
are saying the bar and the blue bar is
ending exactly where the vertical bar is
foreign
so what we are trying to depict is that
whether the state is going Beyond its
Target sales goal or it's behind it
and you can see that using this
particular vertical bar like for example
Michigan its sales goal is 71 952 but
its actual sales is seven six seven two
seven zero average sales so that's why
it is be above its Target
and it's a developing state
because it has more than 100 customers
so you can even sort
by the count of the uh customers higher
to lower so all your developing state
will group from at the top and the
emerging States Will Group at the bottom
or you can sort by
the sales goal
so the orange bar is the sales goal or
the blue bar so depending what sales
goal
has been
derived for each state
the Netflix database which we have and
we will prepare certain reports in order
to identify what kind of reports we can
generate from such a data set
So currently on my screen what you can
see is the Tableau the Netflix data
sheets the data sources where you have
the Netflix shows movies their
Associated duration uh what kind of
shows or movies are there the release
here are the associated rating
description and key which is the show ID
now this is the unique identifier for
each show in this Netflix title sheet
and with this show ID all other sheets
are related like you know who are the
directors of the show in which country
the show was released what is the cost
of each show all that information is in
this sheet and to which particular
category basically the listed in
category is being listed in this
particular sheets so what we are going
to do is first we are going to import
this sheet into tableau
okay and then create relationship
between them using the Tableau
relationship canvas so first our the
primary transaction table the sheet in
which all the information related to
movies is there or shows is there is in
Netflix titles and then we will drag
sheet like Netflix cast titles cast now
W has automatically identified the
relationship between the show ID of
titles and show ID of titles cast and it
has made a join
so if you double click this
you can see this relationship
cardinality and the related fields
similarly I'll drag
titles category
countries and directors
Now by virtue of this all the sheets
have now been joined with Netflix titles
and with this relationship ready we can
start preparing our reports
now let's create a basic report where we
can just glance the data like you know
whatever we were seeing in the Excel how
it looks in w
so you have all the types of movies then
for example I drag the release Here
now first I do not want to consider it
as a
Dimension so I'll just
release year or category per type there
is a release Here and then I'll drop the
listed in
so now these are the categories of per
year the the details of the categories
right and then you can
drag the title and the associated rating
so this is just a view of your data
we can name it as shows listing report
now let's try to create some report for
some
measures some numbers
Etc
so now let's check in which country how
many movies or titles were released you
know what is the count
so first let's drag the
country
so as soon as we dragged the country uh
uh field it is identified that it has
the geographical names and identified
the latitude and longitude details so
Tableau internally does that
automatically and it has identified the
spots across the globe of the relevant
country
now let's drag the listed in on the
color section
now what it is doing is it is showing in
which country what different kind of
uh category wise movies are or shows are
being released like in Sri Lanka
documentaries have been released in
India action and adventure United States
action and adventure like this
now let's
put
account of
the titles right so if you see 247
action adventure
movies or shows have been released in
United States
okay so this is one inference by this
particular report you can
identify
so let's save this report as
listed
in
by country
okay now let's create another report
we will call it as the per year
statistical report in this
first I'll put the release years in the
column
now
count of Netflix titles so this is the
count of Netflix titles per year 2017
2016 14. and then count of Netflix
titles in the countries
this is the second bar chart okay now
what I'll do is I'll combine it into one
so one report
we are
moving in the bar creating the bar and
one in the line now I just have to
so we will click on the count of Netflix
titles by country right click Market
dual access
so now as soon as you click click this
both the uh charts have been combined
and right click over here and say
synchronize access
okay
okay so now if you can see see right in
2017 you had uh 2 303 Netflix releases
across all categories and 1159
titles right one zero six three titles
in 2017. so this is a descending
representation of the count of titles
release per year across category and
across titles
so let's call this as
per year
stats
now let's create another report
number of shows
per title okay
so or or sorry per rating so we will
drag the rating column
and
we will
count of titles
and
unique count of titles and unique count
of show IDs
okay
one is bar and one is line
okay
so this is a report which shows rating
wise titles and the show IDs
so in the tooltip you can see the
listing count of Titus and show ID per
rating
okay so let's call it
shows per rating
now let's create another sheet
call it as
shows
by caste
so in this
what we're going to do is first drag the
cast column on the rows section you have
name all of all the cast and then we
drag the
show ID on the column section and put a
County
and sort it okay
you can remove the null cost and this is
your
sorted order and on the labels section
you can say show Mark labels and you
will see the count that anupam care has
done the maximum Shahrukh Khan
Shah so this is the details on this
sorted order that who has done how many
shows okay
then next is
shows by director similar to shows by
cast
drag
director into rows
or differently if you want to prepare
into columns and then count off
show ID
okay sort it
and you can actually filter out the null
director value
and this is the account
put the label
so you can see Jan's Twitter has the
maximum shows
okay
then create another report
shows by category
now similarly drag the listed in
in the rows and show ID count
remove the null category
and sort
labels show Mark labels so International
movies are the highest category dramas
the next comedy International TV shows
this way
you have your category
now let's create a dashboard in which we
want to bring combine all these reports
and
take a common view so first let's drag
listed in by country
then
shows by director
also please let's set the size as
automatic
then let's drag shows by category
and shows by cast
now these four reports are on a single
dashboard we will link them to each
other so go to worksheet actions
add action
filter
select dashboard one
only select shows by category here
and in Target dashboard one
except shows by category keep everything
else
and in the source sheet just select
click select
click ok
okay now whatever category you will
select over here
that related category data will
automatically be shown in other reports
like see International movies across the
globe across countries directors of only
International movies who has done the
maximum
Johnny Tow and shows by cast right that
who has done the maximum International
movies or dramas
or comedies
travel has a maximum number of comedies
and then if you see the comedy movies uh
you know these are the count of comedy
movies released across the countries and
the who is the director
another a very interesting report which
you can prepare is that for example you
want to check in which country maximum
duration of
uh your
maximum duration of
movies have been released so
first let's create uh to measure
remove this
okay
so if you see
maximum duration of the movies or the
entire Netflix content is maximum United
States then in India these many minutes
next is United Kingdom and you can also
change the colors
whatever you feel is as per your
standards or as per the convention you
can change the color combination
so there are multiple ways you can
generate reports and uh hope you have
understood how you can leverage such a
data to create your reports
hello and welcome to data analytics
interview questions
that's
www.simplylearn.com get certified get
ahead
today we're going to jump into some
common questions you might see on numpy
arrays and pandas data frames in the
python along with some Excel Tableau and
SQL
let's start with our first question what
is the difference between Data Mining
and data profiling
it's real important to note that data
mining is a process of finding relevant
information which has not been found
before it is a way in which raw data is
turned into valuable information you can
think of this as anything from the cells
stats and from their SQL Server all the
way to web scraping and Census Bureau
information where the heck do you mine
it from where do you get all this data
and information
then we look at data profiling is
usually done to assess a data set for
its uniqueness consistency and logic it
cannot identify incorrect or inaccurate
data values so if somebody has a
statistical analysis on one side and
they're doing their you might in the
wrong data to then program your data
setup so you got to be aware that when
you're talking about data mining you
need to look at the Integrity of what
you're bringing in where it's coming
from data profiling is looking at it and
saying hey how is this going to work
what's the logic what's the consistency
is it related to what I'm working with
find the term data wrangling and data
analytics data wrangling is a process of
cleaning structuring and enriching the
raw data into a desired usable format
for better decision making
and you can see a nice chart here with
our Discover it we structure the data
how we want it we clean it up get rid of
all those null values we enrich it so we
might take and reformat some of the
settings instead of having five
different terms for height of somebody
you know in American English or whatever
clean some of that up and we might do a
calculation and bring some of them
together
and validate I was just talking about
that in the last one need to validate
your data make sure you have a solid
data source and then of course it goes
into the analysis very important to
notice here in data wrangling 80 percent
of data analytics is usually in this
whole part of wrangling the data getting
it to fit correctly and don't confuse
that with data cooking which is actually
when you're going into neural networks
cooking the data so it's all between
zero and one values
what are common problems that data
analysts encounter during analysis
handling duplicate and missing values
collecting the meaningful write data the
right time making data secure and
dealing with compliance issues handling
data purging and storage problems again
we're talking about data wrangling here
eighty percent of most jobs are in
wrangling that data and getting it in
the right format and making sure it's
good data to use
number four what are the various steps
involved in any analytics project
understand the problem we may spend 80
percent doing wrangling but you better
be ready to understand the problem
because if you can't you're going to
spend all your time in the wrong
direction this is probably uh the most
important part of the process everything
after it falls in and then you can come
back to it
two data collection data cleaning number
three four data exploration analysis and
five interpret the results
number five is a close second for being
the most important if you can't
interpret what you bring to the table to
your clients you're in trouble
so when this question comes up you
probably want to focus on those two
noting that the rest of it does eighty
percent of the work is in two three and
four well one and five are the most
important parts
which technical tools have you used for
analysis and presentation purposes
being a data analyst you are expected to
have knowledge of the below tools for
analysis and presentation purposes
there's a wide variety out there SQL
Server MySQL you have your Excel your
SPSS which is the IBM platform tab blue
python you have all these different
Tools in here now certainly a lot of
jobs are going to be narrowed in on just
a few of these tools like you're not
going to have a Microsoft SQL Server
MySQL server but you better understand
how to do basic SQL polls and also
understanding Excel and how the
different formats from column and how to
get those set up
number six what are the best practices
for data cleaning this is really
important to remember to go through this
in detail these always come up because
80 percent of most data analysis is in
cleaning the data make a data cleaning
plan by understanding where the common
errors take place and keep
Communications open identify and remove
duplicates before working with the data
this will lead to an effective data
analysis process focus on the accuracy
of the data maintain the value types of
data provide mandatory constraints and
set Cross Field validation
standardize the data at the point of
entry so it is less chaotic and you will
be able to ensure that all the
information is standardized leading to
fewer errors on Entry
number seven how can you handle missing
values in a data set list wise deletion
in listwise deletion method entire
record is excluded from analysis if any
single value is missing sometimes we're
talking about records remember this
could be a single line in a database so
if you have your SQL comes back and you
have 15 different columns every one of
those has a missing value you might just
drop it just to make it easy because you
already have enough data to do the
processing average imputation use the
average value of the responses from the
other participants to fill in the
missing value this is really useful and
they'll ask you why these are useful I
guarantee it if you have a whole group
of data that's collected and it doesn't
have that information in it at that
point you might average it in there
regression substitution you can use
multiple regression analysis to estimate
a missing value that kind of goes with
the average imputation input regression
model means you're just going to get
you're going to actually generate
generate a prediction as to what you
think that value should be for those
people based on the ones you do have
multiple imputation so we talk about
multiple inputs it creates plausible
values based on the correlations for the
missing data and then average the
simulated data sets by incorporating
random errors in your predictions
what do you understand by the term
normal distribution and the second you
hear the word normal distribution should
be you think in a bell curve like we see
here normal distribution is a type of
continuous probability distribution that
is symmetric about the mean and in the
graph normal distribution will appear as
a bell curve the mean median and mode
are equal that's a quick way to know if
you have normal distribution is you can
compute mean median and mode all of them
are located at the center of the
distribution 68 of the data lies within
one standard deviation of the mean 95 of
the data Falls within two standard
deviations of the mean 99.7 of the data
lies within three standard deviations of
the mean
what is time series analysis
time series analysis is a statistical
method that deals with ordered sequence
of values of a variable of equally
spaced time intervals time series data
on a covid-19 cases and you can see
we're looking at by day so our space is
of days and each day goes by if we take
a graph it you continue the time series
graph always looks really nice if you
have like two different in this case we
have what the United States going over
there I'd have to look at the other
setup in there but they picked a couple
different countries and it is it's time
sensitive you know the next result is
based on what the last one was Cove is
an excellent example of this anytime you
do any word analytics where you're
figuring out what someone's saying what
they said before makes a huge difference
is what they're going to say next
another form of Time series analysis
10. how is joining different from
blending in tableau so now we're going
to jump into the Tableau package data
joining data joining can only be done
when the data comes from the same Source
combining two tables from the same
database or two or more worksheets from
the same Excel file all the combined
tables or sheets contains common set of
dimensions and measures
data blending data blending is used when
the data is from two or more different
sources combining the Oracle table with
the SQL server or two sheets from Excel
or combining the Excel sheet and Oracle
table in data blending each data source
contains its own set of dimensions and
measures
how is overfitting different from
underfitting
always a good one overfitting probably
the biggest danger in data analytics
today is overfitting model trains from
the data too well using the training set
the performance drops significantly over
the test set happens when the model
learns the noise and random fluctuations
in the training data set in detail
and again the performance drops way
below what the test set has
the model neither trains the data well
nor can generalize to new data performs
poorly both on train and the test set
happens when there is less data to build
and an accurate model and also when we
try to build a linear model with a
non-linear data
in Microsoft Excel a numeric value can
be treated as a text value if it
proceeds with an apostrophe definitely
not an exclamation if you're used to
programming in Python you'll look for
that hash code and not an Amber sign
and we can see here if you enter the
value 10 into a fill but you put the
apostrophe in front of it it will read
that as a text not as a number
what is the difference between count
count a count blank and count if in
Excel
we can see here when we run in just
count D1 through D 23 we get 19 and
you'll notice that there is 19 numbers
coming down here
and so it doesn't count the cost of each
which is a top bracket it doesn't count
the blank spaces either with the
straight count
when you do a count a you'll get the
answer is 20. so now when you do count a
it counts all of them even the title
cost of each
when you do count blank we'll get three
why there's three blank fields
and finally the count if if we do count
F of e 1 to e23 is greater than 10
there's 11 values in there basic
counting of whatever is in your column
pretty solid on the table there
explain how vlookup Works in Excel
vlookup is used when you need to find
things in a table or a range by row
the syntax has four different parts to
it we have our lookup value that's a
value you want to look up we have our
table array
the range where the lookup value is
located
column index number the column number
and range that contains the return value
and the range lookup specify true if you
want an approximate match or false if
you want an exact match of the return
value
so here we see vlookup F3 A2 to C8 2
comma zero for prints now they don't
show the F3 F3 is the actual cell that
prints is in that's what we're looking
at is F3 so there's your prints he pulls
in from F3 A2 to C8 is the the data
we're looking into and then number two
is a column in that data so in this case
we're looking for uh age and we count
name as one age is two keep in mind this
is Excel versus a lot of your Python and
programming languages where you start at
zero in Excel we always look at the
cells as one two three so two represents
the h
0 is false for having an exact match up
versus one we don't actually need to
worry about that too much in this 0 or 1
would work with this example and you can
see with the Angela lookup again her
name would be in the F column number
four that's what the F4 stands for is
where they pulled Angela from and then
you have A1 to C8 and then we're looking
at number three so number three is
height name being one age two and then
height three and you'll see here pulls
in her height 5.8
so we're going to run jump over to SQL
how do you subset or filter data in SQL
to subset or filter data in SQL we use
where and having clause and you can see
we have a nice table on the left where
we have the title the director the year
the duration we want to filter the table
for movies that were directed by Brad
Bird why just because we want to know
who what Brad Bird did so we're going to
do select star you should know that the
star refers to all in this case we're
what are we going to return we're going
to return all title directory year and
duration that's what you mean by all
movies movies being our table where
director equals Brad Bird and you can
see he comes back and he did the
incredible on Ratatouille
two subsetter filter data SQL we can
also use the where and having Clause so
we're going to take a closer look at the
different ways we can filter here filter
the table for directors whose movies
have an average duration greater than
115 minutes
so there's a lot of really cool things
into this SQL query and these SQL
queries can get pretty crazy select
director sum duration as total duration
average duration as average duration
from movies Group by director having
average duration greater than 115.
uh so again what are we going to return
we're going to return whenever we put in
our select which in this case is
director we're going to have total
duration and that's going to be the sum
of the duration we're going to have the
average duration average underscore
duration which is going to be the
average duration on there and then we of
course go ahead and group by director
and we want to make sure we group them
by anyone that has an having an average
duration greater than 115. these SQL
queries are so important I don't know
how many times you the SQL comes up and
there's so many different other
languages not just MySQL and not
Microsoft SQL but in addition to that
where the SQL language comes in
especially with Hadoop in other areas so
you really should know your basic SQL
doesn't hurt to get that little cheat
sheet and glance over it and double
check some of the different features in
SQL
what is the difference between where and
having clause in SQL where where Clause
works on row data in where Clause a
filter occurs before any groupings are
made aggregate Junctions cannot be used
so the syntax is select your columns
from table where what the condition is
having Clause works on aggregated data
having is used to filter values from a
group aggregate functions can be used in
the syntaxes select column names from
table where the condition is grouped by
having a condition ordered by column
names
what is the correct Syntax for reshape
function in numpy so we're going to jump
to the numpy array program
and what you come up with is you have in
this case it'd be numpy dot reshape a
lot of times you do an import numpy as
NP
reshape and then your array and the new
shape
and you can see here as we as the actual
example comes in the reshape is a and
we're going to reshape it in two comma
five setups and you can see the printout
in there that prints in two rows with
five values in each one
what are the different ways to create a
data frame in pandas
well we can do it by initializing a list
so you can Port your pandas as PD very
common data equals Tom 30 jerry20 Angela
35 we'll go ahead and create the data
frame and we'll say uh pd.dataframe is
the data columns equals name and age so
you can designate your columns you can
also it is a index in there you should
always remember that the index in this
case maybe you want the index instead of
one two to be the date they signed up or
who knows you know whatever and you can
see right there it just generates a nice
pandas data frame with Tom Jerry and
Angela
another way you can initialize a data
frame is from dictionary you can see
here we have a dictionary where the date
equals name Tom Jerry Angela Mary ages
20 21 1918 and if we do a DF PD dot data
frame on the data you'll get a nice the
same kind of setup you get your name age
Tom Jerry Angela and Mary
write the python code to create an
employee's data frame from the
emp.csv file and display the head and
summary of it
to create a data frame in Python you
need to import the pandas library and
use the read CSV function to load the
CSV file
and here you can see we have import
pandas is PD employees or the data frame
employees equals pd.read CSV and then
you have your path to that CSV file
there's a number of settings in the read
CSV where you can tell it how many rows
are the top index you can set the
columns in there
you can have skip rows there's all kinds
of things you can also go in there and
double check with your read CSV but the
most basic one is just to read a basic
CSV
how will you select the department and
age columns from an employee's data
frame
so we have import pandas is PD you can
see we have created our data we will go
ahead and create our employees PD data
frame on the left
and then on the right to select
department and age from the data frame
we just do employees and you put the
brackets around it now if you're just
doing one column you could do just
department but if you're doing multiple
columns you've got to have those in a
second set of brackets it's got to be a
reference with a list within the
reference
what is the criteria to say whether a
developed data model is good or not a
good model should be intuitive
insightful and self-explanatory follow
the old saying kiss keep it simple
the model develops should be able to
easily consumed by the clients for
actionable and profitable results
so if they can't read it what good is it
a good model should easily adapt to
changes according to business
requirements we live in quite a dynamic
world nowadays so it's pretty
self-evident and if the data gets
updated the model should be able to
scale accordingly to the new data so you
have a nice data pipeline going where
when something when you get new data
coming in you don't have to go and
rewrite the whole code
what is the significance of exploratory
data analysis
exploratory data analysis is an
important step in any data analysis
process exploratory data analysis Eda
helps to understand the data better it
helps you obtain confidence in your data
to a point where you're ready to engage
a machine learning algorithm it allows
you to refine your selection of feature
variables that will be used later for
model building you can discover hidden
Trends and insights from the data
how do you treat outliers in a data set
an outlier is a data point that is
distant from other similar points they
may be due to variability in the
measurement or may indicate experimental
errors
uh one you can drop the outlier records
pretty straightforward you can cap your
outliers data so it doesn't go past a
certain value you can assign it a new
value you can also try a new
transformation to see if those outliers
come in if you transform it slightly
differently
explain descriptive predictive and
prescriptive analytics descriptive
provides insights into the past to
answer what has happened uses data
aggregation and data mining techniques
examples an ice cream company can
analyze how much ice cream was sold
which flavors were sold and whether more
or less ice cream was sold than before
predictive understands the future to the
answer what could happen use the
statistical models and forecasting
techniques
example predicts a sale of ice creams
during the summer spring and rainy days
so this is always interesting because
you have your descriptive which comes in
and your businesses are always looking
to know what happened hey did we have
good sales last quarter what are we
expecting next quarter in the sales and
we have a huge jump when we do uh
prescriptive suggest various courses of
action to answer what should you do uses
optimization and simulation algorithms
to advise possible outcomes example
lower prices to increase sell of ice
creams produce more or less quantities
of certain flavor of ice cream if we can
certainly today's world with the covid
virus because we had that on our earlier
graph you could see that as a
descriptive what's happened how many
people have been infected how many
people have died in an area predictive
where do we predict that to go
do we see it going to get worse is it
going to get better what do we predict
that we're going to need in hospital
beds and pre-scriptive what can we
change in our setup to have a better
outcome maybe if we did more social
distancing if we tracked the virus
how do these different things directly
affect the end and can we create a
better ending by changing some
underlying criteria
what are the different types of sampling
techniques used by data analysis
sampling is a statistical method to
select a subset of data from an entire
data set population to estimate the
characteristics of the whole population
one we can do a simple random sampling
so we can just pick out 500 random
people in the United States to sample
them
they call it a population in regular
data we also call that a population just
because that's where it came from was
mainly from doing census
systematic sampling
cluster sampling
dratified sampling
and judgment or purposive sampling
then we have our systematic sampling
that's where you're doing like using one
five ten fifteen twenty use a very
systematic approach for pulling samples
from the setup cluster sampling that's
where we look at it and we say hey some
of these things just naturally group
together if you were talking about
population which is a really nice way of
looking at this cluster sampling would
be maybe by a zip code we're going to do
everybody's zip code and just naturally
cluster it that way
stratified sampling would be more
looking for shared things the group has
like income so if you're studying
something on poverty you might look at
their naturally group People based on
income to begin with and then study
those individuals in the income to find
out what kind of traits they have
and then judgmental that is where the
researcher very carefully selects each
member of their own group so it's very
much based on their personal knowledge
jumping on the 26 what are the different
types of hypothesis testing
hypothesis testing is a procedure used
by estheticians and scientists to accept
or reject statistical hypothesis we
start with a hypothesis testing we have
null hypothesis and alternative
hypothesis
on the null hypothesis it states that
there is no relation between the
predictor and the outcome variables in
the population it is denoted by H naught
example there is no association between
patients BMI and diabetes
alternative hypothesis it states there
is some relation between the predictor
and outcome variables in the population
it is denoted by H1 example there could
be an association between patients BMI
and diabetes
and that's the body mass index if you
didn't catch the BMI and you're not in
medical
describe univariate bivariate and
multivariate Analysis
a unit variate analysis it is the
simplest form of data analysis where the
data being analyzed contains only one
variable an example of studying the
heights of players in the NBA because
it's so simple it can be described using
Central Tendencies dispersion quartiles
bar charts histograms pie charts
frequency distribution tables
the bivariate analysis it involves
analysis of two variables to find causes
relationships and correlations between
the variables example analyzing sale of
ice creams based on the temperature
outside
bivariate analysis can be explained
using correlation coefficients linear
regression logistic regression Scatter
Plots and box plots
and multivariate Analysis it involves
analysis of three or more variables to
understand the relationship of each
variable with the other variables
example analyzing Revenue based on
expenditure so if we have our TV ads we
have our newspaper ads our social media
ads and a revenue we can now compare all
those together
the multiverted analysis can be
performed using multiple regression
factor analysis classification and
regression trees cluster analysis
principle component analysis clustering
bar chart dual axis chart
what function would you use to get the
current date and time in Excel
in Excel you can use the today and now
function to get the current date and
time and you can see down here the two
examples are just equals today or equals
now
using the sumifs function in Excel find
the total quantity sold by cells
Representatives whose name start with a
and the cost of each item they have sold
is greater than 10.
and you can see here on the left we have
our actual table
and then we want to go ahead and sumifs
so we want the E2 through E20 B2 through
B20 greater than 10. and this basically
is just saying hey we're going to take
everything in the E column
and we're going to sum it up but only
those objects where the D column is
greater than 10 that's what that means
there
is the below query correct if not how
will you Rectify it
select customer ID year order date as
order Year from order where order year
is greater than or equal to 2016.
and hopefully you caught it right there
it's in the devils in the details we
can't not use the Alias name while
filtering data using the where Clause so
the correct format is all the same
except for where it says where the year
order date is greater than or equal to
16 versus using the order year which we
assign under the select setup
how are union intersect and accept used
in SQL the union operator is used to
combine the results of two or more
select statements
and you can see here we have select star
from region one and we're going to make
a union with select star from region two
and it basically takes both these SQL
tables and combines them to form a full
new table on there so that's your union
as we bring everything together
we look at the intersect operator
Returns the common records that are the
result of the two or more select
statements
so you can see here we select star from
region one intersect select star from
region two
and we come up with only those records
that are shared that have the same data
in them
and hopefully you jumped ahead to the
accept the accept operator returns The
Uncommon records that are the result of
two or more select statements so these
are the two records or the records that
are not shared between the two databases
using the product price table write an
SQL query to find the record with the
fourth highest market price
so here we have a little bit of a brain
teaser uh they're always fun and the
first thing we want to do is we're going
to go ahead and I'm going to if you look
at the script on the left we really want
the fourth one down so we're going to
select the top four from product price
but we're going to order it by market
price descending SP order by market
price ascending
so we do is we take the top four of the
market price ascending and that's going
to give us the four greatest values
and then we're going to reverse that
order and do descending and we're going
to take the top one of that which is
going to give us the lowest value which
would be the fourth greatest one in the
list
from the product price table find the
total and average market price for each
currency where the average market price
is greater than 100 and currency is in
the INR or the AUD
so INR or AUD India Rupal or Australia
dollar
you can see over here the SQL query if
you had trouble putting this together
you might actually do some of it in
reverse
and you can see right here where the
average market price is greater than 50.
remember we use having not where at the
end because it's part of the group so
Group by currency because we want those
two currencies and we want the currency
India the INR or the AUD
and as you keep going backwards we're
actually going to be selecting the
currency the sum of the market price as
total price and the average Marketplace
as average price so there's our select
it's going to come from the product
price which is just our table over there
and then we have where our currency is
in uh and like I said you can put it
together however you want but hopefully
you got to the end there
so this question will test your
knowledge in Tableau exploring the
different features of Tableau and
creating a suitable graph to solve a
business problem
and of course tablue is very visual in
its use so it's very hard to test it
without actually just getting your hands
on and if you can't visualize some of
this and how to do it then you should go
back and refresh yourself
using the sample Superstore data set
creative view to analyze the sales
profits and quantities sold across
different subcategories of items present
under each category so the first step is
to go ahead and load the sample
Superstore data set
so make sure you know how to load the
sample the superstore data set that's
underneath either the connect button in
the upper left or the Tableau icon up
there and be able to pull in the data
set and then once you've done that you
just drag the category and subcategory
on rows and salaries onto columns it
will result in a horizontal bar chart
so in this one we're just going to drag
profit onto color and quantity onto
label sort the sales axes in descending
order of sum and cells within each sub
category
and if you're at home doing this you'll
see the chairs in their Furniture
category have the highest sales and
profit while tables had the lowest
profit for office supplies subcategory
binders made the highest profit even
though storage had the highest sales
under technology category copiers made
the highest profit though it was the
least amount of sales
let's work to create a dual axis chart
in Tableau to present cells and profits
across different years using sample
Superstore data set
load the orders sheet from the sample
Superstore data set
drag the ordered data field from the
dimensions onto columns and convert it
into continuous months
drag cells onto rows and profits to the
right corner of the view until you see a
light green rectangle one of those
things if you haven't done this Hands-On
you don't know what you're doing you're
right into a buying so you can be just
kind of dropping it and wondering what
happened synchronize the right axes by
right-clicking on the profit axes
and then let's finalize it by going
under the marks card change some cells
to bar and some profit to line and
adjust the size
and then we have a nice display that we
can either print out or save and send
off to the shareholders
let's go and do one more Tableau design
a view in Tableau to show Statewide
cells and profits using the sample
Superstore data set
and here you go ahead and drag the
country field onto the view section and
expand it to see the states drag the
states field onto size and profit onto
color
increase the size of the Bubbles at a
border and a Halo color States like
Washington California and New York have
the highest sales and profits while
Texas Pennsylvania and Ohio have a good
amount of sales but the least amount of
profits
we'll go ahead and Skip back to python
numpy Suppose there is an array number
equals NP or numpy if you're using numpy
depending on how you set it up dot array
and we just have one to nine broken up
into three groups extract the value 8
using 2D indexing so you can see on the
left we have our import numpy is in p
number equals our NP array if we print
the number we have one two three four
five six seven eight nine
since the value 8 is present in the
second row and First Column we use the
same index position and pass it to the
array and you just have number two comma
one and you get eight and remember we're
in Python so you start at zero not one
like you do in Excel
always kiss me if I'm working between
Excel and python where I just kind of
flip and usually it's the Excel that
messes up so I do a lot more programming
Suppose there is an array that has value
0 1 all the way up to nine how will you
display the following values from the
array one three five seven nine
uh so first of all we go ahead and
create the array NP dot a range of 10
which goes from 0 to 9 because there's
ten numbers in it but we don't include
the 10. we print it out the first thing
you want to do is what's going on here
with one three five seven nine well if
we divide by two there's going to be a
remainder equal to one and then from
python we remember that if you use the
percentage sign you get the remainder on
there so the remainder is 1 and then you
have the your numpy array and then we
just want to do a logical statement of
all values that have a remainder of 1
and that generates our nice one three
five seven nine
there are two arrays A and B stack the
arrays A and B horizontally boy these
horizontal vertical questions will get
you every time
and in numpy we go ahead and we've
created two different arrays over here A
and B the first one is your concatenate
NP dot concatenate
A and B on X's equal one
that is the same as H stack and in the
back end they're still identical they
run the same that's all each stack is a
concatenate and axes equals one
how can you add a column to a panda's
data frame
suppose there's an imp data frame that
has information about few employees
let's add address column to that data
frame and you can see on the left we
have our basic data frame you should
know your data frames very well
basically looks like an Excel
spreadsheet as you come over here it's
really simple you just do DF of address
equals the address once you've assigned
values to the address
using the below given data create a
pivot table to find the total cells made
by each cells represented for each item
display the cells as a percentage of the
grand total
so we're back in Tableau select the
entire table range click on insert Tab
and choose pivot table
select the table range and the worksheet
where you want to place the pivot table
it'll return a pivot table where you can
analyze your data
drag the cell total on the values in
sales rep and item onto row labels it'll
give the sum of the cells made by each
representative for each item they have
sold
and finally right click on sum of cell
total and expand show values as to
select percentage of grand total
uh real important just understand what a
pivot table is we're just pivoting it
from rows and columns and switching this
direction on there
and finally we have our final pivot
table and you can see the values rules
and sum of total sale
so we're going to go ahead and take a
product table this is off of an SQL so
we're going to do some SQL here
and we're going to use the product and
sales order detail table find the
products that have total units sold
greater than 1.5 million and here's our
sales order detail table so we have a
product table and a sales order detail
table two separate tables in the
database
and we're going to do is put together
the SQL query we want to select PP name
sum sod unit price as cells and then we
have our p p dot product ID from
production product as PP inner join
sales dot sales order detail as sod on
PP product ID equals sod.product ID
Group by pp.name comma pp.product ID
having a sum of sod.uniprice greater
than the 150 million there that's a
mouthful and again these SQL queries
they start looking really crazy until
you just break them apart and do them
step by step
and what we're looking for is the inner
join and how did you do the group by
this really when they know how do you do
this inner join this comes up so much in
SQL uh how do you pull in the ID from
one chart and the information from
another chart and the sum totals on that
chart
how do you write a stored procedure in
SQL let's create a stored procedure to
find the sum the squares are the first n
natural numbers so here we have our
formula n times n plus 1 times 2N plus
one over six and you can see from the
command prompt or the setup you have
which depending on what your login is
the command is create procedure Square
sum 1.
declare a variable at n of integer as
begin and then we're going to declare
the sum of integer set sum equals n
times n plus 1 plus 2 times n plus 1
over 6.
of course we can go ahead and print
those out print First cast
member sign in or our variable as a
variable character 20 natural numbers
print the sum of the square is cast the
at sum as a variable character 40 and
then we do the output display the sum of
the square for first four natural
numbers we have execute Square sum 1 and
then we're going to put in 4 and you can
see here where it brings up the first
four natural numbers sum of square is
30.
write a store procedure to find the
total even number between two user given
numbers
couple things to note here first we go
and create our procedure you have your
two different variables the N1 N2
and we go ahead and begin we're going to
declare our variable count as an integer
we're going to set count equal to zero
and then we have while n is less than N2
we're going to begin and if N1 remainder
2 equals 0 so we're going to divide it
by two even number begin we're going to
set the count equal to count plus one
we're going to print even number plus
cast n as a variable character 10 for
printing count is plus cast variable
count as variable character 10 end else
print odd number plus cast variable
number one as variable character ten and
then we go ahead and set the increment
our variable one up one so it'll go from
in one all the way to N2 and I'll print
the total number of even numbers
and you can see here we went ahead and
executed it we're going to count the
even numbers between 30 and 45 and you
can just see it goes all the way down to
eight
what is the difference between tree maps
and heat maps in tableau
now if you've worked in Python other
programmings you should automatically
know what a heat map is but a tree map
are used to display data in nested
rectangles use Dimensions to define the
structure of the tree map and measure to
define the size or color of individual
rectangles
tree maps are a relatively simple data
visualization that can provide Insight
in a visually attractive format
and again you can see the squares over
here this is our tree map over here with
the each block also has this information
inside of its different blocks
a heat map helps to visualize measures
against Dimensions with the help of
colors and size to compare one or more
dimensions and up to two measures the
layout is similar to a text table with
variations in values encoded as colors
in heat map you can quickly see a wide
array of information
and in this one you can see they use the
colors to denote one thing and the size
of the little square to denote something
else
a lot of times you can even graph this
into a three-dimensional graph with
other data so it pops out but again a
heat map is the color and the size
using the sample Superstore data set
display the top five and bottom five
customers based on their profit so you
start by dragging the customer name
field onto rows and profit on columns
right click on the customer name column
to create a set
give a name to the set and select top
tab to choose top 5 customers by some
profit similarly create a set for the
bottom five customers by some profit
select both the sets right click to
create a combined set give a name to the
set and choose all members in both sets
and then you can drag top and bottom
customer sets onto the filters and
profit field onto color to get the
desired results
as we get down to the end of our list
we're going to try to keep you on your
toes we're going to skip back to numpy
how to print four random integers
between 1 and 15 using numpy to Generate
random numbers using numpy we use a
random random integer function and you
see here we did the import numpy as in p
random Arrangement equals np.random dot
random integer 1 through 15 of 4.
from the below data frame I'm going to
jump again on you now we're into pandas
how will you find the unique values for
each column and subset the data for age
less than 35 and height greater than 6.
to find the unique values and the number
of unique elements use the unique and
the in unique function
you can see here we just did DF Heights
we're selecting just the height column
and we want to look for The Unique that
returns an array where in unique if we
do that on the height or the age we'll
return just the number of unique values
and then we can do a subset the data for
ages less than 35 and height greater
than 6. so if we look over here we have
a new DF remember this is going to be
taking slices of our original data frame
it doesn't actually change the data
frame so our new DF equals the data
frame or DF the data frame where age is
less than 35
and the height is greater than 6.
and in case you're not using uh tab blue
which has a lot of its own uh different
mapping programs in there make sure you
understand how to use the basics of
matplot Library plot a sine graph using
numpy and matplot library in Python and
the way we did this is we went ahead and
generated an X we know our y equals NP
dot sine of x if you print out X you'll
see a whole value here our matplot
library Pi plot as PLT if you are
working in Jupiter notebook make sure
you understand the matplot library
inline that little percentage sign
matplot Library Online that prints it on
the page in the jupyter notebook the
newer version of jupyter notebook or
Jupiter Labs automatically does that for
you but I usually put it in there just
in case I end up on an older version
if you print y you can see here we have
our different y values and our different
X values
you simply put in plt.plot x y and do a
plot show
and before we go let's get one more in
we're going to do a pandas using the
below pandas data frame find the company
with the highest average cells derive
the summary statistics for the cells
column and transpose these statistics
that's a mouthful and just like any of
these computer problems break it apart
so first of all we're looking for the
highest average cells so group the
company column and use the mean function
to find the average cells you see here
by company equals df.group by company
once we've done that using the describe
function we can now go ahead and look at
the summary of statistics on here use
the describe function to find the
summary so by company those are groups
we're just going to describe them and
you could actually bundle those together
if you wanted and just do a Mullen one
line so here we go by company dot
describe you can see we have a nice
breakout always good to remember whether
you're using any of the packages whether
it's tab blue or pandas in python or
even r or some other package being able
to quick look and describe your data is
very important and then we can go ahead
and just do a basic apply a transpose
function over the describe method to
transpose the statistics
all we've done here is flip the index
with the column names but if you're
following the numbers a lot of times
it's easier to follow across one line or
maybe you want to average out the count
or it's all kinds of different reasons
to do that if you're an inspiring data
analyst looking for online training and
certifications from prestigious
universities and in collaboration with
leading experts then search no more
simply lens postgraduate program in data
analytics from Purdue University in
collaboration with IBM should be a right
choice for more details use the link
mentioned in the description box below
in today's data driven world and
Cutthroat business landscape the update
you extract meaningful insights from
vast amounts of information has become
Paramount this is where data analytics
come into play revolutionizing the way
organizations operate make decisions and
achieve their goals data analytics refer
to the process of collecting analyzing
and interpreting data to uncover
meaningful insights that can be used to
make informed decisions now with the
ever increasing amount of data available
there has never been a greater demand
for analysts who can extract insights
from data as the world becomes
increasingly Digital Data is being
generated at an unprecedented rate
creating an enormous opportunity for
businesses to leverage this data to gain
a competitive Advantage by leveraging
data analytics businesses can make
informed decisions better understanding
their customers and predict future
Trends whether you are passionate about
data interested in improving your job
prospects or simply want to gain a
competitive advantage in this industry
learning data analytics is a valuable
investment by understanding the
fundamentals of data analytics you can
gain the skills necessary to become a
successful data analyst and contribute
to the growth of your organization so
stay tuned with us till the end of this
video as we discuss some of the amazing
data analytics boot camps you can pursue
so fasten your seat belts as we embark
on a journey into the captivating world
of data analytics where information
transforms into insights and decision
becomes data driven but before we begin
if you're new to the channel and haven't
subscribed already consider hitting
subscribed to Simply learn to stay
updated with all the latest Technologies
and don't forget to hit that Bell icon
to never miss an update from us so
without any further Ado let's get
started firstly let us understand what
is data analytics now data analytics
involves the exploration and examination
of extensive data sets with the aim of
uncovering concealed patterns
identifying previously unseen Trends
establishing correlations between data
and extracting valuable insights that
will enable businesses to make
predictions Now by leveraging data
analytics businesses can enhance their
operational speed as well as efficiency
now comes the main question why we need
data analytics the first point is
improved decision making now data
analytics enables information making by
providing data driven insights it allows
businesses to understand patterns
relationships within data important
decision makers to make strategic
choices that will drive growth improve
efficiency and mitigate any sort of risk
next better customer understanding now
data analytics allows you to tailor
customer service according to their
needs it provides valuable insights into
customer Behavior preferences and needs
it helps businesses to segment customers
understand buying bad returns predict
future actions and personalized
marketing and customer experiences so
this allows for targeted product Service
delivery improved customer satisfaction
and loyalty as well next we have
efficient operations now data analytics
Fosters Innovation by encoding insights
identifying market trends and
recognizing emerging opportunities Now
by leveraging this data organizations
can develop Innovative products by
efficiently increasing their operation
existing offering and stay ahead of the
competition it enables businesses to
understand market dynamics monitor
competitors and make data driven static
decisions and finally performance
optimization data analytics helps
optimize performance by analyzing
metrics and key performance indicators
so it identifies areas for any sort of
improvements uncovers inefficiencies and
facilitates data bad changes to energy
productivity reduce cost and Achieve
operational excellence so these are some
of the main reasons why we need data
analytics moving forward let us
understand what exactly a data analyst
do now a data analyst is responsible for
collecting organizing analyzing and
interpreting data to uncover valuable
insights to make informed decisions
improve operations and write business
growth so let us now check in detail
process of what does a data analyst do
on a daily basis the first thing is data
collection now a data analyst gathers
data from various sources including
databases spreadsheets apis or any
external sources by ensuring data
quality and accuracy next we have data
training now data cleaning and
pre-processing is another important
factor where a data analyst has to be
consistent in now he has to clean and
transform the data to remove any sort of
Errors inconsistencies and missing
values and prepare the data for analysis
now once the data is clean they the
analyst will now do a proper data
modeling and Analysis of that data by
applying statistical methods and
analytical techniques to analyze data
and derive insights this may involve
hypothesis testing by using machine
learning techniques like regression
analysis clustering or other data
modeling techniques and finally
visualization and interpretation now
finally we have to present the analyze
data in a visually appealing and
understandable format by using charts
graphs and dashboards and also create
reports and summaries to communicate
findings to stakeholders by drawing
meaningful conclusions and insights from
the data analysis providing actionable
recommendations and solutions based on
the finding now let us discuss some of
the tools that you have to master for
data analytics now tools such as Excel
are programming language python Tableau
Q Link power bi SQL are some of the
important tools that you have to master
if you want to become proficient in data
analytics let us now talk about the
salary and job prospects now according
to Glassdoor the average salary of a
data analyst in USA is around 75 000 per
annum and it can go as high as thousand
dollars per annum and in India the
average salary of a data analyst is
around 9 LPA and for an experienced data
analyst it can be as high as 25 lakhs
per annum and it can also land you in
various job opportunities such as
business analyst data engineer data
scientist bi analyst data mining
specialist and much more
so all these Trends suggest that data
analytics skills are high in demand
across Industries offering a wide range
of job opportunities so let us go
through some of the boot camps offered
by simply learn which should provide
valuable skills numerous career
opportunities and ability to contribute
to data-driven success in order to excel
in the field of data analytics
now the first program we have on our
list is Caltech data analytics bootcamp
stay ahead of the data Revolution with
the Caltech data analytics bootcamp a
collaborative program offered by Caltech
designed specifically for working
professionals this bootcamp adopts an
applied learning approach providing
integrated labs and real world projects
tailored to the business environment
experience academic Excellence with
Caltech data analytics bootcamp while
also enjoying the benefits of Caltech
Campus Connect the program offers highly
Interactive Learning ensuring active
participation and engagement by
providing ample hands-on experience to
reinforce your skills this Caltech data
analytics bootcamp caters to individuals
from diverse backgrounds offering
substantial benefits to working
professionals gain essential skills such
as Excel data driven presentation
techniques data manipulation with SQL
data analysis using Python and data
visualization using W Additionally you
will learn data analysis with tools like
AWS and other industrial relevant
Technologies covering a comprehensive
curriculum the Caltech data analytics
boot camp builds into key Concepts
including data analytics with Excel
python-based data analytics database
management with SQL tablet for data
visualization and much more by choosing
this bootcamp you open doors to an
exciting career opportunities with
renowned companies such as Microsoft
Google Amazon IBM many more
this Caltech data analytics bootcamp has
successfully impart numerous aspirant
data analysts and their testimonials are
available on the course page accessible
through the link in the description box
below so a few aspect to become a data
analyst and acquired job ready skills
don't miss out on this intensive
training program join the cash Tech data
analytics bootcamp and Embark your
journey to excel in the world of data
analytics
now the next program on our list is
professional certificate course and data
analytics by IIT carpool are you ready
to unlock the secrets hidden within vast
modes of data and gain a Competitive
Edge in today's cultural business World
well simply learns data analyst course
delivered in collaboration with IID
kanpur will provide you with extensive
expertise in a booming field of data
analytics this data analytics courses
iot kanpur is designed to provide a deep
understanding of the principles
techniques and applications of data
analytics to develop a holistic skill
set to effectively analyze interpret and
extract actionable insights from data
now talking about this course it follows
a structured learning path that covers
various aspects of data analytics
including business analytics using Excel
SQL programming Foundation using python
data analytics with r language tablet
training and much more some of the key
features of this program include master
classes delivered by distinguished IIT
cardboard faculty Hands-On lab
experience to help you master 14 plus
tools and Frameworks and industrial
revenue projects designed to advance
your career trajectory and also simply
learns job assist helps you get noticed
by top hiring companies and can get you
hired by renowned companies like
Microsoft Google Amazon IBM Goldman
shags and many more so what are you
waiting for enroll now and embark on
this transformative Journey with IIT
kanpur's data analytics course and
unlock the boundless potential of data
now many aspiring data analysts have
gained benefits from this data analytics
program and some of them have shared
their feedback you can find their
testimonials by following the link to
the course page in the description box
below we have reached the end of this
session on the entire data analytics
tools full course should you need any
assistance PPT project code and other
resources used in this session please
let us know in the comment section below
and our team of experts will be happy to
help you as soon as possible until next
time thank you and keep learning stay
tuned for more from Simply learning
staying ahead in your career requires
continuous learning and upskilling
whether you're a student aiming to learn
today's top skills or a working
professional looking to advance your
career we've got you covered explore our
impressive catalog of certification
programs in Cutting Edge domains
including data science cloud computing
cyber security AI machine learning or
digital marketing designed in
collaboration with leading universities
and top corporations and delivered by
industry experts choose any of our
programs and set yourself on the path to
Career Success click the link in the
description to know more
hi there if you like this video
subscribe to the simply learn YouTube
channel and click here to watch similar
videos turn it up and get certified
click here
foreign